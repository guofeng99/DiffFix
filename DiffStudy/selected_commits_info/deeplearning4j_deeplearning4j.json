[
  {
    "oid": "819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3",
    "message": "Fixed #9050 regularization loss/override bug\n\nSigned-off-by: jljljl <jijiji95@bk.ru>",
    "date": "2021-04-02T16:40:57Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3",
    "details": {
      "sha": "2a5f16be64795683f1655397777c324d622f0ff8",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LayerValidation.java",
      "status": "modified",
      "additions": 81,
      "deletions": 12,
      "changes": 93,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java?ref=819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3",
      "patch": "@@ -26,6 +26,8 @@\n import org.deeplearning4j.nn.conf.dropout.IDropout;\n import org.deeplearning4j.nn.conf.layers.misc.FrozenLayer;\n import org.deeplearning4j.nn.conf.layers.recurrent.Bidirectional;\n+import org.nd4j.linalg.learning.regularization.L1Regularization;\n+import org.nd4j.linalg.learning.regularization.L2Regularization;\n import org.nd4j.linalg.learning.regularization.Regularization;\n \n import java.util.ArrayList;\n@@ -126,17 +128,84 @@ public static void generalValidation(String layerName, Layer layer, IDropout iDr\n         }\n     }\n \n-    private static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout, List<Regularization> regularization,\n-                                           List<Regularization> regularizationBias) {\n-        if (regularization != null && !regularization.isEmpty()) {\n-            bLayer.setRegularization(regularization);\n-        }\n-        if (regularizationBias != null && !regularizationBias.isEmpty()) {\n-            bLayer.setRegularizationBias(regularizationBias);\n-        }\n+\tprivate static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout,\n+\t\t\tList<Regularization> regularization, List<Regularization> regularizationBias) {\n+\t\tif (regularization != null && !regularization.isEmpty()) {\n \n-        if (bLayer.getIDropout() == null) {\n-            bLayer.setIDropout(iDropout);\n-        }\n-    }\n+\t\t\tfinal List<Regularization> bLayerRegs = bLayer.getRegularization();\n+\t\t\tif (bLayerRegs == null || bLayerRegs.isEmpty()) {\n+\n+\t\t\t\tbLayer.setRegularization(regularization);\n+\t\t\t} else {\n+\n+\t\t\t\tboolean hasL1 = false;\n+\t\t\t\tboolean hasL2 = false;\n+\t\t\t\tfinal List<Regularization> regContext = regularization;\n+\t\t\t\tfor (final Regularization reg : bLayerRegs) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\thasL1 = true;\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\thasL2 = true;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tfor (final Regularization reg : regContext) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL1)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL2)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else\n+\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\tif (regularizationBias != null && !regularizationBias.isEmpty()) {\n+\n+\t\t\tfinal List<Regularization> bLayerRegs = bLayer.getRegularizationBias();\n+\t\t\tif (bLayerRegs == null || bLayerRegs.isEmpty()) {\n+\n+\t\t\t\tbLayer.setRegularizationBias(regularizationBias);\n+\t\t\t} else {\n+\n+\t\t\t\tboolean hasL1 = false;\n+\t\t\t\tboolean hasL2 = false;\n+\t\t\t\tfinal List<Regularization> regContext = regularizationBias;\n+\t\t\t\tfor (final Regularization reg : bLayerRegs) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\thasL1 = true;\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\thasL2 = true;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tfor (final Regularization reg : regContext) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL1)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL2)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else\n+\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (bLayer.getIDropout() == null) {\n+\n+\t\t\tbLayer.setIDropout(iDropout);\n+\t\t}\n+\t}\n }",
      "parent_sha": "552c5d0b72e353e34d800e935c83ae442830bc42"
    }
  },
  {
    "oid": "ef1de6a4aad3672920d17bb02709d68d687e11f5",
    "message": "rcorbish #8617 (#8188)\n\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-09-01T04:17:36Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/ef1de6a4aad3672920d17bb02709d68d687e11f5",
    "details": {
      "sha": "3eade74e937abe04299ab173082e1d8de283535d",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-cuda/src/main/java/org/nd4j/linalg/jcublas/blas/JcublasLapack.java",
      "status": "modified",
      "additions": 17,
      "deletions": 13,
      "changes": 30,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/ef1de6a4aad3672920d17bb02709d68d687e11f5/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fblas%2FJcublasLapack.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/ef1de6a4aad3672920d17bb02709d68d687e11f5/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fblas%2FJcublasLapack.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fblas%2FJcublasLapack.java?ref=ef1de6a4aad3672920d17bb02709d68d687e11f5",
      "patch": "@@ -53,7 +53,8 @@\n  * JCublas lapack\n  *\n  * @author Adam Gibson\n- * @author Richard Corbishley\n+ * @author Richard Corbishley (signed)\n+ *\n  */\n @Slf4j\n public class JcublasLapack extends BaseLapack {\n@@ -70,7 +71,6 @@ public void sgetrf(int M, int N, INDArray A, INDArray IPIV, INDArray INFO) {\n         if (A.ordering() == 'c')\n             a = A.dup('f');\n \n-\n         if (Nd4j.getExecutioner() instanceof GridExecutioner)\n             ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();\n \n@@ -193,7 +193,7 @@ public void dgetrf(int M, int N, INDArray A, INDArray IPIV, INDArray INFO) {\n \n \n     //=========================\n-// Q R DECOMP\n+    // Q R DECOMP\n     @Override\n     public void sgeqrf(int M, int N, INDArray A, INDArray R, INDArray INFO) {\n         INDArray a = A;\n@@ -306,8 +306,8 @@ public void sgeqrf(int M, int N, INDArray A, INDArray R, INDArray INFO) {\n         if (r != null && r != R)\n             R.assign(r);\n \n-        log.info(\"A: {}\", A);\n-        if (R != null) log.info(\"R: {}\", R);\n+        log.debug(\"A: {}\", A);\n+        if (R != null) log.debug(\"R: {}\", R);\n     }\n \n     @Override\n@@ -419,16 +419,18 @@ public void dgeqrf(int M, int N, INDArray A, INDArray R, INDArray INFO) {\n         if (r != null && r != R)\n             R.assign(r);\n \n-        log.info(\"A: {}\", A);\n-        if (R != null) log.info(\"R: {}\", R);\n+        log.debug(\"A: {}\", A);\n+        if (R != null) log.debug(\"R: {}\", R);\n     }\n \n     //=========================\n // CHOLESKY DECOMP\n     @Override\n-    public void spotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n+    public void spotrf(byte _uplo, int N, INDArray A, INDArray INFO) {\n         INDArray a = A;\n \n+        int uplo = _uplo == 'L' ? CUBLAS_FILL_MODE_LOWER : CUBLAS_FILL_MODE_UPPER;\n+\n         if (A.dataType() != DataType.FLOAT)\n             log.warn(\"FLOAT potrf called for \" + A.dataType());\n \n@@ -489,7 +491,7 @@ public void spotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n         if (a != A)\n             A.assign(a);\n \n-        if (uplo == 'U') {\n+        if (uplo == CUBLAS_FILL_MODE_UPPER ) {\n             A.assign(A.transpose());\n             INDArrayIndex ix[] = new INDArrayIndex[2];\n             for (int i = 1; i < Math.min(A.rows(), A.columns()); i++) {\n@@ -506,13 +508,15 @@ public void spotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n             }\n         }\n \n-        log.info(\"A: {}\", A);\n+        log.debug(\"A: {}\", A);\n     }\n \n     @Override\n-    public void dpotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n+    public void dpotrf(byte _uplo, int N, INDArray A, INDArray INFO) {\n         INDArray a = A;\n \n+        int uplo = _uplo == 'L' ? CUBLAS_FILL_MODE_LOWER : CUBLAS_FILL_MODE_UPPER;\n+\n         if (A.dataType() != DataType.DOUBLE)\n             log.warn(\"DOUBLE potrf called for \" + A.dataType());\n \n@@ -573,7 +577,7 @@ public void dpotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n         if (a != A)\n             A.assign(a);\n \n-        if (uplo == 'U') {\n+        if (uplo == CUBLAS_FILL_MODE_UPPER ) {\n             A.assign(A.transpose());\n             INDArrayIndex ix[] = new INDArrayIndex[2];\n             for (int i = 1; i < Math.min(A.rows(), A.columns()); i++) {\n@@ -590,7 +594,7 @@ public void dpotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n             }\n         }\n \n-        log.info(\"A: {}\", A);\n+        log.debug(\"A: {}\", A);\n     }\n \n ",
      "parent_sha": "b393d3fdb1c1c677baedd528f3dfd6b195ef0478"
    }
  },
  {
    "oid": "4e41312fdf7fe613199543c038577695516a6cf1",
    "message": "Word2vec google new update (#9752)\n\n* Update ArrayCacheMemoryMgr.java\r\n\r\n* Log warning for invalid ops. Alows for more flexibility when importing models.\r\n\r\n* Add back fix for LSTM nullpointer\r\n\r\n* Fix debug logging for cache\r\n\r\n* Update ArrayCacheMemoryMgr.java\r\n\r\n* Update CharacterIterator.java",
    "date": "2022-08-12T14:17:45Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/4e41312fdf7fe613199543c038577695516a6cf1",
    "details": {
      "sha": "5b04c267a340d26fc4013dbdba875ecd083c24ba",
      "filename": "platform-tests/src/test/java/org/eclipse/deeplearning4j/integration/testcases/dl4j/misc/CharacterIterator.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/4e41312fdf7fe613199543c038577695516a6cf1/platform-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Feclipse%2Fdeeplearning4j%2Fintegration%2Ftestcases%2Fdl4j%2Fmisc%2FCharacterIterator.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/4e41312fdf7fe613199543c038577695516a6cf1/platform-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Feclipse%2Fdeeplearning4j%2Fintegration%2Ftestcases%2Fdl4j%2Fmisc%2FCharacterIterator.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/platform-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Feclipse%2Fdeeplearning4j%2Fintegration%2Ftestcases%2Fdl4j%2Fmisc%2FCharacterIterator.java?ref=4e41312fdf7fe613199543c038577695516a6cf1",
      "patch": "@@ -285,7 +285,7 @@ public static CharacterIterator getShakespeareIterator(int miniBatchSize, int se\n         //The Complete Works of William Shakespeare\n         //5.3MB file in UTF-8 Encoding, ~5.4 million characters\n         //https://www.gutenberg.org/ebooks/100\n-        String url = \"https://s3.amazonaws.com/dl4j-distribution/pg100.txt\";\n+        String url = \"https://raw.githubusercontent.com/KonduitAI/dl4j-test-resources/master/src/main/resources/word2vec/shakespeare.txt\";\n         String tempDir = System.getProperty(\"java.io.tmpdir\");\n         String fileLocation = tempDir + \"/Shakespeare.txt\";    //Storage location from downloaded file\n         File f = new File(fileLocation);",
      "parent_sha": "b238938a5e067fc019504c87d5261007fd596a28"
    }
  },
  {
    "oid": "d3d7e4cd13a0206607c011fa3d1f6e39dbdfacc2",
    "message": "Add fix for args referencing.",
    "date": "2021-08-16T10:47:52Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d3d7e4cd13a0206607c011fa3d1f6e39dbdfacc2",
    "details": {
      "sha": "1653f842f38b9090f02d82d86a4e6c90da66cee0",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/serde/FlatBuffersMapper.java",
      "status": "modified",
      "additions": 1,
      "deletions": 2,
      "changes": 3,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d3d7e4cd13a0206607c011fa3d1f6e39dbdfacc2/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d3d7e4cd13a0206607c011fa3d1f6e39dbdfacc2/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java?ref=d3d7e4cd13a0206607c011fa3d1f6e39dbdfacc2",
      "patch": "@@ -756,11 +756,10 @@ public static int asFlatNode(@NonNull SameDiff sameDiff, @NonNull DifferentialFu\n             }\n \n             if(dynamicCustomOp.numSArguments() > 0) {\n-                sArgs = new String[dynamicCustomOp.numSArguments()];\n+                sArgs = dynamicCustomOp.sArgs();\n                 extraStringIds = new int[dynamicCustomOp.numSArguments()];\n                 val sArgs2 = dynamicCustomOp.sArgs();\n                 for(int i = 0; i < sArgs2.length; i++) {\n-                    sArgs[i] = sArgs2[i];\n                     extraStringIds[i] = bufferBuilder.createString(sArgs[i]);\n                 }\n             }",
      "parent_sha": "33bbb381142e5a893ad8ce40b7217290a31e55c7"
    }
  },
  {
    "oid": "e2db3856828f44db82fd06e95c4b25301ad1cd5e",
    "message": "Fix link to AdaDelta paper (#7942)\n\nFix link to AdaDelta paper hosted on matthewzeiler.com\r\n\r\nSigned-off-by: Jxtps",
    "date": "2019-06-25T00:50:17Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/e2db3856828f44db82fd06e95c4b25301ad1cd5e",
    "details": {
      "sha": "c6cb4af4207dc0582be1eb50fdf4206a355d03ac",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/AdaDelta.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/e2db3856828f44db82fd06e95c4b25301ad1cd5e/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FAdaDelta.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/e2db3856828f44db82fd06e95c4b25301ad1cd5e/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FAdaDelta.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FAdaDelta.java?ref=e2db3856828f44db82fd06e95c4b25301ad1cd5e",
      "patch": "@@ -28,7 +28,7 @@\n import java.util.Map;\n \n /**\n- * http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf\n+ * https://www.matthewzeiler.com/mattzeiler/adadelta.pdf\n  * https://arxiv.org/pdf/1212.5701v1.pdf\n  * <p>\n  * Ada delta updater. More robust adagrad that keeps track of a moving window",
      "parent_sha": "d3a9e5b41d5c7ab02a9dc42156b1e9e451ed3a40"
    }
  },
  {
    "oid": "acf559425aef523628ff20b44eddf4f5691435b1",
    "message": "Small test fix (#216)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2019-09-02T06:44:57Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/acf559425aef523628ff20b44eddf4f5691435b1",
    "details": {
      "sha": "2cae12e6148921efc8bb522383cd84b59ee55884",
      "filename": "deeplearning4j/deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/test/java/org/deeplearning4j/spark/text/TextPipelineTest.java",
      "status": "modified",
      "additions": 3,
      "deletions": 4,
      "changes": 7,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/acf559425aef523628ff20b44eddf4f5691435b1/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/acf559425aef523628ff20b44eddf4f5691435b1/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java?ref=acf559425aef523628ff20b44eddf4f5691435b1",
      "patch": "@@ -25,7 +25,6 @@\n import org.deeplearning4j.models.word2vec.VocabWord;\n import org.deeplearning4j.models.word2vec.wordstore.VocabCache;\n import org.deeplearning4j.spark.models.embeddings.word2vec.FirstIterationFunction;\n-import org.deeplearning4j.spark.models.embeddings.word2vec.FirstIterationFunctionAdapter;\n import org.deeplearning4j.spark.models.embeddings.word2vec.MapToPairFunction;\n import org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec;\n import org.deeplearning4j.spark.text.functions.CountCumSum;\n@@ -470,11 +469,11 @@ public void testFirstIteration() throws Exception {\n \n         Iterator<Tuple2<List<VocabWord>, Long>> iterator = vocabWordListSentenceCumSumRDD.collect().iterator();\n \n-        FirstIterationFunctionAdapter firstIterationFunction = new FirstIterationFunctionAdapter(\n+        FirstIterationFunction firstIterationFunction = new FirstIterationFunction(\n                         word2vecVarMapBroadcast, expTableBroadcast, pipeline.getBroadCastVocabCache());\n \n-        Iterable<Map.Entry<VocabWord, INDArray>> ret = firstIterationFunction.call(iterator);\n-        assertTrue(ret.iterator().hasNext());\n+        Iterator<Map.Entry<VocabWord, INDArray>> ret = firstIterationFunction.call(iterator);\n+        assertTrue(ret.hasNext());\n     }\n \n     @Test",
      "parent_sha": "b3a134b608337a7eae11cf3ded5737e8e6508813"
    }
  },
  {
    "oid": "6d3b4509a7156d54603c4fdbf9c31bc65e20dfd3",
    "message": "Preload libgomp on arm architectures (#9897)",
    "date": "2023-02-01T10:04:50Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/6d3b4509a7156d54603c4fdbf9c31bc65e20dfd3",
    "details": {
      "sha": "5d189f273a5fe3a5151423309f3b6c2b37b8e1b3",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-native-preset/src/main/java/org/nd4j/presets/cpu/Nd4jCpuPresets.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/6d3b4509a7156d54603c4fdbf9c31bc65e20dfd3/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpresets%2Fcpu%2FNd4jCpuPresets.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/6d3b4509a7156d54603c4fdbf9c31bc65e20dfd3/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpresets%2Fcpu%2FNd4jCpuPresets.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpresets%2Fcpu%2FNd4jCpuPresets.java?ref=6d3b4509a7156d54603c4fdbf9c31bc65e20dfd3",
      "patch": "@@ -155,8 +155,8 @@\n                 compiler = {\"cpp11\", \"nowarnings\"},\n                 library = \"jnind4jcpu\", link = \"nd4jcpu\", preload = \"libnd4jcpu\"),\n                 @Platform(value = \"linux\", preload = \"gomp@.1\", preloadpath = {\"/lib64/\", \"/lib/\", \"/usr/lib64/\", \"/usr/lib/\"}),\n-                @Platform(value = \"linux-armhf\", preloadpath = {\"/usr/arm-linux-gnueabihf/lib/\", \"/usr/lib/arm-linux-gnueabihf/\"}),\n-                @Platform(value = \"linux-arm64\", preloadpath = {\"/usr/aarch64-linux-gnu/lib/\", \"/usr/lib/aarch64-linux-gnu/\"}),\n+                @Platform(value = \"linux-armhf\",preload = \"gomp@.1\", preloadpath = {\"/usr/arm-linux-gnueabihf/lib/\", \"/usr/lib/arm-linux-gnueabihf/\"}),\n+                @Platform(value = \"linux-arm64\",preload = \"gomp@.1\", preloadpath = {\"/usr/aarch64-linux-gnu/lib/\", \"/usr/lib/aarch64-linux-gnu/\"}),\n                 @Platform(value = \"linux-ppc64\", preloadpath = {\"/usr/powerpc64-linux-gnu/lib/\", \"/usr/powerpc64le-linux-gnu/lib/\", \"/usr/lib/powerpc64-linux-gnu/\", \"/usr/lib/powerpc64le-linux-gnu/\"}),\n                 @Platform(value = \"windows\", preload = {\"libwinpthread-1\", \"libgcc_s_seh-1\", \"libgomp-1\", \"libstdc++-6\", \"libnd4jcpu\"}),\n                 @Platform(extension = {\"-onednn\", \"-onednn-avx512\",\"-onednn-avx2\", \"-vednn\", \"-vednn-avx512\", \"-vednn-avx2\", \"-\",\"-avx2\",\"-avx512\", \"-compat\"}, resource={\"libnd4jcpu_device.vso\"})",
      "parent_sha": "00993d9293f4d4255d903411b2e1ef761ee8beff"
    }
  },
  {
    "oid": "d7c261ec40466a2af0fa12024f8aae1e98708172",
    "message": "added ability to run as test, and comments (#44)\n\nSigned-off-by: Ryan Nett <rnett@skymind.io>",
    "date": "2019-07-20T12:22:34Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d7c261ec40466a2af0fa12024f8aae1e98708172",
    "details": {
      "sha": "b0906f75e197e9aac629b04c3fed60a51a1d00b9",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/imports/listeners/ImportModelDebugger.java",
      "status": "modified",
      "additions": 13,
      "deletions": 2,
      "changes": 15,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d7c261ec40466a2af0fa12024f8aae1e98708172/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2Flisteners%2FImportModelDebugger.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d7c261ec40466a2af0fa12024f8aae1e98708172/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2Flisteners%2FImportModelDebugger.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2Flisteners%2FImportModelDebugger.java?ref=d7c261ec40466a2af0fa12024f8aae1e98708172",
      "patch": "@@ -1,6 +1,8 @@\n package org.nd4j.imports.listeners;\n \n import org.apache.commons.io.FileUtils;\n+import org.junit.Ignore;\n+import org.junit.Test;\n import org.nd4j.autodiff.samediff.SameDiff;\n import org.nd4j.imports.graphmapper.tf.TFGraphMapper;\n import org.nd4j.linalg.api.ndarray.INDArray;\n@@ -15,9 +17,12 @@\n /**\n  * Small utility for debugging Tensorflow import.\n  *\n+ * If you get a java.lang.NoSuchMethodError: java.nio.ByteBuffer.rewind() run with Java 9 or higher\n  *\n  * Quick and dirty Python code to generate test data: (this is slow and could no doubt be improved)\n  *\n+ * Also available in TFOpsTests via ZooEvaluation#write_intermediates\n+ *\n  * <pre>\n  * {@code\n  * import os\n@@ -71,10 +76,16 @@\n  */\n public class ImportModelDebugger {\n \n+    @Test\n+    @Ignore\n+    public void doTest(){\n+        main(new String[0]);\n+    }\n+\n     public static void main(String[] args) {\n \n-        File modelFile = new File(\"C:\\\\Temp\\\\TF_Graphs\\\\faster_rcnn_resnet101_coco_2018_01_28\\\\frozen_inference_graph.pb\");\n-        File rootDir = new File(\"C:\\\\Temp\\\\TF_Test\");\n+        File modelFile = new File(\"C:\\\\Temp\\\\TF_Graphs\\\\cifar10_gan_85\\\\tf_model.pb\");\n+        File rootDir = new File(\"C:\\\\Temp\\\\TF_Graphs\\\\cifar10_gan_85\");\n \n         SameDiff sd = TFGraphMapper.getInstance().importGraph(modelFile);\n ",
      "parent_sha": "5708fc087a5db85b5d36aac70833710f0413daf5"
    }
  },
  {
    "oid": "12badf53ec2c27b7617fceafc6819238e7b9a5dc",
    "message": "Fix https://github.com/eclipse/deeplearning4j/issues/9403",
    "date": "2021-08-01T07:01:27Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/12badf53ec2c27b7617fceafc6819238e7b9a5dc",
    "details": {
      "sha": "0225c889f6787371e36e346c86255177e9769d1f",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/NeuralNetConfiguration.java",
      "status": "modified",
      "additions": 87,
      "deletions": 10,
      "changes": 97,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/12badf53ec2c27b7617fceafc6819238e7b9a5dc/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2FNeuralNetConfiguration.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/12badf53ec2c27b7617fceafc6819238e7b9a5dc/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2FNeuralNetConfiguration.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2FNeuralNetConfiguration.java?ref=12badf53ec2c27b7617fceafc6819238e7b9a5dc",
      "patch": "@@ -181,6 +181,83 @@ public Map<Integer, Builder> getLayerwise() {\n             return layerwise;\n         }\n \n+        @Override\n+        public ListBuilder overrideNinUponBuild(boolean overrideNinUponBuild) {\n+            super.overrideNinUponBuild(overrideNinUponBuild);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder inputPreProcessor(Integer layer, InputPreProcessor processor) {\n+            super.inputPreProcessor(layer, processor);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder inputPreProcessors(Map<Integer, InputPreProcessor> processors) {\n+            super.inputPreProcessors(processors);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder cacheMode(@NonNull CacheMode cacheMode) {\n+            super.cacheMode(cacheMode);\n+            return this;\n+        }\n+\n+        @Override\n+        public MultiLayerConfiguration.Builder backpropType(@NonNull BackpropType type) {\n+            super.backpropType(type);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder tBPTTLength(int bpttLength) {\n+            super.tBPTTLength(bpttLength);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder tBPTTForwardLength(int forwardLength) {\n+            super.tBPTTForwardLength(forwardLength);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder tBPTTBackwardLength(int backwardLength) {\n+             super.tBPTTBackwardLength(backwardLength);\n+             return this;\n+        }\n+\n+        @Override\n+        public ListBuilder confs(List<NeuralNetConfiguration> confs) {\n+             super.confs(confs);\n+             return this;\n+        }\n+\n+        @Override\n+        public ListBuilder validateOutputLayerConfig(boolean validate) {\n+             super.validateOutputLayerConfig(validate);\n+             return this;\n+        }\n+\n+        @Override\n+        public ListBuilder validateTbpttConfig(boolean validate) {\n+            super.validateTbpttConfig(validate);\n+            return this;\n+        }\n+\n+        @Override\n+        public ListBuilder dataType(@NonNull DataType dataType) {\n+             super.dataType(dataType);\n+             return this;\n+        }\n+\n+        @Override\n+        protected void finalize() throws Throwable {\n+            super.finalize();\n+        }\n+\n         @Override\n         public ListBuilder setInputType(InputType inputType){\n             return (ListBuilder)super.setInputType(inputType);\n@@ -228,12 +305,12 @@ public MultiLayerConfiguration build() {\n             for (int i = 0; i < layerwise.size(); i++) {\n                 if (layerwise.get(i) == null) {\n                     throw new IllegalStateException(\"Invalid configuration: layer number \" + i\n-                                    + \" not specified. Expect layer \" + \"numbers to be 0 to \" + (layerwise.size() - 1)\n-                                    + \" inclusive (number of layers defined: \" + layerwise.size() + \")\");\n+                            + \" not specified. Expect layer \" + \"numbers to be 0 to \" + (layerwise.size() - 1)\n+                            + \" inclusive (number of layers defined: \" + layerwise.size() + \")\");\n                 }\n                 if (layerwise.get(i).getLayer() == null)\n                     throw new IllegalStateException(\"Cannot construct network: Layer config for\" + \"layer with index \"\n-                                    + i + \" is not defined)\");\n+                            + i + \" is not defined)\");\n \n                 //Layer names: set to default, if not set\n                 if (layerwise.get(i).getLayer().getLayerName() == null) {\n@@ -248,12 +325,12 @@ public MultiLayerConfiguration build() {\n \n \n             return new MultiLayerConfiguration.Builder().inputPreProcessors(inputPreProcessors)\n-                            .backpropType(backpropType).tBPTTForwardLength(tbpttFwdLength)\n-                            .tBPTTBackwardLength(tbpttBackLength).setInputType(this.inputType)\n-                            .trainingWorkspaceMode(wsmTrain).cacheMode(globalConfig.cacheMode)\n-                            .inferenceWorkspaceMode(wsmTest).confs(list).validateOutputLayerConfig(validateOutputConfig)\n-                            .dataType(globalConfig.dataType)\n-                            .build();\n+                    .backpropType(backpropType).tBPTTForwardLength(tbpttFwdLength)\n+                    .tBPTTBackwardLength(tbpttBackLength).setInputType(this.inputType)\n+                    .trainingWorkspaceMode(wsmTrain).cacheMode(globalConfig.cacheMode)\n+                    .inferenceWorkspaceMode(wsmTest).confs(list).validateOutputLayerConfig(validateOutputConfig)\n+                    .dataType(globalConfig.dataType)\n+                    .build();\n         }\n \n         /** Helper class for setting input types */\n@@ -651,7 +728,7 @@ public Builder weightInit(IWeightInit weightInit) {\n          */\n         public Builder weightInit(WeightInit weightInit) {\n             if(weightInit == WeightInit.DISTRIBUTION) {\n-             //   throw new UnsupportedOperationException(\"Not supported!, Use weightInit(Distribution distribution) instead!\");\n+                //   throw new UnsupportedOperationException(\"Not supported!, Use weightInit(Distribution distribution) instead!\");\n             }\n \n             this.weightInitFn = weightInit.getWeightInitFunction();",
      "parent_sha": "a066e465f4eee86bf1f50b0525373f97c359a512"
    }
  },
  {
    "oid": "aa6839f7b1a17cfef6ef633bd5bb1fa53917793e",
    "message": "Postfix\n\nArgs changed from null to Object[0]\n\nSigned-off-by: jljljl <jijiji95@bk.ru>",
    "date": "2021-05-30T17:50:59Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/aa6839f7b1a17cfef6ef633bd5bb1fa53917793e",
    "details": {
      "sha": "89ea5eea4bdbe008186f7b5b1d8b5b1b782b33c6",
      "filename": "deeplearning4j/deeplearning4j-common/src/main/java/org/deeplearning4j/common/config/DL4JClassLoading.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/aa6839f7b1a17cfef6ef633bd5bb1fa53917793e/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/aa6839f7b1a17cfef6ef633bd5bb1fa53917793e/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java?ref=aa6839f7b1a17cfef6ef633bd5bb1fa53917793e",
      "patch": "@@ -71,7 +71,7 @@ public static <T> Class<T> loadClassByName(String className, boolean initialize,\n     }\n \n     public static <T> T createNewInstance(String className) {\n-        return createNewInstance(className, Object.class, null);//or new Object[0];\n+        return createNewInstance(className, Object.class, new Object[0]);//or null;\n     }\n     \n     public static <T> T createNewInstance(String className, Object[] args) {",
      "parent_sha": "68aac13f974809e534e644470efdfa01182f56ee"
    }
  },
  {
    "oid": "5972b952f1a62d42237ad0365cb88649e350361b",
    "message": "Remove unneeded casts",
    "date": "2021-04-06T05:08:25Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/5972b952f1a62d42237ad0365cb88649e350361b",
    "details": {
      "sha": "ae3a922cfda5860864dfdc0ee133bf66594c4fad",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 6,
      "deletions": 6,
      "changes": 12,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/5972b952f1a62d42237ad0365cb88649e350361b/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/5972b952f1a62d42237ad0365cb88649e350361b/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=5972b952f1a62d42237ad0365cb88649e350361b",
      "patch": "@@ -2806,7 +2806,7 @@ public static INDArray rand(@NonNull long... shape) {\n     public static INDArray rand(@NonNull DataType dataType, @NonNull long... shape) {\n         Preconditions.checkArgument(dataType.isFPType(),\n                 \"Can't create a random array of a non-floating point data type\");\n-        INDArray ret = createUninitialized(dataType, shape, order()).castTo(Nd4j.defaultFloatingPointType()); //INSTANCE.rand(shape, Nd4j.getRandom());\n+        INDArray ret = createUninitialized(dataType, shape, order()); //INSTANCE.rand(shape, Nd4j.getRandom());\n         return rand(ret);\n     }\n \n@@ -2829,15 +2829,15 @@ public static INDArray rand(char order, @NonNull int... shape) {\n      */\n     @Deprecated\n     public static INDArray rand(@NonNull DataType dataType, int[] shape, char order) {\n-        return rand(dataType, order, ArrayUtil.toLongArray(shape)).castTo(Nd4j.defaultFloatingPointType());\n+        return rand(dataType, order, ArrayUtil.toLongArray(shape));\n     }\n \n     /**\n      * @deprecated use {@link org.nd4j.linalg.factory.Nd4j#rand(org.nd4j.linalg.api.buffer.DataType, char, long...)}\n      */\n     @Deprecated\n     public static INDArray rand(@NonNull DataType dataType, char order, @NonNull int... shape) {\n-        return rand(dataType, order, ArrayUtil.toLongArray(shape)).castTo(Nd4j.defaultFloatingPointType());\n+        return rand(dataType, order, ArrayUtil.toLongArray(shape));\n     }\n \n     /**\n@@ -2851,7 +2851,7 @@ public static INDArray rand(@NonNull DataType dataType, char order, @NonNull int\n      * @return the random ndarray with the specified shape\n      */\n     public static INDArray rand(@NonNull DataType dataType, char order, @NonNull long... shape) {\n-        INDArray ret = Nd4j.createUninitialized(dataType, shape, order).castTo(Nd4j.defaultFloatingPointType());\n+        INDArray ret = Nd4j.createUninitialized(dataType, shape, order);\n         return rand(ret);\n     }\n \n@@ -2866,7 +2866,7 @@ public static INDArray rand(@NonNull DataType dataType, char order, @NonNull lon\n      * @return the random ndarray with the specified shape\n      */\n     public static INDArray rand(@NonNull DataType dataType, @NonNull int... shape) {\n-        INDArray ret = Nd4j.createUninitialized(dataType, ArrayUtil.toLongArray(shape), Nd4j.order()).castTo(Nd4j.defaultFloatingPointType());\n+        INDArray ret = Nd4j.createUninitialized(dataType, ArrayUtil.toLongArray(shape), Nd4j.order());\n         return rand(ret);\n     }\n \n@@ -2911,7 +2911,7 @@ public static INDArray rand(@NonNull DataType dataType, @NonNull int... shape) {\n      * @return the random ndarray with the specified shape\n      */\n     public static INDArray rand(long seed, @NonNull long... shape) {\n-        INDArray ret = createUninitialized(shape, Nd4j.order()).castTo(Nd4j.defaultFloatingPointType());//;INSTANCE.rand(shape, seed);\n+        INDArray ret = createUninitialized(shape, Nd4j.order());//;INSTANCE.rand(shape, seed);\n         return rand(ret, seed);\n     }\n ",
      "parent_sha": "bcc0c212bcc567e52f8c7024ed3485a968b8d48a"
    }
  },
  {
    "oid": "22042843f69c71a9aaef5d4e69190434b5c9aaed",
    "message": "Fix string histograms",
    "date": "2021-05-15T12:31:35Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/22042843f69c71a9aaef5d4e69190434b5c9aaed",
    "details": {
      "sha": "78799372f02a3adc04d28a082e35d828045e4599",
      "filename": "datavec/datavec-api/src/main/java/org/datavec/api/transform/analysis/histogram/StringHistogramCounter.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/22042843f69c71a9aaef5d4e69190434b5c9aaed/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fhistogram%2FStringHistogramCounter.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/22042843f69c71a9aaef5d4e69190434b5c9aaed/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fhistogram%2FStringHistogramCounter.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fhistogram%2FStringHistogramCounter.java?ref=22042843f69c71a9aaef5d4e69190434b5c9aaed",
      "patch": "@@ -55,7 +55,7 @@ public HistogramCounter add(Writable w) {\n         //Not super efficient, but linear search on 20-50 items should be good enough\n         int idx = -1;\n         for (int i = 0; i < nBins; i++) {\n-            if (d >= bins[i] && d < bins[i]) {\n+            if (d >= bins[i] && d < bins[i + 1]) {\n                 idx = i;\n                 break;\n             }",
      "parent_sha": "6168a1eef90347a382834d2fb8f30dae8e267910"
    }
  },
  {
    "oid": "5039fb22b7dced128093ed18e01cc185df067e13",
    "message": "Fix datatype issue with GpuGraphRunnerTest (#198)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2020-01-29T10:16:56Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/5039fb22b7dced128093ed18e01cc185df067e13",
    "details": {
      "sha": "a035592dfbc904bf4c62cc018350c4625774a384",
      "filename": "nd4j/nd4j-backends/nd4j-tests-tensorflow/src/test/gpujava/org/nd4j/tensorflow/conversion/GpuGraphRunnerTest.java",
      "status": "modified",
      "additions": 8,
      "deletions": 2,
      "changes": 10,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/5039fb22b7dced128093ed18e01cc185df067e13/nd4j%2Fnd4j-backends%2Fnd4j-tests-tensorflow%2Fsrc%2Ftest%2Fgpujava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FGpuGraphRunnerTest.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/5039fb22b7dced128093ed18e01cc185df067e13/nd4j%2Fnd4j-backends%2Fnd4j-tests-tensorflow%2Fsrc%2Ftest%2Fgpujava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FGpuGraphRunnerTest.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests-tensorflow%2Fsrc%2Ftest%2Fgpujava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FGpuGraphRunnerTest.java?ref=5039fb22b7dced128093ed18e01cc185df067e13",
      "patch": "@@ -18,6 +18,7 @@\n package org.nd4j.tensorflow.conversion;\n \n import org.nd4j.BaseND4JTest;\n+import org.nd4j.linalg.api.buffer.DataType;\n import org.nd4j.shade.protobuf.util.JsonFormat;\n import org.apache.commons.io.IOUtils;\n import org.junit.Test;\n@@ -40,6 +41,11 @@\n \n public class GpuGraphRunnerTest extends BaseND4JTest {\n \n+    @Override\n+    public long getTimeoutMilliseconds() {\n+        return 180000L;\n+    }\n+\n     @Test\n     public void testGraphRunner() throws Exception {\n         byte[] content = IOUtils.toByteArray(new ClassPathResource(\"/tf_graphs/nd4j_convert/simple_graph/frozen_model.pb\").getInputStream());\n@@ -68,8 +74,8 @@ public void testGraphRunner() throws Exception {\n             assertEquals(2,graphRunner.getInputOrder().size());\n             assertEquals(1,graphRunner.getOutputOrder().size());\n \n-            INDArray input1 = Nd4j.linspace(1,4,4).reshape(4);\n-            INDArray input2 = Nd4j.linspace(1,4,4).reshape(4);\n+            INDArray input1 = Nd4j.linspace(1,4,4).reshape(4).castTo(DataType.FLOAT);\n+            INDArray input2 = Nd4j.linspace(1,4,4).reshape(4).castTo(DataType.FLOAT);\n \n             Map<String,INDArray> inputs = new LinkedHashMap<>();\n             inputs.put(\"input_0\",input1);",
      "parent_sha": "f25056363b7bdb801eb208506b08c219ca5f9755"
    }
  },
  {
    "oid": "4781cf171ca10836192dd2d344b2623066d5640f",
    "message": "remove autogened Nd4jCpu changes\n\nSigned-off-by: AbdelRauf <rauf@konduit.ai>",
    "date": "2021-08-27T07:28:34Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/4781cf171ca10836192dd2d344b2623066d5640f",
    "details": {
      "sha": "750c024a9822898f60f33b27ea67548cac68fc68",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-native/src/main/java/org/nd4j/nativeblas/Nd4jCpu.java",
      "status": "modified",
      "additions": 544,
      "deletions": 541,
      "changes": 1085,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/4781cf171ca10836192dd2d344b2623066d5640f/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpu.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/4781cf171ca10836192dd2d344b2623066d5640f/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpu.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpu.java?ref=4781cf171ca10836192dd2d344b2623066d5640f",
      "parent_sha": "58b63a1c6dccbfa481e8d5890ded7bd89d87fb4d"
    }
  },
  {
    "oid": "0c74c03d945fe8805a42993a0459606a24d4bbb7",
    "message": "Update KerasUpsampling2D.java",
    "date": "2021-04-08T01:46:09Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/0c74c03d945fe8805a42993a0459606a24d4bbb7",
    "details": {
      "sha": "c9099e17b4d422c9d4d844a1799c8f8a0304510d",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/main/java/org/deeplearning4j/nn/modelimport/keras/layers/convolutional/KerasUpsampling2D.java",
      "status": "modified",
      "additions": 1,
      "deletions": 5,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/0c74c03d945fe8805a42993a0459606a24d4bbb7/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fconvolutional%2FKerasUpsampling2D.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/0c74c03d945fe8805a42993a0459606a24d4bbb7/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fconvolutional%2FKerasUpsampling2D.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fconvolutional%2FKerasUpsampling2D.java?ref=0c74c03d945fe8805a42993a0459606a24d4bbb7",
      "patch": "@@ -61,14 +61,10 @@ public KerasUpsampling2D(Map<String, Object> layerConfig, boolean enforceTrainin\n         super(layerConfig, enforceTrainingConfig);\n \n         int[] size = KerasConvolutionUtils.getUpsamplingSizeFromConfig(layerConfig, 2, conf);\n-        if (size[0] != size[1])\n-            throw new UnsupportedKerasConfigurationException(\"First and second size arguments have to be the same\" +\n-                    \"got: \" + size[0] + \" and \" + size[1]);\n-\n         Upsampling2D.Builder builder = new Upsampling2D.Builder()\n                 .name(this.layerName)\n                 .dropOut(this.dropout)\n-                .size(size[0]);\n+                .size(size);\n \n         this.layer = builder.build();\n         this.vertex = null;",
      "parent_sha": "01039802d885f20ae4c4d4db495cfab598108098"
    }
  },
  {
    "oid": "abd2017a0ae532e1f2789c9045ef274e04de988b",
    "message": "Add ignore for known issue with non_max_suppression_v2/float16 test (#85)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2019-11-27T05:35:05Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/abd2017a0ae532e1f2789c9045ef274e04de988b",
    "details": {
      "sha": "277bb8a83fd74cdbec0c94c21345f7b0f7d6a191",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/imports/TFGraphs/TFGraphTestAllSameDiff.java",
      "status": "modified",
      "additions": 4,
      "deletions": 1,
      "changes": 5,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/abd2017a0ae532e1f2789c9045ef274e04de988b/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2FTFGraphs%2FTFGraphTestAllSameDiff.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/abd2017a0ae532e1f2789c9045ef274e04de988b/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2FTFGraphs%2FTFGraphTestAllSameDiff.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fimports%2FTFGraphs%2FTFGraphTestAllSameDiff.java?ref=abd2017a0ae532e1f2789c9045ef274e04de988b",
      "patch": "@@ -126,7 +126,10 @@ protected void starting(Description description){\n             \"fake_quant/min_max_args_per_channel.*\",\n \n             // 2019/11/15 - failure https://github.com/eclipse/deeplearning4j/issues/8403\n-            \"resize_bilinear/int32.*\"\n+            \"resize_bilinear/int32.*\",\n+\n+            // Suggesting TF 1.15 bug - see https://github.com/eclipse/deeplearning4j/issues/8449\n+            \"non_max_suppression_v2/float16.*\"\n     };\n \n     /* As per TFGraphTestList.printArraysDebugging - this field defines a set of regexes for test cases that should have",
      "parent_sha": "a8dd6713aa64d34c59a3bbcd5710ceb5fb700323"
    }
  },
  {
    "oid": "492bfe9c5835d9f3cd39c432259acf11145d39f1",
    "message": "Update HelperUtils.java",
    "date": "2021-05-06T11:30:10Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/492bfe9c5835d9f3cd39c432259acf11145d39f1",
    "details": {
      "sha": "1f052b0b5d632684f43c790c89f7618daf8e90fc",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/HelperUtils.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/492bfe9c5835d9f3cd39c432259acf11145d39f1/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtils.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/492bfe9c5835d9f3cd39c432259acf11145d39f1/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtils.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtils.java?ref=492bfe9c5835d9f3cd39c432259acf11145d39f1",
      "patch": "@@ -63,7 +63,7 @@ public static <T extends LayerHelper> T createHelper(String cudnnHelperClassName\n \n             }\n             else {\n-                log.warn(\"Unable to find class {}  using the classloader set for Dl4jClassLoading. Trying to use class loader that loaded this class instead.\",cudnnHelperClassName);\n+                log.warn(\"Unable to find class {}  using the classloader set for Dl4jClassLoading. Trying to use class loader that loaded the  class {} instead.\",cudnnHelperClassName,cudnnHelperClassName);\n                 ClassLoader classLoader = DL4JClassLoading.getDl4jClassloader();\n                 DL4JClassLoading.setDl4jClassloaderFromClass(layerHelperSuperClass);\n                 try {",
      "parent_sha": "5e600abfb84792702d40aff68166213341576590"
    }
  },
  {
    "oid": "d864ba85d7f97185ece41b1e25169ea5bbc3e781",
    "message": "Fix casting issue when running tests",
    "date": "2021-11-19T01:49:15Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d864ba85d7f97185ece41b1e25169ea5bbc3e781",
    "details": {
      "sha": "cf0acf782c93020a7cef56a85075c4f41ebd2e20",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/memory/provider/BasicWorkspaceManager.java",
      "status": "modified",
      "additions": 12,
      "deletions": 9,
      "changes": 21,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d864ba85d7f97185ece41b1e25169ea5bbc3e781/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fprovider%2FBasicWorkspaceManager.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d864ba85d7f97185ece41b1e25169ea5bbc3e781/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fprovider%2FBasicWorkspaceManager.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fprovider%2FBasicWorkspaceManager.java?ref=d864ba85d7f97185ece41b1e25169ea5bbc3e781",
      "patch": "@@ -54,8 +54,8 @@ public abstract class BasicWorkspaceManager implements MemoryWorkspaceManager {\n \n     public BasicWorkspaceManager() {\n         this(WorkspaceConfiguration.builder().initialSize(0).maxSize(0).overallocationLimit(0.3)\n-                        .policyAllocation(AllocationPolicy.OVERALLOCATE).policyLearning(LearningPolicy.FIRST_LOOP)\n-                        .policyMirroring(MirroringPolicy.FULL).policySpill(SpillPolicy.EXTERNAL).build());\n+                .policyAllocation(AllocationPolicy.OVERALLOCATE).policyLearning(LearningPolicy.FIRST_LOOP)\n+                .policyMirroring(MirroringPolicy.FULL).policySpill(SpillPolicy.EXTERNAL).build());\n     }\n \n     public BasicWorkspaceManager(@NonNull WorkspaceConfiguration defaultConfiguration) {\n@@ -352,13 +352,16 @@ public synchronized void printAllocationStatisticsForCurrentThread() {\n         log.info(\"Workspace name: Allocated / external (spilled) / external (pinned)\");\n         for (String key : map.keySet()) {\n             long current = map.get(key).getCurrentSize();\n-            long spilled = ((Nd4jWorkspace) map.get(key)).getSpilledSize();\n-            long pinned = ((Nd4jWorkspace) map.get(key)).getPinnedSize();\n-            log.info(String.format(\"%-26s %8s / %8s / %8s (%11d / %11d / %11d)\", (key + \":\"),\n-                    BinaryByteUnit.format(current, \"#.00\"),\n-                    BinaryByteUnit.format(spilled, \"#.00\"),\n-                    BinaryByteUnit.format(pinned, \"#.00\"),\n-                    current, spilled, pinned));\n+            if(map.get(key) instanceof Nd4jWorkspace) {\n+                long spilled = ((Nd4jWorkspace) map.get(key)).getSpilledSize();\n+                long pinned = ((Nd4jWorkspace) map.get(key)).getPinnedSize();\n+                log.info(String.format(\"%-26s %8s / %8s / %8s (%11d / %11d / %11d)\", (key + \":\"),\n+                        BinaryByteUnit.format(current, \"#.00\"),\n+                        BinaryByteUnit.format(spilled, \"#.00\"),\n+                        BinaryByteUnit.format(pinned, \"#.00\"),\n+                        current, spilled, pinned));\n+            }\n+\n         }\n     }\n ",
      "parent_sha": "008ba79ba0cad7c90dd9934245ec90c06e99e610"
    }
  },
  {
    "oid": "65c6a141e7fa101ff45506b236a6d38a9ff2b981",
    "message": "Move buffer/bufferMat to local variable",
    "date": "2021-11-22T08:52:25Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/65c6a141e7fa101ff45506b236a6d38a9ff2b981",
    "details": {
      "sha": "f518cb45222d7bc99d6ffc53973d24ad3efa0eb9",
      "filename": "datavec/datavec-data/datavec-data-image/src/main/java/org/datavec/image/loader/NativeImageLoader.java",
      "status": "modified",
      "additions": 16,
      "deletions": 57,
      "changes": 73,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/65c6a141e7fa101ff45506b236a6d38a9ff2b981/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fimage%2Floader%2FNativeImageLoader.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/65c6a141e7fa101ff45506b236a6d38a9ff2b981/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fimage%2Floader%2FNativeImageLoader.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fimage%2Floader%2FNativeImageLoader.java?ref=65c6a141e7fa101ff45506b236a6d38a9ff2b981",
      "patch": "@@ -50,12 +50,11 @@\n \n public class NativeImageLoader extends BaseImageLoader {\n     private static final int MIN_BUFFER_STEP_SIZE = 64 * 1024;\n-    private byte[] buffer = null;\n-    private Mat bufferMat = null;\n+\n \n     public static final String[] ALLOWED_FORMATS = {\"bmp\", \"gif\", \"jpg\", \"jpeg\", \"jp2\", \"pbm\", \"pgm\", \"ppm\", \"pnm\",\n-                    \"png\", \"tif\", \"tiff\", \"exr\", \"webp\", \"BMP\", \"GIF\", \"JPG\", \"JPEG\", \"JP2\", \"PBM\", \"PGM\", \"PPM\", \"PNM\",\n-                    \"PNG\", \"TIF\", \"TIFF\", \"EXR\", \"WEBP\"};\n+            \"png\", \"tif\", \"tiff\", \"exr\", \"webp\", \"BMP\", \"GIF\", \"JPG\", \"JPEG\", \"JP2\", \"PBM\", \"PGM\", \"PPM\", \"PNM\",\n+            \"PNG\", \"TIF\", \"TIFF\", \"EXR\", \"WEBP\"};\n \n     protected OpenCVFrameConverter.ToMat converter = new OpenCVFrameConverter.ToMat();\n \n@@ -71,7 +70,7 @@ public NativeImageLoader() {}\n      * height and width\n      * @param height the height to load\n      * @param width  the width to load\n-    \n+\n      */\n     public NativeImageLoader(long height, long width) {\n         this.height = height;\n@@ -117,7 +116,7 @@ public NativeImageLoader(long height, long width, long channels, ImageTransform\n         this(height, width, channels);\n         this.imageTransform = imageTransform;\n     }\n-    \n+\n     /**\n      * Instantiate an image with the given\n      * height and width\n@@ -295,53 +294,13 @@ public INDArray asMatrix(InputStream inputStream, boolean nchw) throws IOExcepti\n      * @throws IOException\n      */\n     private Mat streamToMat(InputStream is) throws IOException {\n-        if(buffer == null){\n-            buffer = IOUtils.toByteArray(is);\n-            if(buffer.length <= 0){\n-                throw new IOException(\"Could not decode image from input stream: input stream was empty (no data)\");\n-            }\n-            bufferMat = new Mat(buffer);\n-            return bufferMat;\n-        } else {\n-            int numReadTotal = is.read(buffer);\n-            //Need to know if all data has been read.\n-            //(a) if numRead < buffer.length - got everything\n-            //(b) if numRead >= buffer.length: we MIGHT have got everything (exact right size buffer) OR we need more data\n-\n-            if(numReadTotal <= 0){\n-                throw new IOException(\"Could not decode image from input stream: input stream was empty (no data)\");\n-            }\n-\n-            if(numReadTotal < buffer.length){\n-                bufferMat.data().put(buffer, 0, numReadTotal);\n-                bufferMat.cols(numReadTotal);\n-                return bufferMat;\n-            }\n-\n-            //Buffer is full; reallocate and keep reading\n-            int numReadCurrent = numReadTotal;\n-            while(numReadCurrent != -1){\n-                byte[] oldBuffer = buffer;\n-                if(oldBuffer.length == Integer.MAX_VALUE) {\n-                    throw new IllegalStateException(\"Cannot read more than Integer.MAX_VALUE bytes\");\n-                }\n-                //Double buffer, but allocate at least 1MB more\n-                long increase = Math.max(buffer.length, MIN_BUFFER_STEP_SIZE);\n-                int newBufferLength = (int)Math.min(Integer.MAX_VALUE, buffer.length + increase);\n-\n-                buffer = new byte[newBufferLength];\n-                System.arraycopy(oldBuffer, 0, buffer, 0, oldBuffer.length);\n-                numReadCurrent = is.read(buffer, oldBuffer.length, buffer.length - oldBuffer.length);\n-                if(numReadCurrent > 0){\n-                    numReadTotal += numReadCurrent;\n-                }\n-            }\n-\n-            bufferMat = new Mat(buffer);\n-            buffer = null;\n-            return bufferMat;\n+        byte[] buffer = IOUtils.toByteArray(is);\n+        Mat bufferMat = null;\n+        if (buffer.length <= 0) {\n+            throw new IOException(\"Could not decode image from input stream: input stream was empty (no data)\");\n         }\n-\n+        bufferMat = new Mat(buffer);\n+        return bufferMat;\n     }\n \n     public Image asImageMatrix(String filename) throws IOException {\n@@ -421,19 +380,19 @@ protected void fillNDArray(Mat image, INDArray ret) {\n \n         if (ret.length() != rows * cols * channels) {\n             throw new ND4JIllegalStateException(\"INDArray provided to store image not equal to image: {channels: \"\n-                            + channels + \", rows: \" + rows + \", columns: \" + cols + \"}\");\n+                    + channels + \", rows: \" + rows + \", columns: \" + cols + \"}\");\n         }\n \n         Indexer idx = image.createIndexer(direct);\n         Pointer pointer = ret.data().pointer();\n         long[] stride = ret.stride();\n         boolean done = false;\n         PagedPointer pagedPointer = new PagedPointer(pointer, rows * cols * channels,\n-                        ret.data().offset() * Nd4j.sizeOfDataType(ret.data().dataType()));\n+                ret.data().offset() * Nd4j.sizeOfDataType(ret.data().dataType()));\n \n         if (pointer instanceof FloatPointer) {\n             FloatIndexer retidx = FloatIndexer.create((FloatPointer) pagedPointer.asFloatPointer(),\n-                            new long[] {channels, rows, cols}, new long[] {stride[0], stride[1], stride[2]}, direct);\n+                    new long[] {channels, rows, cols}, new long[] {stride[0], stride[1], stride[2]}, direct);\n             if (idx instanceof UByteIndexer) {\n                 UByteIndexer ubyteidx = (UByteIndexer) idx;\n                 for (long k = 0; k < channels; k++) {\n@@ -478,7 +437,7 @@ protected void fillNDArray(Mat image, INDArray ret) {\n             retidx.release();\n         } else if (pointer instanceof DoublePointer) {\n             DoubleIndexer retidx = DoubleIndexer.create((DoublePointer) pagedPointer.asDoublePointer(),\n-                            new long[] {channels, rows, cols}, new long[] {stride[0], stride[1], stride[2]}, direct);\n+                    new long[] {channels, rows, cols}, new long[] {stride[0], stride[1], stride[2]}, direct);\n             if (idx instanceof UByteIndexer) {\n                 UByteIndexer ubyteidx = (UByteIndexer) idx;\n                 for (long k = 0; k < channels; k++) {\n@@ -907,5 +866,5 @@ private INDArray asMatrix(BytePointer bytes, long length) throws IOException {\n \n         return data;\n     }\n-    \n+\n }",
      "parent_sha": "3db6404c8e34119aa7663f64c516f9847d2c2f73"
    }
  },
  {
    "oid": "aa4af2c36d5fbcc15e99250a1dc718b8c8e88a98",
    "message": "refactor duplicate code from pad methods. (#86)\n\n* refactor duplicate code from pad methods.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* replace switch with if.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-05T01:24:20Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/aa4af2c36d5fbcc15e99250a1dc718b8c8e88a98",
    "details": {
      "sha": "b82a9e19ecf6ad8bca39d039278022336ab6e46e",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 43,
      "deletions": 64,
      "changes": 107,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/aa4af2c36d5fbcc15e99250a1dc718b8c8e88a98/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/aa4af2c36d5fbcc15e99250a1dc718b8c8e88a98/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=aa4af2c36d5fbcc15e99250a1dc718b8c8e88a98",
      "patch": "@@ -225,85 +225,64 @@ public static INDArray pad(INDArray toPad, int[][] padWidth, PadMode padMode) {\n      * based on the specified mode\n      */\n     public static INDArray pad(INDArray toPad, int[][] padWidth, List<double[]> constantValues, PadMode padMode) {\n-        switch (padMode) {\n-            case CONSTANT:\n-                if (padWidth.length < toPad.rank())\n-                    throw new IllegalArgumentException(\"Please specify a pad width for each dimension\");\n-\n-                List<int[]> sizes = new ArrayList<>();\n-                for (int i = 0; i < toPad.rank(); i++) {\n-                    sizes.add(padWidth[i]);\n-                }\n-\n-                INDArray ret = toPad;\n-                for (int i = 0; i < toPad.rank(); i++) {\n-                    int[] pad = sizes.get(i);\n-                    double[] constant = constantValues.get(i);\n-                    int padBefore = pad[0];\n-                    int padAfter = pad[1];\n-                    if (constant.length < 2) {\n-                        double val = constant[0];\n-                        constant = new double[2];\n-                        constant[0] = val;\n-                        constant[1] = val;\n-                    }\n-\n-                    double beforeVal = constant[0];\n-                    double afterVal = constant[1];\n-                    ret = Nd4j.prepend(ret, padBefore, beforeVal, i);\n-                    ret = Nd4j.append(ret, padAfter, afterVal, i);\n-\n-                }\n-\n-                return ret;\n+        if (padMode == PadMode.CONSTANT) {\n+            if (padWidth.length < toPad.rank())\n+                throw new IllegalArgumentException(\"Please specify a pad width for each dimension\");\n \n-            default:\n-                throw new UnsupportedOperationException();\n+            List<int[]> sizes = new ArrayList<>();\n+            for (int i = 0; i < toPad.rank(); i++) {\n+                sizes.add(padWidth[i]);\n+            }\n \n+            return padImpl(toPad, sizes, constantValues);\n         }\n+        throw new UnsupportedOperationException();\n     }\n \n     /**\n      * See {@link #pad(INDArray, int[][], List, PadMode)} with a 1D int[] for padWidth.\n      */\n     public static INDArray pad(INDArray toPad, int[] padWidth, List<double[]> constantValues, PadMode padMode) {\n-        switch (padMode) {\n-            case CONSTANT:\n-                if (padWidth.length < toPad.rank())\n-                    throw new IllegalArgumentException(\"Please specify a pad width for each dimension\");\n+        if (padMode == PadMode.CONSTANT) {\n+            if (padWidth.length < toPad.rank())\n+                throw new IllegalArgumentException(\"Please specify a pad width for each dimension\");\n \n-                toPad = Nd4j.stripOnes(toPad);\n+            toPad = Nd4j.stripOnes(toPad);\n \n-                List<int[]> sizes = new ArrayList<>();\n-                for (int i = 0; i < toPad.rank(); i++) {\n-                    sizes.add(padWidth);\n-                }\n-\n-                INDArray ret = toPad;\n-                //TODO: Remove duplicate code.\n-                for (int i = 0; i < toPad.rank(); i++) {\n-                    int[] pad = sizes.get(i);\n-                    double[] constant = constantValues.get(i);\n-                    int padBefore = pad[0];\n-                    int padAfter = pad[1];\n-                    if (constant.length < 2) {\n-                        double val = constant[0];\n-                        constant = new double[2];\n-                        constant[0] = val;\n-                        constant[1] = val;\n-                    }\n+            List<int[]> sizes = new ArrayList<>();\n+            for (int i = 0; i < toPad.rank(); i++) {\n+                sizes.add(padWidth);\n+            }\n \n-                    double beforeVal = constant[0];\n-                    double afterVal = constant[1];\n-                    ret = Nd4j.prepend(ret, padBefore, beforeVal, i);\n-                    ret = Nd4j.append(ret, padAfter, afterVal, i);\n+            return padImpl(toPad, sizes, constantValues);\n+        }\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    // common code for pad(INDArray, int[],   List<double[]>, PadMode) and\n+    //                 pad(INDArray, int[][], List<double[]>, PadMode)\n+    private static INDArray padImpl(INDArray toPad, List<int[]> sizes, List<double[]> constantValues){\n+\n+        INDArray ret = toPad;\n+        for (int i = 0; i < toPad.rank(); i++) {\n+            int[] pad = sizes.get(i);\n+            double[] constant = constantValues.get(i);\n+            int padBefore = pad[0];\n+            int padAfter = pad[1];\n+            if (constant.length < 2) {\n+                double val = constant[0];\n+                constant = new double[2];\n+                constant[0] = val;\n+                constant[1] = val;\n+            }\n \n-                }\n-                return ret;\n+            double beforeVal = constant[0];\n+            double afterVal = constant[1];\n+            ret = Nd4j.prepend(ret, padBefore, beforeVal, i);\n+            ret = Nd4j.append(ret, padAfter, afterVal, i);\n \n-            default:\n-                throw new UnsupportedOperationException();\n         }\n+        return ret;\n     }\n \n     /**",
      "parent_sha": "d4e7997134eeec8b5c4d71badd9637eb960e6e21"
    }
  },
  {
    "oid": "7fbc4b09336ba5803b444d29808f9c75e5aa265a",
    "message": "Nd4j refactoring (last one!) (#123)\n\n* fix: IOException no longer thrown by read().\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* refactoring\r\n\r\n* last refactorings\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-16T06:39:11Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/7fbc4b09336ba5803b444d29808f9c75e5aa265a",
    "details": {
      "sha": "1f55de3dc4be80e7ace758f7dd32147b5fa907b2",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 67,
      "deletions": 72,
      "changes": 139,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/7fbc4b09336ba5803b444d29808f9c75e5aa265a/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/7fbc4b09336ba5803b444d29808f9c75e5aa265a/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=7fbc4b09336ba5803b444d29808f9c75e5aa265a",
      "patch": "@@ -1,4 +1,4 @@\n-/*******************************************************************************\n+/* *****************************************************************************\n  * Copyright (c) 2015-2018 Skymind, Inc.\n  *\n  * This program and the accompanying materials are made available under the\n@@ -5673,14 +5673,14 @@ public static INDArray tri(int n,int m,int k) {\n     public static INDArray[] where(INDArray condition, INDArray x, INDArray y){\n         Preconditions.checkState((x == null && y == null) || (x != null && y != null), \"Both X and Y must be\" +\n                 \"null, or neither must be null\");\n-        INDArray out;\n         DynamicCustomOp.DynamicCustomOpsBuilder op = DynamicCustomOp.builder(\"where_np\");\n         List<LongShapeDescriptor> outShapes;\n         if(x == null){\n             //First case: condition only...\n             op.addInputs(condition);\n         } else {\n             if(!x.equalShapes(y) || !x.equalShapes(condition)){\n+                //noinspection ConstantConditions\n                 Preconditions.throwStateEx(\"Shapes must be equal: condition=%s, x=%s, y=%s\", condition.shape(), x.shape(), y.shape());\n             }\n             op.addInputs(condition, x, y);\n@@ -5713,6 +5713,7 @@ public static INDArray[] where(INDArray condition, INDArray x, INDArray y){\n      * @param file the file to write to\n      * @throws IOException if an error occurs when writing the file\n      */\n+    @SuppressWarnings(\"WeakerAccess\")\n     public static void writeAsNumpy(INDArray arr, File file) throws IOException {\n         writeAsNumpy(arr, new FileOutputStream(file));\n     }\n@@ -5723,6 +5724,7 @@ public static void writeAsNumpy(INDArray arr, File file) throws IOException {\n      * @param arr the array to convert\n      * @return a pointer to the numpy struct\n      */\n+    @SuppressWarnings(\"WeakerAccess\")\n     public static Pointer convertToNumpy(INDArray arr)  {\n         return INSTANCE.convertToNumpy(arr);\n     }\n@@ -5732,8 +5734,8 @@ public static Pointer convertToNumpy(INDArray arr)  {\n      * Writes an array to an output stream\n      * @param arr the array to write\n      * @param writeTo the output stream to write to\n-     * @throws IOException\n      */\n+    @SuppressWarnings(\"WeakerAccess\")\n     public static void writeAsNumpy(INDArray arr, OutputStream writeTo) throws IOException {\n         try(BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(writeTo)) {\n             Pointer asNumpy = convertToNumpy(arr);\n@@ -5746,7 +5748,6 @@ public static void writeAsNumpy(INDArray arr, OutputStream writeTo) throws IOExc\n \n             bufferedOutputStream.flush();\n         }\n-\n     }\n \n \n@@ -5759,6 +5760,7 @@ public static void writeAsNumpy(INDArray arr, OutputStream writeTo) throws IOExc\n      * numpy pointer\n      */\n \n+    @SuppressWarnings(\"WeakerAccess\")\n     public static INDArray createFromNpyPointer(Pointer pointer) {\n         return INSTANCE.createFromNpyPointer(pointer);\n     }\n@@ -5784,8 +5786,8 @@ public static Map<String, INDArray> createFromNpzFile(File file) throws Exceptio\n      * Create a numpy array based on the passed in input stream\n      * @param is the input stream to read\n      * @return the loaded ndarray\n-     * @throws IOException\n      */\n+    @SuppressWarnings(\"unused\")\n     public static INDArray createNpyFromInputStream(InputStream is) throws IOException {\n         byte[] content = IOUtils.toByteArray(is);\n         return createNpyFromByteArray(content);\n@@ -5814,7 +5816,6 @@ public static INDArray createNpyFromByteArray(byte[] input) {\n      * @return the {@link INDArray} as a byte array\n      * with the numpy format.\n      * For more on the format, see: https://docs.scipy.org/doc/numpy-1.14.0/neps/npy-format.html\n-     * @throws IOException\n      */\n     public static byte[] toNpyByteArray(INDArray input) {\n         try {\n@@ -5907,7 +5908,7 @@ public static INDArray createFromFlatArray(FlatArray array) {\n                 val bytes = new byte[prod];\n                 val sb = bb.order(_order).asReadOnlyBuffer();\n                 for (int e = 0; e < prod; e++)\n-                    bytes[e] = (byte) sb.get(e + sb.position());\n+                    bytes[e] = sb.get(e + sb.position());\n \n                 return Nd4j.create(bytes, shapeOf, stridesOf, ordering, DataType.BYTE);\n             }\n@@ -5951,7 +5952,7 @@ public static INDArray createFromFlatArray(FlatArray array) {\n     /**\n      * This method returns maximal allowed number of threads for Nd4j.\n      * If value wasn't set in advance, max(1, availableProcessor) will be returned\n-     * @return\n+     * @return maximal allowed number of threads\n      */\n     public static int numThreads() {\n         val v = numThreads.get();\n@@ -5963,7 +5964,7 @@ public static int numThreads() {\n \n     /**\n      * This method sets maximal allowed number of threads for Nd4j\n-     * @param numthreads\n+     * @param numthreads maximal allowed number of threads\n      */\n     public static void setNumThreads(int numthreads) {\n         numThreads.set(numthreads);\n@@ -5979,6 +5980,7 @@ public static boolean isPrecisionBoostAllowed() {\n \n \n     public static INDArray scalar(@NonNull String string) {\n+        //noinspection RedundantArrayCreation\n         return create(Collections.singletonList(string), new long[0]);\n     }\n \n@@ -5998,7 +6000,7 @@ public static INDArray create(@NonNull Collection<String> strings, long[] shape,\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(double... array) {\n@@ -6011,7 +6013,7 @@ public static INDArray createFromArray(double... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(float... array) {\n@@ -6024,7 +6026,7 @@ public static INDArray createFromArray(float... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(int... array) {\n@@ -6037,7 +6039,7 @@ public static INDArray createFromArray(int... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(short... array) {\n@@ -6050,7 +6052,7 @@ public static INDArray createFromArray(short... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(byte... array) {\n@@ -6063,7 +6065,7 @@ public static INDArray createFromArray(byte... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(long... array) {\n@@ -6076,7 +6078,7 @@ public static INDArray createFromArray(long... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(boolean... array) {\n@@ -6091,7 +6093,7 @@ public static INDArray createFromArray(boolean... array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(double[][] array) {\n@@ -6105,7 +6107,7 @@ public static INDArray createFromArray(double[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(float[][] array) {\n@@ -6119,7 +6121,7 @@ public static INDArray createFromArray(float[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(long[][] array) {\n@@ -6133,7 +6135,7 @@ public static INDArray createFromArray(long[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(int[][] array) {\n@@ -6147,7 +6149,7 @@ public static INDArray createFromArray(int[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(short[][] array) {\n@@ -6161,7 +6163,7 @@ public static INDArray createFromArray(short[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(byte[][] array) {\n@@ -6175,7 +6177,7 @@ public static INDArray createFromArray(byte[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(boolean[][] array) {\n@@ -6192,7 +6194,7 @@ public static INDArray createFromArray(boolean[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(double[][][] array) {\n@@ -6206,7 +6208,7 @@ public static INDArray createFromArray(double[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(float[][][] array) {\n@@ -6220,7 +6222,7 @@ public static INDArray createFromArray(float[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(long[][][] array) {\n@@ -6235,7 +6237,7 @@ public static INDArray createFromArray(long[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(int[][][] array) {\n@@ -6250,7 +6252,7 @@ public static INDArray createFromArray(int[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(short[][][] array) {\n@@ -6264,7 +6266,7 @@ public static INDArray createFromArray(short[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(byte[][][] array) {\n@@ -6278,7 +6280,7 @@ public static INDArray createFromArray(byte[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(boolean[][][] array) {\n@@ -6294,7 +6296,7 @@ public static INDArray createFromArray(boolean[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(double[][][][] array) {\n@@ -6308,7 +6310,7 @@ public static INDArray createFromArray(double[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(float[][][][] array) {\n@@ -6322,7 +6324,7 @@ public static INDArray createFromArray(float[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(long[][][][] array) {\n@@ -6336,7 +6338,7 @@ public static INDArray createFromArray(long[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(int[][][][] array) {\n@@ -6350,7 +6352,7 @@ public static INDArray createFromArray(int[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(short[][][][] array) {\n@@ -6364,7 +6366,7 @@ public static INDArray createFromArray(short[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(byte[][][][] array) {\n@@ -6378,7 +6380,7 @@ public static INDArray createFromArray(byte[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(boolean[][][][] array) {\n@@ -6390,7 +6392,6 @@ public static INDArray createFromArray(boolean[][][][] array) {\n         return create(ArrayUtil.flatten(array), shape, ArrayUtil.calcStrides(shape), 'c', DataType.BOOL);\n     }\n \n-\n     public static synchronized DeallocatorService getDeallocatorService() {\n         if (deallocatorService == null)\n             deallocatorService = new DeallocatorService();\n@@ -6402,7 +6403,7 @@ public static synchronized DeallocatorService getDeallocatorService() {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(Double[] array) {\n@@ -6411,7 +6412,7 @@ public static INDArray createFromArray(Double[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(Float[] array) {\n@@ -6420,7 +6421,7 @@ public static INDArray createFromArray(Float[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(Integer[] array) {\n@@ -6429,7 +6430,7 @@ public static INDArray createFromArray(Integer[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(Short[] array) {\n@@ -6438,7 +6439,7 @@ public static INDArray createFromArray(Short[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(Byte[] array) {\n@@ -6447,7 +6448,7 @@ public static INDArray createFromArray(Byte[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(Long[] array) {\n@@ -6456,7 +6457,7 @@ public static INDArray createFromArray(Long[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 1D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(Boolean[] array) {\n@@ -6467,7 +6468,7 @@ public static INDArray createFromArray(Boolean[] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(Double[][] array) {\n@@ -6476,7 +6477,7 @@ public static INDArray createFromArray(Double[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(Float[][] array) {\n@@ -6485,7 +6486,7 @@ public static INDArray createFromArray(Float[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(Integer[][] array) {\n@@ -6494,7 +6495,7 @@ public static INDArray createFromArray(Integer[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(Short[][] array) {\n@@ -6503,7 +6504,7 @@ public static INDArray createFromArray(Short[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(Byte[][] array) {\n@@ -6512,7 +6513,7 @@ public static INDArray createFromArray(Byte[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(Long[][] array) {\n@@ -6521,7 +6522,7 @@ public static INDArray createFromArray(Long[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 2D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(Boolean[][] array) {\n@@ -6532,7 +6533,7 @@ public static INDArray createFromArray(Boolean[][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(Double[][][] array) {\n@@ -6541,7 +6542,7 @@ public static INDArray createFromArray(Double[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(Float[][][] array) {\n@@ -6550,7 +6551,7 @@ public static INDArray createFromArray(Float[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(Integer[][][] array) {\n@@ -6559,7 +6560,7 @@ public static INDArray createFromArray(Integer[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(Short[][][] array) {\n@@ -6568,7 +6569,7 @@ public static INDArray createFromArray(Short[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(Byte[][][] array) {\n@@ -6577,7 +6578,7 @@ public static INDArray createFromArray(Byte[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(Long[][][] array) {\n@@ -6586,7 +6587,7 @@ public static INDArray createFromArray(Long[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 3D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(Boolean[][][] array) {\n@@ -6597,7 +6598,7 @@ public static INDArray createFromArray(Boolean[][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with DOUBLE data type\n      */\n     public static INDArray createFromArray(Double[][][][] array) {\n@@ -6606,7 +6607,7 @@ public static INDArray createFromArray(Double[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with FLOAT data type\n      */\n     public static INDArray createFromArray(Float[][][][] array) {\n@@ -6615,7 +6616,7 @@ public static INDArray createFromArray(Float[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT32 data type\n      */\n     public static INDArray createFromArray(Integer[][][][] array) {\n@@ -6624,7 +6625,7 @@ public static INDArray createFromArray(Integer[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT16 data type\n      */\n     public static INDArray createFromArray(Short[][][][] array) {\n@@ -6633,7 +6634,7 @@ public static INDArray createFromArray(Short[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT8 data type\n      */\n     public static INDArray createFromArray(Byte[][][][] array) {\n@@ -6642,7 +6643,7 @@ public static INDArray createFromArray(Byte[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with INT64 data type\n      */\n     public static INDArray createFromArray(Long[][][][] array) {\n@@ -6651,7 +6652,7 @@ public static INDArray createFromArray(Long[][][][] array) {\n \n     /**\n      * This method creates INDArray from provided jvm array\n-     * @param array\n+     * @param array jvm array\n      * @return 4D INDArray with BOOL data type\n      */\n     public static INDArray createFromArray(Boolean[][][][] array) {\n@@ -6692,12 +6693,6 @@ public static INDArray[] exec(CustomOp op, OpContext context){\n \n     /**\n      * This method applies ScatterUpdate op\n-     *\n-     * @param op\n-     * @param array\n-     * @param indices\n-     * @param updates\n-     * @param axis\n      */\n     @Deprecated\n     public static void scatterUpdate(ScatterUpdate.UpdateOp op, @NonNull INDArray array, @NonNull INDArray indices, @NonNull INDArray updates, int... axis) {",
      "parent_sha": "5c908886b09c18cf26c7faa34c1f15d727ba15a1"
    }
  },
  {
    "oid": "ec6abacdb887f68f9cbd74de9a0a24bb5a1cbb76",
    "message": "Fix limits on flaky test to avoid spurious failure (#344)\n\nSigned-off-by: Alex Black <blacka101@gmail.com>",
    "date": "2020-03-24T09:33:43Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/ec6abacdb887f68f9cbd74de9a0a24bb5a1cbb76",
    "details": {
      "sha": "4585b4a150cba8a6d668c9642ba8c63b62e8e14d",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/autodiff/opvalidation/RandomOpValidation.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/ec6abacdb887f68f9cbd74de9a0a24bb5a1cbb76/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fopvalidation%2FRandomOpValidation.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/ec6abacdb887f68f9cbd74de9a0a24bb5a1cbb76/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fopvalidation%2FRandomOpValidation.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fopvalidation%2FRandomOpValidation.java?ref=ec6abacdb887f68f9cbd74de9a0a24bb5a1cbb76",
      "patch": "@@ -76,7 +76,7 @@ public void testRandomOpsSDVarShape() {\n                             double min = in.minNumber().doubleValue();\n                             double max = in.maxNumber().doubleValue();\n                             double mean = in.meanNumber().doubleValue();\n-                            if (min >= 1 && max <= 2 && (in.length() == 1 || Math.abs(mean - 1.5) < 0.1))\n+                            if (min >= 1 && max <= 2 && (in.length() == 1 || Math.abs(mean - 1.5) < 0.2))\n                                 return null;\n                             return \"Failed: min = \" + min + \", max = \" + max + \", mean = \" + mean;\n                         };\n@@ -87,7 +87,7 @@ public void testRandomOpsSDVarShape() {\n                         checkFn = in -> {\n                             double mean = in.meanNumber().doubleValue();\n                             double stdev = in.std(true).getDouble(0);\n-                            if (in.length() == 1 || (Math.abs(mean - 1) < 0.1 && Math.abs(stdev - 1) < 0.1))\n+                            if (in.length() == 1 || (Math.abs(mean - 1) < 0.2 && Math.abs(stdev - 1) < 0.2))\n                                 return null;\n                             return \"Failed: mean = \" + mean + \", stdev = \" + stdev;\n                         };",
      "parent_sha": "4e8f3a025faea346bda2e43d18767100c3e59753"
    }
  },
  {
    "oid": "05d45ec0508def2034510b373a0f61d1abe8bf0e",
    "message": "IndexReduce along dim CUDA fix\n\nSigned-off-by: raver119 <raver119@gmail.com>",
    "date": "2019-08-27T08:31:59Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/05d45ec0508def2034510b373a0f61d1abe8bf0e",
    "details": {
      "sha": "afeff4d8b6e8113fdc24d5a8258572f3b6eb3d83",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-cuda/src/main/java/org/nd4j/linalg/jcublas/ops/executioner/CudaExecutioner.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/05d45ec0508def2034510b373a0f61d1abe8bf0e/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fops%2Fexecutioner%2FCudaExecutioner.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/05d45ec0508def2034510b373a0f61d1abe8bf0e/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fops%2Fexecutioner%2FCudaExecutioner.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fjcublas%2Fops%2Fexecutioner%2FCudaExecutioner.java?ref=05d45ec0508def2034510b373a0f61d1abe8bf0e",
      "patch": "@@ -894,13 +894,13 @@ protected CudaContext invoke(IndexAccumulation op, int[] dimension) {\n \n             //long dimensionPointer = AtomicAllocator.getInstance().getPointer(Nd4j.createBuffer(dimension), context);\n             Pointer dimensionPointer = AtomicAllocator.getInstance()\n-                    .getPointer(AtomicAllocator.getInstance().getConstantBuffer(dimension), context);\n+                    .getHostPointer(AtomicAllocator.getInstance().getConstantBuffer(dimension));\n \n             nativeOps.execIndexReduce(xShapeInfoHostPointer, op.opNum(),\n                     null, (LongPointer) hostXShapeInfo, x, (LongPointer) xShapeInfo,\n                      extraArgs,\n                     null, (LongPointer) hostZShapeInfo, z, (LongPointer) zShapeInfo,\n-                    null,\n+                    dimensionPointer,\n                     (LongPointer) op.dimensions().shapeInfoDataBuffer().addressPointer(),\n                     AtomicAllocator.getInstance().getPointer(op.dimensions(), context),\n                     null);",
      "parent_sha": "df84bc7255b53c359ab1e2284eab73de4d390a79"
    }
  },
  {
    "oid": "01f5fa8c1eb52f21a845d83d767fda34008d366a",
    "message": "Update TestNd4jKryoSerialization.java",
    "date": "2021-03-11T02:58:33Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/01f5fa8c1eb52f21a845d83d767fda34008d366a",
    "details": {
      "sha": "457b462eaffa7ffe4bab5f4313bbb1ce868209c1",
      "filename": "nd4j/nd4j-serde/nd4j-kryo/src/test/java/org/nd4j/TestNd4jKryoSerialization.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/01f5fa8c1eb52f21a845d83d767fda34008d366a/nd4j%2Fnd4j-serde%2Fnd4j-kryo%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2FTestNd4jKryoSerialization.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/01f5fa8c1eb52f21a845d83d767fda34008d366a/nd4j%2Fnd4j-serde%2Fnd4j-kryo%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2FTestNd4jKryoSerialization.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-serde%2Fnd4j-kryo%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2FTestNd4jKryoSerialization.java?ref=01f5fa8c1eb52f21a845d83d767fda34008d366a",
      "patch": "@@ -29,6 +29,7 @@\n import org.apache.spark.serializer.SerializerInstance;\n import org.junit.After;\n import org.junit.Before;\n+import org.junit.Ignore;\n import org.junit.Test;\n import org.nd4j.common.primitives.*;\n import org.nd4j.common.tests.BaseND4JTest;\n@@ -43,7 +44,7 @@\n \n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n-\n+@Ignore(\"Ignoring due to flaky nature of tests\")\n public class TestNd4jKryoSerialization extends BaseND4JTest {\n \n     private JavaSparkContext sc;",
      "parent_sha": "c14f8845c260eb34ab6e783b09703e9f6381a9d6"
    }
  },
  {
    "oid": "e3a86292146a4e0f666c69495cd51ec93f808f9a",
    "message": "2 more try-with-resources (buffered + close)\n\nSigned-off-by: Alex Black <blacka101@gmail.com>",
    "date": "2020-03-31T00:38:12Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/e3a86292146a4e0f666c69495cd51ec93f808f9a",
    "details": {
      "sha": "997303977e900423b2e71ff5a010f02567783628",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java",
      "status": "modified",
      "additions": 5,
      "deletions": 5,
      "changes": 10,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/e3a86292146a4e0f666c69495cd51ec93f808f9a/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/e3a86292146a4e0f666c69495cd51ec93f808f9a/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java?ref=e3a86292146a4e0f666c69495cd51ec93f808f9a",
      "patch": "@@ -415,7 +415,9 @@ public static Pair<MultiLayerNetwork, Normalizer> restoreMultiLayerNetworkAndNor\n      */\n     public static Pair<MultiLayerNetwork, Normalizer> restoreMultiLayerNetworkAndNormalizer(@NonNull File file, boolean loadUpdater)\n             throws IOException {\n-    \treturn restoreMultiLayerNetworkAndNormalizer(new FileInputStream(file), loadUpdater);\n+        try(InputStream is = new BufferedInputStream(new FileInputStream(file))){\n+            return restoreMultiLayerNetworkAndNormalizer(is, loadUpdater);\n+        }\n     }\n \n     /**\n@@ -876,8 +878,8 @@ public static List<String> listObjectsInFile(@NonNull File f){\n      * @return\n      */\n     public static <T extends Normalizer> T restoreNormalizerFromFile(File file) throws IOException {\n-        try {\n-        \treturn restoreNormalizerFromInputStream(new FileInputStream(file));\n+        try (InputStream is = new BufferedInputStream(new FileInputStream(file))) {\n+        \treturn restoreNormalizerFromInputStream(is);\n         } catch (Exception e) {\n             log.warn(\"Error while restoring normalizer, trying to restore assuming deprecated format...\");\n             DataNormalization restoredDeprecated = restoreNormalizerFromInputStreamDeprecated(new FileInputStream(file));\n@@ -918,8 +920,6 @@ public static <T extends Normalizer> T restoreNormalizerFromInputStream(InputStr\n      *\n      * This method restores normalizer from a given persisted model file serialized with Java object serialization\n      *\n-     * @param file\n-     * @return\n      */\n     private static DataNormalization restoreNormalizerFromInputStreamDeprecated(InputStream stream) {\n     \ttry {",
      "parent_sha": "3f49d646fcbafafdb3e8e7880b00e1350bba1a63"
    }
  },
  {
    "oid": "2f74137b5a7eaa934ba9ca8572153a53418d04e4",
    "message": "Update SameDiff.java",
    "date": "2021-04-19T10:05:37Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/2f74137b5a7eaa934ba9ca8572153a53418d04e4",
    "details": {
      "sha": "3366c594b38bdc02cf461f77429f63033be461aa",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/SameDiff.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/2f74137b5a7eaa934ba9ca8572153a53418d04e4/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/2f74137b5a7eaa934ba9ca8572153a53418d04e4/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java?ref=2f74137b5a7eaa934ba9ca8572153a53418d04e4",
      "patch": "@@ -3843,7 +3843,7 @@ public SDVariable[] generateOutputVariableForOp(DifferentialFunction function, S\n \n             //Infer the output types: we can always determine datatype but not always shapes\n             if(isImport || (outputDataTypes != null && outputDataTypes.size() == num_outputs))\n-                log.warn(\n+                log.trace(\n                         \"Incorrect number of output datatypes: got %s but expected datatypes for %s outputs - %s (op: %s), could be due to variable input types.\",\n                         (outputDataTypes == null ? null : outputDataTypes.size()), num_outputs, outputDataTypes, function.getClass().getSimpleName());\n ",
      "parent_sha": "651d578f56910d84e62fae5ad7696cf70fcd056d"
    }
  },
  {
    "oid": "ea56ce747138e413d8fdd953b9994b92f973fbfd",
    "message": "Import fix given recent refactoring\n\nSigned-off-by: Alex Black <blacka101@gmail.com>",
    "date": "2020-05-11T02:25:31Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/ea56ce747138e413d8fdd953b9994b92f973fbfd",
    "details": {
      "sha": "3ecefe0b3bba82a3078d79ec5d614525ee6cd6b9",
      "filename": "arbiter/arbiter-ui/src/test/java/org/deeplearning4j/arbiter/optimize/TestBasic.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/ea56ce747138e413d8fdd953b9994b92f973fbfd/arbiter%2Farbiter-ui%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Foptimize%2FTestBasic.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/ea56ce747138e413d8fdd953b9994b92f973fbfd/arbiter%2Farbiter-ui%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Foptimize%2FTestBasic.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/arbiter%2Farbiter-ui%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Foptimize%2FTestBasic.java?ref=ea56ce747138e413d8fdd953b9994b92f973fbfd",
      "patch": "@@ -57,12 +57,12 @@\n import org.deeplearning4j.ui.model.storage.InMemoryStatsStorage;\n import org.junit.Ignore;\n import org.junit.Test;\n+import org.nd4j.common.function.Function;\n import org.nd4j.evaluation.classification.Evaluation;\n import org.nd4j.linalg.activations.Activation;\n import org.nd4j.linalg.api.buffer.DataType;\n import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n import org.nd4j.linalg.factory.Nd4j;\n-import org.nd4j.linalg.function.Function;\n import org.nd4j.linalg.lossfunctions.LossFunctions;\n \n import java.io.File;",
      "parent_sha": "20f451e807510aee8b3845dbbc364e9ea4867aa9"
    }
  },
  {
    "oid": "206fc1caeba78ffe164f3257a8ef77480dbafb8f",
    "message": "Fixed hashCode() NullPointerException\n\nSigned-off-by: jljljl <jijiji95@bk.ru>",
    "date": "2021-04-02T16:43:45Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/206fc1caeba78ffe164f3257a8ef77480dbafb8f",
    "details": {
      "sha": "71bb2a95a74236b545e92828530a8952beb183c6",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/samediff/AbstractSameDiffLayer.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/206fc1caeba78ffe164f3257a8ef77480dbafb8f/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2Fsamediff%2FAbstractSameDiffLayer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/206fc1caeba78ffe164f3257a8ef77480dbafb8f/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2Fsamediff%2FAbstractSameDiffLayer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2Fsamediff%2FAbstractSameDiffLayer.java?ref=206fc1caeba78ffe164f3257a8ef77480dbafb8f",
      "patch": "@@ -53,7 +53,7 @@\n \n @Slf4j\n @Data\n-@EqualsAndHashCode(callSuper = true)\n+@EqualsAndHashCode(callSuper = true, doNotUseGetters = true)\n public abstract class AbstractSameDiffLayer extends Layer {\n \n     protected List<Regularization> regularization;",
      "parent_sha": "819f3b8c9d5377ed8c3031b4c519f0a3c13e65d3"
    }
  },
  {
    "oid": "2b4d930c35cb353a2ac245a8741d611d7c205ae4",
    "message": "Update NumpyArray.java",
    "date": "2021-07-20T10:40:17Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/2b4d930c35cb353a2ac245a8741d611d7c205ae4",
    "details": {
      "sha": "6de9a9acb04d63cf94e815340cd62aaf789bb9d0",
      "filename": "python4j/python4j-numpy/src/main/java/org/nd4j/python4j/NumpyArray.java",
      "status": "modified",
      "additions": 5,
      "deletions": 5,
      "changes": 10,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/2b4d930c35cb353a2ac245a8741d611d7c205ae4/python4j%2Fpython4j-numpy%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpython4j%2FNumpyArray.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/2b4d930c35cb353a2ac245a8741d611d7c205ae4/python4j%2Fpython4j-numpy%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpython4j%2FNumpyArray.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/python4j%2Fpython4j-numpy%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fpython4j%2FNumpyArray.java?ref=2b4d930c35cb353a2ac245a8741d611d7c205ae4",
      "patch": "@@ -110,7 +110,7 @@ public NumpyArray() {\n \n     @Override\n     public INDArray toJava(PythonObject pythonObject) {\n-        log.info(\"Converting PythonObject to INDArray...\");\n+        log.debug(\"Converting PythonObject to INDArray...\");\n         PyObject np = PyImport_ImportModule(\"numpy\");\n         PyObject ndarray = PyObject_GetAttrString(np, \"ndarray\");\n         if (PyObject_IsInstance(pythonObject.getNativePythonObject(), ndarray) != 1) {\n@@ -199,15 +199,15 @@ public INDArray toJava(PythonObject pythonObject) {\n         }\n         ret = Nd4j.create(buff, shape, nd4jStrides, 0, Shape.getOrder(shape, nd4jStrides, 1), dtype);\n         Nd4j.getAffinityManager().tagLocation(ret, AffinityManager.Location.HOST);\n-        log.info(\"Done.\");\n+        log.debug(\"Done creating numpy arrray.\");\n         return ret;\n \n \n     }\n \n     @Override\n     public PythonObject toPython(INDArray indArray) {\n-        log.info(\"Converting INDArray to PythonObject...\");\n+        log.debug(\"Converting INDArray to PythonObject...\");\n         DataType dataType = indArray.dataType();\n         DataBuffer buff = indArray.data();\n         String key = buff.pointer().address() + \"_\" + buff.length() + \"_\" + dataType;\n@@ -285,14 +285,14 @@ public PythonObject toPython(INDArray indArray) {\n         //likely embedded in python, always use this method instead\n         if(!PythonConstants.releaseGilAutomatically() || PythonConstants.createNpyViaPython()) {\n             try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n-                log.info(\"Stringing exec...\");\n+                log.debug(\"Stringing exec...\");\n                 String code = \"import ctypes\\nimport numpy as np\\n\" +\n                         \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n                         \".from_address(\" + indArray.data().pointer().address() + \")\\n\"+\n                         \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n                         \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n                 PythonExecutioner.exec(code);\n-                log.info(\"exec done.\");\n+                log.debug(\"exec done.\");\n                 PythonObject ret = PythonExecutioner.getVariable(\"npArr\");\n                 Py_IncRef(ret.getNativePythonObject());\n                 return ret;",
      "parent_sha": "10f2808e0ce90bd1da3eaec2e72f7a9a25f67265"
    }
  },
  {
    "oid": "d2489a63df876d3180cb80755442bf6990c44fea",
    "message": "Update CpuLapack.java (#9758)",
    "date": "2022-08-30T07:09:46Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d2489a63df876d3180cb80755442bf6990c44fea",
    "details": {
      "sha": "584099b5929b229922a28fa2202c9cf3db63845f",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-cpu-backend-common/src/main/java/org/nd4j/linalg/cpu/nativecpu/blas/CpuLapack.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d2489a63df876d3180cb80755442bf6990c44fea/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cpu-backend-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fcpu%2Fnativecpu%2Fblas%2FCpuLapack.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d2489a63df876d3180cb80755442bf6990c44fea/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cpu-backend-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fcpu%2Fnativecpu%2Fblas%2FCpuLapack.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cpu-backend-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fcpu%2Fnativecpu%2Fblas%2FCpuLapack.java?ref=d2489a63df876d3180cb80755442bf6990c44fea",
      "patch": "@@ -32,9 +32,11 @@\n import org.nd4j.linalg.indexing.INDArrayIndex;\n import org.nd4j.linalg.indexing.NDArrayIndex;\n \n-import static org.bytedeco.openblas.global.openblas.*;\n \n public class CpuLapack extends BaseLapack {\n+    public static final int LAPACK_ROW_MAJOR = 101;\n+    public static final int LAPACK_COL_MAJOR = 102;\n+\n     protected static int getColumnOrder(INDArray A) {\n         return A.ordering() == 'f' ? LAPACK_COL_MAJOR : LAPACK_ROW_MAJOR;\n     }",
      "parent_sha": "29fd9c70c0dfa690ccedba130b43dc3e36c37b24"
    }
  },
  {
    "oid": "b91dfee7f08ecc649d7887b271c6b8ec6d1f2362",
    "message": "Update Conditions.java",
    "date": "2021-11-08T12:29:59Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b91dfee7f08ecc649d7887b271c6b8ec6d1f2362",
    "details": {
      "sha": "5b157db6ce014fac0e464a60243965b61dc45fc4",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/indexing/conditions/Conditions.java",
      "status": "modified",
      "additions": 16,
      "deletions": 16,
      "changes": 32,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b91dfee7f08ecc649d7887b271c6b8ec6d1f2362/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Findexing%2Fconditions%2FConditions.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b91dfee7f08ecc649d7887b271c6b8ec6d1f2362/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Findexing%2Fconditions%2FConditions.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Findexing%2Fconditions%2FConditions.java?ref=b91dfee7f08ecc649d7887b271c6b8ec6d1f2362",
      "patch": "@@ -27,22 +27,22 @@ public class Conditions {\n     private Conditions() {}\n \n     public enum ConditionMode {\n-        EPSILON_EQUALS(0), //0\n-        EPSILON_NOT_EQUALS(1), //1\n-        LESS_THAN(2), //2\n-        GREATER_THAN(3), //3\n-        LESS_THAN_OR_EQUAL(4), //4\n-        GREATER_THAN_OR_EQUAL(5), //5\n-        ABS_LESS_THAN(6), //6\n-        ABS_GREATER_THAN(7), //7\n-        IS_INFINITE(8), //8\n-        IS_NAN(9), //9\n-        ABS_EQUALS(10), //10\n-        NOT_EQUALS(11), //11\n-        ABS_GREATER_OR_EQUAL(12), //12\n-        ABS_LESS_THAN_OR_EQUAL(13), //13\n-        IS_FINITE(14), //14\n-        NOT_FINITE(15), //15\n+        EPSILON_EQUALS(0),\n+        EPSILON_NOT_EQUALS(1),\n+        LESS_THAN(2),\n+        GREATER_THAN(3),\n+        LESS_THAN_OR_EQUAL(4),\n+        GREATER_THAN_OR_EQUAL(5),\n+        ABS_LESS_THAN(6),\n+        ABS_GREATER_THAN(7),\n+        IS_INFINITE(8),\n+        IS_NAN(9),\n+        ABS_EQUALS(10),\n+        NOT_EQUALS(11),\n+        ABS_GREATER_OR_EQUAL(12),\n+        ABS_LESS_THAN_OR_EQUAL(13),\n+        IS_FINITE(14),\n+        NOT_FINITE(15), \n         AGGREGATE(-1); // this is an aggregate enum for or, and, not, and other indirect conditions that depend on others\n \n ",
      "parent_sha": "db6d7b91c2142a1d4dd4089a5eba879f947325f9"
    }
  },
  {
    "oid": "8e29b1a9eb79cb7ca30b9a0190aaf2c77614f148",
    "message": "Update Nd4jCpuPresets.java",
    "date": "2021-04-22T08:29:25Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/8e29b1a9eb79cb7ca30b9a0190aaf2c77614f148",
    "details": {
      "sha": "9a58316f40027fd4e7927531d5ad6dcce8755f25",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-native-preset/src/main/java/org/nd4j/nativeblas/Nd4jCpuPresets.java",
      "status": "modified",
      "additions": 11,
      "deletions": 7,
      "changes": 18,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/8e29b1a9eb79cb7ca30b9a0190aaf2c77614f148/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/8e29b1a9eb79cb7ca30b9a0190aaf2c77614f148/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java?ref=8e29b1a9eb79cb7ca30b9a0190aaf2c77614f148",
      "patch": "@@ -27,10 +27,7 @@\n \n import java.io.File;\n import java.io.IOException;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collections;\n-import java.util.Scanner;\n+import java.util.*;\n \n /**\n  *\n@@ -254,10 +251,17 @@ public void map(InfoMap infoMap) {\n                 break;\n             }\n         }\n-        ArrayList<File> files = new ArrayList<File>();\n-        ArrayList<String> opTemplates = new ArrayList<String>();\n+        List<File> files = new ArrayList<>();\n+        List<String> opTemplates = new ArrayList<>();\n+        if(file == null) {\n+            throw new IllegalStateException(\"No file found in include paths. Please ensure one of the include paths leads to path/ops/declarable/CustomOperations.h\");\n+        }\n         files.add(file);\n-        files.addAll(Arrays.asList(new File(file.getParent(), \"headers\").listFiles()));\n+        File[] headers = new File(file.getParent(), \"headers\").listFiles();\n+        if(headers == null) {\n+            throw new IllegalStateException(\"No headers found for file \" + file.getAbsolutePath());\n+        }\n+        files.addAll(Arrays.asList(headers));\n         Collections.sort(files);\n         for (File f : files) {\n             try (Scanner scanner = new Scanner(f, \"UTF-8\")) {",
      "parent_sha": "67ae50c61f47736b94c9c64ad706d7a60061950c"
    }
  },
  {
    "oid": "b6b8c3c4ecb0206b47de8a1ad40b5b985caccdf8",
    "message": "Update TestStrumpf.java",
    "date": "2021-03-12T00:24:04Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b6b8c3c4ecb0206b47de8a1ad40b5b985caccdf8",
    "details": {
      "sha": "292f0b8b7671217c370b8e07e52e5a94653b61a8",
      "filename": "nd4j/nd4j-common/src/test/java/org/nd4j/common/resources/TestStrumpf.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b6b8c3c4ecb0206b47de8a1ad40b5b985caccdf8/nd4j%2Fnd4j-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fcommon%2Fresources%2FTestStrumpf.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b6b8c3c4ecb0206b47de8a1ad40b5b985caccdf8/nd4j%2Fnd4j-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fcommon%2Fresources%2FTestStrumpf.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Fcommon%2Fresources%2FTestStrumpf.java?ref=b6b8c3c4ecb0206b47de8a1ad40b5b985caccdf8",
      "patch": "@@ -45,7 +45,7 @@ public class TestStrumpf {\n     @Rule\n     public TemporaryFolder testDir = new TemporaryFolder();\n \n-    @Test\n+/*    @Test\n     public void testResolvingReference() throws Exception {\n \n         File f = Resources.asFile(\"big/raw_sentences.txt\");\n@@ -58,7 +58,7 @@ public void testResolvingReference() throws Exception {\n                 System.out.println(\"LINE \" + i + \": \" + iter.next());\n             }\n         }\n-    }\n+    }*/\n \n     @Test\n     public void testResolvingActual() throws Exception {",
      "parent_sha": "d7b12dab16fa8f1cc644668ae56002c4feaaf8fe"
    }
  },
  {
    "oid": "d256f08d98c594efbb52625813a09b02141bceba",
    "message": "Update Nd4jCpuPresets.java",
    "date": "2021-06-20T01:57:06Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d256f08d98c594efbb52625813a09b02141bceba",
    "details": {
      "sha": "903b3fcedcd46208bd941c9ef01f8149b61800a0",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-native-preset/src/main/java/org/nd4j/nativeblas/Nd4jCpuPresets.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d256f08d98c594efbb52625813a09b02141bceba/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d256f08d98c594efbb52625813a09b02141bceba/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java?ref=d256f08d98c594efbb52625813a09b02141bceba",
      "patch": "@@ -152,7 +152,7 @@\n                 @Platform(value = \"linux-arm64\", preloadpath = {\"/usr/aarch64-linux-gnu/lib/\", \"/usr/lib/aarch64-linux-gnu/\"}),\n                 @Platform(value = \"linux-ppc64\", preloadpath = {\"/usr/powerpc64-linux-gnu/lib/\", \"/usr/powerpc64le-linux-gnu/lib/\", \"/usr/lib/powerpc64-linux-gnu/\", \"/usr/lib/powerpc64le-linux-gnu/\"}),\n                 @Platform(value = \"windows\", preload = {\"libwinpthread-1\", \"libgcc_s_seh-1\", \"libgomp-1\", \"libstdc++-6\", \"libnd4jcpu\"}),\n-                @Platform(extension = {\"-onednn\", \"-onednn-avx512\",\"-onednn-avx2\",\"-\",\"-avx2\",\"-avx512\"}) })\n+                @Platform(extension = {\"-onednn\", \"-onednn-avx512\",\"-onednn-avx2\",\"-\",\"-avx2\",\"-avx512\",\"-compat\"}) })\n public class Nd4jCpuPresets implements InfoMapper, BuildEnabled {\n \n     private Logger logger;",
      "parent_sha": "8f6f6f86167fd6daddaa9f7fa4341a234e04c155"
    }
  },
  {
    "oid": "f9c1faaaf968d6f0e5a5add2627908f7a2565f96",
    "message": "Fix the URL in the NoAvailableBackendException (#10051)\n\nSigned-off-by: jtaubner <JakeTaubner@protonmail.com>",
    "date": "2023-12-10T00:55:22Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/f9c1faaaf968d6f0e5a5add2627908f7a2565f96",
    "details": {
      "sha": "89c4c5cd73513d30d91125b0eef7fa1899873480",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4jBackend.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/f9c1faaaf968d6f0e5a5add2627908f7a2565f96/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4jBackend.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/f9c1faaaf968d6f0e5a5add2627908f7a2565f96/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4jBackend.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4jBackend.java?ref=f9c1faaaf968d6f0e5a5add2627908f7a2565f96",
      "patch": "@@ -209,7 +209,7 @@ public static Nd4jBackend load() throws NoAvailableBackendException {\n \n         else\n             throw new NoAvailableBackendException(\n-                            \"Please ensure that you have an nd4j backend on your classpath. Please see: https://deeplearning4j.konduit.ai/nd4j/backend\");\n+                            \"Please ensure that you have an nd4j backend on your classpath. Please see: https://deeplearning4j.konduit.ai/multi-project/explanation/configuration/backends\");\n \n         triedDynamicLoad = true;\n         //load all the discoverable uris and try to load the backend again",
      "parent_sha": "6082079d30bf877d6306b7db28dc11de5328635a"
    }
  },
  {
    "oid": "203c5434b30905dc8b5b4dacf254d5f35bb4487d",
    "message": "Update HelperUtilsTest.java",
    "date": "2021-05-24T13:51:23Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/203c5434b30905dc8b5b4dacf254d5f35bb4487d",
    "details": {
      "sha": "3a0dcafba5e55b943fb7c20b2fb72359431f158d",
      "filename": "deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/layers/HelperUtilsTest.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/203c5434b30905dc8b5b4dacf254d5f35bb4487d/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtilsTest.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/203c5434b30905dc8b5b4dacf254d5f35bb4487d/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtilsTest.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Flayers%2FHelperUtilsTest.java?ref=203c5434b30905dc8b5b4dacf254d5f35bb4487d",
      "patch": "@@ -25,6 +25,7 @@\n import org.deeplearning4j.nn.conf.ComputationGraphConfiguration;\n import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n+import org.deeplearning4j.nn.conf.dropout.DropoutHelper;\n import org.deeplearning4j.nn.conf.inputs.InputType;\n import org.deeplearning4j.nn.conf.layers.ActivationLayer;\n import org.deeplearning4j.nn.conf.layers.OutputLayer;\n@@ -82,7 +83,8 @@ public void testOneDnnHelperCreation() {\n                 LocalResponseNormalizationHelper.class,\"layername\",getDataType()));\n         assertNotNull(HelperUtils.createHelper(\"\", MKLDNNSubsamplingHelper.class.getName(),\n                 SubsamplingHelper.class,\"layername\",getDataType()));\n-\n+        assertNotNull(HelperUtils.createHelper(\"\", \"\",\n+                DropoutHelper.class,\"layername\",getDataType()));\n \n     }\n ",
      "parent_sha": "9a610ad57c88eb3b27c34be4c1f4b8d32a822ae7"
    }
  },
  {
    "oid": "d58a4b45b17058ef5d5f8e71261405fadb99c835",
    "message": "Fix Nadam updater clone missing schedule (#8243)\n\nSigned-off-by: Steven Lang <steven.lang.mz@gmail.com>",
    "date": "2019-09-17T19:56:49Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d58a4b45b17058ef5d5f8e71261405fadb99c835",
    "details": {
      "sha": "781bd2d07f3ff7a2719999df728e4d1d6cb36a80",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/learning/config/Nadam.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d58a4b45b17058ef5d5f8e71261405fadb99c835/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FNadam.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d58a4b45b17058ef5d5f8e71261405fadb99c835/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FNadam.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Flearning%2Fconfig%2FNadam.java?ref=d58a4b45b17058ef5d5f8e71261405fadb99c835",
      "patch": "@@ -101,7 +101,7 @@ public GradientUpdater instantiate(Map<String, INDArray> updaterState, boolean i\n \n     @Override\n     public Nadam clone() {\n-        return new Nadam(learningRate, beta1, beta2, epsilon);\n+        return new Nadam(learningRate, learningRateSchedule, beta1, beta2, epsilon);\n     }\n \n     @Override",
      "parent_sha": "83d958d53638550df2a98384d609ef0cb1178ecd"
    }
  },
  {
    "oid": "7f571b3c5287f288c21c8e3d7fadaad559a2edb7",
    "message": "Fixing DL4J UI system property for getting port value (#9162)\n\nSigned-off-by: shamsulazeem <shamsazeem20@gmail.com>",
    "date": "2021-01-24T23:13:34Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/7f571b3c5287f288c21c8e3d7fadaad559a2edb7",
    "details": {
      "sha": "ddc8187e4555008ac89ddd5d10f4f3127aeb4e38",
      "filename": "deeplearning4j/deeplearning4j-ui-parent/deeplearning4j-vertx/src/main/java/org/deeplearning4j/ui/VertxUIServer.java",
      "status": "modified",
      "additions": 5,
      "deletions": 1,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/7f571b3c5287f288c21c8e3d7fadaad559a2edb7/deeplearning4j%2Fdeeplearning4j-ui-parent%2Fdeeplearning4j-vertx%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fui%2FVertxUIServer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/7f571b3c5287f288c21c8e3d7fadaad559a2edb7/deeplearning4j%2Fdeeplearning4j-ui-parent%2Fdeeplearning4j-vertx%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fui%2FVertxUIServer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-ui-parent%2Fdeeplearning4j-vertx%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fui%2FVertxUIServer.java?ref=7f571b3c5287f288c21c8e3d7fadaad559a2edb7",
      "patch": "@@ -369,7 +369,7 @@ public void start(Promise<Void> startCallback) throws Exception {\n \n         //Check port property\n         int port = instancePort == null ? DEFAULT_UI_PORT : instancePort;\n-        String portProp = System.getenv(DL4JSystemProperties.UI_SERVER_PORT_PROPERTY);\n+        String portProp = System.getProperty(DL4JSystemProperties.UI_SERVER_PORT_PROPERTY);\n         if(portProp != null && !portProp.isEmpty()){\n             try{\n                 port = Integer.parseInt(portProp);\n@@ -378,6 +378,10 @@ public void start(Promise<Void> startCallback) throws Exception {\n             }\n         }\n \n+\tif (port < 0 || port > 0xFFFF) {\n+            throw new IllegalStateException(\"Valid port range is 0 <= port <= 65535. The given port was \" + port);\n+        }\n+\n         uiEventRoutingThread = new Thread(new StatsEventRouterRunnable());\n         uiEventRoutingThread.setDaemon(true);\n         uiEventRoutingThread.start();",
      "parent_sha": "124d0a1965c99e5c8a8fb39430fb82a710df600f"
    }
  },
  {
    "oid": "b84bdc4e1db73bcb2471481505258541a9b8d72d",
    "message": "Update BaseLoss.java",
    "date": "2021-10-27T08:09:27Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b84bdc4e1db73bcb2471481505258541a9b8d72d",
    "details": {
      "sha": "2826f6c91323d652107539d7cd9023bb1902496a",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/loss/BaseLoss.java",
      "status": "modified",
      "additions": 1,
      "deletions": 4,
      "changes": 5,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b84bdc4e1db73bcb2471481505258541a9b8d72d/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Floss%2FBaseLoss.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b84bdc4e1db73bcb2471481505258541a9b8d72d/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Floss%2FBaseLoss.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Floss%2FBaseLoss.java?ref=b84bdc4e1db73bcb2471481505258541a9b8d72d",
      "patch": "@@ -71,10 +71,7 @@ protected void addArgs(){\n \n     public abstract String opName();\n \n-    @Override\n-    public int getNumOutputs() {\n-        return 1;\n-    }\n+ \n \n     @Override\n     public List<DataType> calculateOutputDataTypes(List<DataType> inputDataTypes){",
      "parent_sha": "cc802f7dad353e777fbe098d637d98f69bb15e0d"
    }
  },
  {
    "oid": "6e9c849e4a4e6ae87c8876b6b3929d6581c20f39",
    "message": "Fix typo (#469)",
    "date": "2020-05-18T05:46:46Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/6e9c849e4a4e6ae87c8876b6b3929d6581c20f39",
    "details": {
      "sha": "b57171a144ca62cd9d330da483e230bb947ba283",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/main/java/org/deeplearning4j/nn/modelimport/keras/KerasModel.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/6e9c849e4a4e6ae87c8876b6b3929d6581c20f39/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2FKerasModel.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/6e9c849e4a4e6ae87c8876b6b3929d6581c20f39/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2FKerasModel.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2FKerasModel.java?ref=6e9c849e4a4e6ae87c8876b6b3929d6581c20f39",
      "patch": "@@ -171,7 +171,7 @@ protected KerasModel(String modelJson, String modelYaml, Hdf5Archive weightsArch\n                 importTrainingConfiguration(trainingJson);\n             else log.warn(\"If enforceTrainingConfig is true, a training \" +\n                     \"configuration object has to be provided. Usually the only practical way to do this is to store\" +\n-                    \" your keras model with `model.save('model_path.h5'. If you store model config and weights\" +\n+                    \" your keras model with `model.save('model_path.h5')`. If you store model config and weights\" +\n                     \" separately no training configuration is attached.\");\n         }\n ",
      "parent_sha": "4bdd5cb8ff4b08b80031abebfd88d4da8307f7f9"
    }
  },
  {
    "oid": "c1595586fa4bfc7e6bdb6e1487c6afdf4aadccd7",
    "message": "Fixes #7865 (#9832)\n\n* Fixes #9830\r\n\r\n* Fix https://github.com/deeplearning4j/deeplearning4j/issues/7865",
    "date": "2022-11-01T21:26:25Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/c1595586fa4bfc7e6bdb6e1487c6afdf4aadccd7",
    "details": {
      "sha": "293b8c8e2aa1bc4093bf034afe31d3f8aedf2fd3",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java",
      "status": "modified",
      "additions": 1,
      "deletions": 11,
      "changes": 12,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/c1595586fa4bfc7e6bdb6e1487c6afdf4aadccd7/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmultilayer%2FMultiLayerNetwork.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/c1595586fa4bfc7e6bdb6e1487c6afdf4aadccd7/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmultilayer%2FMultiLayerNetwork.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmultilayer%2FMultiLayerNetwork.java?ref=c1595586fa4bfc7e6bdb6e1487c6afdf4aadccd7",
      "patch": "@@ -2104,17 +2104,7 @@ protected Pair<Gradient, INDArray> calcBackpropGradients(INDArray epsilon, boole\n \n     protected void doTruncatedBPTT(INDArray input, INDArray labels, INDArray featuresMaskArray,\n                                    INDArray labelsMaskArray, LayerWorkspaceMgr workspaceMgr) {\n-        if (input.rank() != 3 || labels.rank() != 3) {\n-            log.warn(\"Cannot do truncated BPTT with non-3d inputs or labels. Expect input with shape [miniBatchSize,nIn,timeSeriesLength], got \"\n-                    + Arrays.toString(input.shape()) + \"\\tand labels with shape \"\n-                    + Arrays.toString(labels.shape()));\n-            return;\n-        }\n-        if (input.size(2) != labels.size(2)) {\n-            log.warn(\"Input and label time series have different lengths: {} input length, {} label length\",\n-                    input.size(2), labels.size(2));\n-            return;\n-        }\n+\n \n         int fwdLen = layerWiseConfigurations.getTbpttFwdLength();\n         update(TaskUtils.buildTask(input, labels));",
      "parent_sha": "1d7b8ddb9388fb08b79e06ac9befb375a97d7a23"
    }
  },
  {
    "oid": "f446c74bf4e90f6447be8f98ea1a81f882fd82b5",
    "message": "Update SubsamplingLayer.java",
    "date": "2021-06-08T08:43:08Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/f446c74bf4e90f6447be8f98ea1a81f882fd82b5",
    "details": {
      "sha": "91d97ff437dcf146fceccaef6c3bb3851031dd27",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/SubsamplingLayer.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/f446c74bf4e90f6447be8f98ea1a81f882fd82b5/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FSubsamplingLayer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/f446c74bf4e90f6447be8f98ea1a81f882fd82b5/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FSubsamplingLayer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FSubsamplingLayer.java?ref=f446c74bf4e90f6447be8f98ea1a81f882fd82b5",
      "patch": "@@ -100,12 +100,12 @@ protected SubsamplingLayer(BaseSubsamplingBuilder builder) {\n         this.stride = builder.stride;\n         this.padding = builder.padding;\n         this.convolutionMode = builder.convolutionMode;\n+        this.cnn2dDataFormat = builder.cnn2DFormat;\n+\n         if (builder instanceof Builder) {\n             this.dilation = ((Builder) builder).dilation;\n-            this.cnn2dDataFormat = builder.cnn2DFormat;\n-        } else {\n-            this.cnn2dDataFormat = builder.cnn2DFormat;\n         }\n+        \n         this.pnorm = builder.pnorm;\n         this.eps = builder.eps;\n         this.cudnnAllowFallback = builder.cudnnAllowFallback;",
      "parent_sha": "0ac00c951db491600d4ca967897c5eddc7ab3988"
    }
  },
  {
    "oid": "7d68fc1d123b3079a9d3b6ab4a576876e9360132",
    "message": "Update LayerValidation.java",
    "date": "2021-05-06T04:13:10Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/7d68fc1d123b3079a9d3b6ab4a576876e9360132",
    "details": {
      "sha": "f2d7b9da1ebe3484526f60ed847cb4da505b6d5f",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LayerValidation.java",
      "status": "modified",
      "additions": 1,
      "deletions": 4,
      "changes": 5,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/7d68fc1d123b3079a9d3b6ab4a576876e9360132/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/7d68fc1d123b3079a9d3b6ab4a576876e9360132/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java?ref=7d68fc1d123b3079a9d3b6ab4a576876e9360132",
      "patch": "@@ -131,25 +131,22 @@ public static void generalValidation(String layerName, Layer layer, IDropout iDr\n     private static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout,\n                                            List<Regularization> regularization, List<Regularization> regularizationBias) {\n         if (regularization != null && !regularization.isEmpty()) {\n-            final List<Regularization> bLayerRegs = bLayer.getRegularization();\n+            final List<Regularization> bLayerRegs = new ArrayList<>(bLayer.getRegularization());\n             if (bLayerRegs == null || bLayerRegs.isEmpty()) {\n                 bLayer.setRegularization(regularization);\n             } else {\n                 boolean hasL1 = false;\n                 boolean hasL2 = false;\n                 final List<Regularization> regContext = regularization;\n                 for (final Regularization reg : bLayerRegs) {\n-\n                     if (reg instanceof L1Regularization) {\n-\n                         hasL1 = true;\n                     } else if (reg instanceof L2Regularization) {\n                         hasL2 = true;\n                     }\n                 }\n                 for (final Regularization reg : regContext) {\n                     if (reg instanceof L1Regularization) {\n-\n                         if (!hasL1)\n                             bLayerRegs.add(reg);\n                     } else if (reg instanceof L2Regularization) {",
      "parent_sha": "38be0b6387c095b5e0a0d41f2c780e9f985068a0"
    }
  },
  {
    "oid": "0caf50f80f6ee411fa8f83d91bf45910e700e512",
    "message": "SDLoss cleanup. (#180)\n\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2020-01-23T11:22:06Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/0caf50f80f6ee411fa8f83d91bf45910e700e512",
    "details": {
      "sha": "96d76c52dc0c3e7ce29aea00d9ee262abbc0e0ea",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/ops/SDLoss.java",
      "status": "modified",
      "additions": 20,
      "deletions": 63,
      "changes": 83,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/0caf50f80f6ee411fa8f83d91bf45910e700e512/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fops%2FSDLoss.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/0caf50f80f6ee411fa8f83d91bf45910e700e512/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fops%2FSDLoss.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fops%2FSDLoss.java?ref=0caf50f80f6ee411fa8f83d91bf45910e700e512",
      "patch": "@@ -1,4 +1,4 @@\n-/*******************************************************************************\n+/* *****************************************************************************\n  * Copyright (c) 2015-2019 Skymind, Inc.\n  *\n  * This program and the accompanying materials are made available under the\n@@ -34,11 +34,20 @@\n  *\n  * @author Alex Black\n  */\n+@SuppressWarnings(\"unused\")\n public class SDLoss extends SDOps {\n     public SDLoss(SameDiff sameDiff) {\n         super(sameDiff);\n     }\n \n+    /**\n+     * helper to refactor duplicate code\n+     */\n+    private SDVariable getWeights(SDVariable weights, String name, SDVariable predictions){\n+        String weightName = (name == null) ? null : name + \"/weight\";\n+        return (weights == null) ? null : sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n+    }\n+\n     /**\n      * See {@link #absoluteDifference(String, SDVariable, SDVariable, SDVariable, LossReduce)}.\n      */\n@@ -60,12 +69,7 @@ public SDVariable absoluteDifference(String name, @NonNull SDVariable label, @No\n                                          SDVariable weights, @NonNull LossReduce lossReduce) {\n         validateFloatingPoint(\"absolute difference loss\", \"predictions\", predictions);\n         validateNumerical(\"absolute difference loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossAbsoluteDifference(label, predictions, weights, lossReduce);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -105,12 +109,7 @@ public SDVariable cosineDistance(String name, @NonNull SDVariable label, @NonNul\n                                      SDVariable weights, @NonNull LossReduce lossReduce, int dimension) {\n         validateFloatingPoint(\"cosine distance loss\", \"predictions\", predictions);\n         validateNumerical(\"cosine distance loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossCosineDistance(label, predictions, weights, lossReduce, dimension);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -192,12 +191,7 @@ public SDVariable huberLoss(String name, @NonNull SDVariable label, @NonNull SDV\n                                 SDVariable weights, @NonNull LossReduce lossReduce, double delta) {\n         validateFloatingPoint(\"huber loss\", \"predictions\", predictions);\n         validateNumerical(\"huber loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossHuber(label, predictions, weights, lossReduce, delta);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -258,12 +252,7 @@ public SDVariable logLoss(String name, @NonNull SDVariable label, @NonNull SDVar\n                               SDVariable weights, @NonNull LossReduce lossReduce, double epsilon) {\n         validateFloatingPoint(\"log loss\", \"predictions\", predictions);\n         validateNumerical(\"log loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossLog(label, predictions, weights, lossReduce, epsilon);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -299,12 +288,7 @@ public SDVariable logPoisson(String name, @NonNull SDVariable label, @NonNull SD\n                                  SDVariable weights, @NonNull LossReduce lossReduce) {\n         validateFloatingPoint(\"log poisson loss\", \"predictions\", predictions);\n         validateNumerical(\"log poisson loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossLogPoisson(label, predictions, weights, lossReduce);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -341,12 +325,7 @@ public SDVariable logPoissonFull(String name, @NonNull SDVariable label, @NonNul\n                                      SDVariable weights, @NonNull LossReduce lossReduce) {\n         validateFloatingPoint(\"log poisson (full) loss\", \"predictions\", predictions);\n         validateNumerical(\"log poisson (full) loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossLogPoissonFull(label, predictions, weights, lossReduce);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -382,12 +361,7 @@ public SDVariable meanPairwiseSquaredError(String name, @NonNull SDVariable labe\n     public SDVariable meanPairwiseSquaredError(String name, @NonNull SDVariable label, @NonNull SDVariable predictions, SDVariable weights, @NonNull LossReduce lossReduce) {\n         validateFloatingPoint(\"main pairwise squared error loss\", \"predictions\", predictions);\n         validateNumerical(\"mean pairwise squared error loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossMeanPairwiseSquaredError(label, predictions, weights, lossReduce);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -417,12 +391,7 @@ public SDVariable meanSquaredError(String name, @NonNull SDVariable label, @NonN\n                                        SDVariable weights, @NonNull LossReduce lossReduce) {\n         validateFloatingPoint(\"mean squared error loss\", \"predictions\", predictions);\n         validateNumerical(\"mean squared error loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictions);\n         SDVariable result = f().lossMeanSquaredError(label, predictions, weights, lossReduce);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -468,12 +437,7 @@ public SDVariable sigmoidCrossEntropy(String name, @NonNull SDVariable label, @N\n                                           SDVariable weights, @NonNull LossReduce lossReduce, double labelSmoothing) {\n         validateFloatingPoint(\"sigmoid cross entropy loss\", \"predictions\", predictionLogits);\n         validateNumerical(\"sigmoid cross entropy loss\", \"labels\", label);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(predictionLogits.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, predictionLogits);\n         SDVariable result = f().lossSigmoidCrossEntropy(label, predictionLogits, weights, lossReduce, labelSmoothing);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -518,12 +482,7 @@ public SDVariable softmaxCrossEntropy(String name, @NonNull SDVariable oneHotLab\n                                           SDVariable weights, @NonNull LossReduce lossReduce, double labelSmoothing) {\n         validateFloatingPoint(\"softmax cross entropy loss\", \"predictions\", logitPredictions);\n         validateNumerical(\"softmax cross entropy loss\", \"oneHotLabels\", oneHotLabels);\n-        if (weights == null) {\n-            String weightName = null;\n-            if(name != null)\n-                weightName = name + \"/weight\";\n-            weights = sd.constant(weightName, Nd4j.scalar(logitPredictions.dataType(), 1.0));\n-        }\n+        weights = getWeights(weights, name, logitPredictions);\n         SDVariable result = f().lossSoftmaxCrossEntropy(oneHotLabels, logitPredictions, weights, lossReduce, labelSmoothing);\n         result = updateVariableNameAndReference(result, name);\n         result.markAsLoss();\n@@ -595,6 +554,4 @@ public SDVariable weightedCrossEntropyWithLogits(String name, SDVariable targets\n         result.markAsLoss();\n         return result;\n     }\n-\n-\n }",
      "parent_sha": "256c9d20b0482df7c84843ca42794fd5289591e0"
    }
  },
  {
    "oid": "37f0b0274811df62aeec0354429b7232c82b2cbe",
    "message": "Update Nd4jCpuPresets.java",
    "date": "2021-06-17T07:17:01Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/37f0b0274811df62aeec0354429b7232c82b2cbe",
    "details": {
      "sha": "903b3fcedcd46208bd941c9ef01f8149b61800a0",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-native-preset/src/main/java/org/nd4j/nativeblas/Nd4jCpuPresets.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/37f0b0274811df62aeec0354429b7232c82b2cbe/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/37f0b0274811df62aeec0354429b7232c82b2cbe/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-native-preset%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jCpuPresets.java?ref=37f0b0274811df62aeec0354429b7232c82b2cbe",
      "patch": "@@ -152,7 +152,7 @@\n                 @Platform(value = \"linux-arm64\", preloadpath = {\"/usr/aarch64-linux-gnu/lib/\", \"/usr/lib/aarch64-linux-gnu/\"}),\n                 @Platform(value = \"linux-ppc64\", preloadpath = {\"/usr/powerpc64-linux-gnu/lib/\", \"/usr/powerpc64le-linux-gnu/lib/\", \"/usr/lib/powerpc64-linux-gnu/\", \"/usr/lib/powerpc64le-linux-gnu/\"}),\n                 @Platform(value = \"windows\", preload = {\"libwinpthread-1\", \"libgcc_s_seh-1\", \"libgomp-1\", \"libstdc++-6\", \"libnd4jcpu\"}),\n-                @Platform(extension = {\"-onednn\", \"-onednn-avx512\",\"-onednn-avx2\",\"-\",\"-avx2\",\"-avx512\"}) })\n+                @Platform(extension = {\"-onednn\", \"-onednn-avx512\",\"-onednn-avx2\",\"-\",\"-avx2\",\"-avx512\",\"-compat\"}) })\n public class Nd4jCpuPresets implements InfoMapper, BuildEnabled {\n \n     private Logger logger;",
      "parent_sha": "3ef99ef2b8715158dc6ed04e0183c6cd3763b26b"
    }
  },
  {
    "oid": "55be66906966a49e8f9fbb7236d23636c1250e13",
    "message": "use last completed task for Total Runtime instead of currentTimeMillis in ArbiterModule Summary Status\n\nSigned-off-by: Tam\u00e1s Fenyvesi <tamas.fenyvesi@doknet.hu>",
    "date": "2020-05-08T11:07:59Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/55be66906966a49e8f9fbb7236d23636c1250e13",
    "details": {
      "sha": "7a8d703878de96946b7a0b5d9155d3babae8f375",
      "filename": "arbiter/arbiter-ui/src/main/java/org/deeplearning4j/arbiter/ui/module/ArbiterModule.java",
      "status": "modified",
      "additions": 6,
      "deletions": 2,
      "changes": 8,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/55be66906966a49e8f9fbb7236d23636c1250e13/arbiter%2Farbiter-ui%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Fui%2Fmodule%2FArbiterModule.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/55be66906966a49e8f9fbb7236d23636c1250e13/arbiter%2Farbiter-ui%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Fui%2Fmodule%2FArbiterModule.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/arbiter%2Farbiter-ui%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Farbiter%2Fui%2Fmodule%2FArbiterModule.java?ref=55be66906966a49e8f9fbb7236d23636c1250e13",
      "patch": "@@ -788,7 +788,6 @@ private void getSummaryStatus(String sessionId, RoutingContext rc){\n \n         //TODO: I18N\n \n-        //TODO don't use currentTimeMillis due to stored data??\n         long bestTime;\n         Double bestScore = null;\n         String bestModelString = null;\n@@ -805,7 +804,12 @@ private void getSummaryStatus(String sessionId, RoutingContext rc){\n         String execTotalRuntimeStr = \"\";\n         if(execStartTime > 0){\n             execStartTimeStr = TIME_FORMATTER.print(execStartTime);\n-            execTotalRuntimeStr = UIUtils.formatDuration(System.currentTimeMillis() - execStartTime);\n+            // allModelInfo is sorted by Persistable::getTimeStamp\n+            long lastCompleteTime = execStartTime;\n+            if (!allModelInfo.isEmpty()) {\n+                lastCompleteTime = allModelInfo.get(allModelInfo.size() - 1).getTimeStamp();\n+            }\n+            execTotalRuntimeStr = UIUtils.formatDuration(lastCompleteTime - execStartTime);\n         }\n \n ",
      "parent_sha": "cf11c2394a18d3e00e56eef92bd99570d2f135d7"
    }
  },
  {
    "oid": "fa98b8329519a033330b91719f38b08729d04b18",
    "message": "remove duplicate code in createBufferDetached. (#83)\n\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-05T01:22:59Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/fa98b8329519a033330b91719f38b08729d04b18",
    "details": {
      "sha": "82dd64337f12c6db0bcc2607c72ec66c1d90a650",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 16,
      "deletions": 46,
      "changes": 62,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/fa98b8329519a033330b91719f38b08729d04b18/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/fa98b8329519a033330b91719f38b08729d04b18/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=fa98b8329519a033330b91719f38b08729d04b18",
      "patch": "@@ -1389,51 +1389,6 @@ else if (type == DataType.DOUBLE)\n             return Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.createFloat(length, true) : DATA_BUFFER_FACTORY_INSTANCE.createFloat(length, true, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n-    /**\n-     * Create a buffer equal of length prod(shape). The buffer is 'detached': Not in any memory workspace even if a\n-     * workspace is currently open.\n-     *\n-     * @param shape the shape of the buffer to create\n-     * @param type the opType to create\n-     * @return\n-     */\n-    public static DataBuffer createBufferDetached(int[] shape, DataType type) {\n-        long length = ArrayUtil.prodLong(shape);\n-        switch (type){\n-            case DOUBLE:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createDouble(length);\n-            case FLOAT:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createFloat(length);\n-            case HALF:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createHalf(length);\n-            case BFLOAT16:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createBFloat16(length);\n-            case UINT64:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createULong(length);\n-            case LONG:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createLong(length);\n-            case UINT32:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createUInt(length);\n-            case INT:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createInt(length);\n-            case UINT16:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createUShort(length);\n-            case SHORT:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createShort(length);\n-            case UBYTE:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createUByte(length);\n-            case BYTE:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createByte(length);\n-            case BOOL:\n-                return DATA_BUFFER_FACTORY_INSTANCE.createBool(length);\n-            case UTF8:\n-            case COMPRESSED:\n-            case UNKNOWN:\n-            default:\n-                throw new UnsupportedOperationException(\"Cannot create type: \" + type);\n-        }\n-    }\n-\n     /**\n      * See {@link  #createBuffer(int[], DataType)}\n      */\n@@ -1475,12 +1430,27 @@ public static DataBuffer createBuffer(long[] shape, DataType type) {\n         }\n     }\n \n+    /**\n+     * Create a buffer equal of length prod(shape). The buffer is 'detached': Not in any memory workspace even if a\n+     * workspace is currently open.\n+     *\n+     * @param shape the shape of the buffer to create\n+     * @param type the opType to create\n+     * @return\n+     */\n+    public static DataBuffer createBufferDetached(int[] shape, DataType type) {\n+        return createBufferDetachedImpl( ArrayUtil.prodLong(shape), type);\n+    }\n \n     /**\n      * See {@link  #createBufferDetached(int[], DataType)}\n      */\n     public static DataBuffer createBufferDetached(long[] shape, DataType type) {\n-        long length = ArrayUtil.prodLong(shape);\n+        return createBufferDetachedImpl( ArrayUtil.prodLong(shape), type);\n+    }\n+\n+    // used by createBufferDetached(long[] DataType) and createBufferDetached(int[] , DataType)\n+    private static DataBuffer createBufferDetachedImpl(long length, DataType type){\n         switch (type){\n \n             case DOUBLE:",
      "parent_sha": "526b782e5122fac314c3d01367da86e79701e8f2"
    }
  },
  {
    "oid": "d3221dbfd24881869696b94d37de9e133f578c2d",
    "message": "Fix minor one hot bug",
    "date": "2021-11-29T01:18:11Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/d3221dbfd24881869696b94d37de9e133f578c2d",
    "details": {
      "sha": "b265099739928851b07ceb859a73f707650ec78a",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/shape/OneHot.java",
      "status": "modified",
      "additions": 9,
      "deletions": 2,
      "changes": 11,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/d3221dbfd24881869696b94d37de9e133f578c2d/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FOneHot.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/d3221dbfd24881869696b94d37de9e133f578c2d/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FOneHot.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FOneHot.java?ref=d3221dbfd24881869696b94d37de9e133f578c2d",
      "patch": "@@ -163,8 +163,15 @@ public void configureFromArguments() {\n     @Override\n     public void setPropertiesForFunction(Map<String, Object> properties) {\n         if(properties.containsKey(\"depth\")) {\n-            Long depth = getLongValueFromProperty(\"depth\",properties);\n-            this.depth = depth;\n+            if(properties.get(\"depth\") instanceof Integer) {\n+                Integer depth = getIntValueFromProperty(\"depth\",properties);\n+                this.depth = depth;\n+            }\n+            else if(properties.get(\"depth\") instanceof Long) {\n+                Long depth = getLongValueFromProperty(\"depth\",properties);\n+                this.depth = depth;\n+            }\n+\n         }\n \n         if(properties.containsKey(\"off\")) {",
      "parent_sha": "8332a2b4cb022e1cce9288d765096a22d49b5cc1"
    }
  },
  {
    "oid": "68b5ff83ac47ce16436f1450b25dcdccdac6407f",
    "message": "Fix backend debugging",
    "date": "2021-08-16T10:56:02Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/68b5ff83ac47ce16436f1450b25dcdccdac6407f",
    "details": {
      "sha": "2c194c4450ae249df91ef146286f9e4d48032e54",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/optimize/optimizations/CuDNNFunctionOptimizations.java",
      "status": "modified",
      "additions": 1,
      "deletions": 2,
      "changes": 3,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/68b5ff83ac47ce16436f1450b25dcdccdac6407f/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Foptimize%2Foptimizations%2FCuDNNFunctionOptimizations.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/68b5ff83ac47ce16436f1450b25dcdccdac6407f/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Foptimize%2Foptimizations%2FCuDNNFunctionOptimizations.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Foptimize%2Foptimizations%2FCuDNNFunctionOptimizations.java?ref=68b5ff83ac47ce16436f1450b25dcdccdac6407f",
      "patch": "@@ -37,8 +37,7 @@ public class CuDNNFunctionOptimizations extends BaseOptimizerSet {\n \n     static {\n         String backend = Nd4j.getExecutioner().getEnvironmentInformation().getProperty(\"backend\");\n-//        isCudaBackend = \"CUDA\".equalsIgnoreCase(backend);\n-        isCudaBackend = true;   //For testing only\n+        isCudaBackend = \"CUDA\".equalsIgnoreCase(backend);\n     }\n \n     /**",
      "parent_sha": "49495294ddf1ab0e1190b3d6c2ffe2dedc691cdd"
    }
  },
  {
    "oid": "70dbe7059400a4885365cae57476c6c3080f5fe7",
    "message": "fix javadoc. (#76)\n\n* fix javadoc.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* replace most @see with @link s.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-05T01:21:23Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/70dbe7059400a4885365cae57476c6c3080f5fe7",
    "details": {
      "sha": "a4460480d1a85427f7e45783b55e037b241d9d75",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 114,
      "deletions": 108,
      "changes": 222,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/70dbe7059400a4885365cae57476c6c3080f5fe7/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/70dbe7059400a4885365cae57476c6c3080f5fe7/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=70dbe7059400a4885365cae57476c6c3080f5fe7",
      "patch": "@@ -209,7 +209,7 @@ public enum PadMode {\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], List, PadMode) with zero padding. (zeros for constantValues).\n+     * See {@link #pad(INDArray, int[][], List, PadMode)} with zero padding. (zeros for constantValues).\n      */\n     public static INDArray pad(INDArray toPad, int[][] padWidth, PadMode padMode) {\n         return pad(toPad, padWidth, ArrayUtil.zerosMatrix(toPad.shape()), padMode);\n@@ -264,7 +264,7 @@ public static INDArray pad(INDArray toPad, int[][] padWidth, List<double[]> cons\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], List, PadMode) with a 1D int[] for padWidth.\n+     * See {@link #pad(INDArray, int[][], List, PadMode)} with a 1D int[] for padWidth.\n      */\n     public static INDArray pad(INDArray toPad, int[] padWidth, List<double[]> constantValues, PadMode padMode) {\n         switch (padMode) {\n@@ -307,7 +307,7 @@ public static INDArray pad(INDArray toPad, int[] padWidth, List<double[]> consta\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], List, PadMode) with a 1D int[] for padWidth and zero padding.\n+     * See {@link #pad(INDArray, int[][], List, PadMode)} with a 1D int[] for padWidth and zero padding.\n      */\n     public static INDArray pad(INDArray toPad, int[] padWidth, PadMode padMode) {\n         return pad(toPad, padWidth, ArrayUtil.zerosMatrix(padWidth), padMode);\n@@ -327,12 +327,15 @@ public static INDArray append(INDArray arr, int padAmount, double val, int axis)\n     }\n \n     /**\n-     * @see #append(INDArray, int, double, int)\n+     * See {@link #append(INDArray, int, double, int)}. This function calls the implementation with appendFlag = false\n+     * to prepend.\n      */\n     public static INDArray prepend(INDArray arr, int padAmount, double val, int axis) {\n         return appendImpl(arr, padAmount, val, axis, false);\n     }\n \n+    // For this function we actually want the 'See also' tag. (Private methods do not generate javadoc, This Javadoc for\n+    // maintaining the code.)\n     /**\n      * Append / Prepend shared implementation.\n      * @param appendFlag flag to determine Append / Prepend.\n@@ -563,7 +566,7 @@ public static INDArray create(int[] sliceShape, float[]... arrays) {\n     }\n \n     /**\n-     * @see #create(LongShapeDescriptor)\n+     * See {@link #create(LongShapeDescriptor, boolean)} with initialize set to true.\n      */\n     public static INDArray create(LongShapeDescriptor descriptor) {\n         return create(descriptor, true);\n@@ -586,7 +589,7 @@ public static INDArray create(LongShapeDescriptor descriptor, boolean initialize\n     }\n \n     /**\n-     * @see #create(int[], float[]...)\n+     * See {@link #create(int[], float[]...)}\n      */\n     public static INDArray create(int[] sliceShape, double[]... arrays) {\n         int slices = arrays.length;\n@@ -652,7 +655,7 @@ public static INDArray rollAxis(INDArray a, int axis) {\n     }\n \n     /**\n-     * Get the maximum (argmax) or minimum (argmin) values for a dimension.\n+     * Get the maximum  values for a dimension.\n      * @param arr input array.\n      * @param dimension the dimension along which to get the maximum\n      * @return array of maximum values.\n@@ -663,7 +666,7 @@ public static INDArray argMax(INDArray arr, @NonNull int... dimension) {\n     }\n \n     /**\n-     * @see #argMax(INDArray, int...)\n+     * See {@link #argMax(INDArray, int...)} but return minimum values.\n      */\n     public static INDArray argMin(INDArray arr, @NonNull int... dimension) {\n         IMin imin = new IMin(arr, dimension);\n@@ -893,19 +896,19 @@ public static INDArray matmul(INDArray a, INDArray b, INDArray result, boolean t\n     }\n \n     /**\n-     * Matrix multiplication/dot product\n+     * Matrix multiplication/dot product.<br>\n      *\n-     * @see #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)\n+     * See {@link #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)}\n      */\n     public static INDArray matmul(INDArray a, INDArray b, INDArray result){\n         final Mmul op = new Mmul(a, b, result, null);\n         return exec(op)[0];\n     }\n \n     /**\n-     * Matrix multiplication/dot product\n+     * Matrix multiplication/dot product.<br>\n      *\n-     * @see #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)\n+     * See {@link #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)}\n      */\n     public static INDArray matmul(INDArray a, INDArray b, boolean transposeA, boolean transposeB, boolean transposeResult){\n        return matmul(a, b, null, transposeA, transposeB, transposeResult);\n@@ -914,7 +917,7 @@ public static INDArray matmul(INDArray a, INDArray b, boolean transposeA, boolea\n     /**\n      * Matrix multiplication/dot product\n      *\n-     * @see #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)\n+     * See {@link #matmul(INDArray, INDArray, INDArray, boolean, boolean, boolean)}\n      */\n     public static INDArray matmul(INDArray a, INDArray b){\n         return matmul(a,b, null);\n@@ -960,156 +963,157 @@ public static NDArrayFactory sparseFactory() {\n         return SPARSE_INSTANCE;\n     }\n \n-    // TODO: We forward the following methods with a default dimension argument. Doc should say something about that.\n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#cumsum(int)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#cumsum(int)} with Integer.MAX_VALUE for full array reduction.\n+     *\n+     * @return scalar ndarray.\n      */\n     public static INDArray cumsum(INDArray compute) {\n         return compute.cumsum(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#max(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#max(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray max(INDArray compute) {\n         return compute.max(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#min(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#min(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray min(INDArray compute) {\n         return compute.min(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#prod(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#prod(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray prod(INDArray compute) {\n         return compute.prod(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#normmax(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#normmax(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray normmax(INDArray compute) {\n         return compute.normmax(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#norm2(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#norm2(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray norm2(INDArray compute) {\n         return compute.norm2(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#norm1(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#norm1(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray norm1(INDArray compute) {\n         return compute.norm1(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#std(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#std(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray std(INDArray compute) {\n         return compute.std(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#var(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#var(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray var(INDArray compute) {\n         return compute.var(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#sum(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#sum(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray sum(INDArray compute) {\n         return compute.sum(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#mean(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#mean(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray mean(INDArray compute) {\n         return compute.mean(Integer.MAX_VALUE);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#cumsum(int)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#cumsum(int)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray cumsum(INDArray compute, int dimension) {\n         return compute.cumsum(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#max(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#max(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray max(INDArray compute, int dimension) {\n         return compute.max(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#min(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#min(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray min(INDArray compute, int dimension) {\n         return compute.min(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#prod(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#prod(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray prod(INDArray compute, int dimension) {\n         return compute.prod(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#normmax(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#normmax(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray normmax(INDArray compute, int dimension) {\n         return compute.normmax(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#norm2(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#norm2(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray norm2(INDArray compute, int dimension) {\n         return compute.norm2(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#norm1(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#norm1(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray norm1(INDArray compute, int dimension) {\n         return compute.norm1(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#std(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#std(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray std(INDArray compute, int dimension) {\n         return compute.std(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#var(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#var(int...)} with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray var(INDArray compute, int dimension) {\n         return compute.var(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#sum(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#sum(int...)}with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray sum(INDArray compute, int dimension) {\n         return compute.sum(dimension);\n     }\n \n     /**\n-     * @see org.nd4j.linalg.api.ndarray.INDArray#mean(int...)\n+     * See {@link org.nd4j.linalg.api.ndarray.INDArray#mean(int...)}with Integer.MAX_VALUE for full array reduction.\n      */\n     public static INDArray mean(INDArray compute, int dimension) {\n         return compute.mean(dimension);\n@@ -1386,7 +1390,8 @@ else if (type == DataType.DOUBLE)\n     }\n \n     /**\n-     * Create a buffer equal of length prod(shape)\n+     * Create a buffer equal of length prod(shape). The buffer is 'detached': Not in any memory workspace even if a\n+     * workspace is currently open.\n      *\n      * @param shape the shape of the buffer to create\n      * @param type the opType to create\n@@ -1430,7 +1435,7 @@ public static DataBuffer createBufferDetached(int[] shape, DataType type) {\n     }\n \n     /**\n-     * @see #createBuffer(int[], DataType)\n+     * See {@link  #createBuffer(int[], DataType)}\n      */\n     public static DataBuffer createBuffer(long[] shape, DataType type) {\n         long length = ArrayUtil.prodLong(shape);\n@@ -1472,7 +1477,7 @@ public static DataBuffer createBuffer(long[] shape, DataType type) {\n \n \n     /**\n-     * @see #createBufferDetached(int[], DataType)\n+     * See {@link  #createBufferDetached(int[], DataType)}\n      */\n     public static DataBuffer createBufferDetached(long[] shape, DataType type) {\n         long length = ArrayUtil.prodLong(shape);\n@@ -1630,7 +1635,7 @@ public static DataBuffer createBuffer(Pointer pointer, DataType type, long lengt\n     }\n \n     /**\n-     * @see #createBuffer(DataType dataType, long length, boolean initialize)\n+     * See {@link  #createBuffer(DataType dataType, long length, boolean initialize) with default datatype.\n      */\n     public static DataBuffer createBuffer(long length, boolean initialize) {\n         DataBuffer ret = createBuffer(Nd4j.dataType(), length, initialize);\n@@ -1680,14 +1685,14 @@ public static DataBuffer createBufferDetached(float[] data) {\n     }\n \n     /**\n-     * @see #createBufferDetached(float[])\n+     * See {@link #createBufferDetached(float[])}\n      */\n     public static DataBuffer createBufferDetached(double[] data) {\n         return DATA_BUFFER_FACTORY_INSTANCE.createDouble(data);\n     }\n \n     /**\n-     * @see #createBuffer(float[])\n+     * See {@link #createBuffer(float[])}\n      */\n     public static DataBuffer createBuffer(double[] data) {\n         return Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.createDouble(data) : DATA_BUFFER_FACTORY_INSTANCE.createDouble(data, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1706,7 +1711,7 @@ public static DataBuffer createTypedBuffer(double[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(float[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1715,7 +1720,7 @@ public static DataBuffer createTypedBuffer(float[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(int[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1724,7 +1729,7 @@ public static DataBuffer createTypedBuffer(int[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(long[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1733,7 +1738,7 @@ public static DataBuffer createTypedBuffer(long[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(short[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1742,7 +1747,7 @@ public static DataBuffer createTypedBuffer(short[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(byte[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1751,7 +1756,7 @@ public static DataBuffer createTypedBuffer(byte[] data, DataType dataType) {\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType)\n+     * See {@link #createTypedBuffer(float[], DataType)}\n      */\n     public static DataBuffer createTypedBuffer(boolean[] data, DataType dataType) {\n         val buffer = Nd4j.getMemoryManager().getCurrentWorkspace() == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -1773,7 +1778,7 @@ public static DataBuffer createTypedBuffer(double[] data, DataType dataType, Mem\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(float[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1782,7 +1787,7 @@ public static DataBuffer createTypedBuffer(float[] data, DataType dataType, Memo\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(int[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1791,7 +1796,7 @@ public static DataBuffer createTypedBuffer(int[] data, DataType dataType, Memory\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(long[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1800,7 +1805,7 @@ public static DataBuffer createTypedBuffer(long[] data, DataType dataType, Memor\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(short[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1809,7 +1814,7 @@ public static DataBuffer createTypedBuffer(short[] data, DataType dataType, Memo\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(byte[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1818,7 +1823,7 @@ public static DataBuffer createTypedBuffer(byte[] data, DataType dataType, Memor\n     }\n \n     /**\n-     * @see #createTypedBuffer(float[], DataType, MemoryWorkspace)\n+     * See {@link #createTypedBuffer(float[], DataType, MemoryWorkspace)}\n      */\n     public static DataBuffer createTypedBuffer(boolean[] data, DataType dataType, MemoryWorkspace workspace) {\n         val buffer = workspace == null ? DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false) : DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false, workspace);\n@@ -1839,7 +1844,7 @@ public static DataBuffer createTypedBufferDetached(double[] data, DataType dataT\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(float[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -1848,7 +1853,7 @@ public static DataBuffer createTypedBufferDetached(float[] data, DataType dataTy\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(int[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -1857,7 +1862,7 @@ public static DataBuffer createTypedBufferDetached(int[] data, DataType dataType\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(long[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -1866,7 +1871,7 @@ public static DataBuffer createTypedBufferDetached(long[] data, DataType dataTyp\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(short[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -1875,7 +1880,7 @@ public static DataBuffer createTypedBufferDetached(short[] data, DataType dataTy\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(byte[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -1884,7 +1889,7 @@ public static DataBuffer createTypedBufferDetached(byte[] data, DataType dataTyp\n     }\n \n     /**\n-     * @see #createTypedBufferDetached(double[], DataType)\n+     * See {@link #createTypedBufferDetached(double[], DataType)}\n      */\n     public static DataBuffer createTypedBufferDetached(boolean[] data, DataType dataType) {\n         val buffer = DATA_BUFFER_FACTORY_INSTANCE.create(dataType, data.length, false);\n@@ -2669,9 +2674,9 @@ public static INDArray readNumpy(String filePath, String split) throws IOExcepti\n     }\n \n     /**\n-     * Read array via input stream using standard UTF-8 encoding.\n+     * Read array via input stream.\n      *\n-     * @see #readNumpy(DataType, InputStream, String , Charset)\n+     * See {@link #readNumpy(DataType, InputStream, String , Charset)} using standard UTF-8 encoding\n      */\n     public static INDArray readNumpy(DataType dataType, String filePath, String split) throws IOException {\n         try(InputStream is = new FileInputStream(filePath)) {\n@@ -2690,9 +2695,9 @@ public static INDArray readNumpy(String filePath) throws IOException {\n     }\n \n     /**\n-     * Read array with default split and UTF-8 encoding.\n+     * Read array.<br>\n      *\n-     * @see #readNumpy(DataType, InputStream, String , Charset)\n+     * See {@link #readNumpy(DataType, InputStream, String , Charset)} with default split and UTF-8 encoding.\n      */\n     public static INDArray readNumpy(DataType dataType, String filePath) throws IOException {\n         return readNumpy(dataType, filePath, \" \");\n@@ -2701,7 +2706,7 @@ public static INDArray readNumpy(DataType dataType, String filePath) throws IOEx\n     /**\n      * Raad an ndarray from an input stream\n      *\n-     * @see #read(DataInputStream)\n+     * See {@link #read(DataInputStream)}\n      */\n     public static INDArray read(InputStream reader) throws IOException {\n         return read(new DataInputStream(reader));\n@@ -3019,7 +3024,7 @@ public static INDArray arange(double begin, double end, double step) {\n      * Create a 1D array of evenly spaced values between {@code begin} (inclusive) and {@code end} (exclusive)\n      * with a step size of 1\n      *\n-     * @see #arange(double, double, double)\n+     * See {@link #arange(double, double, double)} with step size 1.\n      */\n     public static INDArray arange(double begin, double end) {\n         INDArray ret = INSTANCE.arange(begin, end, 1);\n@@ -3030,7 +3035,7 @@ public static INDArray arange(double begin, double end) {\n      * Create a 1D array of evenly spaced values between 0 (inclusive) and {@code end} (exclusive)\n      * with a step size of 1\n      *\n-     * @see #arange(double, double, double)\n+     * See {@link #arange(double, double, double)} with begin = 0 and step size 1.\n      */\n     public static INDArray arange(double end) {\n         return arange(0, end);\n@@ -3096,6 +3101,7 @@ public static INDArray choice(@NonNull INDArray source, @NonNull INDArray probs,\n         return Nd4j.getExecutioner().exec(new Choice(source, probs, target), rng);\n     }\n \n+    // @see tag works well here.\n     /**\n      * This method samples value from Source array to Target,the default random number generator.\n      *\n@@ -3114,6 +3120,7 @@ public static INDArray choice(INDArray source, INDArray probs, INDArray target)\n      * @return\n      */\n \n+    // @see tag works well here.\n     /**\n      * This method returns new INDArray instance, sampled from Source array with probabilities given in Probs.\n      *\n@@ -3128,6 +3135,7 @@ public static INDArray choice(INDArray source, INDArray probs, int numSamples,\n         return choice(source, probs, createUninitialized(numSamples), rng);\n     }\n \n+    // @see tag works well here.\n     /**\n      * This method returns new INDArray instance, sampled from Source array with probabilities given in Probs\n      * using the default random number generator.\n@@ -3170,7 +3178,7 @@ public static INDArray rand(@NonNull int... shape) {\n     }\n \n     /**\n-     * @see #rand(int[])\n+     * See {@link #rand(int[])}\n      */\n     public static INDArray rand(@NonNull long... shape) {\n         INDArray ret = createUninitialized(shape, order()); //INSTANCE.rand(shape, Nd4j.getRandom());\n@@ -4031,42 +4039,42 @@ public static INDArray create(int[] data, long[] shape, DataType type) {\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(long[] data, long[] shape, DataType type) {\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(double[] data, long[] shape, DataType type) {\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(float[] data, long[] shape, DataType type) {\n         return  INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(short[] data, long[] shape, DataType type) {\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(byte[] data, long[] shape, DataType type) {\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], DataType)\n+     * See {@link #create(int[], long[], DataType)}\n      */\n     public static INDArray create(boolean[] data, long[] shape, DataType type) {\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape), type, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -4089,42 +4097,42 @@ public static INDArray create(int[] data, long[] shape, long[]strides, char orde\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(long[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(double[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(float[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(short[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(byte[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n     }\n \n     /**\n-     * @see #create(int[], long[], long[], char, DataType)\n+     * See {@link #create(int[], long[], long[], char, DataType)}\n      */\n     public static INDArray create(boolean[] data, long[] shape, long[]strides, char order, DataType type) {\n         return INSTANCE.create(data, shape, strides, order, type, Nd4j.getMemoryManager().getCurrentWorkspace());\n@@ -4237,7 +4245,7 @@ public static INDArray create(float[] data, int... shape) {\n     }\n \n     /**\n-     * @see #create(float[], int[])\n+     * See {@link #create(float[], int[])}\n      */\n     public static INDArray create(float[] data, long... shape) {\n         if (shape.length == 0 && data.length == 1) {\n@@ -4256,7 +4264,7 @@ public static INDArray create(float[] data, long... shape) {\n     }\n \n     /**\n-     * @see #create(float[], int[])\n+     * See {@link #create(float[], int[])}\n      */\n     public static INDArray create(double[] data, long... shape) {\n         if (shape.length == 0 && data.length == 1) {\n@@ -4439,7 +4447,7 @@ public static INDArray create(double[] data, int[] shape, long offset, char orde\n     }\n \n     /**\n-     * @see #create(double[], int[], long, char )\n+     * See {@link #create(double[], int[], long, char )}\n      */\n     public static INDArray create(double[] data, long[] shape, long offset, char ordering) {\n         if (shape.length == 1) {\n@@ -4491,7 +4499,7 @@ public static INDArray create(List<INDArray> list, int... shape) {\n     }\n \n     /**\n-     * @see #create(List, int[])\n+     * See {@link #create(List, int[])}\n      */\n     public static INDArray create(List<INDArray> list, long... shape) {\n         checkShapeValues(shape);\n@@ -4517,7 +4525,7 @@ public static INDArray create(int rows, int columns, int[] stride, long offset)\n     }\n \n     /**\n-     * @see #create(int , int , int[] , long )\n+     * See {@link #create(int , int , int[] , long )}\n      */\n     public static INDArray zeros(int rows, int columns, int[] stride, long offset) {\n         return create(rows, columns, stride, offset);\n@@ -4540,7 +4548,7 @@ public static INDArray create(int[] shape, int[] stride, long offset) {\n     }\n \n     /**\n-     * @see #create(int[] , int[] , long )\n+     * See {@link #create(int[] , int[] , long )}\n      */\n     public static INDArray zeros(int[] shape, int[] stride, long offset) {\n         return create(shape, stride, offset);\n@@ -4559,7 +4567,7 @@ public static INDArray create(int rows, int columns, int[] stride) {\n     }\n \n     /**\n-     * @see #create(int, int, int[], char)\n+     * See {@link @see #create(int, int, int[], char)}\n      */\n     public static INDArray zeros(int rows, int columns, int[] stride) {\n         return create(rows, columns, stride, order());\n@@ -4577,15 +4585,15 @@ public static INDArray create(int[] shape, int[] stride) {\n     }\n \n     /**\n-     * @see #create(int[], int[])\n+     * See {@link #create(int[], int[])}\n      */\n     public static INDArray create(long[] shape, long[] stride) {\n         return create(shape, stride, order());\n     }\n \n \n     /**\n-     * @see #create(int[], int[])\n+     * See {@link #create(int[], int[])}\n      */\n     public static INDArray zeros(int[] shape, int[] stride) {\n         return create(shape, stride);\n@@ -4705,33 +4713,31 @@ public static INDArray create(DataBuffer data, int[] shape, int[] strides, long\n     }\n \n     /**\n-     * @see #create(DataBuffer, int[], int[], long)\n+     * See {@link #create(DataBuffer, int[], int[], long)}\n      */\n     public static INDArray create(DataBuffer data, long[] shape, long[] strides, long offset) {\n         checkShapeValues(shape);\n         return  INSTANCE.create(data, shape, strides, offset);\n     }\n \n     /**\n-     * @see #create(DataBuffer, int[], int[], long)\n-     *\n-     * Uses default strides based on shape.\n+     * See {@link #create(DataBuffer, int[], int[], long)}. Uses default strides based on shape.\n      */\n     public static INDArray create(DataBuffer data, int[] shape, long offset) {\n         checkShapeValues(shape);\n         return  INSTANCE.create(data, shape, getStrides(shape), offset);\n     }\n \n     /**\n-     * @see #create(DataBuffer data, long[], long[], long, long, char )\n+     * See {@link #create(DataBuffer data, long[], long[], long, long, char )}\n      */\n     public static INDArray create(DataBuffer data, int[] newShape, int[] newStride, long offset, char ordering) {\n         checkShapeValues(newShape);\n         return INSTANCE.create(data, newShape, newStride, offset, ordering);\n     }\n \n     /**\n-     * @see #create(DataBuffer data, long[], long[], long, long, char )\n+     * See {@link #create(DataBuffer data, long[], long[], long, long, char )}\n      */\n     public static INDArray create(DataBuffer data, long[] newShape, long[] newStride, long offset, char ordering) {\n         checkShapeValues(newShape);\n@@ -4784,7 +4790,7 @@ public static INDArray create(DataBuffer data, int... shape) {\n     }\n \n     /**\n-     * @see #create(DataBuffer, int[])\n+     * See {@link #create(DataBuffer, int[])}\n      */\n     public static INDArray create(DataBuffer data, long... shape) {\n         checkShapeValues(shape);\n@@ -4886,7 +4892,7 @@ public static INDArray create(double[] data, int[] shape, char ordering) {\n     }\n \n     /**\n-     * @see #create(double[], int[], char)\n+     * See {@link #create(double[], int[], char)}\n      */\n     public static INDArray create(float[] data, int[] shape, char ordering) {\n         if (shape.length == 1) {\n@@ -4900,15 +4906,15 @@ public static INDArray create(float[] data, int[] shape, char ordering) {\n     }\n \n     /**\n-     * @see #create(double[], int[], char)\n+     * See {@link  #create(double[], int[], char)}\n      */\n     public static INDArray create(float[] data, long[] shape, char ordering) {\n         checkShapeValues(data.length, shape);\n         return INSTANCE.create(data, shape, Nd4j.getStrides(shape, ordering), ordering, DataType.FLOAT);\n     }\n \n     /**\n-     * @see #create(double[], int[], char)\n+     * See {@link #create(double[], int[], char)}\n      */\n     public static INDArray create(double[] data, long[] shape, char ordering) {\n         checkShapeValues(data.length, shape);\n@@ -5070,7 +5076,7 @@ public static INDArray create(int[] shape, int[] stride, char ordering) {\n     }\n \n     /**\n-     * @see #create(int[], int[], char)\n+     * See {@link #create(int[], int[], char)}\n      */\n     public static INDArray create(long[] shape, long[] stride, char ordering) {\n         if(shape.length == 0)\n@@ -5280,7 +5286,7 @@ public static INDArray createUninitialized(long[] shape, char ordering) {\n     }\n \n     /**\n-     * @see #createUninitialized(long[], char)\n+     * See {@link #createUninitialized(long[], char)}\n      */\n     public static INDArray createUninitializedDetached(int[] shape, char ordering) {\n         if (shape.length == 0)\n@@ -5306,7 +5312,7 @@ public static INDArray createUninitializedDetached(long[] shape, char ordering)\n     }\n \n     /**\n-     * @see #createUninitialized(long[])\n+     * See {@link #createUninitialized(long[])}\n      */\n     public static INDArray createUninitialized(int... shape) {\n         if(shape.length == 0)\n@@ -5352,7 +5358,7 @@ public static INDArray createUninitializedDetached(long... shape) {\n     }\n \n     /**\n-     * @see #createUninitialized(long)\n+     * See {@link #createUninitialized(long)}\n      */\n     public static INDArray createUninitialized(int length) {\n         return createUninitialized((long)length);\n@@ -5372,7 +5378,7 @@ public static INDArray createUninitialized(long length) {\n     }\n \n     /**\n-     * @see #createUninitialized(long)\n+     * See {@link #createUninitialized(long)}\n      */\n     public static INDArray createUninitializedDetached(int length) {\n         long[] shape = new long[] {length};\n@@ -5631,7 +5637,7 @@ public static INDArray valueArrayOf(long[] shape, int value) {\n     }\n \n     /**\n-     * @see #valueArrayOf(long[], double, DataType)\n+     * See {@link #valueArrayOf(long[], double, DataType)}\n      */\n     public static INDArray valueArrayOf(long[] shape, double value) {\n         if (shape.length == 0)\n@@ -5663,7 +5669,7 @@ public static INDArray valueArrayOf(long[] shape, double value, DataType type) {\n     }\n \n     /**\n-     * @see #valueArrayOf(long[], double, DataType)\n+     * See {@link #valueArrayOf(long[], double, DataType)}\n      */\n     public static INDArray valueArrayOf(long[] shape, long value, DataType type) {\n         if (shape.length == 0)\n@@ -6076,7 +6082,7 @@ public static INDArray zeros(int[] shape, char order) {\n     }\n \n     /**\n-     * @see #zeros(int[] , char)\n+     * See {@link #zeros(int[] , char)}\n      */\n     public static INDArray zeros(long[] shape, char order) {\n         checkShapeValues(shape);\n@@ -6118,7 +6124,7 @@ public static INDArray ones(@NonNull int... shape) {\n \n \n     /**\n-     * @see #ones(int... shape)\n+     * See {@link #ones(int... shape)}\n      */\n     public static INDArray ones(@NonNull long... shape) {\n         if(shape.length == 0)",
      "parent_sha": "ac321265a7bace5556085c83bf6d758933bdb6df"
    }
  },
  {
    "oid": "3900d9ff06e0e3c4289474c9aebf04a165be7eaa",
    "message": "Simple fix in bidirectional lstm import  (#293)\n\n* first pass\r\n\r\nSigned-off-by: eraly <susan.eraly@gmail.com>\r\n\r\n* cleanup\r\n\r\nSigned-off-by: eraly <susan.eraly@gmail.com>",
    "date": "2020-03-30T10:07:47Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/3900d9ff06e0e3c4289474c9aebf04a165be7eaa",
    "details": {
      "sha": "3b7cb17212b0795ba3ea7c15fdf30e4d267dbf06",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/main/java/org/deeplearning4j/nn/modelimport/keras/layers/wrappers/KerasBidirectional.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/3900d9ff06e0e3c4289474c9aebf04a165be7eaa/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fwrappers%2FKerasBidirectional.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/3900d9ff06e0e3c4289474c9aebf04a165be7eaa/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fwrappers%2FKerasBidirectional.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Flayers%2Fwrappers%2FKerasBidirectional.java?ref=3900d9ff06e0e3c4289474c9aebf04a165be7eaa",
      "patch": "@@ -190,7 +190,7 @@ public InputType getOutputType(InputType... inputType) throws InvalidKerasConfig\n                     \"Keras Bidirectional layer accepts only one input (received \" + inputType.length + \")\");\n         InputPreProcessor preProcessor = getInputPreprocessor(inputType);\n         if (preProcessor != null)\n-            return preProcessor.getOutputType(inputType[0]);\n+            return this.getBidirectionalLayer().getOutputType(-1, preProcessor.getOutputType(inputType[0]));\n         else\n             return this.getBidirectionalLayer().getOutputType(-1, inputType[0]);\n     }",
      "parent_sha": "63c9223bc2d95e3311e7f551aac829abf3693875"
    }
  },
  {
    "oid": "6b215e12b3df886c8e292bc05b3e537622ba34da",
    "message": "Fix Nullpointer Exception\n\nFor me, this fixes\r\nhttps://github.com/eclipse/deeplearning4j/issues/9148",
    "date": "2021-01-22T16:21:50Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/6b215e12b3df886c8e292bc05b3e537622ba34da",
    "details": {
      "sha": "f8797289632beb08f2d2bf8df2cc8774061408aa",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-cuda/src/main/java/org/nd4j/jita/concurrency/CudaAffinityManager.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/6b215e12b3df886c8e292bc05b3e537622ba34da/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fjita%2Fconcurrency%2FCudaAffinityManager.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/6b215e12b3df886c8e292bc05b3e537622ba34da/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fjita%2Fconcurrency%2FCudaAffinityManager.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-cuda%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fjita%2Fconcurrency%2FCudaAffinityManager.java?ref=6b215e12b3df886c8e292bc05b3e537622ba34da",
      "patch": "@@ -304,7 +304,7 @@ public void unsafeSetDevice(Integer deviceId) {\n     @Override\n     public void ensureLocation(INDArray array, Location location) {\n         // to location to ensure for empty array\n-        if (array.isEmpty() || array.isS())\n+        if (array == null || array.isEmpty() || array.isS())\n             return;\n \n         // let's make sure host pointer actually exists",
      "parent_sha": "124d0a1965c99e5c8a8fb39430fb82a710df600f"
    }
  },
  {
    "oid": "c469ddbcbd7b367cc551929ed4c8e94025e69bfe",
    "message": "Bugfix/model serializer os closed (#10155)\n\n* #10154: Redirected all basic writes to the DataOutputStream\n\nThis is done to ensure that the underlying stream is notified when it's closed by any of the write calls (more specifically the NormalizerSerializer.getDefault().write). Previously, the NormalizerSerializer.getDefault().write would close the zipfile stream, but since that's wrapped in the DataOutputStream, the dos would not be notified of the closed stream, and would fail on the dos.close() on line 194.\n\nSigned-off-by: Siebe Krijgsman <skrijgsman@gmail.com>\n\n* #10154: Wrapped the code in try-with-resources to ensure the streams are closed on error\n\nSigned-off-by: Siebe Krijgsman <skrijgsman@gmail.com>\n\n---------\n\nSigned-off-by: Siebe Krijgsman <skrijgsman@gmail.com>",
    "date": "2024-11-26T11:01:13Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/c469ddbcbd7b367cc551929ed4c8e94025e69bfe",
    "details": {
      "sha": "5f3ededaf32ee978227bfb66b478235521fdd85e",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java",
      "status": "modified",
      "additions": 44,
      "deletions": 46,
      "changes": 90,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/c469ddbcbd7b367cc551929ed4c8e94025e69bfe/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/c469ddbcbd7b367cc551929ed4c8e94025e69bfe/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java?ref=c469ddbcbd7b367cc551929ed4c8e94025e69bfe",
      "patch": "@@ -133,66 +133,64 @@ public static void writeModel(@NonNull Model model, @NonNull OutputStream stream\n      */\n     public static void writeModel(@NonNull Model model, @NonNull OutputStream stream, boolean saveUpdater,DataNormalization dataNormalization)\n             throws IOException {\n-        ZipOutputStream zipfile = new ZipOutputStream(new CloseShieldOutputStream(stream));\n+        try (ZipOutputStream zipfile = new ZipOutputStream(new CloseShieldOutputStream(stream));\n+             DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(zipfile))) {\n \n-        // Save configuration as JSON\n-        String json = \"\";\n-        if (model instanceof MultiLayerNetwork) {\n-            json = ((MultiLayerNetwork) model).getLayerWiseConfigurations().toJson();\n-        } else if (model instanceof ComputationGraph) {\n-            json = ((ComputationGraph) model).getConfiguration().toJson();\n-        }\n-\n-        ZipEntry config = new ZipEntry(CONFIGURATION_JSON);\n-        zipfile.putNextEntry(config);\n-        zipfile.write(json.getBytes());\n-\n-        // Save parameters as binary\n-        ZipEntry coefficients = new ZipEntry(COEFFICIENTS_BIN);\n-        zipfile.putNextEntry(coefficients);\n-        DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(zipfile));\n-        INDArray params = model.params();\n-        if(params != null) {\n-            try {\n-                Nd4j.write(model.params(), dos);\n-            } finally {\n-                dos.flush();\n-            }\n-        } else {\n-            ZipEntry noParamsMarker = new ZipEntry(NO_PARAMS_MARKER);\n-            zipfile.putNextEntry(noParamsMarker);\n-        }\n-\n-        if (saveUpdater) {\n-            INDArray updaterState = null;\n+            // Save configuration as JSON\n+            String json = \"\";\n             if (model instanceof MultiLayerNetwork) {\n-                updaterState = ((MultiLayerNetwork) model).getUpdater().getStateViewArray();\n+                json = ((MultiLayerNetwork) model).getLayerWiseConfigurations().toJson();\n             } else if (model instanceof ComputationGraph) {\n-                updaterState = ((ComputationGraph) model).getUpdater().getStateViewArray();\n+                json = ((ComputationGraph) model).getConfiguration().toJson();\n             }\n \n-            if (updaterState != null && updaterState.length() > 0) {\n-                ZipEntry updater = new ZipEntry(UPDATER_BIN);\n-                zipfile.putNextEntry(updater);\n+            ZipEntry config = new ZipEntry(CONFIGURATION_JSON);\n+            zipfile.putNextEntry(config);\n+            dos.write(json.getBytes());\n \n+            // Save parameters as binary\n+            ZipEntry coefficients = new ZipEntry(COEFFICIENTS_BIN);\n+            zipfile.putNextEntry(coefficients);\n+            INDArray params = model.params();\n+            if (params != null) {\n                 try {\n-                    Nd4j.write(updaterState, dos);\n+                    Nd4j.write(model.params(), dos);\n                 } finally {\n                     dos.flush();\n                 }\n+            } else {\n+                ZipEntry noParamsMarker = new ZipEntry(NO_PARAMS_MARKER);\n+                zipfile.putNextEntry(noParamsMarker);\n             }\n-        }\n \n+            if (saveUpdater) {\n+                INDArray updaterState = null;\n+                if (model instanceof MultiLayerNetwork) {\n+                    updaterState = ((MultiLayerNetwork) model).getUpdater().getStateViewArray();\n+                } else if (model instanceof ComputationGraph) {\n+                    updaterState = ((ComputationGraph) model).getUpdater().getStateViewArray();\n+                }\n \n-        if(dataNormalization != null) {\n-            // now, add our normalizer as additional entry\n-            ZipEntry nEntry = new ZipEntry(NORMALIZER_BIN);\n-            zipfile.putNextEntry(nEntry);\n-            NormalizerSerializer.getDefault().write(dataNormalization, zipfile);\n-        }\n+                if (updaterState != null && updaterState.length() > 0) {\n+                    ZipEntry updater = new ZipEntry(UPDATER_BIN);\n+                    zipfile.putNextEntry(updater);\n+\n+                    try {\n+                        Nd4j.write(updaterState, dos);\n+                    } finally {\n+                        dos.flush();\n+                    }\n+                }\n+            }\n \n-        dos.close();\n-        zipfile.close();\n+\n+            if (dataNormalization != null) {\n+                // now, add our normalizer as additional entry\n+                ZipEntry nEntry = new ZipEntry(NORMALIZER_BIN);\n+                zipfile.putNextEntry(nEntry);\n+                NormalizerSerializer.getDefault().write(dataNormalization, dos);\n+            }\n+        }\n     }\n \n     /**",
      "parent_sha": "6f9eff5ca7ca8da9a29fbfefb141642779907037"
    }
  },
  {
    "oid": "181f3b1bec9f255c449d596b645cb18f09d8f115",
    "message": "Add dynamic gradient depending on number of inputs",
    "date": "2021-11-11T07:56:52Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/181f3b1bec9f255c449d596b645cb18f09d8f115",
    "details": {
      "sha": "d9c7ae453940eb8faf653294633b67aa29a58fe4",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/transforms/comparison/CompareAndSet.java",
      "status": "modified",
      "additions": 5,
      "deletions": 1,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/181f3b1bec9f255c449d596b645cb18f09d8f115/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Ftransforms%2Fcomparison%2FCompareAndSet.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/181f3b1bec9f255c449d596b645cb18f09d8f115/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Ftransforms%2Fcomparison%2FCompareAndSet.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Ftransforms%2Fcomparison%2FCompareAndSet.java?ref=181f3b1bec9f255c449d596b645cb18f09d8f115",
      "patch": "@@ -253,7 +253,11 @@ public List<SDVariable> doDiff(List<SDVariable> gradient) {\n         //Pass through gradient where condition is NOT matched (condition matched: output replaced by scalar)\n         SDVariable maskNotMatched = sameDiff.matchCondition(arg(), condition).castTo(arg().dataType()).rsub(1.0);\n         SDVariable gradAtIn = gradient.get(0).mul(maskNotMatched);\n-        return Arrays.asList(gradAtIn);\n+        SDVariable[] args = args();\n+        if(args.length == 1)\n+            return Arrays.asList(gradAtIn);\n+        else\n+            return Arrays.asList(gradAtIn,gradAtIn);\n     }\n }\n ",
      "parent_sha": "6e53d96872c37ec6693da627c522b12fa28e6b6e"
    }
  },
  {
    "oid": "ac38c704cd235ffc9810c10e94631e877cc59eb0",
    "message": "Update Nd4jTestsC.java",
    "date": "2021-03-23T08:38:45Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/ac38c704cd235ffc9810c10e94631e877cc59eb0",
    "details": {
      "sha": "059412c191c83d3a6581838466537bf059ebc28e",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/Nd4jTestsC.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/ac38c704cd235ffc9810c10e94631e877cc59eb0/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/ac38c704cd235ffc9810c10e94631e877cc59eb0/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java?ref=ac38c704cd235ffc9810c10e94631e877cc59eb0",
      "patch": "@@ -2413,7 +2413,7 @@ public void testGetPermuteReshapeSub(Nd4jBackend backend) {\n     @ParameterizedTest\n     @MethodSource(\"org.nd4j.linalg.BaseNd4jTestWithBackends#configs\")\n     public void testPutAtIntervalIndexWithStride(Nd4jBackend backend) {\n-        INDArray n1 = Nd4j.create(3, 3).assign(0.0).castTo(DataType.DOUBLE));\n+        INDArray n1 = Nd4j.create(3, 3).assign(0.0).castTo(DataType.DOUBLE);\n         INDArrayIndex[] indices = {NDArrayIndex.interval(0, 2, 3), NDArrayIndex.all()};\n         n1.put(indices, 1);\n         INDArray expected = Nd4j.create(new double[][] {{1d, 1d, 1d}, {0d, 0d, 0d}, {1d, 1d, 1d}});",
      "parent_sha": "bcce1f8db41dce5a1834fdf7de78a5b8591a78e5"
    }
  },
  {
    "oid": "000334ea2a717a2b5bf2a61f021aad85bb79d9cb",
    "message": "affinity fix for tensorflow conversion\n\nSigned-off-by: raver119 <raver119@gmail.com>",
    "date": "2019-08-17T14:59:14Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/000334ea2a717a2b5bf2a61f021aad85bb79d9cb",
    "details": {
      "sha": "b47cd30d1f5e8fa733a39b1ed90f2fa683245214",
      "filename": "nd4j/nd4j-tensorflow/src/main/java/org/nd4j/tensorflow/conversion/TensorflowConversion.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/000334ea2a717a2b5bf2a61f021aad85bb79d9cb/nd4j%2Fnd4j-tensorflow%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FTensorflowConversion.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/000334ea2a717a2b5bf2a61f021aad85bb79d9cb/nd4j%2Fnd4j-tensorflow%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FTensorflowConversion.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-tensorflow%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Ftensorflow%2Fconversion%2FTensorflowConversion.java?ref=000334ea2a717a2b5bf2a61f021aad85bb79d9cb",
      "patch": "@@ -296,7 +296,7 @@ public TF_Graph loadGraph(String filePath, TF_Status status) throws IOException\n      * @return\n      */\n     public static String defaultDeviceForThread() {\n-        Integer deviceForThread = Nd4j.getAffinityManager().getDeviceForThread(Thread.currentThread());\n+        Integer deviceForThread = Nd4j.getAffinityManager().getDeviceForCurrentThread();\n         String deviceName = null;\n         //gpu\n         if(Nd4j.getBackend().getClass().getName().contains(\"JCublasBackend\")) {",
      "parent_sha": "56910ddee72b670983f2c402192c34619bd680ce"
    }
  },
  {
    "oid": "cbd9d50078111578689334aa6ba3d82e08002c06",
    "message": "Update LayerValidation.java",
    "date": "2021-05-06T06:57:37Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/cbd9d50078111578689334aa6ba3d82e08002c06",
    "details": {
      "sha": "2a5f16be64795683f1655397777c324d622f0ff8",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LayerValidation.java",
      "status": "modified",
      "additions": 79,
      "deletions": 71,
      "changes": 150,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/cbd9d50078111578689334aa6ba3d82e08002c06/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/cbd9d50078111578689334aa6ba3d82e08002c06/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java?ref=cbd9d50078111578689334aa6ba3d82e08002c06",
      "patch": "@@ -53,7 +53,7 @@ public static void assertNInNOutSet(String layerType, String layerName, long lay\n             if (layerName == null)\n                 layerName = \"(name not set)\";\n             throw new DL4JInvalidConfigException(layerType + \" (index=\" + layerIndex + \", name=\" + layerName + \") nIn=\"\n-                    + nIn + \", nOut=\" + nOut + \"; nIn and nOut must be > 0\");\n+                            + nIn + \", nOut=\" + nOut + \"; nIn and nOut must be > 0\");\n         }\n     }\n \n@@ -70,13 +70,13 @@ public static void assertNOutSet(String layerType, String layerName, long layerI\n             if (layerName == null)\n                 layerName = \"(name not set)\";\n             throw new DL4JInvalidConfigException(layerType + \" (index=\" + layerIndex + \", name=\" + layerName + \") nOut=\"\n-                    + nOut + \"; nOut must be > 0\");\n+                            + nOut + \"; nOut must be > 0\");\n         }\n     }\n \n     public static void generalValidation(String layerName, Layer layer, IDropout iDropout, List<Regularization> regularization,\n                                          List<Regularization> regularizationBias, List<LayerConstraint> allParamConstraints,\n-                                         List<LayerConstraint> weightConstraints, List<LayerConstraint> biasConstraints) {\n+                    List<LayerConstraint> weightConstraints, List<LayerConstraint> biasConstraints) {\n \n         if (layer != null) {\n             if (layer instanceof BaseLayer) {\n@@ -88,9 +88,9 @@ public static void generalValidation(String layerName, Layer layer, IDropout iDr\n             } else if (layer instanceof Bidirectional) {\n                 Bidirectional l = (Bidirectional) layer;\n                 generalValidation(layerName, l.getFwd(), iDropout, regularization, regularizationBias, allParamConstraints,\n-                        weightConstraints, biasConstraints);\n+                                weightConstraints, biasConstraints);\n                 generalValidation(layerName, l.getBwd(), iDropout, regularization, regularizationBias, allParamConstraints,\n-                        weightConstraints, biasConstraints);\n+                                weightConstraints, biasConstraints);\n             }\n \n             if (layer.getConstraints() == null || layer.constraints.isEmpty()) {\n@@ -128,76 +128,84 @@ public static void generalValidation(String layerName, Layer layer, IDropout iDr\n         }\n     }\n \n-    private static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout,\n-                                           List<Regularization> regularization, List<Regularization> regularizationBias) {\n-        if (regularization != null && !regularization.isEmpty()) {\n-            final List<Regularization> bLayerRegs = new ArrayList<>(bLayer.getRegularization());\n-            if (bLayerRegs == null || bLayerRegs.isEmpty()) {\n-                bLayer.setRegularization(regularization);\n-            } else {\n-                boolean hasL1 = false;\n-                boolean hasL2 = false;\n-                final List<Regularization> regContext = regularization;\n-                for (final Regularization reg : bLayerRegs) {\n-\n-                    if (reg instanceof L1Regularization) {\n-\n-                        hasL1 = true;\n-                    } else if (reg instanceof L2Regularization) {\n-                        hasL2 = true;\n-                    }\n-                }\n-                for (final Regularization reg : regContext) {\n-                    if (reg instanceof L1Regularization) {\n-\n-                        if (!hasL1)\n-                            bLayerRegs.add(reg);\n-                    } else if (reg instanceof L2Regularization) {\n-                        if (!hasL2)\n-                            bLayerRegs.add(reg);\n-                    } else\n-                        bLayerRegs.add(reg);\n-                }\n-            }\n+\tprivate static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout,\n+\t\t\tList<Regularization> regularization, List<Regularization> regularizationBias) {\n+\t\tif (regularization != null && !regularization.isEmpty()) {\n \n-            bLayer.setRegularization(bLayerRegs);\n-        }\n+\t\t\tfinal List<Regularization> bLayerRegs = bLayer.getRegularization();\n+\t\t\tif (bLayerRegs == null || bLayerRegs.isEmpty()) {\n \n+\t\t\t\tbLayer.setRegularization(regularization);\n+\t\t\t} else {\n \n-        if (regularizationBias != null && !regularizationBias.isEmpty()) {\n-            final List<Regularization> bLayerRegs = new ArrayList<>(bLayer.getRegularizationBias());\n-            if (bLayerRegs == null || bLayerRegs.isEmpty()) {\n-                bLayer.setRegularizationBias(regularizationBias);\n-            } else {\n-                boolean hasL1 = false;\n-                boolean hasL2 = false;\n-                final List<Regularization> regContext = regularizationBias;\n-                for (final Regularization reg : bLayerRegs) {\n-                    if (reg instanceof L1Regularization) {\n-                        hasL1 = true;\n-                    } else if (reg instanceof L2Regularization) {\n-                        hasL2 = true;\n-                    }\n-                }\n-                for (final Regularization reg : regContext) {\n-                    if (reg instanceof L1Regularization) {\n-                        if (!hasL1)\n-                            bLayerRegs.add(reg);\n-                    } else if (reg instanceof L2Regularization) {\n-\n-                        if (!hasL2)\n-                            bLayerRegs.add(reg);\n-                    } else\n-                        bLayerRegs.add(reg);\n-                }\n-            }\n+\t\t\t\tboolean hasL1 = false;\n+\t\t\t\tboolean hasL2 = false;\n+\t\t\t\tfinal List<Regularization> regContext = regularization;\n+\t\t\t\tfor (final Regularization reg : bLayerRegs) {\n \n-            bLayer.setRegularizationBias(bLayerRegs);\n-        }\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n \n-        if (bLayer.getIDropout() == null) {\n+\t\t\t\t\t\thasL1 = true;\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n \n-            bLayer.setIDropout(iDropout);\n-        }\n-    }\n+\t\t\t\t\t\thasL2 = true;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tfor (final Regularization reg : regContext) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL1)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL2)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else\n+\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\tif (regularizationBias != null && !regularizationBias.isEmpty()) {\n+\n+\t\t\tfinal List<Regularization> bLayerRegs = bLayer.getRegularizationBias();\n+\t\t\tif (bLayerRegs == null || bLayerRegs.isEmpty()) {\n+\n+\t\t\t\tbLayer.setRegularizationBias(regularizationBias);\n+\t\t\t} else {\n+\n+\t\t\t\tboolean hasL1 = false;\n+\t\t\t\tboolean hasL2 = false;\n+\t\t\t\tfinal List<Regularization> regContext = regularizationBias;\n+\t\t\t\tfor (final Regularization reg : bLayerRegs) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\thasL1 = true;\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\thasL2 = true;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tfor (final Regularization reg : regContext) {\n+\n+\t\t\t\t\tif (reg instanceof L1Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL1)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else if (reg instanceof L2Regularization) {\n+\n+\t\t\t\t\t\tif (!hasL2)\n+\t\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t\t} else\n+\t\t\t\t\t\tbLayerRegs.add(reg);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (bLayer.getIDropout() == null) {\n+\n+\t\t\tbLayer.setIDropout(iDropout);\n+\t\t}\n+\t}\n }",
      "parent_sha": "a745b17969527411454856fb44e5d51794f897fd"
    }
  },
  {
    "oid": "00d88298e24b993a06829d4f639a04cb455eb463",
    "message": "Fix compilation error with system properties inc uda",
    "date": "2021-07-20T23:08:38Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/00d88298e24b993a06829d4f639a04cb455eb463",
    "details": {
      "sha": "7b6c7147f7f5830650ca45e806f91d678ee9e38b",
      "filename": "deeplearning4j/deeplearning4j-cuda/src/test/java/org/deeplearning4j/cuda/HelperUtilsTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/00d88298e24b993a06829d4f639a04cb455eb463/deeplearning4j%2Fdeeplearning4j-cuda%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fcuda%2FHelperUtilsTests.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/00d88298e24b993a06829d4f639a04cb455eb463/deeplearning4j%2Fdeeplearning4j-cuda%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fcuda%2FHelperUtilsTests.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-cuda%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fcuda%2FHelperUtilsTests.java?ref=00d88298e24b993a06829d4f639a04cb455eb463",
      "patch": "@@ -15,6 +15,7 @@\n import org.deeplearning4j.nn.layers.recurrent.LSTMHelper;\n import org.junit.jupiter.api.Test;\n import org.nd4j.common.tests.tags.NativeTag;\n+import org.deeplearning4j.common.config.DL4JSystemProperties;\n \n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n@@ -25,9 +26,8 @@ public class HelperUtilsTests extends BaseDL4JTest  {\n \n     @Test\n     public void testHelperCreation() {\n-        System.setProperty(HelperUtils.DISABLE_HELPER_PROPERTY,\"false\");\n+        System.setProperty(DL4JSystemProperties.DISABLE_HELPER_PROPERTY,\"false\");\n \n-        assertNotNull(HelperUtils.createHelper(CudnnLSTMHelper.class.getName(),\"\", LSTMHelper.class,\"layer-name\",getDataType()));\n         assertNotNull(HelperUtils.createHelper(CudnnDropoutHelper.class.getName(),\"\", DropoutHelper.class,\"layer-name\",getDataType()));\n         assertNotNull(HelperUtils.createHelper(CudnnConvolutionHelper.class.getName(),\"\", ConvolutionHelper.class,\"layer-name\",getDataType()));\n         assertNotNull(HelperUtils.createHelper(CudnnLocalResponseNormalizationHelper.class.getName(),\"\", LocalResponseNormalizationHelper.class,\"layer-name\",getDataType()));",
      "parent_sha": "72a51359ef4746031caa7dc7c08105c12cfe71e8"
    }
  },
  {
    "oid": "c08a0eb09d21dc366fd9014fb22bb6dc318a2adf",
    "message": "Update AuroraPresets.java",
    "date": "2021-11-29T04:49:28Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/c08a0eb09d21dc366fd9014fb22bb6dc318a2adf",
    "details": {
      "sha": "8017eb8eea06f37d50cd5afabc9888922456d6b3",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-aurora-presets/src/main/java/org/nd4j/aurora/AuroraPresets.java",
      "status": "modified",
      "additions": 1,
      "deletions": 6,
      "changes": 7,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/c08a0eb09d21dc366fd9014fb22bb6dc318a2adf/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora-presets%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Faurora%2FAuroraPresets.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/c08a0eb09d21dc366fd9014fb22bb6dc318a2adf/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora-presets%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Faurora%2FAuroraPresets.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora-presets%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Faurora%2FAuroraPresets.java?ref=c08a0eb09d21dc366fd9014fb22bb6dc318a2adf",
      "patch": "@@ -72,12 +72,7 @@ public void init(ClassProperties properties) {\n         if(!Loader.isLoadLibraries()) {\n             return;\n         }\n-\n-        List<String> resources = properties.get(\"platform.preloadresource\");\n-        resources.add(\"org/nd4j/aurora\");\n-\n-        logger.info( \"PRINTING FROM INIT \" + properties);\n-\n+        \n \n     }\n }\n\\ No newline at end of file",
      "parent_sha": "4ff7522f1433623d9c2a6d0a45fc4c0826efd074"
    }
  },
  {
    "oid": "e1b320f269ce78e2b009872e16f04474c8a5eb69",
    "message": "NaN comparison does not behave as expected\n\nSee https://www.baeldung.com/java-not-a-number for details.",
    "date": "2021-09-17T05:37:51Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/e1b320f269ce78e2b009872e16f04474c8a5eb69",
    "details": {
      "sha": "6779edd72dd3979a5b618f5954b9f034055c8a5c",
      "filename": "datavec/datavec-api/src/main/java/org/datavec/api/transform/analysis/counter/DoubleAnalysisCounter.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/e1b320f269ce78e2b009872e16f04474c8a5eb69/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fcounter%2FDoubleAnalysisCounter.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/e1b320f269ce78e2b009872e16f04474c8a5eb69/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fcounter%2FDoubleAnalysisCounter.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Fanalysis%2Fcounter%2FDoubleAnalysisCounter.java?ref=e1b320f269ce78e2b009872e16f04474c8a5eb69",
      "patch": "@@ -85,7 +85,7 @@ public DoubleAnalysisCounter add(Writable writable) {\n         if (value == 0)\n             countZero++;\n \n-        if (value == Double.NaN)\n+        if (Double.isNaN(value))\n             countNaN++;\n \n         if (value == getMinValueSeen())",
      "parent_sha": "fe1a9d3c30e9d39faae7f6b68d9fc3e4d3977521"
    }
  },
  {
    "oid": "8f2932b6253216ad20fba47d9e9d916357b8df14",
    "message": "Fix redundancy",
    "date": "2021-08-16T11:56:27Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/8f2932b6253216ad20fba47d9e9d916357b8df14",
    "details": {
      "sha": "24d5cb9d717a92fe3afe870c2878868b083ff785",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/serde/FlatBuffersMapper.java",
      "status": "modified",
      "additions": 1,
      "deletions": 2,
      "changes": 3,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/8f2932b6253216ad20fba47d9e9d916357b8df14/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/8f2932b6253216ad20fba47d9e9d916357b8df14/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Fserde%2FFlatBuffersMapper.java?ref=8f2932b6253216ad20fba47d9e9d916357b8df14",
      "patch": "@@ -758,8 +758,7 @@ public static int asFlatNode(@NonNull SameDiff sameDiff, @NonNull DifferentialFu\n             if(dynamicCustomOp.numSArguments() > 0) {\n                 sArgs = dynamicCustomOp.sArgs();\n                 extraStringIds = new int[dynamicCustomOp.numSArguments()];\n-                val sArgs2 = dynamicCustomOp.sArgs();\n-                for(int i = 0; i < sArgs2.length; i++) {\n+                for(int i = 0; i < sArgs.length; i++) {\n                     extraStringIds[i] = bufferBuilder.createString(sArgs[i]);\n                 }\n             }",
      "parent_sha": "d0ae56ca17eb617e59d6d648e4f6489c0247db83"
    }
  },
  {
    "oid": "3fb9aecb59f437f9d2a5f4ac7b34b7773123bb49",
    "message": "Fix for null shape in SameDiff.var validation (#250)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2019-09-10T02:22:10Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/3fb9aecb59f437f9d2a5f4ac7b34b7773123bb49",
    "details": {
      "sha": "452077238cdc201ef878a3ac3f7f6aa195bf67a7",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/SameDiff.java",
      "status": "modified",
      "additions": 4,
      "deletions": 2,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/3fb9aecb59f437f9d2a5f4ac7b34b7773123bb49/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/3fb9aecb59f437f9d2a5f4ac7b34b7773123bb49/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java?ref=3fb9aecb59f437f9d2a5f4ac7b34b7773123bb49",
      "patch": "@@ -3367,8 +3367,10 @@ public SDVariable var(@NonNull String name, @NonNull WeightInitScheme weightInit\n      */\n     public SDVariable var(@NonNull String name, @NonNull VariableType variableType, WeightInitScheme weightInitScheme,\n                           org.nd4j.linalg.api.buffer.DataType dataType, long... shape) {\n-        for(long l : shape){\n-            Preconditions.checkArgument(l != 0, \"Cannot create variable with a shape that contains zeros (empty array shape) - got shape %s\", shape);\n+        if(shape != null) {\n+            for (long l : shape) {\n+                Preconditions.checkArgument(l != 0, \"Cannot create variable with a shape that contains zeros (empty array shape) - got shape %s\", shape);\n+            }\n         }\n \n         if (name == null || name.length() < 1)",
      "parent_sha": "c9f8a904ad3add51bd62ccd4088d277a2e55342e"
    }
  },
  {
    "oid": "691164007ebca396dc5d79fd825a91862d80e294",
    "message": "Fixed tests for #9333\n\nSigned-off-by: jljljl <jijiji95@bk.ru>",
    "date": "2021-06-03T10:57:46Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/691164007ebca396dc5d79fd825a91862d80e294",
    "details": {
      "sha": "e4392ea990d4f6842ec0e201e57fc082ff5f3b11",
      "filename": "deeplearning4j/deeplearning4j-common/src/main/java/org/deeplearning4j/common/config/DL4JClassLoading.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/691164007ebca396dc5d79fd825a91862d80e294/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/691164007ebca396dc5d79fd825a91862d80e294/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java?ref=691164007ebca396dc5d79fd825a91862d80e294",
      "patch": "@@ -83,7 +83,7 @@ public static <T> T createNewInstance(String className, Class<? super T> supercl\n         return createNewInstance(className, superclass, new Class<?>[]{}, new Object[]{});\n     }\n \n-    public static <T> T createNewInstance(String className, Class<? super T> superclass, Object [] args) {\n+    public static <T> T createNewInstance(String className, Class<? super T> superclass, Object... args) {\n         Class<?>[] parameterTypes = new Class<?>[args.length];\n         for (int i = 0; i < args.length; i++) {\n             Object arg = args[i];",
      "parent_sha": "aa6839f7b1a17cfef6ef633bd5bb1fa53917793e"
    }
  },
  {
    "oid": "77e03670c87e7635aad0f572b39320e8860a0263",
    "message": "fix eclipse/deeplearning4j#9266 and eclipse/deeplearning4j-examples#1029\n\nSigned-off-by: yumg <16405589@qq.com>",
    "date": "2021-06-20T01:57:18Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/77e03670c87e7635aad0f572b39320e8860a0263",
    "details": {
      "sha": "e2e6a8de1c0cc2ccb089d712c518f14dfe3529ae",
      "filename": "datavec/datavec-api/src/main/java/org/datavec/api/transform/transform/time/StringToTimeTransform.java",
      "status": "modified",
      "additions": 258,
      "deletions": 255,
      "changes": 513,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/77e03670c87e7635aad0f572b39320e8860a0263/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Ftransform%2Ftime%2FStringToTimeTransform.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/77e03670c87e7635aad0f572b39320e8860a0263/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Ftransform%2Ftime%2FStringToTimeTransform.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fapi%2Ftransform%2Ftransform%2Ftime%2FStringToTimeTransform.java?ref=77e03670c87e7635aad0f572b39320e8860a0263",
      "patch": "@@ -20,8 +20,15 @@\n \n package org.datavec.api.transform.transform.time;\n \n-import lombok.Data;\n-import lombok.EqualsAndHashCode;\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.TimeZone;\n+import java.util.regex.Pattern;\n+\n import org.datavec.api.transform.metadata.ColumnMetaData;\n import org.datavec.api.transform.metadata.TimeMetaData;\n import org.datavec.api.transform.transform.BaseColumnTransform;\n@@ -33,261 +40,257 @@\n import org.nd4j.shade.jackson.annotation.JsonIgnoreProperties;\n import org.nd4j.shade.jackson.annotation.JsonProperty;\n \n-import java.io.IOException;\n-import java.io.ObjectInputStream;\n-import java.io.ObjectOutputStream;\n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.TimeZone;\n-import java.util.Locale;\n-import java.util.regex.Pattern;\n+import lombok.Data;\n+import lombok.EqualsAndHashCode;\n \n @Data\n-@EqualsAndHashCode(exclude = {\"formatter\", \"formatters\"})\n-@JsonIgnoreProperties({\"formatters\", \"formatter\"})\n+@EqualsAndHashCode(exclude = { \"formatter\", \"formatters\" })\n+@JsonIgnoreProperties({ \"formatters\", \"formatter\" })\n public class StringToTimeTransform extends BaseColumnTransform {\n \n-    private final String timeFormat;\n-    private final DateTimeZone timeZone;\n-    private final Locale locale;\n-    private final Long minValidTime;\n-    private final Long maxValidTime;\n-    //formats from: http://www.java2s.com/Tutorials/Java/Data_Type_How_to/Legacy_Date_Format/Guess_the_format_pattern_based_on_date_value.htm\n-    //2017-09-21T17:06:29.064687\n-    // 12/1/2010 11:21\n-    private static final String[] formats = { \"YYYY-MM-dd'T'HH:mm:ss\",\"YYYY-MM-dd\",\"YYYY-MM-dd'T'HH:mm:ss'Z'\",\n-            \"YYYY-MM-dd'T'HH:mm:ssZ\",\n-            \"YYYY-MM-dd'T'HH:mm:ss.SSS'Z'\", \"YYYY-MM-dd'T'HH:mm:ss.SSSZ\",\n-            \"YYYY-MM-dd HH:mm:ss\", \"MM/dd/YYYY HH:mm:ss\",\n-            \"MM/dd/YYYY'T'HH:mm:ss.SSS'Z'\", \"MM/dd/YYYY'T'HH:mm:ss.SSSZ\",\n-            \"MM/dd/YYYY'T'HH:mm:ss.SSS\", \"MM/dd/YYYY'T'HH:mm:ssZ\",\n-            \"MM/dd/YYYY'T'HH:mm:ss\", \"YYYY:MM:dd HH:mm:ss\", \"YYYYMMdd\", \"YYYY-MM-dd HH:mm:ss\",\"MM/dd/YYYY HH:mm\",\n-\n-    };\n-    private transient DateTimeFormatter[] formatters;\n-\n-    private transient DateTimeFormatter formatter;\n-\n-\n-    /**\n-     * Instantiate this without a time format specified.\n-     * If this constructor is used, this transform will be allowed\n-     * to handle several common transforms as defined in the\n-     * static formats array.\n-     *\n-     *\n-     * @param columnName Name of the String column\n-     * @param timeZone   Timezone for time parsing\n-     */\n-    public StringToTimeTransform(String columnName,  TimeZone timeZone) {\n-        this(columnName, null, timeZone, null, null, null);\n-    }\n-\n-    /**\n-     * @param columnName Name of the String column\n-     * @param timeZone   Timezone for time parsing\n-     * @param locale     Locale for i18n\n-     */\n-    public StringToTimeTransform(String columnName,  TimeZone timeZone, Locale locale) {\n-        this(columnName, null, timeZone, locale, null, null);\n-    }\n-\n-    /**\n-     * @param columnName Name of the String column\n-     * @param timeFormat Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone   Timezone for time parsing\n-     */\n-    public StringToTimeTransform(String columnName, String timeFormat, TimeZone timeZone) {\n-        this(columnName, timeFormat, timeZone, null, null, null);\n-    }\n-\n-    /**\n-     * @param columnName Name of the String column\n-     * @param timeFormat Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone   Timezone for time parsing\n-     * @param locale     Locale for i18n\n-     */\n-    public StringToTimeTransform(String columnName, String timeFormat, TimeZone timeZone, Locale locale) {\n-        this(columnName, timeFormat, timeZone, locale, null, null);\n-    }\n-\n-\n-    /**\n-     * Instantiate this without a time format specified.\n-     * If this constructor is used, this transform will be allowed\n-     * to handle several common transforms as defined in the\n-     * static formats array.\n-     *\n-     *\n-     * @param columnName Name of the String column\n-     * @param timeZone   Timezone for time parsing\n-     * @param locale     Locale for i18n\n-     */\n-    public StringToTimeTransform(String columnName, DateTimeZone timeZone, Locale locale) {\n-        this(columnName, null, timeZone, locale, null, null);\n-    }\n-\n-\n-    /**\n-     * @param columnName Name of the String column\n-     * @param timeFormat Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone   Timezone for time parsing\n-     */\n-    public StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone) {\n-        this(columnName, timeFormat, timeZone, null, null, null);\n-    }\n-\n-    /**\n-     * @param columnName Name of the String column\n-     * @param timeFormat Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone   Timezone for time parsing\n-     * @param locale     Locale for i18n\n-     */\n-    public StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone, Locale locale) {\n-        this(columnName, timeFormat, timeZone, locale, null, null);\n-    }\n-\n-    /**\n-     * @param columnName   Name of the String column\n-     * @param timeFormat   Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone     Timezone for time parsing\n-     * @param locale       Locale for i18n\n-     * @param minValidTime Min valid time (epoch millisecond format). If null: no restriction in min valid time\n-     * @param maxValidTime Max valid time (epoch millisecond format). If null: no restriction in max valid time\n-     */\n-    public StringToTimeTransform(@JsonProperty(\"columnName\") String columnName,\n-                                 @JsonProperty(\"timeFormat\") String timeFormat, @JsonProperty(\"timeZone\") TimeZone timeZone,\n-                                 @JsonProperty(\"locale\") Locale locale,\n-                                 @JsonProperty(\"minValidTime\") Long minValidTime, @JsonProperty(\"maxValidTime\") Long maxValidTime) {\n-        this(columnName, timeFormat, DateTimeZone.forTimeZone(timeZone), locale, minValidTime, maxValidTime);\n-    }\n-\n-    /**\n-     * @param columnName   Name of the String column\n-     * @param timeFormat   Time format, as per <a href=\"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n-     * @param timeZone     Timezone for time parsing\n-     * @param locale       Locale for i18n\n-     * @param minValidTime Min valid time (epoch millisecond format). If null: no restriction in min valid time\n-     * @param maxValidTime Max valid time (epoch millisecond format). If null: no restriction in max valid time\n-     */\n-    public StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone, Locale locale, Long minValidTime,\n-                                 Long maxValidTime) {\n-        super(columnName);\n-        this.timeFormat = timeFormat;\n-        this.timeZone = timeZone;\n-        this.locale = locale;\n-        this.minValidTime = minValidTime;\n-        this.maxValidTime = maxValidTime;\n-        if(timeFormat != null)\n-            if (locale != null) {\n-                this.formatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone).withLocale(locale);\n-            } else {\n-                this.formatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone);\n-            }\n-        else {\n-            List<DateTimeFormatter> dateFormatList = new ArrayList<>();\n-            formatters = new DateTimeFormatter[formats.length];\n-            for(int i = 0; i < formatters.length; i++) {\n-                if (locale != null) {\n-                    dateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone).withLocale(locale));\n-                } else {\n-                    dateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone));\n-                }\n-            }\n-            formatters = dateFormatList.toArray(new DateTimeFormatter[dateFormatList.size()]);\n-        }\n-    }\n-\n-\n-    @Override\n-    public ColumnMetaData getNewColumnMetaData(String newName, ColumnMetaData oldColumnType) {\n-        return new TimeMetaData(newName, timeZone, minValidTime, maxValidTime);\n-    }\n-\n-    @Override\n-    public Writable map(Writable columnWritable) {\n-        String str = columnWritable.toString().trim();\n-        if(str.contains(\"'T'\")) {\n-            str = str.replaceFirst(\"'T'\",\"T\");\n-        }\n-\n-\n-\n-        if(formatter == null) {\n-            long result = -1;\n-            if(Pattern.compile(\"\\\\.[0-9]+\").matcher(str).find()) {\n-                str = str.replaceAll(\"\\\\.[0-9]+\",\"\");\n-            }\n-\n-\n-            for(DateTimeFormatter formatter : formatters) {\n-                try {\n-                    result = formatter.parseMillis(str);\n-                    return new LongWritable(result);\n-                }catch (Exception e) {\n-\n-                }\n-\n-\n-            }\n-\n-            if(result  < 0) {\n-                throw new IllegalStateException(\"Unable to parse date time \" + str);\n-            }\n-        }\n-        else {\n-            long time = formatter.parseMillis(str);\n-            return new LongWritable(time);\n-        }\n-\n-        throw new IllegalStateException(\"Unable to parse date time \" + str);\n-\n-    }\n-\n-    @Override\n-    public String toString() {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"StringToTimeTransform(timeZone=\").append(timeZone);\n-        if (minValidTime != null)\n-            sb.append(\",minValidTime=\").append(minValidTime);\n-        if (maxValidTime != null) {\n-            if (minValidTime != null)\n-                sb.append(\",\");\n-            sb.append(\"maxValidTime=\").append(maxValidTime);\n-        }\n-        sb.append(\")\");\n-        return sb.toString();\n-    }\n-\n-    //Custom serialization methods, because Joda Time doesn't allow DateTimeFormatter objects to be serialized :(\n-    private void writeObject(ObjectOutputStream out) throws IOException {\n-        out.defaultWriteObject();\n-    }\n-\n-    private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {\n-        in.defaultReadObject();\n-        if(timeFormat != null)\n-            formatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone);\n-        else {\n-            List<DateTimeFormatter> dateFormatList = new ArrayList<>();\n-            formatters = new DateTimeFormatter[formats.length];\n-            for(int i = 0; i < formatters.length; i++) {\n-                dateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone));\n-            }\n-\n-            formatters = dateFormatList.toArray(new DateTimeFormatter[dateFormatList.size()]);\n-        }\n-    }\n-\n-    /**\n-     * Transform an object\n-     * in to another object\n-     *\n-     * @param input the record to transform\n-     * @return the transformed writable\n-     */\n-    @Override\n-    public Object map(Object input) {\n-        return null;\n-    }\n+\tprivate final String timeFormat;\n+\tprivate final DateTimeZone timeZone;\n+\tprivate final Locale locale;\n+\tprivate final Long minValidTime;\n+\tprivate final Long maxValidTime;\n+\t// formats from:\n+\t// http://www.java2s.com/Tutorials/Java/Data_Type_How_to/Legacy_Date_Format/Guess_the_format_pattern_based_on_date_value.htm\n+\t// 2017-09-21T17:06:29.064687\n+\t// 12/1/2010 11:21\n+\tprivate static final String[] formats = { \"YYYY-MM-dd'T'HH:mm:ss\", \"YYYY-MM-dd\", \"YYYY-MM-dd'T'HH:mm:ss'Z'\",\n+\t\t\t\"YYYY-MM-dd'T'HH:mm:ssZ\", \"YYYY-MM-dd'T'HH:mm:ss.SSS'Z'\", \"YYYY-MM-dd'T'HH:mm:ss.SSSZ\",\n+\t\t\t\"YYYY-MM-dd HH:mm:ss\", \"MM/dd/YYYY HH:mm:ss\", \"MM/dd/YYYY'T'HH:mm:ss.SSS'Z'\", \"MM/dd/YYYY'T'HH:mm:ss.SSSZ\",\n+\t\t\t\"MM/dd/YYYY'T'HH:mm:ss.SSS\", \"MM/dd/YYYY'T'HH:mm:ssZ\", \"MM/dd/YYYY'T'HH:mm:ss\", \"YYYY:MM:dd HH:mm:ss\",\n+\t\t\t\"YYYYMMdd\", \"YYYY-MM-dd HH:mm:ss\", \"MM/dd/YYYY HH:mm\",\n+\n+\t};\n+\tprivate transient DateTimeFormatter[] formatters;\n+\n+\tprivate transient DateTimeFormatter formatter;\n+\n+\t/**\n+\t * Instantiate this without a time format specified. If this constructor is\n+\t * used, this transform will be allowed to handle several common transforms as\n+\t * defined in the static formats array.\n+\t *\n+\t *\n+\t * @param columnName Name of the String column\n+\t * @param timeZone   Timezone for time parsing\n+\t */\n+\tpublic StringToTimeTransform(String columnName, TimeZone timeZone) {\n+\t\tthis(columnName, null, timeZone, null, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName Name of the String column\n+\t * @param timeZone   Timezone for time parsing\n+\t * @param locale     Locale for i18n\n+\t */\n+\tpublic StringToTimeTransform(String columnName, TimeZone timeZone, Locale locale) {\n+\t\tthis(columnName, null, timeZone, locale, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName Name of the String column\n+\t * @param timeFormat Time format, as per <a href=\n+\t *                   \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone   Timezone for time parsing\n+\t */\n+\tpublic StringToTimeTransform(String columnName, String timeFormat, TimeZone timeZone) {\n+\t\tthis(columnName, timeFormat, timeZone, null, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName Name of the String column\n+\t * @param timeFormat Time format, as per <a href=\n+\t *                   \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone   Timezone for time parsing\n+\t * @param locale     Locale for i18n\n+\t */\n+\tpublic StringToTimeTransform(String columnName, String timeFormat, TimeZone timeZone, Locale locale) {\n+\t\tthis(columnName, timeFormat, timeZone, locale, null, null);\n+\t}\n+\n+\t/**\n+\t * Instantiate this without a time format specified. If this constructor is\n+\t * used, this transform will be allowed to handle several common transforms as\n+\t * defined in the static formats array.\n+\t *\n+\t *\n+\t * @param columnName Name of the String column\n+\t * @param timeZone   Timezone for time parsing\n+\t * @param locale     Locale for i18n\n+\t */\n+\tpublic StringToTimeTransform(String columnName, DateTimeZone timeZone, Locale locale) {\n+\t\tthis(columnName, null, timeZone, locale, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName Name of the String column\n+\t * @param timeFormat Time format, as per <a href=\n+\t *                   \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone   Timezone for time parsing\n+\t */\n+\tpublic StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone) {\n+\t\tthis(columnName, timeFormat, timeZone, null, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName Name of the String column\n+\t * @param timeFormat Time format, as per <a href=\n+\t *                   \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone   Timezone for time parsing\n+\t * @param locale     Locale for i18n\n+\t */\n+\tpublic StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone, Locale locale) {\n+\t\tthis(columnName, timeFormat, timeZone, locale, null, null);\n+\t}\n+\n+\t/**\n+\t * @param columnName   Name of the String column\n+\t * @param timeFormat   Time format, as per <a href=\n+\t *                     \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone     Timezone for time parsing\n+\t * @param locale       Locale for i18n\n+\t * @param minValidTime Min valid time (epoch millisecond format). If null: no\n+\t *                     restriction in min valid time\n+\t * @param maxValidTime Max valid time (epoch millisecond format). If null: no\n+\t *                     restriction in max valid time\n+\t */\n+\tpublic StringToTimeTransform(@JsonProperty(\"columnName\") String columnName,\n+\t\t\t@JsonProperty(\"timeFormat\") String timeFormat, @JsonProperty(\"timeZone\") TimeZone timeZone,\n+\t\t\t@JsonProperty(\"locale\") Locale locale, @JsonProperty(\"minValidTime\") Long minValidTime,\n+\t\t\t@JsonProperty(\"maxValidTime\") Long maxValidTime) {\n+\t\tthis(columnName, timeFormat, DateTimeZone.forTimeZone(timeZone), locale, minValidTime, maxValidTime);\n+\t}\n+\n+\t/**\n+\t * @param columnName   Name of the String column\n+\t * @param timeFormat   Time format, as per <a href=\n+\t *                     \"http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>\n+\t * @param timeZone     Timezone for time parsing\n+\t * @param locale       Locale for i18n\n+\t * @param minValidTime Min valid time (epoch millisecond format). If null: no\n+\t *                     restriction in min valid time\n+\t * @param maxValidTime Max valid time (epoch millisecond format). If null: no\n+\t *                     restriction in max valid time\n+\t */\n+\tpublic StringToTimeTransform(String columnName, String timeFormat, DateTimeZone timeZone, Locale locale,\n+\t\t\tLong minValidTime, Long maxValidTime) {\n+\t\tsuper(columnName);\n+\t\tthis.timeFormat = timeFormat;\n+\t\tthis.timeZone = timeZone;\n+\t\tthis.locale = locale;\n+\t\tthis.minValidTime = minValidTime;\n+\t\tthis.maxValidTime = maxValidTime;\n+\t\tif (timeFormat != null)\n+\t\t\tif (locale != null) {\n+\t\t\t\tthis.formatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone).withLocale(locale);\n+\t\t\t} else {\n+\t\t\t\tthis.formatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone);\n+\t\t\t}\n+\t\telse {\n+\t\t\tList<DateTimeFormatter> dateFormatList = new ArrayList<>();\n+\t\t\tformatters = new DateTimeFormatter[formats.length];\n+\t\t\tfor (int i = 0; i < formatters.length; i++) {\n+\t\t\t\tif (locale != null) {\n+\t\t\t\t\tdateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone).withLocale(locale));\n+\t\t\t\t} else {\n+\t\t\t\t\tdateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone));\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tformatters = dateFormatList.toArray(new DateTimeFormatter[dateFormatList.size()]);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ColumnMetaData getNewColumnMetaData(String newName, ColumnMetaData oldColumnType) {\n+\t\treturn new TimeMetaData(newName, timeZone, minValidTime, maxValidTime);\n+\t}\n+\n+\t@Override\n+\tpublic Writable map(Writable columnWritable) {\n+\t\tString str = columnWritable.toString().trim();\n+\t\tif (str.contains(\"'T'\")) {\n+\t\t\tstr = str.replaceFirst(\"'T'\", \"T\");\n+\t\t}\n+\n+\t\tif (formatter == null) {\n+\t\t\tlong result = -1;\n+\t\t\tif (Pattern.compile(\"\\\\.[0-9]+\").matcher(str).find()) {\n+\t\t\t\tstr = str.replaceAll(\"\\\\.[0-9]+\", \"\");\n+\t\t\t}\n+\n+\t\t\tfor (DateTimeFormatter formatter : formatters) {\n+\t\t\t\ttry {\n+\t\t\t\t\tresult = formatter.parseMillis(str);\n+\t\t\t\t\treturn new LongWritable(result);\n+\t\t\t\t} catch (Exception e) {\n+\n+\t\t\t\t}\n+\n+\t\t\t}\n+\n+\t\t\tif (result < 0) {\n+\t\t\t\tthrow new IllegalStateException(\"Unable to parse date time \" + str);\n+\t\t\t}\n+\t\t} else {\n+\t\t\tlong time = formatter.parseMillis(str);\n+\t\t\treturn new LongWritable(time);\n+\t\t}\n+\n+\t\tthrow new IllegalStateException(\"Unable to parse date time \" + str);\n+\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"StringToTimeTransform(timeZone=\").append(timeZone);\n+\t\tif (minValidTime != null)\n+\t\t\tsb.append(\",minValidTime=\").append(minValidTime);\n+\t\tif (maxValidTime != null) {\n+\t\t\tif (minValidTime != null)\n+\t\t\t\tsb.append(\",\");\n+\t\t\tsb.append(\"maxValidTime=\").append(maxValidTime);\n+\t\t}\n+\t\tsb.append(\")\");\n+\t\treturn sb.toString();\n+\t}\n+\n+\t// Custom serialization methods, because Joda Time doesn't allow\n+\t// DateTimeFormatter objects to be serialized :(\n+\tprivate void writeObject(ObjectOutputStream out) throws IOException {\n+\t\tout.defaultWriteObject();\n+\t}\n+\n+\tprivate void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {\n+\t\tin.defaultReadObject();\n+\t\tif (timeFormat != null)\n+\t\t\tif (locale != null) {\n+\t\t\t\tformatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone).withLocale(locale);\n+\t\t\t} else {\n+\t\t\t\tformatter = DateTimeFormat.forPattern(timeFormat).withZone(timeZone);\n+\t\t\t}\n+\t\telse {\n+\t\t\tList<DateTimeFormatter> dateFormatList = new ArrayList<>();\n+\t\t\tformatters = new DateTimeFormatter[formats.length];\n+\t\t\tfor (int i = 0; i < formatters.length; i++) {\n+\t\t\t\tdateFormatList.add(DateTimeFormat.forPattern(formats[i]).withZone(timeZone));\n+\t\t\t}\n+\n+\t\t\tformatters = dateFormatList.toArray(new DateTimeFormatter[dateFormatList.size()]);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Transform an object in to another object\n+\t *\n+\t * @param input the record to transform\n+\t * @return the transformed writable\n+\t */\n+\t@Override\n+\tpublic Object map(Object input) {\n+\t\treturn null;\n+\t}\n }",
      "parent_sha": "82edf877dbe7c71dfec78ef60e006706fbb6de76"
    }
  },
  {
    "oid": "1cb48a5a0c8ce42feb5b24761cd2d1c90aa87db6",
    "message": "Amend array cache memory manager debug logging (#9747)\n\n* Update ArrayCacheMemoryMgr.java\r\n\r\n* Log warning for invalid ops. Alows for more flexibility when importing models.\r\n\r\n* Add back fix for LSTM nullpointer\r\n\r\n* Fix debug logging for cache",
    "date": "2022-08-10T15:22:10Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/1cb48a5a0c8ce42feb5b24761cd2d1c90aa87db6",
    "details": {
      "sha": "5689e3159cb3a06aa5cda83327b4856e66875c60",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/internal/memory/ArrayCacheMemoryMgr.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/1cb48a5a0c8ce42feb5b24761cd2d1c90aa87db6/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/1cb48a5a0c8ce42feb5b24761cd2d1c90aa87db6/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java?ref=1cb48a5a0c8ce42feb5b24761cd2d1c90aa87db6",
      "patch": "@@ -171,7 +171,7 @@ public INDArray allocate(boolean detached, LongShapeDescriptor descriptor) {\n             if (arr != null && !arr.wasClosed()) {\n                 // Decrement cache size\n                 currentCacheSize -= dataType.width() * arr.data().length();\n-                log.info(\"Cache hit for data type \" + dataType + \" and shape \" + Arrays.toString(arr.shape()));\n+                log.debug(\"Cache hit for data type \" + dataType + \" and shape \" + Arrays.toString(arr.shape()));\n                 // We need to assign new Id. this way we will break any possible relationship it\n                 // had in Tracker.\n                 // the old cache was recreating New Array using buffer and thus gaining new",
      "parent_sha": "4b4161c9c87263e0c3983b935c856a42e5fdccaa"
    }
  },
  {
    "oid": "c300902e3a9aa6734ff8ba591b7974161a7744c3",
    "message": "Rename rand methods with seed (#10004)\n\nSigned-off-by: Anthony F <anthony.femenia@hotmail.fr>",
    "date": "2023-06-11T20:59:08Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/c300902e3a9aa6734ff8ba591b7974161a7744c3",
    "details": {
      "sha": "3c729d7722c7bf729cad3aa80a89aae74d9296de",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 6,
      "deletions": 6,
      "changes": 12,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/c300902e3a9aa6734ff8ba591b7974161a7744c3/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/c300902e3a9aa6734ff8ba591b7974161a7744c3/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=c300902e3a9aa6734ff8ba591b7974161a7744c3",
      "patch": "@@ -3060,17 +3060,17 @@ public static INDArray rand(@NonNull DataType dataType, @NonNull int... shape) {\n      * @param seed  the  seed to use\r\n      * @return the random ndarray with the specified shape\r\n      */\r\n-    public static INDArray rand(long seed, @NonNull long... shape) {\r\n+    public static INDArray randWithSeed(long seed, @NonNull long... shape) {\r\n         INDArray ret = createUninitialized(shape, Nd4j.order());//;INSTANCE.rand(shape, seed);\r\n-        return rand(ret, seed);\r\n+        return randWithSeed(ret, seed);\r\n     }\r\n \r\n     /**\r\n-     * @deprecated use {@link Nd4j#rand(long, long...)}\r\n+     * @deprecated use {@link Nd4j#randWithSeed(long, long...)}\r\n      */\r\n     @Deprecated\r\n-    public static INDArray rand(int[] shape, long seed) {\r\n-        return rand(seed, ArrayUtil.toLongArray(shape)).castTo(Nd4j.defaultFloatingPointType());\r\n+    public static INDArray randWithSeed(int[] shape, long seed) {\r\n+        return randWithSeed(seed, ArrayUtil.toLongArray(shape)).castTo(Nd4j.defaultFloatingPointType());\r\n     }\r\n \r\n \r\n@@ -3360,7 +3360,7 @@ public static INDArray rand(INDArray target) {\n      * @param seed the  seed to use\r\n      * @return the given target array\r\n      */\r\n-    public static INDArray rand(INDArray target, long seed) {\r\n+    public static INDArray randWithSeed(INDArray target, long seed) {\r\n         Nd4j.getRandom().setSeed(seed);\r\n         return getExecutioner().exec(new UniformDistribution(target), Nd4j.getRandom());\r\n     }\r",
      "parent_sha": "603cf98dec942990415a4920312bab48db2728d9"
    }
  },
  {
    "oid": "7f6e464622fedb6c8a49181172dbf347a5017bbb",
    "message": "Update based on feedback",
    "date": "2021-10-29T23:58:24Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/7f6e464622fedb6c8a49181172dbf347a5017bbb",
    "details": {
      "sha": "446df70046b2890102f16835beeb3c1a6cc1be36",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/shape/Reshape.java",
      "status": "modified",
      "additions": 7,
      "deletions": 4,
      "changes": 11,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/7f6e464622fedb6c8a49181172dbf347a5017bbb/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FReshape.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/7f6e464622fedb6c8a49181172dbf347a5017bbb/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FReshape.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fops%2Fimpl%2Fshape%2FReshape.java?ref=7f6e464622fedb6c8a49181172dbf347a5017bbb",
      "patch": "@@ -46,20 +46,23 @@ public class Reshape extends DynamicCustomOp {\n \n     private long[] shape;\n \n+    public final static int C_ORDER = -99;\n+    public final static int F_ORDER = -127;\n+\n     public Reshape(SameDiff sameDiff, SDVariable i_v, long[] shape) {\n         super(null, sameDiff, new SDVariable[]{i_v});\n         this.shape = shape;\n         //c ordering: see (char) 99 for c ordering and (char) 'f' is 102\n         //note it has to be negative for the long array case only\n         //to flag the difference between an ordering being specified\n         //and a dimension.\n-        addIArgument(-99);\n+        addIArgument(C_ORDER);\n         addIArgument(shape);\n     }\n \n     public Reshape(SameDiff sameDiff, SDVariable i_v, SDVariable shape) {\n         super(null, sameDiff, new SDVariable[]{i_v, shape});\n-        addIArgument(-99);\n+        addIArgument(C_ORDER);\n     }\n \n     public Reshape(INDArray in, long... shape) {\n@@ -69,7 +72,7 @@ public Reshape(INDArray in, long... shape) {\n         //note it has to be negative for the long array case only\n         //to flag the difference between an ordering being specified\n         //and a dimension.\n-        addIArgument(-99);\n+        addIArgument(C_ORDER);\n         addIArgument(shape);\n     }\n \n@@ -81,7 +84,7 @@ public Reshape(@NonNull INDArray in, @NonNull INDArray shape, INDArray out) {\n \n     public Reshape(INDArray in, INDArray shape){\n         this(in, shape, null);\n-        addIArgument(-99);\n+        addIArgument(C_ORDER);\n \n     }\n ",
      "parent_sha": "cdc35ac173a3d0fbf27c9a0eeffbb46938eaad04"
    }
  },
  {
    "oid": "b1f8819bdecf67ea310b245a43d14c6d10a475e1",
    "message": "Update Nd4jTestsC.java",
    "date": "2021-03-23T11:21:56Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b1f8819bdecf67ea310b245a43d14c6d10a475e1",
    "details": {
      "sha": "4d2ffed77ab0fdc07ac869c311191561c7792425",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/Nd4jTestsC.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b1f8819bdecf67ea310b245a43d14c6d10a475e1/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b1f8819bdecf67ea310b245a43d14c6d10a475e1/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java?ref=b1f8819bdecf67ea310b245a43d14c6d10a475e1",
      "patch": "@@ -8591,7 +8591,7 @@ public void testToFromByteArray() throws IOException {\n     }\n \n     private static INDArray fwd(INDArray input, INDArray W, INDArray b){\n-        INDArray ret = Nd4j.createUninitialized(input.size(0), W.size(1));\n+        INDArray ret = Nd4j.createUninitialized(input.size(0), W.size(1)).castTo(DataType.DOUBLE);\n         input.mmuli(W, ret);\n         ret.addiRowVector(b);\n         return ret;",
      "parent_sha": "95f3067010fd4977e00d1ada109e6fc906e82355"
    }
  },
  {
    "oid": "4c504e9c564452589744cd2684a6194dddf67e7c",
    "message": "Re add enum fix",
    "date": "2021-11-10T12:48:54Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/4c504e9c564452589744cd2684a6194dddf67e7c",
    "details": {
      "sha": "893ec05e91e063e85a598dddfdc7c83511d6e5e4",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/functions/DifferentialFunction.java",
      "status": "modified",
      "additions": 14,
      "deletions": 4,
      "changes": 18,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/4c504e9c564452589744cd2684a6194dddf67e7c/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Ffunctions%2FDifferentialFunction.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/4c504e9c564452589744cd2684a6194dddf67e7c/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Ffunctions%2FDifferentialFunction.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Ffunctions%2FDifferentialFunction.java?ref=4c504e9c564452589744cd2684a6194dddf67e7c",
      "patch": "@@ -20,11 +20,8 @@\n \n package org.nd4j.autodiff.functions;\n \n-import lombok.Data;\n-import lombok.Getter;\n-import lombok.Setter;\n+import lombok.*;\n import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n import onnx.Onnx;\n import org.nd4j.autodiff.samediff.SDVariable;\n import org.nd4j.autodiff.samediff.SameDiff;\n@@ -45,6 +42,7 @@\n import org.tensorflow.framework.NodeDef;\n \n import java.lang.reflect.Field;\n+import java.lang.reflect.Method;\n import java.util.*;\n \n \n@@ -252,6 +250,7 @@ public Object getValue(Field property) {\n      * @param target the target field\n      * @param value the value to set\n      */\n+    @SneakyThrows\n     public void setValueFor(Field target, Object value) {\n         if(value == null && target.getType().isPrimitive()) {\n             throw new ND4JIllegalStateException(\"Unable to set primitive field \" + target + \" of type \" + target.getClass()\n@@ -347,6 +346,17 @@ public void setValueFor(Field target, Object value) {\n                 }\n \n \n+                if(target.getType().isEnum() && value instanceof Long || value instanceof Integer && !target.getType().equals(int.class) && !target.getType().equals(long.class)) {\n+                    Class<? extends Enum> enumType = (Class<? extends Enum>) target.getType();\n+                    Method method = enumType.getMethod(\"values\");\n+                    method.setAccessible(true);\n+                    Object[] invoke = (Object[])method.invoke(null);\n+                    Number number = (Number) value;\n+                    int idx = number.intValue();\n+                    Object get = invoke[idx];\n+                    value = get;\n+                }\n+\n                 target.set(this,value);\n             } catch (IllegalAccessException e) {\n                 throw new RuntimeException(\"Error setting property for function \" + getClass().getName(), e);",
      "parent_sha": "47e413d6f748ae106aff7defe01434e84fd4e68f"
    }
  },
  {
    "oid": "c1bcbdda18ee77300b90bdc7fbb3d5aabe47999f",
    "message": "Build fix - tsne random method signature (#259)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2019-09-13T03:40:46Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/c1bcbdda18ee77300b90bdc7fbb3d5aabe47999f",
    "details": {
      "sha": "c530d768a55436b8aca958534703cab9ba630f90",
      "filename": "deeplearning4j/deeplearning4j-manifold/deeplearning4j-tsne/src/main/java/org/deeplearning4j/plot/Tsne.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/c1bcbdda18ee77300b90bdc7fbb3d5aabe47999f/deeplearning4j%2Fdeeplearning4j-manifold%2Fdeeplearning4j-tsne%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fplot%2FTsne.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/c1bcbdda18ee77300b90bdc7fbb3d5aabe47999f/deeplearning4j%2Fdeeplearning4j-manifold%2Fdeeplearning4j-tsne%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fplot%2FTsne.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-manifold%2Fdeeplearning4j-tsne%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fplot%2FTsne.java?ref=c1bcbdda18ee77300b90bdc7fbb3d5aabe47999f",
      "patch": "@@ -108,7 +108,7 @@ public INDArray calculate(INDArray X, int targetDimensions, double perplexity) {\n \n         int n = X.rows();\n         // FIXME: this is wrong, another distribution required here\n-        Y = randn(X.rows(), targetDimensions, Nd4j.getRandom());\n+        Y = Nd4j.randn(X.dataType(), X.rows(), targetDimensions);\n         INDArray dY = Nd4j.zeros(n, targetDimensions);\n         INDArray iY = Nd4j.zeros(n, targetDimensions);\n         INDArray gains = Nd4j.ones(n, targetDimensions);",
      "parent_sha": "bc2a7dd7ae56519080407153b60efe54794b8a31"
    }
  },
  {
    "oid": "b2f86ab8a85df997391bd3bb5a6ba35318b4642f",
    "message": "#8849 Add ignore for randomly failing test (#399)\n\nSigned-off-by: Alex Black <blacka101@gmail.com>",
    "date": "2020-04-20T13:59:30Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b2f86ab8a85df997391bd3bb5a6ba35318b4642f",
    "details": {
      "sha": "de141c061c81fc4402609b4ebc0483cd33c36f80",
      "filename": "deeplearning4j/deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/test/java/org/deeplearning4j/spark/text/TextPipelineTest.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b2f86ab8a85df997391bd3bb5a6ba35318b4642f/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b2f86ab8a85df997391bd3bb5a6ba35318b4642f/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-scaleout%2Fspark%2Fdl4j-spark-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fspark%2Ftext%2FTextPipelineTest.java?ref=b2f86ab8a85df997391bd3bb5a6ba35318b4642f",
      "patch": "@@ -326,7 +326,7 @@ public void testHuffman() throws Exception {\n         sc.stop();\n     }\n \n-    @Test\n+    @Test @Ignore   //AB 2020/04/20 https://github.com/eclipse/deeplearning4j/issues/8849\n     public void testCountCumSum() throws Exception {\n         JavaSparkContext sc = getContext();\n         JavaRDD<String> corpusRDD = getCorpusRDD(sc);",
      "parent_sha": "fe516ae6cff74b25b088705019dfbcd0b10956e8"
    }
  },
  {
    "oid": "68d1269d5cfd187a22a07dbfa751f687c4a18671",
    "message": "Fixes https://github.com/eclipse/deeplearning4j/issues/8876",
    "date": "2021-06-09T06:43:47Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/68d1269d5cfd187a22a07dbfa751f687c4a18671",
    "details": {
      "sha": "7f49e3ef28a6dcc4c090dc46f1672eb962c1a95e",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/SameDiff.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/68d1269d5cfd187a22a07dbfa751f687c4a18671/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/68d1269d5cfd187a22a07dbfa751f687c4a18671/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2FSameDiff.java?ref=68d1269d5cfd187a22a07dbfa751f687c4a18671",
      "patch": "@@ -744,7 +744,8 @@ public INDArray getArrForVarName(@NonNull String varName) {\n                 //Only stored in inference session...\n                 InferenceSession s = sessions.get(Thread.currentThread().getId());\n                 if (s == null)\n-                    return null;\n+                    throw new UnsupportedOperationException(\"Cannot get array for ARRAY type SDVariable - use SDVariable.exec or SameDiff.output instead\");\n+\n                 return s.get(varName, InferenceSession.OUTER_FRAME, 0, null, false);\n             case PLACEHOLDER:\n                 long tid = Thread.currentThread().getId();",
      "parent_sha": "0d5f5ba1a181e070f21674d0f810f8e120fcb436"
    }
  },
  {
    "oid": "0c48e55f910d0b26dff5fa6848ceca13b82f1f92",
    "message": "Remove duplicate code for append() and prepend() Fix #7983 (#7987)\n\n* fix #7983\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* small fix.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* fix javadoc.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-07-09T03:58:50Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/0c48e55f910d0b26dff5fa6848ceca13b82f1f92",
    "details": {
      "sha": "7c5c960e56aa1e4766e97f255a9490c3775bac64",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 16,
      "deletions": 23,
      "changes": 39,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/0c48e55f910d0b26dff5fa6848ceca13b82f1f92/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/0c48e55f910d0b26dff5fa6848ceca13b82f1f92/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=0c48e55f910d0b26dff5fa6848ceca13b82f1f92",
      "patch": "@@ -343,48 +343,41 @@ public static INDArray pad(INDArray toPad, int[] padWidth, PadMode padMode) {\n \n \n     /**\n-     * Append the given\n-     * array with the specified value size\n-     * along a particular axis\n+     * Append the given array with the specified value size along a particular axis.\n+     * The prepend method has the same signature and prepends the given array.\n      * @param arr the array to append to\n      * @param padAmount the pad amount of the array to be returned\n      * @param val the value to append\n      * @param axis the axis to append to\n      * @return the newly created array\n      */\n     public static INDArray append(INDArray arr, int padAmount, double val, int axis) {\n-        if (padAmount == 0)\n-            return arr;\n-        long[] paShape = ArrayUtil.copy(arr.shape());\n-        if (axis < 0)\n-            axis = axis + arr.shape().length;\n-        paShape[axis] = padAmount;\n-        INDArray concatArray = Nd4j.valueArrayOf(paShape, val, arr.dataType());\n-        return Nd4j.concat(axis, arr, concatArray);\n+        return appendImpl(arr, padAmount, val, axis, true);\n     }\n \n     /**\n-     * Append the given\n-     * array with the specified value size\n-     * along a particular axis\n-     * @param arr the array to append to\n-     * @param padAmount the pad amount of the array to be returned\n-     * @param val the value to append\n-     * @param axis the axis to append to\n-     * @return the newly created array\n+     * @see #append(INDArray, int, double, int)\n      */\n     public static INDArray prepend(INDArray arr, int padAmount, double val, int axis) {\n+        return appendImpl(arr, padAmount, val, axis, false);\n+    }\n+\n+    /**\n+     * Append / Prepend shared implementation.\n+     * @param appendFlag flag to determine Append / Prepend.\n+     * @see #append(INDArray, int, double, int)\n+     */\n+    private static INDArray appendImpl(INDArray arr, int padAmount, double val, int axis, boolean appendFlag){\n         if (padAmount == 0)\n             return arr;\n-\n         long[] paShape = ArrayUtil.copy(arr.shape());\n         if (axis < 0)\n             axis = axis + arr.shape().length;\n         paShape[axis] = padAmount;\n-        INDArray concatArr = Nd4j.valueArrayOf(paShape, val, arr.dataType());\n-        return Nd4j.concat(axis, concatArr, arr);\n+        INDArray concatArray = Nd4j.valueArrayOf(paShape, val, arr.dataType());\n+        return appendFlag ? Nd4j.concat(axis, arr, concatArray) : Nd4j.concat(axis, concatArray, arr);\n     }\n-\n+    \n     /**\n      * Expand the array dimensions.\n      * This is equivalent to",
      "parent_sha": "595656d01e9ec4be4efa03326b54facc27f549ec"
    }
  },
  {
    "oid": "63ed202057d301755184dbb93fc777d4e590748c",
    "message": "cleaned up bert iterator tests (#110)\n\nSigned-off-by: eraly <susan.eraly@gmail.com>",
    "date": "2019-12-05T02:24:37Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/63ed202057d301755184dbb93fc777d4e590748c",
    "details": {
      "sha": "52644c3603b04aa48b4be70b2c1d30f6f59078f9",
      "filename": "deeplearning4j/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/test/java/org/deeplearning4j/iterator/TestBertIterator.java",
      "status": "modified",
      "additions": 333,
      "deletions": 338,
      "changes": 671,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/63ed202057d301755184dbb93fc777d4e590748c/deeplearning4j%2Fdeeplearning4j-nlp-parent%2Fdeeplearning4j-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fiterator%2FTestBertIterator.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/63ed202057d301755184dbb93fc777d4e590748c/deeplearning4j%2Fdeeplearning4j-nlp-parent%2Fdeeplearning4j-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fiterator%2FTestBertIterator.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nlp-parent%2Fdeeplearning4j-nlp%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fiterator%2FTestBertIterator.java?ref=63ed202057d301755184dbb93fc777d4e590748c",
      "patch": "@@ -17,11 +17,13 @@\n \n package org.deeplearning4j.iterator;\n \n+import lombok.Getter;\n import org.deeplearning4j.BaseDL4JTest;\n import org.deeplearning4j.iterator.bert.BertMaskedLMMasker;\n+import org.deeplearning4j.iterator.provider.CollectionLabeledPairSentenceProvider;\n+import org.deeplearning4j.iterator.provider.CollectionLabeledSentenceProvider;\n import org.deeplearning4j.text.tokenization.tokenizerfactory.BertWordPieceTokenizerFactory;\n import org.junit.Test;\n-import org.nd4j.base.Preconditions;\n import org.nd4j.linalg.api.buffer.DataType;\n import org.nd4j.linalg.api.ndarray.INDArray;\n import org.nd4j.linalg.dataset.api.MultiDataSet;\n@@ -42,29 +44,28 @@\n \n public class TestBertIterator extends BaseDL4JTest {\n \n-    private File pathToVocab = Resources.asFile(\"other/vocab.txt\");\n+    private static File pathToVocab = Resources.asFile(\"other/vocab.txt\");\n     private static Charset c = StandardCharsets.UTF_8;\n+    private static String shortSentence = \"I saw a girl with a telescope.\";\n+    private static String longSentence = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n+    private static String sentenceA = \"Goodnight noises everywhere\";\n+    private static String sentenceB = \"Goodnight moon\";\n \n     public TestBertIterator() throws IOException {\n     }\n \n     @Test(timeout = 20000L)\n     public void testBertSequenceClassification() throws Exception {\n \n-        String toTokenize1 = \"I saw a girl with a telescope.\";\n-        String toTokenize2 = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n-        List<String> forInference = new ArrayList<>();\n-        forInference.add(toTokenize1);\n-        forInference.add(toTokenize2);\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n-\n+        int minibatchSize = 2;\n+        TestSentenceHelper testHelper = new TestSentenceHelper();\n         BertIterator b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, 16)\n-                .minibatchSize(2)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .minibatchSize(minibatchSize)\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .build();\n \n@@ -73,144 +74,132 @@ public void testBertSequenceClassification() throws Exception {\n         System.out.println(mds.getFeatures(0));\n         System.out.println(mds.getFeaturesMaskArray(0));\n \n-\n-        INDArray expEx0 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM0 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens = t.create(toTokenize1).getTokens();\n-        Map<String, Integer> m = t.getVocab();\n-        for (int i = 0; i < tokens.size(); i++) {\n-            int idx = m.get(tokens.get(i));\n-            expEx0.putScalar(0, i, idx);\n-            expM0.putScalar(0, i, 1);\n-        }\n-\n-        INDArray expEx1 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM1 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens2 = t.create(toTokenize2).getTokens();\n-        for (int i = 0; i < tokens2.size(); i++) {\n-            String token = tokens2.get(i);\n-            if (!m.containsKey(token)) {\n-                throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+        INDArray expF = Nd4j.create(DataType.INT, 1, 16);\n+        INDArray expM = Nd4j.create(DataType.INT, 1, 16);\n+        Map<String, Integer> m = testHelper.getTokenizer().getVocab();\n+        for (int i = 0; i < minibatchSize; i++) {\n+            INDArray expFTemp = Nd4j.create(DataType.INT, 1, 16);\n+            INDArray expMTemp = Nd4j.create(DataType.INT, 1, 16);\n+            List<String> tokens = testHelper.getTokenizedSentences().get(i);\n+            System.out.println(tokens);\n+            for (int j = 0; j < tokens.size(); j++) {\n+                String token = tokens.get(j);\n+                if (!m.containsKey(token)) {\n+                    throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+                }\n+                int idx = m.get(token);\n+                expFTemp.putScalar(0, j, idx);\n+                expMTemp.putScalar(0, j, 1);\n+            }\n+            if (i == 0) {\n+                expF = expFTemp.dup();\n+                expM = expMTemp.dup();\n+            } else {\n+                expF = Nd4j.vstack(expF, expFTemp);\n+                expM = Nd4j.vstack(expM, expMTemp);\n             }\n-            int idx = m.get(token);\n-            expEx1.putScalar(0, i, idx);\n-            expM1.putScalar(0, i, 1);\n         }\n-\n-        INDArray expF = Nd4j.vstack(expEx0, expEx1);\n-        INDArray expM = Nd4j.vstack(expM0, expM1);\n-\n         assertEquals(expF, mds.getFeatures(0));\n         assertEquals(expM, mds.getFeaturesMaskArray(0));\n-        assertEquals(expF, b.featurizeSentences(forInference).getFirst()[0]);\n-        assertEquals(expM, b.featurizeSentences(forInference).getSecond()[0]);\n+        assertEquals(expF, b.featurizeSentences(testHelper.getSentences()).getFirst()[0]);\n+        assertEquals(expM, b.featurizeSentences(testHelper.getSentences()).getSecond()[0]);\n \n-        b.next(); //pop the third element\n         assertFalse(b.hasNext());\n         b.reset();\n         assertTrue(b.hasNext());\n \n-        forInference.set(0, toTokenize2);\n         //Same thing, but with segment ID also\n         b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, 16)\n-                .minibatchSize(2)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .minibatchSize(minibatchSize)\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .build();\n         mds = b.next();\n         assertEquals(2, mds.getFeatures().length);\n-        //assertEquals(2, mds.getFeaturesMaskArrays().length); second element is null...\n-        assertEquals(2, b.featurizeSentences(forInference).getFirst().length);\n         //Segment ID should be all 0s for single segment task\n         INDArray segmentId = expM.like();\n         assertEquals(segmentId, mds.getFeatures(1));\n-        assertEquals(segmentId, b.featurizeSentences(forInference).getFirst()[1]);\n+        assertEquals(segmentId, b.featurizeSentences(testHelper.getSentences()).getFirst()[1]);\n     }\n \n     @Test(timeout = 20000L)\n     public void testBertUnsupervised() throws Exception {\n+        int minibatchSize = 2;\n+        TestSentenceHelper testHelper = new TestSentenceHelper();\n         //Task 1: Unsupervised\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n         BertIterator b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, 16)\n-                .minibatchSize(2)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .minibatchSize(minibatchSize)\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.UNSUPERVISED)\n                 .masker(new BertMaskedLMMasker(new Random(12345), 0.2, 0.5, 0.5))\n                 .unsupervisedLabelFormat(BertIterator.UnsupervisedLabelFormat.RANK2_IDX)\n                 .maskToken(\"[MASK]\")\n                 .build();\n \n-        System.out.println(\"Mask token index: \" + t.getVocab().get(\"[MASK]\"));\n+        System.out.println(\"Mask token index: \" + testHelper.getTokenizer().getVocab().get(\"[MASK]\"));\n \n         MultiDataSet mds = b.next();\n         System.out.println(mds.getFeatures(0));\n         System.out.println(mds.getFeaturesMaskArray(0));\n         System.out.println(mds.getLabels(0));\n         System.out.println(mds.getLabelsMaskArray(0));\n \n-        b.next(); //pop the third element\n         assertFalse(b.hasNext());\n         b.reset();\n         assertTrue(b.hasNext());\n     }\n \n     @Test(timeout = 20000L)\n     public void testLengthHandling() throws Exception {\n-        String toTokenize1 = \"I saw a girl with a telescope.\";\n-        String toTokenize2 = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n-        List<String> forInference = new ArrayList<>();\n-        forInference.add(toTokenize1);\n-        forInference.add(toTokenize2);\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n-        INDArray expEx0 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM0 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens = t.create(toTokenize1).getTokens();\n-        System.out.println(tokens);\n-        Map<String, Integer> m = t.getVocab();\n-        for (int i = 0; i < tokens.size(); i++) {\n-            int idx = m.get(tokens.get(i));\n-            expEx0.putScalar(0, i, idx);\n-            expM0.putScalar(0, i, 1);\n-        }\n-\n-        INDArray expEx1 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM1 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens2 = t.create(toTokenize2).getTokens();\n-        System.out.println(tokens2);\n-        for (int i = 0; i < tokens2.size(); i++) {\n-            String token = tokens2.get(i);\n-            if (!m.containsKey(token)) {\n-                throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+        int minibatchSize = 2;\n+        TestSentenceHelper testHelper = new TestSentenceHelper();\n+        INDArray expF = Nd4j.create(DataType.INT, 1, 16);\n+        INDArray expM = Nd4j.create(DataType.INT, 1, 16);\n+        Map<String, Integer> m = testHelper.getTokenizer().getVocab();\n+        for (int i = 0; i < minibatchSize; i++) {\n+            List<String> tokens = testHelper.getTokenizedSentences().get(i);\n+            INDArray expFTemp = Nd4j.create(DataType.INT, 1, 16);\n+            INDArray expMTemp = Nd4j.create(DataType.INT, 1, 16);\n+            System.out.println(tokens);\n+            for (int j = 0; j < tokens.size(); j++) {\n+                String token = tokens.get(j);\n+                if (!m.containsKey(token)) {\n+                    throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+                }\n+                int idx = m.get(token);\n+                expFTemp.putScalar(0, j, idx);\n+                expMTemp.putScalar(0, j, 1);\n+            }\n+            if (i == 0) {\n+                expF = expFTemp.dup();\n+                expM = expMTemp.dup();\n+            } else {\n+                expF = Nd4j.vstack(expF, expFTemp);\n+                expM = Nd4j.vstack(expM, expMTemp);\n             }\n-            int idx = m.get(token);\n-            expEx1.putScalar(0, i, idx);\n-            expM1.putScalar(0, i, 1);\n         }\n \n-        INDArray expF = Nd4j.vstack(expEx0, expEx1);\n-        INDArray expM = Nd4j.vstack(expM0, expM1);\n-\n         //--------------------------------------------------------------\n \n         //Fixed length: clip or pad - already tested in other tests\n \n         //Any length: as long as we need to fit longest sequence\n \n         BertIterator b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.ANY_LENGTH, -1)\n-                .minibatchSize(2)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .minibatchSize(minibatchSize)\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .build();\n         MultiDataSet mds = b.next();\n@@ -219,20 +208,19 @@ public void testLengthHandling() throws Exception {\n         assertArrayEquals(expShape, mds.getFeaturesMaskArray(0).shape());\n         assertEquals(expF.get(NDArrayIndex.all(), NDArrayIndex.interval(0, 14)), mds.getFeatures(0));\n         assertEquals(expM.get(NDArrayIndex.all(), NDArrayIndex.interval(0, 14)), mds.getFeaturesMaskArray(0));\n-        assertEquals(mds.getFeatures(0), b.featurizeSentences(forInference).getFirst()[0]);\n-        assertEquals(mds.getFeaturesMaskArray(0), b.featurizeSentences(forInference).getSecond()[0]);\n+        assertEquals(mds.getFeatures(0), b.featurizeSentences(testHelper.getSentences()).getFirst()[0]);\n+        assertEquals(mds.getFeaturesMaskArray(0), b.featurizeSentences(testHelper.getSentences()).getSecond()[0]);\n \n         //Clip only: clip to maximum, but don't pad if less\n         b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.CLIP_ONLY, 20)\n-                .minibatchSize(2)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .minibatchSize(minibatchSize)\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .build();\n-        mds = b.next();\n         expShape = new long[]{2, 14};\n         assertArrayEquals(expShape, mds.getFeatures(0).shape());\n         assertArrayEquals(expShape, mds.getFeaturesMaskArray(0).shape());\n@@ -241,54 +229,38 @@ public void testLengthHandling() throws Exception {\n     @Test(timeout = 20000L)\n     public void testMinibatchPadding() throws Exception {\n         Nd4j.setDefaultDataTypes(DataType.FLOAT, DataType.FLOAT);\n-        String toTokenize1 = \"I saw a girl with a telescope.\";\n-        String toTokenize2 = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n-        String toTokenize3 = \"Goodnight noises everywhere\";\n-        List<String> forInference = new ArrayList<>();\n-        forInference.add(toTokenize1);\n-        forInference.add(toTokenize2);\n-        forInference.add(toTokenize3);\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n-        INDArray expEx0 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM0 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens = t.create(toTokenize1).getTokens();\n-        Map<String, Integer> m = t.getVocab();\n-        for (int i = 0; i < tokens.size(); i++) {\n-            int idx = m.get(tokens.get(i));\n-            expEx0.putScalar(0, i, idx);\n-            expM0.putScalar(0, i, 1);\n-        }\n-\n-        INDArray expEx1 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM1 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens2 = t.create(toTokenize2).getTokens();\n-        for (int i = 0; i < tokens2.size(); i++) {\n-            String token = tokens2.get(i);\n-            if (!m.containsKey(token)) {\n-                throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+        int minibatchSize = 3;\n+        TestSentenceHelper testHelper = new TestSentenceHelper(minibatchSize);\n+        INDArray zeros = Nd4j.create(DataType.INT, 1, 16);\n+        INDArray expF = Nd4j.create(DataType.INT, 1, 16);\n+        INDArray expM = Nd4j.create(DataType.INT, 1, 16);\n+        Map<String, Integer> m = testHelper.getTokenizer().getVocab();\n+        for (int i = 0; i < minibatchSize; i++) {\n+            List<String> tokens = testHelper.getTokenizedSentences().get(i);\n+            INDArray expFTemp = Nd4j.create(DataType.INT, 1, 16);\n+            INDArray expMTemp = Nd4j.create(DataType.INT, 1, 16);\n+            System.out.println(tokens);\n+            for (int j = 0; j < tokens.size(); j++) {\n+                String token = tokens.get(j);\n+                if (!m.containsKey(token)) {\n+                    throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+                }\n+                int idx = m.get(token);\n+                expFTemp.putScalar(0, j, idx);\n+                expMTemp.putScalar(0, j, 1);\n             }\n-            int idx = m.get(token);\n-            expEx1.putScalar(0, i, idx);\n-            expM1.putScalar(0, i, 1);\n-        }\n-\n-        INDArray expEx3 = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expM3 = Nd4j.create(DataType.INT, 1, 16);\n-        List<String> tokens3 = t.create(toTokenize3).getTokens();\n-        for (int i = 0; i < tokens3.size(); i++) {\n-            String token = tokens3.get(i);\n-            if (!m.containsKey(token)) {\n-                throw new IllegalStateException(\"Unknown token: \\\"\" + token + \"\\\"\");\n+            if (i == 0) {\n+                expF = expFTemp.dup();\n+                expM = expMTemp.dup();\n+            } else {\n+                expF = Nd4j.vstack(expF.dup(), expFTemp);\n+                expM = Nd4j.vstack(expM.dup(), expMTemp);\n             }\n-            int idx = m.get(token);\n-            expEx3.putScalar(0, i, idx);\n-            expM3.putScalar(0, i, 1);\n         }\n \n-        INDArray zeros = Nd4j.create(DataType.INT, 1, 16);\n-        INDArray expF = Nd4j.vstack(expEx0, expEx1, expEx3, zeros);\n-        INDArray expM = Nd4j.vstack(expM0, expM1, expM3, zeros);\n-        INDArray expL = Nd4j.createFromArray(new float[][]{{1, 0}, {0, 1}, {1, 0}, {0, 0}});\n+        expF = Nd4j.vstack(expF, zeros);\n+        expM = Nd4j.vstack(expM, zeros);\n+        INDArray expL = Nd4j.createFromArray(new float[][]{{0, 1}, {1, 0}, {0, 1}, {0, 0}});\n         INDArray expLM = Nd4j.create(DataType.FLOAT, 4, 1);\n         expLM.putScalar(0, 0, 1);\n         expLM.putScalar(1, 0, 1);\n@@ -297,13 +269,13 @@ public void testMinibatchPadding() throws Exception {\n         //--------------------------------------------------------------\n \n         BertIterator b = BertIterator.builder()\n-                .tokenizer(t)\n+                .tokenizer(testHelper.getTokenizer())\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, 16)\n-                .minibatchSize(4)\n+                .minibatchSize(minibatchSize + 1)\n                 .padMinibatches(true)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .sentenceProvider(testHelper.getSentenceProvider())\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .build();\n \n@@ -323,328 +295,351 @@ public void testMinibatchPadding() throws Exception {\n         assertEquals(expL, mds.getLabels(0));\n         assertEquals(expLM, mds.getLabelsMaskArray(0));\n \n-        assertEquals(expF, b.featurizeSentences(forInference).getFirst()[0]);\n-        assertEquals(expM, b.featurizeSentences(forInference).getSecond()[0]);\n+        assertEquals(expF, b.featurizeSentences(testHelper.getSentences()).getFirst()[0]);\n+        assertEquals(expM, b.featurizeSentences(testHelper.getSentences()).getSecond()[0]);\n     }\n \n+    /*\n+        Checks that a mds from a pair sentence is equal to hstack'd mds from the left side and right side of the pair\n+        Checks different lengths for max length to check popping and padding\n+     */\n     @Test\n     public void testSentencePairsSingle() throws IOException {\n-        String shortSent = \"I saw a girl with a telescope.\";\n-        String longSent = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n         boolean prependAppend;\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n-        int shortL = t.create(shortSent).countTokens();\n-        int longL = t.create(longSent).countTokens();\n+        int numOfSentences;\n+\n+        TestSentenceHelper testHelper = new TestSentenceHelper();\n+        int shortL = testHelper.getShortestL();\n+        int longL = testHelper.getLongestL();\n \n         Triple<MultiDataSet, MultiDataSet, MultiDataSet> multiDataSetTriple;\n-        MultiDataSet shortLongPair, shortSentence, longSentence;\n+        MultiDataSet fromPair, leftSide, rightSide;\n \n         // check for pair max length exactly equal to sum of lengths - pop neither no padding\n         // should be the same as hstack with segment ids 1 for second sentence\n         prependAppend = true;\n-        multiDataSetTriple = generateMultiDataSets(new Triple<>(shortL + longL, shortL, longL), prependAppend);\n-        shortLongPair = multiDataSetTriple.getFirst();\n-        shortSentence = multiDataSetTriple.getSecond();\n-        longSentence = multiDataSetTriple.getThird();\n-        assertEquals(shortLongPair.getFeatures(0), Nd4j.hstack(shortSentence.getFeatures(0), longSentence.getFeatures(0)));\n-        longSentence.getFeatures(1).addi(1);\n-        assertEquals(shortLongPair.getFeatures(1), Nd4j.hstack(shortSentence.getFeatures(1), longSentence.getFeatures(1)));\n-        assertEquals(shortLongPair.getFeaturesMaskArray(0), Nd4j.hstack(shortSentence.getFeaturesMaskArray(0), longSentence.getFeaturesMaskArray(0)));\n+        numOfSentences = 1;\n+        multiDataSetTriple = generateMultiDataSets(new Triple<>(shortL + longL, shortL, longL), prependAppend, numOfSentences);\n+        fromPair = multiDataSetTriple.getFirst();\n+        leftSide = multiDataSetTriple.getSecond();\n+        rightSide = multiDataSetTriple.getThird();\n+        assertEquals(fromPair.getFeatures(0), Nd4j.hstack(leftSide.getFeatures(0), rightSide.getFeatures(0)));\n+        rightSide.getFeatures(1).addi(1); //add 1 for right side segment ids\n+        assertEquals(fromPair.getFeatures(1), Nd4j.hstack(leftSide.getFeatures(1), rightSide.getFeatures(1)));\n+        assertEquals(fromPair.getFeaturesMaskArray(0), Nd4j.hstack(leftSide.getFeaturesMaskArray(0), rightSide.getFeaturesMaskArray(0)));\n \n         //check for pair max length greater than sum of lengths - pop neither with padding\n         // features should be the same as hstack of shorter and longer padded with prepend/append\n         // segment id should 1 only in the longer for part of the length of the sentence\n         prependAppend = true;\n-        multiDataSetTriple = generateMultiDataSets(new Triple<>(shortL + longL + 5, shortL, longL + 5), prependAppend);\n-        shortLongPair = multiDataSetTriple.getFirst();\n-        shortSentence = multiDataSetTriple.getSecond();\n-        longSentence = multiDataSetTriple.getThird();\n-        assertEquals(shortLongPair.getFeatures(0), Nd4j.hstack(shortSentence.getFeatures(0), longSentence.getFeatures(0)));\n-        longSentence.getFeatures(1).get(NDArrayIndex.all(), NDArrayIndex.interval(0, longL + 1)).addi(1); //segmentId stays 0 for the padded part\n-        assertEquals(shortLongPair.getFeatures(1), Nd4j.hstack(shortSentence.getFeatures(1), longSentence.getFeatures(1)));\n-        assertEquals(shortLongPair.getFeaturesMaskArray(0), Nd4j.hstack(shortSentence.getFeaturesMaskArray(0), longSentence.getFeaturesMaskArray(0)));\n+        numOfSentences = 1;\n+        multiDataSetTriple = generateMultiDataSets(new Triple<>(shortL + longL + 5, shortL, longL + 5), prependAppend, numOfSentences);\n+        fromPair = multiDataSetTriple.getFirst();\n+        leftSide = multiDataSetTriple.getSecond();\n+        rightSide = multiDataSetTriple.getThird();\n+        assertEquals(fromPair.getFeatures(0), Nd4j.hstack(leftSide.getFeatures(0), rightSide.getFeatures(0)));\n+        rightSide.getFeatures(1).get(NDArrayIndex.all(), NDArrayIndex.interval(0, longL + 1)).addi(1); //segmentId stays 0 for the padded part\n+        assertEquals(fromPair.getFeatures(1), Nd4j.hstack(leftSide.getFeatures(1), rightSide.getFeatures(1)));\n+        assertEquals(fromPair.getFeaturesMaskArray(0), Nd4j.hstack(leftSide.getFeaturesMaskArray(0), rightSide.getFeaturesMaskArray(0)));\n \n         //check for pair max length less than shorter sentence - pop both\n         //should be the same as hstack with segment ids 1 for second sentence if no prepend/append\n-        int maxL = shortL - 2;\n+        int maxL = 5;//checking odd\n+        numOfSentences = 3;\n         prependAppend = false;\n-        multiDataSetTriple = generateMultiDataSets(new Triple<>(maxL, maxL / 2, maxL - maxL / 2), prependAppend);\n-        shortLongPair = multiDataSetTriple.getFirst();\n-        shortSentence = multiDataSetTriple.getSecond();\n-        longSentence = multiDataSetTriple.getThird();\n-        assertEquals(shortLongPair.getFeatures(0), Nd4j.hstack(shortSentence.getFeatures(0), longSentence.getFeatures(0)));\n-        longSentence.getFeatures(1).addi(1);\n-        assertEquals(shortLongPair.getFeatures(1), Nd4j.hstack(shortSentence.getFeatures(1), longSentence.getFeatures(1)));\n-        assertEquals(shortLongPair.getFeaturesMaskArray(0), Nd4j.hstack(shortSentence.getFeaturesMaskArray(0), longSentence.getFeaturesMaskArray(0)));\n+        multiDataSetTriple = generateMultiDataSets(new Triple<>(maxL, maxL / 2, maxL - maxL / 2), prependAppend, numOfSentences);\n+        fromPair = multiDataSetTriple.getFirst();\n+        leftSide = multiDataSetTriple.getSecond();\n+        rightSide = multiDataSetTriple.getThird();\n+        assertEquals(fromPair.getFeatures(0), Nd4j.hstack(leftSide.getFeatures(0), rightSide.getFeatures(0)));\n+        rightSide.getFeatures(1).addi(1);\n+        assertEquals(fromPair.getFeatures(1), Nd4j.hstack(leftSide.getFeatures(1), rightSide.getFeatures(1)));\n+        assertEquals(fromPair.getFeaturesMaskArray(0), Nd4j.hstack(leftSide.getFeaturesMaskArray(0), rightSide.getFeaturesMaskArray(0)));\n     }\n \n+    /*\n+        Same idea as previous test - construct mds from bert iterator with sep sentences and check against one with pairs\n+        Checks various max lengths\n+        Has sentences of varying lengths\n+    */\n     @Test\n     public void testSentencePairsUnequalLengths() throws IOException {\n-        //check for pop only longer (i.e between longer and longer + shorter), first row pop from second sentence, next row pop from first sentence, nothing to pop in the third row\n-        //should be identical to hstack if there is no append, prepend\n-        //batch size is 2\n-        int mbS = 4;\n-        String shortSent = \"I saw a girl with a telescope.\";\n-        String longSent = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n-        String sent1 = \"Goodnight noises everywhere\"; //shorter than shortSent - no popping\n-        String sent2 = \"Goodnight moon\"; //shorter than shortSent - no popping\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n-        int shortL = t.create(shortSent).countTokens();\n-        int longL = t.create(longSent).countTokens();\n-        int sent1L = t.create(sent1).countTokens();\n-        int sent2L = t.create(sent2).countTokens();\n-        //won't check 2*shortL + 1 because this will always pop on the left\n-        for (int maxL = longL + shortL - 1; maxL > 2 * shortL; maxL--) {\n+\n+        int minibatchSize = 4;\n+        int numOfSentencesinIter = 3;\n+\n+        TestSentencePairsHelper testPairHelper = new TestSentencePairsHelper(numOfSentencesinIter);\n+        int shortL = testPairHelper.getShortL();\n+        int longL = testPairHelper.getLongL();\n+        int sent1L = testPairHelper.getSentenceALen();\n+        int sent2L = testPairHelper.getSentenceBLen();\n+\n+        System.out.println(\"Sentence Pairs, Left\");\n+        System.out.println(testPairHelper.getSentencesLeft());\n+        System.out.println(\"Sentence Pairs, Right\");\n+        System.out.println(testPairHelper.getSentencesRight());\n+\n+        //anything outside this range more will need to check padding,truncation\n+        for (int maxL = longL + shortL; maxL > 2 * shortL + 1; maxL--) {\n+\n+            System.out.println(\"Running for max length = \" + maxL);\n+\n             MultiDataSet leftMDS = BertIterator.builder()\n-                    .tokenizer(t)\n-                    .minibatchSize(mbS)\n+                    .tokenizer(testPairHelper.getTokenizer())\n+                    .minibatchSize(minibatchSize)\n                     .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                    .vocabMap(t.getVocab())\n+                    .vocabMap(testPairHelper.getTokenizer().getVocab())\n                     .task(BertIterator.Task.SEQ_CLASSIFICATION)\n-                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, longL + 10) //random big num guaranteed to be longer than either\n-                    .sentenceProvider(new TestSentenceProvider())\n+                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, longL * 10) //random big num guaranteed to be longer than either\n+                    .sentenceProvider(new TestSentenceHelper(numOfSentencesinIter).getSentenceProvider())\n                     .padMinibatches(true)\n                     .build().next();\n \n             MultiDataSet rightMDS = BertIterator.builder()\n-                    .tokenizer(t)\n-                    .minibatchSize(mbS)\n+                    .tokenizer(testPairHelper.getTokenizer())\n+                    .minibatchSize(minibatchSize)\n                     .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                    .vocabMap(t.getVocab())\n+                    .vocabMap(testPairHelper.getTokenizer().getVocab())\n                     .task(BertIterator.Task.SEQ_CLASSIFICATION)\n-                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, longL + 10) //random big num guaranteed to be longer than either\n-                    .sentenceProvider(new TestSentenceProvider(true))\n+                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, longL * 10) //random big num guaranteed to be longer than either\n+                    .sentenceProvider(new TestSentenceHelper(true, numOfSentencesinIter).getSentenceProvider())\n                     .padMinibatches(true)\n                     .build().next();\n \n             MultiDataSet pairMDS = BertIterator.builder()\n-                    .tokenizer(t)\n-                    .minibatchSize(mbS)\n+                    .tokenizer(testPairHelper.getTokenizer())\n+                    .minibatchSize(minibatchSize)\n                     .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                    .vocabMap(t.getVocab())\n+                    .vocabMap(testPairHelper.getTokenizer().getVocab())\n                     .task(BertIterator.Task.SEQ_CLASSIFICATION)\n-                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, maxL) //random big num guaranteed to be longer than either\n-                    .sentencePairProvider(new TestSentencePairProvider())\n+                    .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, maxL)\n+                    .sentencePairProvider(testPairHelper.getPairSentenceProvider())\n                     .padMinibatches(true)\n                     .build().next();\n \n-            //Left sentences here are {{shortSent},\n-            //                         {longSent},\n-            //                         {Sent1}}\n-            //Right sentences here are {{longSent},\n-            //                         {shortSent},\n-            //                         {Sent2}}\n-            //The sentence pairs here are {{shortSent,longSent},\n-            //                             {longSent,shortSent}\n-            //                             {Sent1, Sent2}}\n-\n             //CHECK FEATURES\n-            INDArray combinedFeat = Nd4j.create(DataType.INT,mbS,maxL);\n+            INDArray combinedFeat = Nd4j.create(DataType.INT, minibatchSize, maxL);\n             //left side\n             INDArray leftFeatures = leftMDS.getFeatures(0);\n             INDArray topLSentFeat = leftFeatures.getRow(0).get(NDArrayIndex.interval(0, shortL));\n             INDArray midLSentFeat = leftFeatures.getRow(1).get(NDArrayIndex.interval(0, maxL - shortL));\n-            INDArray bottomLSentFeat = leftFeatures.getRow(2).get(NDArrayIndex.interval(0,sent1L));\n+            INDArray bottomLSentFeat = leftFeatures.getRow(2).get(NDArrayIndex.interval(0, sent1L));\n             //right side\n             INDArray rightFeatures = rightMDS.getFeatures(0);\n             INDArray topRSentFeat = rightFeatures.getRow(0).get(NDArrayIndex.interval(0, maxL - shortL));\n             INDArray midRSentFeat = rightFeatures.getRow(1).get(NDArrayIndex.interval(0, shortL));\n-            INDArray bottomRSentFeat = rightFeatures.getRow(2).get(NDArrayIndex.interval(0,sent2L));\n+            INDArray bottomRSentFeat = rightFeatures.getRow(2).get(NDArrayIndex.interval(0, sent2L));\n             //expected pair\n-            combinedFeat.getRow(0).addi(Nd4j.hstack(topLSentFeat,topRSentFeat));\n-            combinedFeat.getRow(1).addi(Nd4j.hstack(midLSentFeat,midRSentFeat));\n-            combinedFeat.getRow(2).get(NDArrayIndex.interval(0,sent1L+sent2L)).addi(Nd4j.hstack(bottomLSentFeat,bottomRSentFeat));\n+            combinedFeat.getRow(0).addi(Nd4j.hstack(topLSentFeat, topRSentFeat));\n+            combinedFeat.getRow(1).addi(Nd4j.hstack(midLSentFeat, midRSentFeat));\n+            combinedFeat.getRow(2).get(NDArrayIndex.interval(0, sent1L + sent2L)).addi(Nd4j.hstack(bottomLSentFeat, bottomRSentFeat));\n \n             assertEquals(maxL, pairMDS.getFeatures(0).shape()[1]);\n             assertArrayEquals(combinedFeat.shape(), pairMDS.getFeatures(0).shape());\n             assertEquals(combinedFeat, pairMDS.getFeatures(0));\n \n             //CHECK SEGMENT ID\n-            INDArray combinedFetSeg = Nd4j.create(DataType.INT, mbS, maxL);\n+            INDArray combinedFetSeg = Nd4j.create(DataType.INT, minibatchSize, maxL);\n             combinedFetSeg.get(NDArrayIndex.point(0), NDArrayIndex.interval(shortL, maxL)).addi(1);\n             combinedFetSeg.get(NDArrayIndex.point(1), NDArrayIndex.interval(maxL - shortL, maxL)).addi(1);\n-            combinedFetSeg.get(NDArrayIndex.point(2), NDArrayIndex.interval(sent1L, sent1L+sent2L)).addi(1);\n+            combinedFetSeg.get(NDArrayIndex.point(2), NDArrayIndex.interval(sent1L, sent1L + sent2L)).addi(1);\n             assertArrayEquals(combinedFetSeg.shape(), pairMDS.getFeatures(1).shape());\n             assertEquals(maxL, combinedFetSeg.shape()[1]);\n             assertEquals(combinedFetSeg, pairMDS.getFeatures(1));\n+\n+            testPairHelper.getPairSentenceProvider().reset();\n         }\n     }\n \n     @Test\n     public void testSentencePairFeaturizer() throws IOException {\n-        String shortSent = \"I saw a girl with a telescope.\";\n-        String longSent = \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\";\n-        List<Pair<String, String>> listSentencePair = new ArrayList<>();\n-        listSentencePair.add(new Pair<>(shortSent, longSent));\n-        listSentencePair.add(new Pair<>(longSent, shortSent));\n-        BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n+        int minibatchSize = 2;\n+        TestSentencePairsHelper testPairHelper = new TestSentencePairsHelper(minibatchSize);\n         BertIterator b = BertIterator.builder()\n-                .tokenizer(t)\n-                .minibatchSize(2)\n+                .tokenizer(testPairHelper.getTokenizer())\n+                .minibatchSize(minibatchSize)\n                 .padMinibatches(true)\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n-                .vocabMap(t.getVocab())\n+                .vocabMap(testPairHelper.getTokenizer().getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION)\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, 128)\n-                .sentencePairProvider(new TestSentencePairProvider())\n+                .sentencePairProvider(testPairHelper.getPairSentenceProvider())\n                 .prependToken(\"[CLS]\")\n                 .appendToken(\"[SEP]\")\n                 .build();\n         MultiDataSet mds = b.next();\n         INDArray[] featuresArr = mds.getFeatures();\n         INDArray[] featuresMaskArr = mds.getFeaturesMaskArrays();\n \n-        Pair<INDArray[], INDArray[]> p = b.featurizeSentencePairs(listSentencePair);\n+        Pair<INDArray[], INDArray[]> p = b.featurizeSentencePairs(testPairHelper.getSentencePairs());\n         assertEquals(p.getFirst().length, 2);\n         assertEquals(featuresArr[0], p.getFirst()[0]);\n         assertEquals(featuresArr[1], p.getFirst()[1]);\n-        //assertEquals(p.getSecond().length, 2);\n         assertEquals(featuresMaskArr[0], p.getSecond()[0]);\n-        //assertEquals(featuresMaskArr[1], p.getSecond()[1]);\n     }\n \n     /**\n-     * Returns three multidatasets from bert iterator based on given max lengths and whether to prepend/append\n+     * Returns three multidatasets (one from pair of sentences and the other two from single sentence lists) from bert iterator\n+     * with given max lengths and whether to prepend/append\n      * Idea is the sentence pair dataset can be constructed from the single sentence datasets\n-     * First one is constructed from a sentence pair \"I saw a girl with a telescope.\" & \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\"\n-     * Second one is constructed from the left of the sentence pair i.e \"I saw a girl with a telescope.\"\n-     * Third one is constructed from the right of the sentence pair i.e \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\"\n      */\n-    private Triple<MultiDataSet, MultiDataSet, MultiDataSet> generateMultiDataSets(Triple<Integer, Integer, Integer> maxLengths, boolean prependAppend) throws IOException {\n+    private Triple<MultiDataSet, MultiDataSet, MultiDataSet> generateMultiDataSets(Triple<Integer, Integer, Integer> maxLengths, boolean prependAppend, int numSentences) throws IOException {\n         BertWordPieceTokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n         int maxforPair = maxLengths.getFirst();\n         int maxPartOne = maxLengths.getSecond();\n         int maxPartTwo = maxLengths.getThird();\n         BertIterator.Builder commonBuilder;\n         commonBuilder = BertIterator.builder()\n                 .tokenizer(t)\n-                .minibatchSize(1)\n+                .minibatchSize(4)\n                 .featureArrays(BertIterator.FeatureArrays.INDICES_MASK_SEGMENTID)\n                 .vocabMap(t.getVocab())\n                 .task(BertIterator.Task.SEQ_CLASSIFICATION);\n-        BertIterator shortLongPairFirstIter = commonBuilder\n+        BertIterator pairIter = commonBuilder\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, prependAppend ? maxforPair + 3 : maxforPair)\n-                .sentencePairProvider(new TestSentencePairProvider())\n+                .sentencePairProvider(new TestSentencePairsHelper(numSentences).getPairSentenceProvider())\n                 .prependToken(prependAppend ? \"[CLS]\" : null)\n                 .appendToken(prependAppend ? \"[SEP]\" : null)\n                 .build();\n-        BertIterator shortFirstIter = commonBuilder\n+        BertIterator leftIter = commonBuilder\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, prependAppend ? maxPartOne + 2 : maxPartOne)\n-                .sentenceProvider(new TestSentenceProvider())\n+                .sentenceProvider(new TestSentenceHelper(numSentences).getSentenceProvider())\n                 .prependToken(prependAppend ? \"[CLS]\" : null)\n                 .appendToken(prependAppend ? \"[SEP]\" : null)\n                 .build();\n-        BertIterator longFirstIter = commonBuilder\n+        BertIterator rightIter = commonBuilder\n                 .lengthHandling(BertIterator.LengthHandling.FIXED_LENGTH, prependAppend ? maxPartTwo + 1 : maxPartTwo)\n-                .sentenceProvider(new TestSentenceProvider(true))\n+                .sentenceProvider(new TestSentenceHelper(true, numSentences).getSentenceProvider())\n                 .prependToken(null)\n                 .appendToken(prependAppend ? \"[SEP]\" : null)\n                 .build();\n-        return new Triple<>(shortLongPairFirstIter.next(), shortFirstIter.next(), longFirstIter.next());\n+        return new Triple<>(pairIter.next(), leftIter.next(), rightIter.next());\n     }\n \n-    private static class TestSentenceProvider implements LabeledSentenceProvider {\n-\n-        private int pos = 0;\n-        private boolean invert;\n-\n-        private TestSentenceProvider() {\n-            this.invert = false;\n-        }\n-\n-        private TestSentenceProvider(boolean invert) {\n-            this.invert = invert;\n-        }\n-\n-        @Override\n-        public boolean hasNext() {\n-            return pos < totalNumSentences();\n+    @Getter\n+    private static class TestSentencePairsHelper {\n+\n+        private List<String> sentencesLeft;\n+        private List<String> sentencesRight;\n+        private List<Pair<String, String>> sentencePairs;\n+        private List<List<String>> tokenizedSentencesLeft;\n+        private List<List<String>> tokenizedSentencesRight;\n+        private List<String> labels;\n+        private int shortL;\n+        private int longL;\n+        private int sentenceALen;\n+        private int sentenceBLen;\n+        private BertWordPieceTokenizerFactory tokenizer;\n+        private CollectionLabeledPairSentenceProvider pairSentenceProvider;\n+\n+        private TestSentencePairsHelper() throws IOException {\n+            this(3);\n         }\n \n-        @Override\n-        public Pair<String, String> nextSentence() {\n-            Preconditions.checkState(hasNext());\n-            if (pos == 0) {\n-                pos++;\n-                if (!invert) return new Pair<>(\"I saw a girl with a telescope.\", \"positive\");\n-                return new Pair<>(\"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\", \"negative\");\n-            } else {\n-                if (pos == 1) {\n-                    pos++;\n-                    if (!invert) return new Pair<>(\"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\", \"negative\");\n-                    return new Pair<>(\"I saw a girl with a telescope.\", \"positive\");\n+        private TestSentencePairsHelper(int minibatchSize) throws IOException {\n+            sentencesLeft = new ArrayList<>();\n+            sentencesRight = new ArrayList<>();\n+            sentencePairs = new ArrayList<>();\n+            labels = new ArrayList<>();\n+            tokenizedSentencesLeft = new ArrayList<>();\n+            tokenizedSentencesRight = new ArrayList<>();\n+            tokenizer = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n+            sentencesLeft.add(shortSentence);\n+            sentencesRight.add(longSentence);\n+            sentencePairs.add(new Pair<>(shortSentence, longSentence));\n+            labels.add(\"positive\");\n+            if (minibatchSize > 1) {\n+                sentencesLeft.add(longSentence);\n+                sentencesRight.add(shortSentence);\n+                sentencePairs.add(new Pair<>(longSentence, shortSentence));\n+                labels.add(\"negative\");\n+                if (minibatchSize > 2) {\n+                    sentencesLeft.add(sentenceA);\n+                    sentencesRight.add(sentenceB);\n+                    sentencePairs.add(new Pair<>(sentenceA, sentenceB));\n+                    labels.add(\"positive\");\n                 }\n-                pos++;\n-                if (!invert)\n-                    return new Pair<>(\"Goodnight noises everywhere\", \"positive\");\n-                return new Pair<>(\"Goodnight moon\", \"positive\");\n             }\n+            for (int i = 0; i < minibatchSize; i++) {\n+                List<String> tokensL = tokenizer.create(sentencesLeft.get(i)).getTokens();\n+                List<String> tokensR = tokenizer.create(sentencesRight.get(i)).getTokens();\n+                if (i == 0) {\n+                    shortL = tokensL.size();\n+                    longL = tokensR.size();\n+                }\n+                if (i == 2) {\n+                    sentenceALen = tokensL.size();\n+                    sentenceBLen = tokensR.size();\n+                }\n+                tokenizedSentencesLeft.add(tokensL);\n+                tokenizedSentencesRight.add(tokensR);\n+            }\n+            pairSentenceProvider = new CollectionLabeledPairSentenceProvider(sentencesLeft, sentencesRight, labels, null);\n         }\n+    }\n \n-        @Override\n-        public void reset() {\n-            pos = 0;\n-        }\n+    @Getter\n+    private static class TestSentenceHelper {\n \n-        @Override\n-        public int totalNumSentences() {\n-            return 3;\n-        }\n+        private List<String> sentences;\n+        private List<List<String>> tokenizedSentences;\n+        private List<String> labels;\n+        private int shortestL = 0;\n+        private int longestL = 0;\n+        private BertWordPieceTokenizerFactory tokenizer;\n+        private CollectionLabeledSentenceProvider sentenceProvider;\n \n-        @Override\n-        public List<String> allLabels() {\n-            return Arrays.asList(\"positive\", \"negative\");\n+        private TestSentenceHelper() throws IOException {\n+            this(false, 2);\n         }\n \n-        @Override\n-        public int numLabelClasses() {\n-            return 2;\n+        private TestSentenceHelper(int minibatchSize) throws IOException {\n+            this(false, minibatchSize);\n         }\n-    }\n-\n-    private static class TestSentencePairProvider implements LabeledPairSentenceProvider {\n-\n-        private int pos = 0;\n \n-        @Override\n-        public boolean hasNext() {\n-            return pos < totalNumSentences();\n+        private TestSentenceHelper(boolean alternateOrder) throws IOException {\n+            this(false, 3);\n         }\n \n-        @Override\n-        public Triple<String, String, String> nextSentencePair() {\n-            Preconditions.checkState(hasNext());\n-            if (pos == 0) {\n-                pos++;\n-                return new Triple<>(\"I saw a girl with a telescope.\", \"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\", \"positive\");\n+        private TestSentenceHelper(boolean alternateOrder, int minibatchSize) throws IOException {\n+            sentences = new ArrayList<>();\n+            labels = new ArrayList<>();\n+            tokenizedSentences = new ArrayList<>();\n+            tokenizer = new BertWordPieceTokenizerFactory(pathToVocab, false, false, c);\n+            if (!alternateOrder) {\n+                sentences.add(shortSentence);\n+                labels.add(\"positive\");\n+                if (minibatchSize > 1) {\n+                    sentences.add(longSentence);\n+                    labels.add(\"negative\");\n+                    if (minibatchSize > 2) {\n+                        sentences.add(sentenceA);\n+                        labels.add(\"positive\");\n+                    }\n+                }\n             } else {\n-                if (pos == 1) {\n-                    pos++;\n-                    return new Triple<>(\"Donaudampfschifffahrts Kapit\u00e4nsm\u00fctzeninnenfuttersaum\", \"I saw a girl with a telescope.\", \"negative\");\n+                sentences.add(longSentence);\n+                labels.add(\"negative\");\n+                if (minibatchSize > 1) {\n+                    sentences.add(shortSentence);\n+                    labels.add(\"positive\");\n+                    if (minibatchSize > 2) {\n+                        sentences.add(sentenceB);\n+                        labels.add(\"positive\");\n+                    }\n                 }\n-                pos++;\n-                return new Triple<>(\"Goodnight noises everywhere\", \"Goodnight moon\", \"positive\");\n             }\n-        }\n-\n-        @Override\n-        public void reset() {\n-            pos = 0;\n-        }\n-\n-        @Override\n-        public int totalNumSentences() {\n-            return 3;\n-        }\n-\n-        @Override\n-        public List<String> allLabels() {\n-            return Arrays.asList(\"positive\", \"negative\");\n-        }\n-\n-        @Override\n-        public int numLabelClasses() {\n-            return 2;\n+            for (int i = 0; i < sentences.size(); i++) {\n+                List<String> tokenizedSentence = tokenizer.create(sentences.get(i)).getTokens();\n+                if (i == 0)\n+                    shortestL = tokenizedSentence.size();\n+                if (tokenizedSentence.size() > longestL)\n+                    longestL = tokenizedSentence.size();\n+                if (tokenizedSentence.size() < shortestL)\n+                    shortestL = tokenizedSentence.size();\n+                tokenizedSentences.add(tokenizedSentence);\n+            }\n+            sentenceProvider = new CollectionLabeledSentenceProvider(sentences, labels, null);\n         }\n     }\n ",
      "parent_sha": "9592072cefa76a96c434bc92606523b40d44c48f"
    }
  },
  {
    "oid": "378669cc102165f24bc9df8f77ad3380a804ec0d",
    "message": "Fix MNIST Fetcher to not re-allocate each batch (#200)\n\n* don't allocate so many float arrays, use INDArrays instead\r\n\r\nSigned-off-by: Ryan Nett <rnett@skymind.io>\r\n\r\n* re-add pre-processing, better names\r\n\r\nSigned-off-by: Ryan Nett <rnett@skymind.io>\r\n\r\n* use float[][] pool to avoid extra ndarray creation\r\n\r\nSigned-off-by: Ryan Nett <rnett@skymind.io>",
    "date": "2019-08-30T04:28:34Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/378669cc102165f24bc9df8f77ad3380a804ec0d",
    "details": {
      "sha": "3be8401d78e78182facf81db3a55bad657a49a5c",
      "filename": "deeplearning4j/deeplearning4j-data/deeplearning4j-datasets/src/main/java/org/deeplearning4j/datasets/fetchers/MnistDataFetcher.java",
      "status": "modified",
      "additions": 28,
      "deletions": 21,
      "changes": 49,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/378669cc102165f24bc9df8f77ad3380a804ec0d/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datasets%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Ffetchers%2FMnistDataFetcher.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/378669cc102165f24bc9df8f77ad3380a804ec0d/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datasets%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Ffetchers%2FMnistDataFetcher.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datasets%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Ffetchers%2FMnistDataFetcher.java?ref=378669cc102165f24bc9df8f77ad3380a804ec0d",
      "patch": "@@ -22,10 +22,12 @@\n import org.deeplearning4j.common.resources.DL4JResources;\n import org.deeplearning4j.common.resources.ResourceType;\n import org.deeplearning4j.datasets.mnist.MnistManager;\n+import org.nd4j.linalg.api.buffer.DataType;\n import org.nd4j.linalg.api.ndarray.INDArray;\n import org.nd4j.linalg.dataset.DataSet;\n import org.nd4j.linalg.dataset.api.iterator.fetcher.BaseDataFetcher;\n import org.nd4j.linalg.factory.Nd4j;\n+import org.nd4j.linalg.indexing.NDArrayIndex;\n import org.nd4j.linalg.util.MathUtils;\n \n import java.io.File;\n@@ -167,14 +169,19 @@ public MnistDataFetcher() throws IOException {\n         this(true);\n     }\n \n+    private float[][] featureData = null;\n+\n     @Override\n     public void fetch(int numExamples) {\n         if (!hasMore()) {\n             throw new IllegalStateException(\"Unable to get more; there are no more images\");\n         }\n \n-        float[][] featureData = new float[numExamples][0];\n-        float[][] labelData = new float[numExamples][0];\n+        INDArray labels = Nd4j.zeros(DataType.FLOAT, numExamples, numOutcomes);\n+\n+        if(featureData == null || featureData.length < numExamples){\n+            featureData = new float[numExamples][28*28];\n+        }\n \n         int actualExamples = 0;\n         byte[] working = null;\n@@ -202,33 +209,33 @@ public void fetch(int numExamples) {\n                 label--;\n             }\n \n-            float[] featureVec = new float[img.length];\n-            featureData[actualExamples] = featureVec;\n-            labelData[actualExamples] = new float[numOutcomes];\n-            labelData[actualExamples][label] = 1.0f;\n-\n-            for (int j = 0; j < img.length; j++) {\n-                float v = ((int) img[j]) & 0xFF; //byte is loaded as signed -> convert to unsigned\n-                if (binarize) {\n-                    if (v > 30.0f)\n-                        featureVec[j] = 1.0f;\n-                    else\n-                        featureVec[j] = 0.0f;\n-                } else {\n-                    featureVec[j] = v / 255.0f;\n-                }\n+            labels.put(actualExamples, label, 1.0f);\n+\n+            for(int j = 0 ; j < img.length ; j++) {\n+                featureData[actualExamples][j] = ((int) img[j]) & 0xFF;\n             }\n \n             actualExamples++;\n         }\n \n+        INDArray features;\n+\n+        if(featureData.length == actualExamples){\n+            features = Nd4j.create(featureData);\n+        } else {\n+            features = Nd4j.create(Arrays.copyOfRange(featureData, 0, actualExamples));\n+        }\n+\n         if (actualExamples < numExamples) {\n-            featureData = Arrays.copyOfRange(featureData, 0, actualExamples);\n-            labelData = Arrays.copyOfRange(labelData, 0, actualExamples);\n+            labels = labels.get(NDArrayIndex.interval(0, actualExamples), NDArrayIndex.all());\n+        }\n+\n+        if(binarize){\n+            features = features.gt(30.0).castTo(DataType.FLOAT);\n+        } else {\n+            features.divi(255.0);\n         }\n \n-        INDArray features = Nd4j.create(featureData);\n-        INDArray labels = Nd4j.create(labelData);\n         curr = new DataSet(features, labels);\n     }\n ",
      "parent_sha": "5cb6bebe4dace71624d210418b3116d880e179cd"
    }
  },
  {
    "oid": "cba63a25a5c0fd297f9f141529603ade86103322",
    "message": "Remove benchmark suite from running definition",
    "date": "2021-06-14T22:34:04Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/cba63a25a5c0fd297f9f141529603ade86103322",
    "details": {
      "sha": "a483183bc49ca3fb7bb90f7ee9d7036a138f3b9a",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-native-api/src/main/java/org/nd4j/nativeblas/NativeOps.java",
      "status": "modified",
      "additions": 1,
      "deletions": 3,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/cba63a25a5c0fd297f9f141529603ade86103322/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOps.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/cba63a25a5c0fd297f9f141529603ade86103322/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOps.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOps.java?ref=cba63a25a5c0fd297f9f141529603ade86103322",
      "patch": "@@ -1192,9 +1192,7 @@ void scatterUpdate(PointerPointer extraPointers, int opCode, int numOfUpdates,\n     long getRandomGeneratorRelativeLong(OpaqueRandomGenerator ptr, @Cast(\"Nd4jLong\") long index);\n     void deleteRandomGenerator(OpaqueRandomGenerator ptr);\n \n-    String runLightBenchmarkSuit(boolean printOut);\n-\n-    String runFullBenchmarkSuit(boolean printOut);\n+  \n \n     long getCachedMemory(int deviceId);\n ",
      "parent_sha": "75fc5edc94ef056540b54c3945eaa8c15cd3da6d"
    }
  },
  {
    "oid": "2f826b218c5bffdd26014386ba125e218bd6c847",
    "message": "Update KerasLayerUtils.java",
    "date": "2021-04-08T05:00:48Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/2f826b218c5bffdd26014386ba125e218bd6c847",
    "details": {
      "sha": "536afb91501686456e0f8d5a57efaffeafc79675",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/main/java/org/deeplearning4j/nn/modelimport/keras/utils/KerasLayerUtils.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/2f826b218c5bffdd26014386ba125e218bd6c847/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasLayerUtils.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/2f826b218c5bffdd26014386ba125e218bd6c847/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasLayerUtils.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasLayerUtils.java?ref=2f826b218c5bffdd26014386ba125e218bd6c847",
      "patch": "@@ -297,7 +297,7 @@ public static KerasLayer getKerasLayerFromConfig(Map<String, Object> layerConfig\n             layer = new KerasUpsampling1D(layerConfig, enforceTrainingConfig);\n         } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_UPSAMPLING_2D())) {\n             layer = new KerasUpsampling2D(layerConfig, enforceTrainingConfig);\n-        }else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_UPSAMPLING_2D())) {\n+        }else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_UPSAMPLING_3D())) {\n             layer = new KerasUpsampling3D(layerConfig, enforceTrainingConfig);\n         }  else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CROPPING_3D())) {\n             layer = new KerasCropping3D(layerConfig, enforceTrainingConfig);",
      "parent_sha": "67b64e63fc70ef1618c65420c0bb941e16e738c7"
    }
  },
  {
    "oid": "1df8899fb1ff6a4d55f8ce41889ea6d6d3e6b757",
    "message": "restoreMultiLayerNetwork() needlessly writes temp-file #8735\n\nSigned-off-by: cspriegel <christian.spriegel@gmail.com>",
    "date": "2020-02-26T15:24:32Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/1df8899fb1ff6a4d55f8ce41889ea6d6d3e6b757",
    "details": {
      "sha": "aa0cab9a09d5c4640c76cc44f9419ffb1f032601",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java",
      "status": "modified",
      "additions": 156,
      "deletions": 199,
      "changes": 355,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/1df8899fb1ff6a4d55f8ce41889ea6d6d3e6b757/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/1df8899fb1ff6a4d55f8ce41889ea6d6d3e6b757/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Futil%2FModelSerializer.java?ref=1df8899fb1ff6a4d55f8ce41889ea6d6d3e6b757",
      "patch": "@@ -43,9 +43,12 @@\n import java.io.*;\n import java.util.ArrayList;\n import java.util.Enumeration;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n import java.util.zip.ZipEntry;\n import java.util.zip.ZipFile;\n+import java.util.zip.ZipInputStream;\n import java.util.zip.ZipOutputStream;\n \n /**\n@@ -215,7 +218,24 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file) thr\n      */\n     public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boolean loadUpdater)\n             throws IOException {\n-        ZipFile zipFile = new ZipFile(file);\n+        return restoreMultiLayerNetwork(new FileInputStream(file), loadUpdater);\n+    }\n+\n+\n+    /**\n+     * Load a MultiLayerNetwork from InputStream from an input stream<br>\n+     * Note: the input stream is read fully and closed by this method. Consequently, the input stream cannot be re-used.\n+     *\n+     * @param is the inputstream to load from\n+     * @return the loaded multi layer network\n+     * @throws IOException\n+     * @see #restoreMultiLayerNetworkAndNormalizer(InputStream, boolean)\n+     */\n+    public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull InputStream is, boolean loadUpdater)\n+            throws IOException {\n+        checkInputStream(is);\n+\n+        Map<String, byte[]> zipFile = loadZipData(is);\n \n         boolean gotConfig = false;\n         boolean gotCoefficients = false;\n@@ -229,11 +249,11 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boo\n         DataSetPreProcessor preProcessor = null;\n \n \n-        ZipEntry config = zipFile.getEntry(CONFIGURATION_JSON);\n+        byte[] config = zipFile.get(CONFIGURATION_JSON);\n         if (config != null) {\n             //restoring configuration\n \n-            InputStream stream = zipFile.getInputStream(config);\n+            InputStream stream = new ByteArrayInputStream(config);\n             BufferedReader reader = new BufferedReader(new InputStreamReader(stream));\n             String line = \"\";\n             StringBuilder js = new StringBuilder();\n@@ -248,25 +268,25 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boo\n         }\n \n \n-        ZipEntry coefficients = zipFile.getEntry(COEFFICIENTS_BIN);\n+        byte[] coefficients = zipFile.get(COEFFICIENTS_BIN);\n         if (coefficients != null ) {\n-            if(coefficients.getSize() > 0) {\n-                InputStream stream = zipFile.getInputStream(coefficients);\n+            if(coefficients.length > 0) {\n+                InputStream stream = new ByteArrayInputStream(coefficients);\n                 DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));\n                 params = Nd4j.read(dis);\n \n                 dis.close();\n                 gotCoefficients = true;\n             } else {\n-                ZipEntry noParamsMarker = zipFile.getEntry(NO_PARAMS_MARKER);\n+                byte[] noParamsMarker = zipFile.get(NO_PARAMS_MARKER);\n                 gotCoefficients = (noParamsMarker != null);\n             }\n         }\n \n         if (loadUpdater) {\n-            ZipEntry updaterStateEntry = zipFile.getEntry(UPDATER_BIN);\n+        \tbyte[] updaterStateEntry = zipFile.get(UPDATER_BIN);\n             if (updaterStateEntry != null) {\n-                InputStream stream = zipFile.getInputStream(updaterStateEntry);\n+                InputStream stream = new ByteArrayInputStream(updaterStateEntry);\n                 DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));\n                 updaterState = Nd4j.read(dis);\n \n@@ -275,9 +295,9 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boo\n             }\n         }\n \n-        ZipEntry prep = zipFile.getEntry(PREPROCESSOR_BIN);\n+        byte[] prep = zipFile.get(PREPROCESSOR_BIN);\n         if (prep != null) {\n-            InputStream stream = zipFile.getInputStream(prep);\n+            InputStream stream = new ByteArrayInputStream(prep);\n             ObjectInputStream ois = new ObjectInputStream(stream);\n \n             try {\n@@ -290,7 +310,6 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boo\n         }\n \n \n-        zipFile.close();\n \n         if (gotConfig && gotCoefficients) {\n             MultiLayerConfiguration confFromJson;\n@@ -328,31 +347,6 @@ public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull File file, boo\n                     + \"], gotCoefficients: [\" + gotCoefficients + \"], gotUpdater: [\" + gotUpdaterState + \"]\");\n     }\n \n-\n-    /**\n-     * Load a MultiLayerNetwork from InputStream from an input stream<br>\n-     * Note: the input stream is read fully and closed by this method. Consequently, the input stream cannot be re-used.\n-     *\n-     * @param is the inputstream to load from\n-     * @return the loaded multi layer network\n-     * @throws IOException\n-     * @see #restoreMultiLayerNetworkAndNormalizer(InputStream, boolean)\n-     */\n-    public static MultiLayerNetwork restoreMultiLayerNetwork(@NonNull InputStream is, boolean loadUpdater)\n-            throws IOException {\n-        checkInputStream(is);\n-\n-        File tmpFile = null;\n-        try{\n-            tmpFile = tempFileFromStream(is);\n-            return restoreMultiLayerNetwork(tmpFile, loadUpdater);\n-        } finally {\n-            if(tmpFile != null){\n-                tmpFile.delete();\n-            }\n-        }\n-    }\n-\n     /**\n      * Restore a multi layer network from an input stream<br>\n      * * Note: the input stream is read fully and closed by this method. Consequently, the input stream cannot be re-used.\n@@ -404,15 +398,9 @@ public static Pair<MultiLayerNetwork, Normalizer> restoreMultiLayerNetworkAndNor\n             @NonNull InputStream is, boolean loadUpdater) throws IOException {\n         checkInputStream(is);\n \n-        File tmpFile = null;\n-        try {\n-            tmpFile = tempFileFromStream(is);\n-            return restoreMultiLayerNetworkAndNormalizer(tmpFile, loadUpdater);\n-        } finally {\n-            if (tmpFile != null) {\n-                tmpFile.delete();\n-            }\n-        }\n+        MultiLayerNetwork net = restoreMultiLayerNetwork(is, loadUpdater);\n+        Normalizer norm = restoreNormalizerFromInputStream(is);\n+        return new Pair<>(net, norm);\n     }\n \n     /**\n@@ -425,9 +413,7 @@ public static Pair<MultiLayerNetwork, Normalizer> restoreMultiLayerNetworkAndNor\n      */\n     public static Pair<MultiLayerNetwork, Normalizer> restoreMultiLayerNetworkAndNormalizer(@NonNull File file, boolean loadUpdater)\n             throws IOException {\n-        MultiLayerNetwork net = restoreMultiLayerNetwork(file, loadUpdater);\n-        Normalizer norm = restoreNormalizerFromFile(file);\n-        return new Pair<>(net, norm);\n+    \treturn restoreMultiLayerNetworkAndNormalizer(new FileInputStream(file), loadUpdater);\n     }\n \n     /**\n@@ -465,87 +451,7 @@ public static ComputationGraph restoreComputationGraph(@NonNull InputStream is,\n             throws IOException {\n         checkInputStream(is);\n \n-        File tmpFile = null;\n-        try{\n-            tmpFile = tempFileFromStream(is);\n-            return restoreComputationGraph(tmpFile, loadUpdater);\n-        } finally {\n-            if(tmpFile != null){\n-                tmpFile.delete();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Load a computation graph from a InputStream\n-     * @param is the inputstream to get the computation graph from\n-     * @return the loaded computation graph\n-     *\n-     * @throws IOException\n-     */\n-    public static ComputationGraph restoreComputationGraph(@NonNull InputStream is) throws IOException {\n-        return restoreComputationGraph(is, true);\n-    }\n-\n-    /**\n-     * Load a computation graph from a file\n-     * @param file the file to get the computation graph from\n-     * @return the loaded computation graph\n-     *\n-     * @throws IOException\n-     */\n-    public static ComputationGraph restoreComputationGraph(@NonNull File file) throws IOException {\n-        return restoreComputationGraph(file, true);\n-    }\n-\n-    /**\n-     * Restore a ComputationGraph and Normalizer (if present - null if not) from the InputStream.\n-     * Note: the input stream is read fully and closed by this method. Consequently, the input stream cannot be re-used.\n-     *\n-     * @param is          Input stream to read from\n-     * @param loadUpdater Whether to load the updater from the model or not\n-     * @return Model and normalizer, if present\n-     * @throws IOException If an error occurs when reading from the stream\n-     */\n-    public static Pair<ComputationGraph, Normalizer> restoreComputationGraphAndNormalizer(\n-            @NonNull InputStream is, boolean loadUpdater) throws IOException {\n-        checkInputStream(is);\n-\n-        File tmpFile = null;\n-        try {\n-            tmpFile = tempFileFromStream(is);\n-            return restoreComputationGraphAndNormalizer(tmpFile, loadUpdater);\n-        } finally {\n-            if (tmpFile != null) {\n-                tmpFile.delete();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Restore a ComputationGraph and Normalizer (if present - null if not) from a File\n-     *\n-     * @param file        File to read the model and normalizer from\n-     * @param loadUpdater Whether to load the updater from the model or not\n-     * @return Model and normalizer, if present\n-     * @throws IOException If an error occurs when reading from the File\n-     */\n-    public static Pair<ComputationGraph, Normalizer> restoreComputationGraphAndNormalizer(@NonNull File file, boolean loadUpdater)\n-            throws IOException {\n-        ComputationGraph net = restoreComputationGraph(file, loadUpdater);\n-        Normalizer norm = restoreNormalizerFromFile(file);\n-        return new Pair<>(net, norm);\n-    }\n-\n-    /**\n-     * Load a computation graph from a file\n-     * @param file the file to get the computation graph from\n-     * @return the loaded computation graph\n-     *\n-     * @throws IOException\n-     */\n-    public static ComputationGraph restoreComputationGraph(@NonNull File file, boolean loadUpdater) throws IOException {\n-        ZipFile zipFile = new ZipFile(file);\n+        Map<String, byte[]> files = loadZipData(is);\n \n         boolean gotConfig = false;\n         boolean gotCoefficients = false;\n@@ -558,11 +464,11 @@ public static ComputationGraph restoreComputationGraph(@NonNull File file, boole\n         DataSetPreProcessor preProcessor = null;\n \n \n-        ZipEntry config = zipFile.getEntry(CONFIGURATION_JSON);\n+        byte[] config = files.get(CONFIGURATION_JSON);\n         if (config != null) {\n             //restoring configuration\n \n-            InputStream stream = zipFile.getInputStream(config);\n+            InputStream stream = new ByteArrayInputStream(config);\n             BufferedReader reader = new BufferedReader(new InputStreamReader(stream));\n             String line = \"\";\n             StringBuilder js = new StringBuilder();\n@@ -577,37 +483,37 @@ public static ComputationGraph restoreComputationGraph(@NonNull File file, boole\n         }\n \n \n-        ZipEntry coefficients = zipFile.getEntry(COEFFICIENTS_BIN);\n+        byte[] coefficients = files.get(COEFFICIENTS_BIN);\n         if (coefficients != null) {\n-            if(coefficients.getSize() > 0) {\n-                InputStream stream = zipFile.getInputStream(coefficients);\n-                DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));\n+            if(coefficients.length > 0) {\n+                InputStream stream = new ByteArrayInputStream(coefficients);\n+                DataInputStream dis = new DataInputStream(stream);\n                 params = Nd4j.read(dis);\n \n                 dis.close();\n                 gotCoefficients = true;\n             } else {\n-                ZipEntry noParamsMarker = zipFile.getEntry(NO_PARAMS_MARKER);\n+                byte[] noParamsMarker = files.get(NO_PARAMS_MARKER);\n                 gotCoefficients = (noParamsMarker != null);\n             }\n         }\n \n \n         if (loadUpdater) {\n-            ZipEntry updaterStateEntry = zipFile.getEntry(UPDATER_BIN);\n+            byte[] updaterStateEntry = files.get(UPDATER_BIN);\n             if (updaterStateEntry != null) {\n-                InputStream stream = zipFile.getInputStream(updaterStateEntry);\n-                DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));\n+                InputStream stream = new ByteArrayInputStream(updaterStateEntry);\n+                DataInputStream dis = new DataInputStream(stream);\n                 updaterState = Nd4j.read(dis);\n \n                 dis.close();\n                 gotUpdaterState = true;\n             }\n         }\n \n-        ZipEntry prep = zipFile.getEntry(PREPROCESSOR_BIN);\n+        byte[] prep = files.get(PREPROCESSOR_BIN);\n         if (prep != null) {\n-            InputStream stream = zipFile.getInputStream(prep);\n+            InputStream stream = new ByteArrayInputStream(prep);\n             ObjectInputStream ois = new ObjectInputStream(stream);\n \n             try {\n@@ -620,8 +526,6 @@ public static ComputationGraph restoreComputationGraph(@NonNull File file, boole\n         }\n \n \n-        zipFile.close();\n-\n         if (gotConfig && gotCoefficients) {\n             ComputationGraphConfiguration confFromJson;\n             try{\n@@ -662,6 +566,70 @@ public static ComputationGraph restoreComputationGraph(@NonNull File file, boole\n                     + \"], gotCoefficients: [\" + gotCoefficients + \"], gotUpdater: [\" + gotUpdaterState + \"]\");\n     }\n \n+    /**\n+     * Load a computation graph from a InputStream\n+     * @param is the inputstream to get the computation graph from\n+     * @return the loaded computation graph\n+     *\n+     * @throws IOException\n+     */\n+    public static ComputationGraph restoreComputationGraph(@NonNull InputStream is) throws IOException {\n+        return restoreComputationGraph(is, true);\n+    }\n+\n+    /**\n+     * Load a computation graph from a file\n+     * @param file the file to get the computation graph from\n+     * @return the loaded computation graph\n+     *\n+     * @throws IOException\n+     */\n+    public static ComputationGraph restoreComputationGraph(@NonNull File file) throws IOException {\n+        return restoreComputationGraph(file, true);\n+    }\n+\n+    /**\n+     * Restore a ComputationGraph and Normalizer (if present - null if not) from the InputStream.\n+     * Note: the input stream is read fully and closed by this method. Consequently, the input stream cannot be re-used.\n+     *\n+     * @param is          Input stream to read from\n+     * @param loadUpdater Whether to load the updater from the model or not\n+     * @return Model and normalizer, if present\n+     * @throws IOException If an error occurs when reading from the stream\n+     */\n+    public static Pair<ComputationGraph, Normalizer> restoreComputationGraphAndNormalizer(\n+            @NonNull InputStream is, boolean loadUpdater) throws IOException {\n+        checkInputStream(is);\n+        \n+        ComputationGraph net = restoreComputationGraph(is, loadUpdater);\n+        Normalizer norm = restoreNormalizerFromInputStream(is);\n+        return new Pair<>(net, norm);\n+    }\n+\n+    /**\n+     * Restore a ComputationGraph and Normalizer (if present - null if not) from a File\n+     *\n+     * @param file        File to read the model and normalizer from\n+     * @param loadUpdater Whether to load the updater from the model or not\n+     * @return Model and normalizer, if present\n+     * @throws IOException If an error occurs when reading from the File\n+     */\n+    public static Pair<ComputationGraph, Normalizer> restoreComputationGraphAndNormalizer(@NonNull File file, boolean loadUpdater)\n+            throws IOException {\n+    \treturn restoreComputationGraphAndNormalizer(new FileInputStream(file), loadUpdater);\n+    }\n+\n+    /**\n+     * Load a computation graph from a file\n+     * @param file the file to get the computation graph from\n+     * @return the loaded computation graph\n+     *\n+     * @throws IOException\n+     */\n+    public static ComputationGraph restoreComputationGraph(@NonNull File file, boolean loadUpdater) throws IOException {\n+    \treturn restoreComputationGraph(new FileInputStream(file), loadUpdater);\n+    }\n+\n     /**\n      *\n      * @param model\n@@ -811,15 +779,16 @@ public static void addObjectToFile(@NonNull File f, @NonNull String key, @NonNul\n                 }\n \n                 //Add new object:\n-                ZipEntry entry = new ZipEntry(\"objects/\" + key);\n-                writeFile.putNextEntry(entry);\n \n                 try(ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos)){\n                     oos.writeObject(o);\n                     byte[] bytes = baos.toByteArray();\n+                    ZipEntry entry = new ZipEntry(\"objects/\" + key);\n+                    entry.setSize(bytes.length);\n+                    writeFile.putNextEntry(entry);\n                     writeFile.write(bytes);\n+                    writeFile.closeEntry();\n                 }\n-                writeFile.closeEntry();\n \n                 writeFile.close();\n                 zipFile.close();\n@@ -904,18 +873,12 @@ public static List<String> listObjectsInFile(@NonNull File f){\n      * @param file\n      * @return\n      */\n-    public static <T extends Normalizer> T restoreNormalizerFromFile(File file) {\n-        try (ZipFile zipFile = new ZipFile(file)) {\n-            ZipEntry norm = zipFile.getEntry(NORMALIZER_BIN);\n-\n-            // checking for file existence\n-            if (norm == null)\n-                return null;\n-\n-            return NormalizerSerializer.getDefault().restore(zipFile.getInputStream(norm));\n+    public static <T extends Normalizer> T restoreNormalizerFromFile(File file) throws IOException {\n+        try {\n+        \treturn restoreNormalizerFromInputStream(new FileInputStream(file));\n         } catch (Exception e) {\n             log.warn(\"Error while restoring normalizer, trying to restore assuming deprecated format...\");\n-            DataNormalization restoredDeprecated = restoreNormalizerFromFileDeprecated(file);\n+            DataNormalization restoredDeprecated = restoreNormalizerFromInputStreamDeprecated(new FileInputStream(file));\n \n             log.warn(\"Recovered using deprecated method. Will now re-save the normalizer to fix this issue.\");\n             addNormalizerToModel(file, restoredDeprecated);\n@@ -934,15 +897,18 @@ public static <T extends Normalizer> T restoreNormalizerFromFile(File file) {\n     public static <T extends Normalizer> T restoreNormalizerFromInputStream(InputStream is) throws IOException {\n         checkInputStream(is);\n \n-        File tmpFile = null;\n+        Map<String, byte[]> files = loadZipData(is);\n+        byte[] norm = files.get(NORMALIZER_BIN);\n+\n+        // checking for file existence\n+        if (norm == null)\n+            return null;\n         try {\n-            tmpFile = tempFileFromStream(is);\n-            return restoreNormalizerFromFile(tmpFile);\n-        } finally {\n-            if(tmpFile != null){\n-                tmpFile.delete();\n-            }\n+        \treturn NormalizerSerializer.getDefault().restore(new ByteArrayInputStream(norm));\n         }\n+        catch (Exception e) {\n+        \tthrow new IOException(\"Error loading normalizer\", e);\n+\t\t}\n     }\n \n     /**\n@@ -953,17 +919,9 @@ public static <T extends Normalizer> T restoreNormalizerFromInputStream(InputStr\n      * @param file\n      * @return\n      */\n-    private static DataNormalization restoreNormalizerFromFileDeprecated(File file) {\n-        try (ZipFile zipFile = new ZipFile(file)) {\n-            ZipEntry norm = zipFile.getEntry(NORMALIZER_BIN);\n-\n-            // checking for file existence\n-            if (norm == null)\n-                return null;\n-\n-            InputStream stream = zipFile.getInputStream(norm);\n+    private static DataNormalization restoreNormalizerFromInputStreamDeprecated(InputStream stream) {\n+    \ttry {\n             ObjectInputStream ois = new ObjectInputStream(stream);\n-\n             try {\n                 DataNormalization normalizer = (DataNormalization) ois.readObject();\n                 return normalizer;\n@@ -996,31 +954,30 @@ private static void checkInputStream(InputStream inputStream) throws IOException\n         */\n     }\n \n-    private static void checkTempFileFromInputStream(File f) throws IOException {\n-        if (f.length() <= 0) {\n-            throw new IOException(\"Error reading from input stream: temporary file is empty after copying entire stream.\" +\n-                    \" Stream may have been closed before reading, is attempting to be used multiple times, or does not\" +\n-                    \" point to a model file?\");\n-        }\n+    private static Map<String, byte[]> loadZipData(InputStream is) throws IOException {\n+    \tMap<String, byte[]> result = new HashMap<>();\n+\t\ttry (final ZipInputStream zis = new ZipInputStream(is)) {\n+\t\t\twhile (true) {\n+\t\t\t\tfinal ZipEntry zipEntry = zis.getNextEntry();\n+\t\t\t\tif (zipEntry == null)\n+\t\t\t\t\tbreak;\n+\t\t\t\tif(zipEntry.isDirectory() || zipEntry.getSize() > Integer.MAX_VALUE)\n+\t\t\t\t\tthrow new IllegalArgumentException();\n+\n+\t\t\t\tfinal int size = (int) (zipEntry.getSize());\n+\t\t\t\tfinal byte[] data;\n+\t\t\t\tif (size >= 0) { // known size\n+\t\t\t\t\tdata = IOUtils.readFully(zis, size);\n+\t\t\t\t}\n+\t\t\t\telse { // unknown size\n+\t\t\t\t\tfinal ByteArrayOutputStream bout = new ByteArrayOutputStream();\n+\t\t\t\t\tIOUtils.copy(zis, bout);\n+\t\t\t\t\tdata = bout.toByteArray();\n+\t\t\t\t}\n+                                result.put(zipEntry.getName(), data);\n+\t\t\t}\n+\t\t}\n+\t\treturn result;\n     }\n \n-    private static File tempFileFromStream(InputStream is) throws IOException{\n-        checkInputStream(is);\n-        String p = System.getProperty(DL4JSystemProperties.DL4J_TEMP_DIR_PROPERTY);\n-        File tmpFile = DL4JFileUtils.createTempFile(\"dl4jModelSerializer\", \"bin\");\n-        try {\n-            tmpFile.deleteOnExit();\n-            BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(tmpFile));\n-            IOUtils.copy(is, bufferedOutputStream);\n-            bufferedOutputStream.flush();\n-            IOUtils.closeQuietly(bufferedOutputStream);\n-            checkTempFileFromInputStream(tmpFile);\n-            return tmpFile;\n-        } catch (IOException e){\n-            if(tmpFile != null){\n-                tmpFile.delete();\n-            }\n-            throw e;\n-        }\n-    }\n }",
      "parent_sha": "e4ddf109c3dad2680aa3fa79b6c5aed229eb74e4"
    }
  },
  {
    "oid": "9d325ad0700f23754b54405241a2aa5f9d253219",
    "message": "Small optimization to Nd4j.readNumpy (#183)\n\nSigned-off-by: Alex Black <blacka101@gmail.com>",
    "date": "2019-08-27T13:27:41Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/9d325ad0700f23754b54405241a2aa5f9d253219",
    "details": {
      "sha": "c8baedfa5a2a184745fc443ee105d4ba1ad45358",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 4,
      "deletions": 7,
      "changes": 11,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/9d325ad0700f23754b54405241a2aa5f9d253219/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/9d325ad0700f23754b54405241a2aa5f9d253219/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=9d325ad0700f23754b54405241a2aa5f9d253219",
      "patch": "@@ -2265,15 +2265,12 @@ public static INDArray readNumpy(@NonNull DataType dataType, @NonNull InputStrea\n                 Preconditions.checkState(data.length == numColumns,\n                         \"Data has inconsistent number of columns: data length %s, numColumns %s\", data.length, numColumns);\n             data2.add(readSplit(data));\n-\n-\n         }\n-        ret = Nd4j.create(dataType, data2.size(), numColumns);\n-        for (int i = 0; i < data2.size(); i++) {\n-            float[] row = data2.get(i);\n-            INDArray arr = Nd4j.create(row, new long[]{1, row.length}, dataType);\n-            ret.putRow(i, arr);\n+        float[][] fArr = new float[data2.size()][0];\n+        for(int i=0; i<data2.size(); i++ ){\n+            fArr[i] = data2.get(i);\n         }\n+        ret = Nd4j.createFromArray(fArr).castTo(dataType);\n         return ret;\n     }\n ",
      "parent_sha": "7f0c660d8b7ad69bcf4f5f733ea130ac1e1bc619"
    }
  },
  {
    "oid": "9fe4c398d8c18acdab88f25b27e2f012f5f9d062",
    "message": "Update path for model import",
    "date": "2021-11-30T05:01:19Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/9fe4c398d8c18acdab88f25b27e2f012f5f9d062",
    "details": {
      "sha": "c19b54846ff3c9445224a1b169f1940236d66c8f",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/test/java/org/deeplearning4j/nn/modelimport/keras/weights/KerasWeightSettingTests.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/9fe4c398d8c18acdab88f25b27e2f012f5f9d062/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Fweights%2FKerasWeightSettingTests.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/9fe4c398d8c18acdab88f25b27e2f012f5f9d062/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Fweights%2FKerasWeightSettingTests.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Fweights%2FKerasWeightSettingTests.java?ref=9fe4c398d8c18acdab88f25b27e2f012f5f9d062",
      "patch": "@@ -66,7 +66,9 @@ public long getTimeoutMilliseconds() {\n \n     @Test\n     public void testWeights() throws Exception {\n-        MultiLayerNetwork multiLayerNetwork = KerasModelImport.importKerasSequentialModelAndWeights(\"C:\\\\Users\\\\agibs\\\\Downloads\\\\model (1).h5\");\n+        File file = Resources.asFile(\"modelimport/keras/weights/keras_2.7_issue.h5\");\n+        //\"C:\\Users\\agibs\\Documents\\GitHub\\dl4j-test-resources\\src\\main\\resources\\modelimport\\keras\\weights\\keras_2.7_issue.h5\"\n+        MultiLayerNetwork multiLayerNetwork = KerasModelImport.importKerasSequentialModelAndWeights(file.getAbsolutePath());\n         System.out.println(multiLayerNetwork.summary());\n \n     }",
      "parent_sha": "6dbba6fb4d9fe0e7fd4178b7c85861d9a252c6dc"
    }
  },
  {
    "oid": "b9411863028f8725d00145b1a254fa9612461bca",
    "message": "Making TypeName enum public (#235)",
    "date": "2020-02-12T10:17:30Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/b9411863028f8725d00145b1a254fa9612461bca",
    "details": {
      "sha": "d0a3f488f22e2fc19c67afc332d3844f7902d849",
      "filename": "datavec/datavec-python/src/main/java/org/datavec/python/PythonType.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/b9411863028f8725d00145b1a254fa9612461bca/datavec%2Fdatavec-python%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fpython%2FPythonType.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/b9411863028f8725d00145b1a254fa9612461bca/datavec%2Fdatavec-python%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fpython%2FPythonType.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-python%2Fsrc%2Fmain%2Fjava%2Forg%2Fdatavec%2Fpython%2FPythonType.java?ref=b9411863028f8725d00145b1a254fa9612461bca",
      "patch": "@@ -36,7 +36,7 @@ public abstract class PythonType<T> {\n     public abstract T toJava(PythonObject pythonObject) throws PythonException;\n     private final TypeName typeName;\n \n-    enum TypeName{\n+    public enum TypeName{\n         STR,\n         INT,\n         FLOAT,",
      "parent_sha": "f3fa4fd632a6614493f74dc1848fa4c41c8c14c6"
    }
  },
  {
    "oid": "e730a33f801e5fa02cff33bce49eaf18cfd40f31",
    "message": "Update NativeOpsHolder.java",
    "date": "2021-11-28T23:46:02Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/e730a33f801e5fa02cff33bce49eaf18cfd40f31",
    "details": {
      "sha": "a161555c5920bf46b44501a48a290b7fe5b2764c",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-native-api/src/main/java/org/nd4j/nativeblas/NativeOpsHolder.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/e730a33f801e5fa02cff33bce49eaf18cfd40f31/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOpsHolder.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/e730a33f801e5fa02cff33bce49eaf18cfd40f31/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOpsHolder.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-native-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNativeOpsHolder.java?ref=e730a33f801e5fa02cff33bce49eaf18cfd40f31",
      "patch": "@@ -89,7 +89,7 @@ private NativeOpsHolder() {\n                     .asSubclass(NativeOps.class);\n             deviceNativeOps = ReflectionUtils.newInstance(nativeOpsClass);\n \n-            deviceNativeOps.initializeDevicesAndFunctions();\n+            //deviceNativeOps.initializeDevicesAndFunctions();\n             int numThreads;\n             String numThreadsString = System.getenv(ND4JEnvironmentVars.OMP_NUM_THREADS);\n             if (numThreadsString != null && !numThreadsString.isEmpty()) {",
      "parent_sha": "dff2d5cd11a6fc080f67431dae48b22403f0aacb"
    }
  },
  {
    "oid": "83a033d218b27f90091deb4f1a648bddad574f3e",
    "message": "Update Nd4jTestsC.java",
    "date": "2021-03-23T09:47:43Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/83a033d218b27f90091deb4f1a648bddad574f3e",
    "details": {
      "sha": "56a713d6cc1b553f70b004f754247c5da4ea0d79",
      "filename": "nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/Nd4jTestsC.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/83a033d218b27f90091deb4f1a648bddad574f3e/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/83a033d218b27f90091deb4f1a648bddad574f3e/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-tests%2Fsrc%2Ftest%2Fjava%2Forg%2Fnd4j%2Flinalg%2FNd4jTestsC.java?ref=83a033d218b27f90091deb4f1a648bddad574f3e",
      "patch": "@@ -1595,7 +1595,7 @@ public void testDivide(Nd4jBackend backend) {\n     @ParameterizedTest\n     @MethodSource(\"org.nd4j.linalg.BaseNd4jTestWithBackends#configs\")\n     public void testSigmoid(Nd4jBackend backend) {\n-        INDArray n = Nd4j.create(new float[] {1, 2, 3, 4});\n+        INDArray n = Nd4j.create(new float[] {1, 2, 3, 4}).castTo(DataType.DOUBLE);\n         INDArray assertion = Nd4j.create(new float[] {0.73105858f, 0.88079708f, 0.95257413f, 0.98201379f}).castTo(DataType.DOUBLE);\n         INDArray sigmoid = Transforms.sigmoid(n, false);\n         assertEquals(assertion, sigmoid);",
      "parent_sha": "ac38c704cd235ffc9810c10e94631e877cc59eb0"
    }
  },
  {
    "oid": "2ec24c762feadfcd12f580e43326af5d387abf05",
    "message": "Fixed object's removal in ArrayCacheMemoryMgr (#9155)\n\nSigned-off-by: partarstu <partarstu@gmail.com>",
    "date": "2021-01-18T05:52:42Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/2ec24c762feadfcd12f580e43326af5d387abf05",
    "details": {
      "sha": "69db24f032cd0ff185ac40c29083d707998cb8f1",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/internal/memory/ArrayCacheMemoryMgr.java",
      "status": "modified",
      "additions": 5,
      "deletions": 3,
      "changes": 8,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/2ec24c762feadfcd12f580e43326af5d387abf05/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/2ec24c762feadfcd12f580e43326af5d387abf05/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java?ref=2ec24c762feadfcd12f580e43326af5d387abf05",
      "patch": "@@ -252,11 +252,13 @@ private INDArray get(long[] shape) {\n         private void removeObject(INDArray array){\n             long length = array.data().length();\n             int idx = Arrays.binarySearch(lengths, 0, size, length);\n-            Preconditions.checkState(idx > 0, \"Cannot remove array from ArrayStore: no array with this length exists in the cache\");\n+            Preconditions.checkState(idx >= 0,\n+                    \"Cannot remove array from ArrayStore: no array with this length exists in the cache\");\n             boolean found = false;\n             int i = 0;\n-            while(!found && i <= size && lengths[i] == length){\n-                found = sorted[i++] == array; //Object equality\n+            while (!found && i < size) {\n+                found = sorted[i] == array && lengths[i] == length; //Object and length equality\n+                ++i;\n             }\n             Preconditions.checkState(found, \"Cannot remove array: not found in ArrayCache\");\n             removeIdx(i - 1);",
      "parent_sha": "95ca39bd2185e005671889e3a2114a30dc4c0281"
    }
  },
  {
    "oid": "8b9dd25105d36f3a1f6e437afd0764b5739f440a",
    "message": "Update TestOptimizers.java",
    "date": "2021-11-08T12:27:51Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/8b9dd25105d36f3a1f6e437afd0764b5739f440a",
    "details": {
      "sha": "f5c42e391871b1ad36ef6fbcff12d712316118e5",
      "filename": "deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/optimize/solver/TestOptimizers.java",
      "status": "modified",
      "additions": 9,
      "deletions": 4,
      "changes": 13,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/8b9dd25105d36f3a1f6e437afd0764b5739f440a/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Foptimize%2Fsolver%2FTestOptimizers.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/8b9dd25105d36f3a1f6e437afd0764b5739f440a/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Foptimize%2Fsolver%2FTestOptimizers.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fdeeplearning4j%2Foptimize%2Fsolver%2FTestOptimizers.java?ref=8b9dd25105d36f3a1f6e437afd0764b5739f440a",
      "patch": "@@ -58,6 +58,7 @@\n import org.nd4j.linalg.exception.ND4JArraySizeException;\n import org.nd4j.linalg.factory.Nd4j;\n import org.nd4j.linalg.indexing.conditions.Condition;\n+import org.nd4j.linalg.indexing.conditions.Conditions;\n import org.nd4j.linalg.learning.config.AdaGrad;\n import org.nd4j.linalg.learning.config.Sgd;\n import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction;\n@@ -484,9 +485,11 @@ public void computeGradientAndScore(LayerWorkspaceMgr workspaceMgr) {\n             this.gradient = g;\n             //If any parameters are outside range [-5.12,5.12]: score = infinity\n             INDArray paramExceeds512 = parameters.cond(new Condition() {\n+\n+\n                 @Override\n-                public int condtionNum() {\n-                    return 0;\n+                public Conditions.ConditionMode conditionType() {\n+                    return null;\n                 }\n \n                 @Override\n@@ -683,9 +686,11 @@ public void computeGradientAndScore(LayerWorkspaceMgr workspaceMgr) {\n             this.gradient = g;\n \n             INDArray paramExceeds5 = parameters.cond(new Condition() {\n+\n+\n                 @Override\n-                public int condtionNum() {\n-                    return 0;\n+                public Conditions.ConditionMode conditionType() {\n+                    return null;\n                 }\n \n                 @Override",
      "parent_sha": "3a3f3f90f62359faca3254bfc0a48b2664afcf0d"
    }
  },
  {
    "oid": "89b851279663040d893fb379b55acc45bfce162d",
    "message": "Update KerasOptimizerUtils.java (#9939)\n\n* Update KerasOptimizerUtils.java\r\n\r\nFix keras optimizers to be case agnostic.\r\n\r\n* Fix newer keras versions + pretrained model optimizers\r\n\r\n* Fix default decay",
    "date": "2023-03-24T22:10:38Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/89b851279663040d893fb379b55acc45bfce162d",
    "details": {
      "sha": "1479a70d4d7d8eeeed14dd478ddb649ff92a786e",
      "filename": "deeplearning4j/deeplearning4j-modelimport/src/main/java/org/deeplearning4j/nn/modelimport/keras/utils/KerasOptimizerUtils.java",
      "status": "modified",
      "additions": 13,
      "deletions": 10,
      "changes": 23,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/89b851279663040d893fb379b55acc45bfce162d/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasOptimizerUtils.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/89b851279663040d893fb379b55acc45bfce162d/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasOptimizerUtils.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-modelimport%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fmodelimport%2Fkeras%2Futils%2FKerasOptimizerUtils.java?ref=89b851279663040d893fb379b55acc45bfce162d",
      "patch": "@@ -55,6 +55,10 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n             throw new InvalidKerasConfigurationException(\"Optimizer config does not contain a name field.\");\n         }\n         String optimizerName = (String) optimizerConfig.get(\"class_name\");\n+        //newer keras versions\n+        if(optimizerName != null && optimizerName.startsWith(\"Custom>\")) {\n+            optimizerName = optimizerName.replace(\"Custom>\",\"\");\n+        }\n \n         if (!optimizerConfig.containsKey(\"config\"))\n             throw new InvalidKerasConfigurationException(\"Field config missing from layer config\");\n@@ -63,13 +67,13 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n         IUpdater dl4jOptimizer;\n \n \n-        switch (optimizerName) {\n-            case \"Adam\": {\n+        switch (optimizerName.toLowerCase()) {\n+            case \"adam\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double beta1 = (double) optimizerParameters.get(BETA_1);\n                 double beta2 = (double) optimizerParameters.get(BETA_2);\n                 double epsilon = (double) optimizerParameters.get(EPSILON);\n-                double decay = (double) optimizerParameters.get(DECAY);\n+                double decay = (double) (optimizerParameters.containsKey(DECAY) ? optimizerParameters.get(DECAY) : Adam.DEFAULT_ADAM_BETA1_MEAN_DECAY);\n \n                 dl4jOptimizer = new Adam.Builder()\n                         .beta1(beta1).beta2(beta2)\n@@ -78,17 +82,16 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n                         .build();\n                 break;\n             }\n-            case \"Adadelta\": {\n+            case \"adadelta\": {\n                 double rho = (double) optimizerParameters.get(RHO);\n                 double epsilon = (double) optimizerParameters.get(EPSILON);\n-                // double decay = (double) optimizerParameters.get(DECAY); No decay in DL4J Adadelta\n \n                 dl4jOptimizer = new AdaDelta.Builder()\n                         .epsilon(epsilon).rho(rho)\n                         .build();\n                 break;\n             }\n-            case \"Adgrad\": {\n+            case \"adagrad\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double epsilon = (double) optimizerParameters.get(EPSILON);\n                 double decay = (double) optimizerParameters.get(DECAY);\n@@ -99,7 +102,7 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n                         .build();\n                 break;\n             }\n-            case \"Adamax\": {\n+            case \"adamax\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double beta1 = (double) optimizerParameters.get(BETA_1);\n                 double beta2 = (double) optimizerParameters.get(BETA_2);\n@@ -108,7 +111,7 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n                 dl4jOptimizer = new AdaMax(lr, beta1, beta2, epsilon);\n                 break;\n             }\n-            case \"Nadam\": {\n+            case \"nadam\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double beta1 = (double) optimizerParameters.get(BETA_1);\n                 double beta2 = (double) optimizerParameters.get(BETA_2);\n@@ -123,7 +126,7 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n                         .build();\n                 break;\n             }\n-            case \"SGD\": {\n+            case \"sgd\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double momentum = (double) (optimizerParameters.containsKey(EPSILON) ? optimizerParameters.get(EPSILON) : optimizerParameters.get(MOMENTUM));\n \n@@ -135,7 +138,7 @@ public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)\n                         .build();\n                 break;\n             }\n-            case \"RMSprop\": {\n+            case \"rmsprop\": {\n                 double lr = (double) (optimizerParameters.containsKey(LR) ? optimizerParameters.get(LR) : optimizerParameters.get(LR2));\n                 double rho = (double) optimizerParameters.get(RHO);\n                 double epsilon = (double) optimizerParameters.get(EPSILON);",
      "parent_sha": "27660dc640664b7b607130b46fa03eb90e185362"
    }
  },
  {
    "oid": "dff2d5cd11a6fc080f67431dae48b22403f0aacb",
    "message": "Update Nd4jAuroraOps.java",
    "date": "2021-11-28T23:32:23Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/dff2d5cd11a6fc080f67431dae48b22403f0aacb",
    "details": {
      "sha": "36fe1daee277188b0e81389611fb0f9809d840ef",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-aurora/src/main/java/org/nd4j/nativeblas/Nd4jAuroraOps.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/dff2d5cd11a6fc080f67431dae48b22403f0aacb/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/dff2d5cd11a6fc080f67431dae48b22403f0aacb/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java?ref=dff2d5cd11a6fc080f67431dae48b22403f0aacb",
      "patch": "@@ -54,9 +54,9 @@ public Nd4jAuroraOps() {\n             if (s != null) {\n                 deviceId = Integer.parseInt(s);\n             }\n-            File f = Loader.cacheResource(\"org/nd4j/aurora/ \" + Loader.getPlatform() + (LOAD_SHARED_LIBRARY ? \"/libaurora.so\" : \"/nd4jaurora\"));\n+            File f = Loader.cacheResource(\"org/nd4j/aurora/\"  + Loader.getPlatform() + (LOAD_SHARED_LIBRARY ? \"/libaurora.so\" : \"/nd4jaurora\"));\n             if(f == null) {\n-                throw new IllegalArgumentException(\"Unable to load shared library libaurora.so, resource path was \" + Loader.getPlatform() + (LOAD_SHARED_LIBRARY ? \"/libaurora.so\" : \"/nd4jaurora\"));\n+                throw new IllegalArgumentException(\"Unable to load shared library libaurora.so, resource path was \" + \"org/nd4j/aurora/\" + Loader.getPlatform() + (LOAD_SHARED_LIBRARY ? \"/libaurora.so\" : \"/nd4jaurora\"));\n             }\n             f.setExecutable(true);\n             veobin = f.getAbsolutePath();",
      "parent_sha": "c3d073578971bc9b49e69c4d333473ed32d99987"
    }
  },
  {
    "oid": "f6708b5d19f05a4614e07e8919f9cb09873e5d02",
    "message": "Update LayerValidation.java",
    "date": "2021-05-06T01:40:50Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/f6708b5d19f05a4614e07e8919f9cb09873e5d02",
    "details": {
      "sha": "adebad92dbcb3d246d855d46f38f35e9c4f8e325",
      "filename": "deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/layers/LayerValidation.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/f6708b5d19f05a4614e07e8919f9cb09873e5d02/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/f6708b5d19f05a4614e07e8919f9cb09873e5d02/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-nn%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fnn%2Fconf%2Flayers%2FLayerValidation.java?ref=f6708b5d19f05a4614e07e8919f9cb09873e5d02",
      "patch": "@@ -131,7 +131,7 @@ public static void generalValidation(String layerName, Layer layer, IDropout iDr\n     private static void configureBaseLayer(String layerName, BaseLayer bLayer, IDropout iDropout,\n                                            List<Regularization> regularization, List<Regularization> regularizationBias) {\n         if (regularization != null && !regularization.isEmpty()) {\n-            final List<Regularization> bLayerRegs = new ArrayList<>(bLayer.getRegularization());\n+            final List<Regularization> bLayerRegs = bLayer.getRegularization();\n             if (bLayerRegs == null || bLayerRegs.isEmpty()) {\n                 bLayer.setRegularization(regularization);\n             } else {\n@@ -165,7 +165,7 @@ private static void configureBaseLayer(String layerName, BaseLayer bLayer, IDrop\n \n \n         if (regularizationBias != null && !regularizationBias.isEmpty()) {\n-            final List<Regularization> bLayerRegs = new ArrayList<>(bLayer.getRegularizationBias());\n+            final List<Regularization> bLayerRegs = bLayer.getRegularizationBias();\n             if (bLayerRegs == null || bLayerRegs.isEmpty()) {\n                 bLayer.setRegularizationBias(regularizationBias);\n             } else {",
      "parent_sha": "ba10a09c19c94973b15a73a3cbf39bf75888d2ee"
    }
  },
  {
    "oid": "46140eccaccbcaf49b578498824891cf2e5268e1",
    "message": "Moves all array cache state to static (#9782)\n\n* Add more safeguards around caching variables\n\n* Change array cache to use static variables to ensure cache state is consistent across multiple samediff instances, variables may be put in to multiple caches, each one can be created with a session as well. Shared state should be tracked.",
    "date": "2022-09-19T08:56:27Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/46140eccaccbcaf49b578498824891cf2e5268e1",
    "details": {
      "sha": "a10166be0476bf5324826207455797baf02377e3",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/autodiff/samediff/internal/memory/ArrayCacheMemoryMgr.java",
      "status": "modified",
      "additions": 29,
      "deletions": 24,
      "changes": 53,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/46140eccaccbcaf49b578498824891cf2e5268e1/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/46140eccaccbcaf49b578498824891cf2e5268e1/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fautodiff%2Fsamediff%2Finternal%2Fmemory%2FArrayCacheMemoryMgr.java?ref=46140eccaccbcaf49b578498824891cf2e5268e1",
      "patch": "@@ -21,10 +21,14 @@\n package org.nd4j.autodiff.samediff.internal.memory;\n \n import java.util.*;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicLong;\n \n import org.bytedeco.javacpp.Pointer;\n import org.nd4j.common.base.Preconditions;\n import org.nd4j.common.config.ND4JSystemProperties;\n+import org.nd4j.common.primitives.AtomicDouble;\n import org.nd4j.linalg.api.buffer.DataType;\n import org.nd4j.linalg.api.ndarray.BaseNDArray;\n import org.nd4j.linalg.api.ndarray.INDArray;\n@@ -44,23 +48,23 @@\n @Slf4j\n public class ArrayCacheMemoryMgr extends AbstractMemoryMgr {\n \n-    private Map<INDArray,INDArray> released = new IdentityHashMap<>();\n+    private static Map<INDArray,INDArray> released = new IdentityHashMap<>();\n \n-    private final double maxMemFrac;\n-    private long smallArrayThreshold;\n-    private double largerArrayMaxMultiple;\n+    private static  AtomicDouble maxMemFrac;\n+    private static AtomicLong smallArrayThreshold;\n+    private static AtomicDouble largerArrayMaxMultiple;\n \n-    private long maxCacheBytes;\n-    private long totalMemBytes;\n+    private static AtomicLong maxCacheBytes;\n+    private static AtomicLong totalMemBytes;\n \n-    private long currentCacheSize = 0;\n+    private static AtomicLong currentCacheSize =  new AtomicLong(0);\n \n-    private LinkedHashSet<Long> lruCache = new LinkedHashSet<>();\n-    private Map<Long, INDArray> lruCacheValues = new HashMap<>();\n+    private static Set<Long> lruCache = new ConcurrentSkipListSet<>();\n+    private static Map<Long, INDArray> lruCacheValues = new ConcurrentHashMap<>();\n \n-    private Table<DataType, String, List<INDArray>> arrays = HashBasedTable.create();\n+    private static Table<DataType, String, List<INDArray>> arrays = HashBasedTable.create();\n \n-    private boolean enableCache = Boolean\n+    private static boolean enableCache = Boolean\n             .parseBoolean(System.getProperty(ND4JSystemProperties.SAMEDIFF_MEMORY_CACHE_DISABLE, \"true\"));\n \n     /**\n@@ -90,19 +94,20 @@ public ArrayCacheMemoryMgr(double maxMemFrac, long smallArrayThreshold, double l\n                 smallArrayThreshold);\n         Preconditions.checkArgument(largerArrayMaxMultiple >= 1.0, \"Larger array max multiple must be >= 1.0, got %s\",\n                 largerArrayMaxMultiple);\n-        this.maxMemFrac = maxMemFrac;\n-        this.smallArrayThreshold = smallArrayThreshold;\n-        this.largerArrayMaxMultiple = largerArrayMaxMultiple;\n+        this.maxMemFrac = new AtomicDouble(maxMemFrac);\n+        this.smallArrayThreshold = new AtomicLong(smallArrayThreshold);\n+        this.largerArrayMaxMultiple = new AtomicDouble(largerArrayMaxMultiple);\n \n         if (isCpu()) {\n-            totalMemBytes = Pointer.maxBytes();\n+            totalMemBytes = new AtomicLong(Pointer.maxBytes());\n         } else {\n             Properties p = Nd4j.getExecutioner().getEnvironmentInformation();\n             List devList = (List) p.get(\"cuda.devicesInformation\");\n             Map m = (Map) devList.get(0);\n-            totalMemBytes = (Long) m.get(\"cuda.totalMemory\");\n+            totalMemBytes = new AtomicLong((Long) m.get(\"cuda.totalMemory\"));\n         }\n-        maxCacheBytes = (long) (maxMemFrac * totalMemBytes);\n+\n+        maxCacheBytes = new AtomicLong((long) maxMemFrac * totalMemBytes.get());\n     }\n \n     private boolean isCpu() {\n@@ -131,7 +136,7 @@ public INDArray allocate(boolean detached, DataType dataType, long... shape) {\n \n                 if (arr != null) {\n                     // Decrement cache size\n-                    currentCacheSize -= dataType.width() * arr.data().length();\n+                    currentCacheSize.set(currentCacheSize.get() - dataType.width() * arr.data().length());\n                     lruCache.remove(arr.getId());\n                     lruCacheValues.remove(arr.getId());\n                     // We need to assign new Id. this way we will break any possible relationship it\n@@ -185,7 +190,7 @@ public INDArray allocate(boolean detached, LongShapeDescriptor descriptor) {\n \n             if (arr != null && !arr.wasClosed()) {\n                 // Decrement cache size\n-                currentCacheSize -= dataType.width() * arr.data().length();\n+                currentCacheSize.set(currentCacheSize.get() - dataType.width() * arr.data().length());\n                 // We need to assign new Id. this way we will break any possible relationship it\n                 // had in Tracker.\n                 // the old cache was recreating New Array using buffer and thus gaining new\n@@ -235,8 +240,8 @@ public void release(@NonNull INDArray array) {\n             if (array.closeable()) {\n                 array.close();\n             }\n-        } else if (currentCacheSize + thisBytes > maxCacheBytes) {\n-            if (thisBytes > maxCacheBytes) {\n+        } else if (currentCacheSize.get() + thisBytes > maxCacheBytes.get()) {\n+            if (thisBytes > maxCacheBytes.get()) {\n \n                 // Can't store even if we clear everything - too large\n                 if (array.closeable())\n@@ -247,7 +252,7 @@ public void release(@NonNull INDArray array) {\n             // Need to deallocate some arrays to stay under limit - do in \"oldest first\"\n             // order\n             Iterator<Long> iter = lruCache.iterator();\n-            while (currentCacheSize + thisBytes > maxCacheBytes) {\n+            while (currentCacheSize.get() + thisBytes > maxCacheBytes.get()) {\n                 long next = iter.next();\n                 iter.remove();\n                 INDArray nextOldest = lruCacheValues.remove(next);\n@@ -256,7 +261,7 @@ public void release(@NonNull INDArray array) {\n                 List<INDArray> listx = arrays.get(ndt, Arrays.toString(nextOldest.shape()));\n                 if (listx != null)\n                     listx.remove(nextOldest);\n-                currentCacheSize -= nextBytes;\n+                currentCacheSize.set(currentCacheSize.get() - nextBytes);\n \n                 if (nextOldest.closeable()) {\n                     nextOldest.close();\n@@ -281,7 +286,7 @@ private void cacheArray(INDArray array) {\n         if (!arrays.contains(dt, arrayShapeString))\n             arrays.put(dt, arrayShapeString, new ArrayList<>());\n         arrays.get(dt, arrayShapeString).add(array);\n-        currentCacheSize += array.data().length() * dt.width();\n+        currentCacheSize.set(currentCacheSize.get() + array.data().length() * dt.width());\n \n         lruCache.add(array.getId());\n         lruCacheValues.put(array.getId(), array);",
      "parent_sha": "cea211cf913c9b3e020a294b919c9ddd8b02093c"
    }
  },
  {
    "oid": "a438434b1f939a11f947d7726157afb7a7a1ffa3",
    "message": "Nd4j refactoring (#101)\n\n* cleanup\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* wip\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* wip\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-06T07:40:08Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/a438434b1f939a11f947d7726157afb7a7a1ffa3",
    "details": {
      "sha": "07aa9cdc31acd6ea8f6eec23c172cb9321f638b0",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 69,
      "deletions": 169,
      "changes": 238,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/a438434b1f939a11f947d7726157afb7a7a1ffa3/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/a438434b1f939a11f947d7726157afb7a7a1ffa3/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=a438434b1f939a11f947d7726157afb7a7a1ffa3",
      "patch": "@@ -54,7 +54,6 @@\n import org.nd4j.linalg.api.ops.impl.indexaccum.IMin;\n import org.nd4j.linalg.api.ops.impl.reduce.Mmul;\n import org.nd4j.linalg.api.ops.impl.scalar.ReplaceNans;\n-import org.nd4j.linalg.api.ops.impl.reduce.TensorMmul;\n import org.nd4j.linalg.api.ops.impl.scatter.ScatterUpdate;\n import org.nd4j.linalg.api.ops.impl.shape.Diag;\n import org.nd4j.linalg.api.ops.impl.shape.DiagPart;\n@@ -90,7 +89,6 @@\n import org.nd4j.versioncheck.VersionCheck;\n \n import java.io.*;\n-import java.lang.ref.ReferenceQueue;\n import java.lang.reflect.Constructor;\n import java.math.BigDecimal;\n import java.nio.ByteBuffer;\n@@ -114,38 +112,37 @@\n  */\n public class Nd4j {\n \n-    public final static String DATA_BUFFER_OPS = \"databufferfactory\";\n-    public final static String CONVOLUTION_OPS = \"convops\";\n+    private final static String DATA_BUFFER_OPS = \"databufferfactory\";\n+    private final static String CONVOLUTION_OPS = \"convops\";\n     /**@deprecated Use {@link ND4JSystemProperties#DTYPE}*/\n     @Deprecated\n     public final static String DTYPE = ND4JSystemProperties.DTYPE;\n-    public final static String BLAS_OPS = \"blas.ops\";\n-    public final static String SPARSE_BLAS_OPS = \"sparseblas.ops\";\n+    private final static String BLAS_OPS = \"blas.ops\";\n+    private final static String SPARSE_BLAS_OPS = \"sparseblas.ops\";\n     public final static String NATIVE_OPS = \"native.ops\";\n-    public final static String ORDER_KEY = \"ndarray.order\";\n-    public final static String NDARRAY_FACTORY_CLASS = \"ndarrayfactory.class\";\n-    public final static String SPARSE_NDARRAY_FACTORY_CLASS = \"sparsendarrayfactory.class\";\n-    public final static String OP_EXECUTIONER = \"opexec\";\n-    public final static String OP_FACTORY = \"opfactory\";\n+    private final static String ORDER_KEY = \"ndarray.order\";\n+    private final static String NDARRAY_FACTORY_CLASS = \"ndarrayfactory.class\";\n+    private final static String SPARSE_NDARRAY_FACTORY_CLASS = \"sparsendarrayfactory.class\";\n+    private final static String OP_EXECUTIONER = \"opexec\";\n+\n     public final static String DISTRIBUTION = \"dist\";\n-    public final static String SHAPEINFO_PROVIDER = \"shapeinfoprovider\";\n-    public final static String SPARSEINFO_PROVIDER = \"sparseinfoprovider\";\n-    public final static String CONSTANT_PROVIDER = \"constantsprovider\";\n-    public final static String AFFINITY_MANAGER = \"affinitymanager\";\n+    private final static String SHAPEINFO_PROVIDER = \"shapeinfoprovider\";\n+    private final static String SPARSEINFO_PROVIDER = \"sparseinfoprovider\";\n+    private final static String CONSTANT_PROVIDER = \"constantsprovider\";\n+    private final static String AFFINITY_MANAGER = \"affinitymanager\";\n     //disable toString() on compressed arrays for debugging. Should be off by default.\n-    public final static String COMPRESSION_DEBUG = \"compressiondebug\";\n-    public final static String MEMORY_MANAGER = \"memorymanager\";\n-    public final static String WORKSPACE_MANAGER = \"workspacemanager\";\n-    public final static String RANDOM_PROVIDER = \"random\";\n+    private final static String COMPRESSION_DEBUG = \"compressiondebug\";\n+    private final static String MEMORY_MANAGER = \"memorymanager\";\n+    private final static String WORKSPACE_MANAGER = \"workspacemanager\";\n+    private final static String RANDOM_PROVIDER = \"random\";\n     /**@deprecated Use {@link ND4JSystemProperties#LOG_INITIALIZATION}*/\n     @Deprecated\n     public static final String LOG_INIT_ENV_PROPERTY = ND4JSystemProperties.LOG_INITIALIZATION;\n \n     //the datatype used for allocating buffers\n     protected static DataType dtype = DataType.FLOAT;\n     //the allocation mode for the heap\n-    public static DataBuffer.AllocationMode alloc = DataBuffer.AllocationMode.HEAP;\n-    public static char ORDER = 'c';\n+    public static DataBuffer.AllocationMode alloc = DataBuffer.AllocationMode.MIXED_DATA_TYPES;\n     public static double EPS_THRESHOLD = 1e-5;\n     private static boolean allowsOrder = false;\n     public static boolean compressDebug = false;\n@@ -157,45 +154,27 @@ public class Nd4j {\n     private static final AtomicInteger numThreads = new AtomicInteger(-1);\n     private static AtomicReference<DataType> defaultFloatingPointDataType;\n \n-    protected static Class<? extends MemoryWorkspaceManager> workspaceManagerClazz;\n-    protected static Class<? extends BlasWrapper> blasWrapperClazz;\n-    protected static Class<? extends BlasWrapper> sparseBlasWrapperClazz;\n-    protected static Class<? extends NDArrayFactory> ndArrayFactoryClazz;\n-    protected static Class<? extends NDArrayFactory> sparseNDArrayClazz;\n-    protected static Class<? extends ConvolutionInstance> convolutionInstanceClazz;\n-    protected static Class<? extends DataBufferFactory> dataBufferFactoryClazz;\n-    protected static Class<? extends OpExecutioner> opExecutionerClazz;\n-    protected static Class<? extends org.nd4j.linalg.api.rng.Random> randomClazz;\n-    protected static Class<? extends DistributionFactory> distributionFactoryClazz;\n-    protected static Class<? extends BaseShapeInfoProvider> shapeInfoProviderClazz;\n-    protected static Class<? extends BaseSparseInfoProvider> sparseInfoProviderClazz;\n-    protected static Class<? extends BasicConstantHandler> constantProviderClazz;\n-    protected static Class<? extends BasicAffinityManager> affinityManagerClazz;\n-    protected static Class<? extends BasicMemoryManager> memoryManagerClazz;\n-\n-    protected static DataBufferFactory DATA_BUFFER_FACTORY_INSTANCE;\n-    protected static BlasWrapper BLAS_WRAPPER_INSTANCE;\n-    protected static BlasWrapper SPARSE_BLAS_WRAPPER_INSTANCE;\n+    private static DataBufferFactory DATA_BUFFER_FACTORY_INSTANCE;\n+    private static BlasWrapper BLAS_WRAPPER_INSTANCE;\n+    private static BlasWrapper SPARSE_BLAS_WRAPPER_INSTANCE;\n     protected static NDArrayFactory INSTANCE;\n-    protected static NDArrayFactory SPARSE_INSTANCE;\n-    protected static ConvolutionInstance CONVOLUTION_INSTANCE;\n-    protected static OpExecutioner OP_EXECUTIONER_INSTANCE;\n-    protected static DistributionFactory DISTRIBUTION_FACTORY;\n-    protected static ShapeInfoProvider shapeInfoProvider;\n-    protected static SparseInfoProvider sparseInfoProvider;\n-    protected static ConstantHandler constantHandler;\n-    protected static AffinityManager affinityManager;\n-    protected static MemoryManager memoryManager;\n-\n-    protected static AtomicBoolean fallbackMode;\n+    private static NDArrayFactory SPARSE_INSTANCE;\n+    private static ConvolutionInstance CONVOLUTION_INSTANCE;\n+    private static OpExecutioner OP_EXECUTIONER_INSTANCE;\n+    private static DistributionFactory DISTRIBUTION_FACTORY;\n+    private static ShapeInfoProvider shapeInfoProvider;\n+    private static SparseInfoProvider sparseInfoProvider;\n+    private static ConstantHandler constantHandler;\n+    private static AffinityManager affinityManager;\n+    private static MemoryManager memoryManager;\n+\n+    private static AtomicBoolean fallbackMode;\n \n     protected static Properties props = new Properties();\n-    protected static ReferenceQueue<INDArray> referenceQueue = new ReferenceQueue<>();\n-    protected static ReferenceQueue<DataBuffer> bufferQueue = new ReferenceQueue<>();\n \n     private final static Logger logger = Logger.getLogger(Nd4j.class.getName());\n \n-    protected static final INDArray[] EMPTY_ARRAYS = new INDArray[DataType.values().length];\n+    private static final INDArray[] EMPTY_ARRAYS = new INDArray[DataType.values().length];\n \n     static {\n         fallbackMode = new AtomicBoolean(false);\n@@ -385,7 +364,6 @@ public static boolean allowsSpecifyOrdering() {\n      * @param toShuffle the ndarray to shuffle\n      * @param random the random to use\n      * @param dimension the dimension to do the shuffle\n-     * @return\n      */\n     public static void shuffle(INDArray toShuffle, Random random, @NonNull int... dimension) {\n         INSTANCE.shuffle(toShuffle, random, dimension);\n@@ -396,10 +374,8 @@ public static void shuffle(INDArray toShuffle, Random random, @NonNull int... di\n      * along a specified set of dimensions\n      * @param toShuffle the ndarray to shuffle\n      * @param dimension the dimension to do the shuffle\n-     * @return\n      */\n     public static void shuffle(INDArray toShuffle, @NonNull int... dimension) {\n-        //shuffle(toShuffle, new Random(), dimension);\n         INSTANCE.shuffle(toShuffle, new Random(), dimension);\n     }\n \n@@ -408,10 +384,8 @@ public static void shuffle(INDArray toShuffle, @NonNull int... dimension) {\n      * along a specified set of dimensions\n      * @param toShuffle the ndarray to shuffle\n      * @param dimension the dimension to do the shuffle\n-     * @return\n      */\n     public static void shuffle(Collection<INDArray> toShuffle, @NonNull int... dimension) {\n-        //shuffle(toShuffle, new Random(), dimension);\n         INSTANCE.shuffle(toShuffle, new Random(), dimension);\n     }\n \n@@ -420,10 +394,8 @@ public static void shuffle(Collection<INDArray> toShuffle, @NonNull int... dimen\n      * along a specified set of dimensions\n      * @param toShuffle the ndarray to shuffle\n      * @param dimension the dimension to do the shuffle\n-     * @return\n      */\n     public static void shuffle(Collection<INDArray> toShuffle, Random rnd, @NonNull int... dimension) {\n-        //shuffle(toShuffle, new Random(), dimension);\n         INSTANCE.shuffle(toShuffle, rnd, dimension);\n     }\n \n@@ -433,33 +405,11 @@ public static void shuffle(Collection<INDArray> toShuffle, Random rnd, @NonNull\n      *\n      * @param toShuffle the ndarray to shuffle\n      * @param dimensions the dimension to do the shuffle. Please note - order matters here.\n-     * @return\n      */\n     public static void shuffle(List<INDArray> toShuffle, Random rnd, List<int[]> dimensions) {\n-\n         INSTANCE.shuffle(toShuffle, rnd, dimensions);\n     }\n \n-    /**\n-     * The reference queue used for cleaning up\n-     * ndarrays\n-     *\n-     * @return the reference queue for cleaning up ndarrays\n-     */\n-    public static ReferenceQueue<INDArray> refQueue() {\n-        return referenceQueue;\n-    }\n-\n-    /**\n-     * The reference queue used for cleaning up\n-     * databuffers\n-     *\n-     * @return the reference queue for cleaning up databuffers\n-     */\n-    public static ReferenceQueue<DataBuffer> bufferRefQueue() {\n-        return bufferQueue;\n-    }\n-\n     /**\n      * Get the primary distributions\n      * factory\n@@ -480,9 +430,9 @@ public static org.nd4j.linalg.api.rng.Random getRandom() {\n     }\n \n     /**\n-     * This method returns RandomFactory instance\n+     * Get the  RandomFactory instance\n      *\n-     * @return\n+     * @return the  RandomFactory instance\n      */\n     public static RandomFactory getRandomFactory() {\n         return randomFactory;\n@@ -500,7 +450,7 @@ public static ConvolutionInstance getConvolution() {\n     /**\n      * Set a convolution instance\n      *\n-     * @param convolutionInstance\n+     * @param convolutionInstance the new convolution instance\n      */\n     public static void setConvolution(ConvolutionInstance convolutionInstance) {\n         if (convolutionInstance == null)\n@@ -526,7 +476,6 @@ public static long[] shape(INDArray arr) {\n      * slice is the specified shape\n      */\n     public static INDArray create(int[] sliceShape, float[]... arrays) {\n-        //TODO: Remove duplicate code.\n         int slices = arrays.length;\n         INDArray ret = Nd4j.createUninitialized(DataType.FLOAT, ArrayUtil.toLongArray(ArrayUtil.combine(new int[] {slices}, sliceShape)));\n         for (int i = 0; i < ret.slices(); i++)\n@@ -586,30 +535,6 @@ public static DataBufferFactory getDataBufferFactory() {\n         return DATA_BUFFER_FACTORY_INSTANCE;\n     }\n \n-    /**\n-     * Given a sequence of Iterators over a transform of matrices, fill in all of\n-     * the matrices with the entries in the theta vector.  Errors are\n-     * thrown if the theta vector does not exactly fill the matrices.\n-     *\n-     * TODO: unused method.\n-     */\n-    public static void setParams(INDArray theta, Collection<INDArray>... matrices) {\n-        int index = 0;\n-        for (Collection<INDArray> matrixCollection : matrices) {\n-            for (INDArray matrix : matrixCollection) {\n-                INDArray linear = matrix.reshape(-1);\n-                for (int i = 0; i < matrix.length(); i++) {\n-                    linear.putScalar(i, theta.getDouble(index));\n-                    index++;\n-                }\n-            }\n-        }\n-\n-        if (index != theta.length()) {\n-            throw new AssertionError(\"Did not entirely use the theta vector\");\n-        }\n-    }\n-\n     /**\n      *  Roll the specified axis backwards,\n      *  until it lies in a given position.\n@@ -681,7 +606,7 @@ public static INDArray rollAxis(INDArray a, int axis, int start) {\n      * @param b the  right tensor\n      * @param result the result array\n      * @param axes the axes for each array to do matrix multiply along\n-     * @return\n+     * @return the result array\n      */\n     public static INDArray tensorMmul(INDArray a, INDArray b,INDArray result, int[][] axes) {\n         int validationLength = Math.min(axes[0].length, axes[1].length);\n@@ -720,15 +645,7 @@ public static INDArray tensorMmul(INDArray a, INDArray b,INDArray result, int[][\n         //if listA and listB are empty these donot initialize.\n         //so initializing with {1} which will then get overriden if not empty\n         long[] newShapeA = {-1, n2};\n-        //TODO: remove duplicate code.\n-        long[] oldShapeA;\n-        if (listA.size() == 0) {\n-            oldShapeA = new long[] {1};\n-        } else {\n-            oldShapeA = Longs.toArray(listA);\n-            for (int i = 0; i < oldShapeA.length; i++)\n-                oldShapeA[i] = a.size((int) oldShapeA[i]);\n-        }\n+        long[] oldShapeA = getOldShape(listA, a);\n \n         int n3 = 1;\n         int bNax = Math.min(b.rank(), axes[1].length);\n@@ -737,14 +654,7 @@ public static INDArray tensorMmul(INDArray a, INDArray b,INDArray result, int[][\n         }\n \n         long[] newShapeB = {n3, -1};\n-        long[] oldShapeB;\n-        if (listB.size() == 0) {\n-            oldShapeB = new long[] {1};\n-        } else {\n-            oldShapeB = Longs.toArray(listB);\n-            for (int i = 0; i < oldShapeB.length; i++)\n-                oldShapeB[i] = b.size((int) oldShapeB[i]);\n-        }\n+        long[] oldShapeB = getOldShape(listB, b);\n \n         INDArray at = a.permute(newAxesA).reshape(newShapeA);\n         INDArray bt = b.permute(newAxesB).reshape(newShapeB);\n@@ -754,14 +664,27 @@ public static INDArray tensorMmul(INDArray a, INDArray b,INDArray result, int[][\n         return ret.reshape(aPlusB);\n     }\n \n+    // Some duplicate code that refactored out:\n+    private static long[] getOldShape(List<Integer> list, INDArray x){\n+        long[] res;\n+        if (list.size() == 0) {\n+            res = new long[] {1};\n+        } else {\n+            res= Longs.toArray(list);\n+            for (int i = 0; i < res.length; i++)\n+                res[i] = x.size((int) res[i]);\n+        }\n+        return res;\n+    }\n+\n     /**\n      * Tensor matrix multiplication.\n      * Both tensors must be the same rank\n      *\n      * @param a the left tensor\n      * @param b the  right tensor\n      * @param axes the axes for each array to do matrix multiply along\n-     * @return\n+     * @return the multiplication result.\n      */\n     public static INDArray tensorMmul(INDArray a, INDArray b, int[][] axes) {\n         CustomOp op = DynamicCustomOp.builder(\"tensordot\")\n@@ -892,29 +815,6 @@ public static INDArray matmul(INDArray a, INDArray b){\n         return matmul(a,b, null);\n     }\n \n-    /**\n-     * Given a sequence of Iterators over a transform of matrices, fill in all of\n-     * the matrices with the entries in the theta vector.  Errors are\n-     * thrown if the theta vector does not exactly fill the matrices.\n-     * TODO: unused method.\n-     */\n-    public static void setParams(INDArray theta, Iterator<? extends INDArray>... matrices) {\n-        int index = 0;\n-        for (Iterator<? extends INDArray> matrixIterator : matrices) {\n-            while (matrixIterator.hasNext()) {\n-                INDArray matrix = matrixIterator.next().reshape(-1);\n-                for (int i = 0; i < matrix.length(); i++) {\n-                    matrix.putScalar(i, theta.getDouble(index));\n-                    index++;\n-                }\n-            }\n-        }\n-\n-        if (index != theta.length()) {\n-            throw new AssertionError(\"Did not entirely use the theta vector\");\n-        }\n-    }\n-\n     /**\n      * The factory used for creating ndarrays\n      *\n@@ -5766,45 +5666,45 @@ public void initWithBackend(Nd4jBackend backend) {\n             }\n \n             compressDebug = pp.toBoolean(COMPRESSION_DEBUG);\n-            ORDER = pp.toChar(ORDER_KEY, NDArrayFactory.C);\n+            char ORDER = pp.toChar(ORDER_KEY, NDArrayFactory.C);\n \n-            affinityManagerClazz = (Class<? extends BasicAffinityManager>) Class\n+            Class<? extends BasicAffinityManager> affinityManagerClazz = (Class<? extends BasicAffinityManager>) Class\n                     .forName(pp.toString(AFFINITY_MANAGER));\n             affinityManager = affinityManagerClazz.newInstance();\n-            ndArrayFactoryClazz = (Class<? extends NDArrayFactory>) Class.forName(\n+            Class<? extends NDArrayFactory> ndArrayFactoryClazz = (Class<? extends NDArrayFactory>) Class.forName(\n                     pp.toString(NDARRAY_FACTORY_CLASS));\n-            sparseNDArrayClazz = (Class<? extends NDArrayFactory>) Class.forName(\n+            Class<? extends NDArrayFactory> sparseNDArrayClazz = (Class<? extends NDArrayFactory>) Class.forName(\n                     pp.toString(SPARSE_NDARRAY_FACTORY_CLASS));\n-            convolutionInstanceClazz = (Class<? extends ConvolutionInstance>) Class\n+            Class<? extends ConvolutionInstance> convolutionInstanceClazz = (Class<? extends ConvolutionInstance>) Class\n                     .forName(pp.toString(CONVOLUTION_OPS, DefaultConvolutionInstance.class.getName()));\n             String defaultName = pp.toString(DATA_BUFFER_OPS, DefaultDataBufferFactory.class.getName());\n-            dataBufferFactoryClazz = (Class<? extends DataBufferFactory>) Class\n+            Class<? extends DataBufferFactory> dataBufferFactoryClazz = (Class<? extends DataBufferFactory>) Class\n                     .forName(pp.toString(DATA_BUFFER_OPS, defaultName));\n-            shapeInfoProviderClazz = (Class<? extends BaseShapeInfoProvider>) Class\n+            Class<? extends BaseShapeInfoProvider> shapeInfoProviderClazz = (Class<? extends BaseShapeInfoProvider>) Class\n                     .forName(pp.toString(SHAPEINFO_PROVIDER));\n-            sparseInfoProviderClazz = (Class<? extends BaseSparseInfoProvider>) Class.forName(\n+            Class<? extends BaseSparseInfoProvider> sparseInfoProviderClazz = (Class<? extends BaseSparseInfoProvider>) Class.forName(\n                     pp.toString(SPARSEINFO_PROVIDER));\n \n-            constantProviderClazz = (Class<? extends BasicConstantHandler>) Class\n+            Class<? extends BasicConstantHandler> constantProviderClazz = (Class<? extends BasicConstantHandler>) Class\n                     .forName(pp.toString(CONSTANT_PROVIDER));\n \n-            memoryManagerClazz = (Class<? extends BasicMemoryManager>) Class\n+            Class<? extends BasicMemoryManager> memoryManagerClazz = (Class<? extends BasicMemoryManager>) Class\n                     .forName(pp.toString(MEMORY_MANAGER));\n \n             allowsOrder = backend.allowsOrder();\n             String rand = pp.toString(RANDOM_PROVIDER, DefaultRandom.class.getName());\n-            randomClazz = (Class<? extends org.nd4j.linalg.api.rng.Random>) Class.forName(rand);\n+            Class<? extends org.nd4j.linalg.api.rng.Random> randomClazz = (Class<? extends org.nd4j.linalg.api.rng.Random>) Class.forName(rand);\n             randomFactory = new RandomFactory(randomClazz);\n \n-            workspaceManagerClazz = (Class<? extends MemoryWorkspaceManager>) Class\n+            Class<? extends MemoryWorkspaceManager> workspaceManagerClazz = (Class<? extends MemoryWorkspaceManager>) Class\n                     .forName(pp.toString(WORKSPACE_MANAGER));\n \n-            blasWrapperClazz = (Class<? extends BlasWrapper>) Class\n+            Class<? extends BlasWrapper> blasWrapperClazz = (Class<? extends BlasWrapper>) Class\n                     .forName(pp.toString(BLAS_OPS));\n-            sparseBlasWrapperClazz = (Class<? extends BlasWrapper>) Class\n+            Class<? extends BlasWrapper> sparseBlasWrapperClazz = (Class<? extends BlasWrapper>) Class\n                     .forName(pp.toString(SPARSE_BLAS_OPS));\n             String clazzName = pp.toString(DISTRIBUTION, DefaultDistributionFactory.class.getName());\n-            distributionFactoryClazz = (Class<? extends DistributionFactory>) Class.forName(clazzName);\n+            Class<? extends DistributionFactory> distributionFactoryClazz = (Class<? extends DistributionFactory>) Class.forName(clazzName);\n \n \n             memoryManager = memoryManagerClazz.newInstance();\n@@ -5813,7 +5713,7 @@ public void initWithBackend(Nd4jBackend backend) {\n             sparseInfoProvider = sparseInfoProviderClazz.newInstance();\n             workspaceManager = workspaceManagerClazz.newInstance();\n \n-            opExecutionerClazz = (Class<? extends OpExecutioner>) Class\n+            Class<? extends OpExecutioner> opExecutionerClazz = (Class<? extends OpExecutioner>) Class\n                     .forName(pp.toString(OP_EXECUTIONER, DefaultOpExecutioner.class.getName()));\n \n             OP_EXECUTIONER_INSTANCE = opExecutionerClazz.newInstance();",
      "parent_sha": "b8846113bdc522c836bb7fedf3138ebbc270d1bc"
    }
  },
  {
    "oid": "a6ca87dce61b4403e8ffd654df29404c31083123",
    "message": "one deprecated method\n\nSigned-off-by: raver119@gmail.com <raver119@gmail.com>",
    "date": "2020-04-30T08:22:25Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/a6ca87dce61b4403e8ffd654df29404c31083123",
    "details": {
      "sha": "545c858060adcfd0741f11ca19889c14e7202e20",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/util/NDArrayUtil.java",
      "status": "modified",
      "additions": 8,
      "deletions": 1,
      "changes": 9,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/a6ca87dce61b4403e8ffd654df29404c31083123/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Futil%2FNDArrayUtil.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/a6ca87dce61b4403e8ffd654df29404c31083123/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Futil%2FNDArrayUtil.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Futil%2FNDArrayUtil.java?ref=a6ca87dce61b4403e8ffd654df29404c31083123",
      "patch": "@@ -24,11 +24,15 @@\n \n /**\n  * Created by agibsonccc on 2/26/16.\n+ *\n+ * This class is deprecated. Please use Nd4j.createFromArray(...) methods instead\n  */\n+@Deprecated\n public class NDArrayUtil {\n \n     private NDArrayUtil() {}\n \n+    @Deprecated\n     public static INDArray toNDArray(int[][] nums) {\n         if (Nd4j.dataType() == DataType.DOUBLE) {\n             double[] doubles = ArrayUtil.toDoubles(nums);\n@@ -42,6 +46,7 @@ public static INDArray toNDArray(int[][] nums) {\n \n     }\n \n+    @Deprecated\n     public static INDArray toNDArray(int[] nums) {\n         if (Nd4j.dataType() == DataType.DOUBLE) {\n             double[] doubles = ArrayUtil.toDoubles(nums);\n@@ -54,6 +59,7 @@ public static INDArray toNDArray(int[] nums) {\n         }\n     }\n \n+    @Deprecated\n     public static INDArray toNDArray(long[] nums) {\n         if (Nd4j.dataType() == DataType.DOUBLE) {\n             double[] doubles = ArrayUtil.toDoubles(nums);\n@@ -66,7 +72,7 @@ public static INDArray toNDArray(long[] nums) {\n         }\n     }\n \n-\n+    @Deprecated\n     public static int[] toInts(INDArray n) {\n         if (n.length() > Integer.MAX_VALUE)\n             throw new ND4JIllegalStateException(\"Can't convert INDArray with length > Integer.MAX_VALUE\");\n@@ -78,6 +84,7 @@ public static int[] toInts(INDArray n) {\n         return ret;\n     }\n \n+    @Deprecated\n     public static long[] toLongs(INDArray n) {\n         if (n.length() > Integer.MAX_VALUE)\n             throw new ND4JIllegalStateException(\"Can't convert INDArray with length > Integer.MAX_VALUE\");",
      "parent_sha": "cdea8be63adf73d6e03b0b345491e7c49ad02aa9"
    }
  },
  {
    "oid": "0ef373fe454a804c8a69571d93052badddd9d69a",
    "message": "Nd4j.java javadoc  (#7997)\n\n* up to line 500.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 1120.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n*  up to 1286.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 2400.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n*  up to line 2500.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 3600.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n*  up to line 4000.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 4500.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 5000.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>\r\n\r\n* up to line 6000.\r\n\r\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-07-20T02:05:46Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/0ef373fe454a804c8a69571d93052badddd9d69a",
    "details": {
      "sha": "22bf1d84067e0f1155a1df2f2b1761e32299c4a0",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 903,
      "deletions": 529,
      "changes": 1432,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/0ef373fe454a804c8a69571d93052badddd9d69a/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/0ef373fe454a804c8a69571d93052badddd9d69a/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=0ef373fe454a804c8a69571d93052badddd9d69a",
      "parent_sha": "ee6aae268f642daf00a85b1a276dad63a2e6e7d7"
    }
  },
  {
    "oid": "13cae7fb60283966b45e126c4564c86b3e34ab53",
    "message": "Update LabelGeneratorTest.java",
    "date": "2021-03-18T02:40:33Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/13cae7fb60283966b45e126c4564c86b3e34ab53",
    "details": {
      "sha": "ced14a25ee1d482222ec9fbbde645bbce5c5e041",
      "filename": "datavec/datavec-data/datavec-data-image/src/test/java/org/datavec/image/LabelGeneratorTest.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/13cae7fb60283966b45e126c4564c86b3e34ab53/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Ftest%2Fjava%2Forg%2Fdatavec%2Fimage%2FLabelGeneratorTest.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/13cae7fb60283966b45e126c4564c86b3e34ab53/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Ftest%2Fjava%2Forg%2Fdatavec%2Fimage%2FLabelGeneratorTest.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/datavec%2Fdatavec-data%2Fdatavec-data-image%2Fsrc%2Ftest%2Fjava%2Forg%2Fdatavec%2Fimage%2FLabelGeneratorTest.java?ref=13cae7fb60283966b45e126c4564c86b3e34ab53",
      "patch": "@@ -24,6 +24,7 @@\n import org.datavec.api.split.FileSplit;\n import org.datavec.image.recordreader.ImageRecordReader;\n \n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n import org.junit.jupiter.api.io.TempDir;\n import org.nd4j.common.io.ClassPathResource;\n@@ -39,11 +40,10 @@\n @DisplayName(\"Label Generator Test\")\n class LabelGeneratorTest {\n \n-    @TempDir\n-    public Path testDir;\n \n     @Test\n     @DisplayName(\"Test Parent Path Label Generator\")\n+    @Disabled\n     void testParentPathLabelGenerator(@TempDir Path testDir) throws Exception {\n         File orig = new ClassPathResource(\"datavec-data-image/testimages/class0/0.jpg\").getFile();\n         for (String dirPrefix : new String[] { \"m.\", \"m\" }) {",
      "parent_sha": "b403157be0ccb2529414a43847222cdf28aff24d"
    }
  },
  {
    "oid": "8332a2b4cb022e1cce9288d765096a22d49b5cc1",
    "message": "Update Nd4jAuroraOps.java",
    "date": "2021-11-29T00:43:04Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/8332a2b4cb022e1cce9288d765096a22d49b5cc1",
    "details": {
      "sha": "36fe1daee277188b0e81389611fb0f9809d840ef",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-aurora/src/main/java/org/nd4j/nativeblas/Nd4jAuroraOps.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/8332a2b4cb022e1cce9288d765096a22d49b5cc1/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/8332a2b4cb022e1cce9288d765096a22d49b5cc1/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Fnativeblas%2FNd4jAuroraOps.java?ref=8332a2b4cb022e1cce9288d765096a22d49b5cc1",
      "patch": "@@ -581,7 +581,7 @@ public void setOmpMinThreads(int arg0) {\n \n     @Override\n     public void initializeDevicesAndFunctions() {\n-       // call(\"initializeDevicesAndFunctions\");\n+        call(\"initializeDevicesAndFunctions\");\n     }\n \n     @Override",
      "parent_sha": "1d3d128d27a63e104c4285d63d0f72f1c74b06d9"
    }
  },
  {
    "oid": "196af9478ab9eac094b90cd03147b0630fbc4234",
    "message": "Fix  op context info with null/empty arrays (#9923)\n\n* Update OS for CI (github actions deprecation)\n\n* Fix op context info tracking with null/empty arrays\n\n* Fix op context info tracking with null/empty arrays\nSeparate ubuntu ci fix",
    "date": "2023-02-22T07:55:45Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/196af9478ab9eac094b90cd03147b0630fbc4234",
    "details": {
      "sha": "9cfa1a72134b9889a01ee1253404dd50a5a190e6",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/profiler/data/OpContextInfo.java",
      "status": "modified",
      "additions": 13,
      "deletions": 2,
      "changes": 15,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/196af9478ab9eac094b90cd03147b0630fbc4234/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fprofiler%2Fdata%2FOpContextInfo.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/196af9478ab9eac094b90cd03147b0630fbc4234/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fprofiler%2Fdata%2FOpContextInfo.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fprofiler%2Fdata%2FOpContextInfo.java?ref=196af9478ab9eac094b90cd03147b0630fbc4234",
      "patch": "@@ -73,14 +73,25 @@ public void purge() {\n \n \n     public void addOutput(INDArray input,boolean createdByOutput) {\n+       if(input == null)\n+           return;\n         addOutputType(input.dataType());\n         outputCreatedByCtx.add(createdByOutput);\n-        addOutputByteWidth(input.data().length() * input.data().dataType().width());\n+        if(!input.isEmpty())\n+            addOutputByteWidth(input.data().length() * input.data().dataType().width());\n+\n+        else  addOutputByteWidth(0L);\n+\n     }\n \n     public void addInput(INDArray input) {\n+      if(input == null)\n+          return;\n         addInputType(input.dataType());\n-        addInputByteWidth(input.data().length() * input.data().dataType().width());\n+        if(!input.isEmpty())\n+            addInputByteWidth(input.data().length() * input.data().dataType().width());\n+        else  addInputByteWidth(0L);\n+\n     }\n \n     public void addInputType(DataType input) {",
      "parent_sha": "b7184956d4bf81e13f495e3b6c86f3f29dfd5825"
    }
  },
  {
    "oid": "67a5761cb0a1c098c61695dc349b50fae16af67e",
    "message": "Add deallocator service fix removal (#9929)\n\n* Add deallocator service fix removal\r\n\r\n* Add Nd4j.close(...) to cbow to mirror skipgram\r\n\r\n* Fix reference removal",
    "date": "2023-03-09T09:14:09Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/67a5761cb0a1c098c61695dc349b50fae16af67e",
    "details": {
      "sha": "449691a38ef11172b20760ebb630b5651de96781",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/memory/deallocation/DeallocatorService.java",
      "status": "modified",
      "additions": 13,
      "deletions": 11,
      "changes": 24,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/67a5761cb0a1c098c61695dc349b50fae16af67e/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fdeallocation%2FDeallocatorService.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/67a5761cb0a1c098c61695dc349b50fae16af67e/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fdeallocation%2FDeallocatorService.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Fapi%2Fmemory%2Fdeallocation%2FDeallocatorService.java?ref=67a5761cb0a1c098c61695dc349b50fae16af67e",
      "patch": "@@ -143,8 +143,9 @@ public long pickObject(@NonNull Deallocatable deallocatable) {\n             val desiredDevice = deallocatable.targetDevice();\n             val map = deviceMap.get(desiredDevice);\n             val reference = new DeallocatableReference(deallocatable, map.get(RandomUtils.nextInt(0, map.size())));\n-            if(referenceMap.containsKey(deallocatable.getUniqueId()))\n-                throw new IllegalArgumentException(\"Duplicate deallocatable key found!\");\n+            if(referenceMap.containsKey(deallocatable)) {\n+                return -1;\n+            }\n             referenceMap.put(deallocatable, reference);\n             return deallocatable.getUniqueId();\n         }\n@@ -174,9 +175,9 @@ public void run() {\n             boolean canRun = true;\n             while (canRun) {\n                 // if periodicGc is enabled, only first thread will call for it\n-                if (Nd4j.getMemoryManager().isPeriodicGcActive() && threadIdx == 0 && Nd4j.getMemoryManager().getAutoGcWindow() > 0) {\n+                if (threadIdx == 0 && Nd4j.getMemoryManager().getAutoGcWindow() > 0) {\n                     val reference = (DeallocatableReference) queue.poll();\n-                    if (reference == null || (reference != null && reference.get() != null &&  !reference.get().shouldDeAllocate()) || !reference.getDeallocator().isConstant()) {\n+                    if (reference == null || (reference != null || !reference.getDeallocator().isConstant())) {\n                         val timeout = Nd4j.getMemoryManager().getAutoGcWindow();\n                         try {\n                             Thread.sleep(timeout);\n@@ -186,26 +187,27 @@ public void run() {\n                         }\n                     } else {\n                         // invoking deallocator\n-                        if (reference != null && (reference.get().shouldDeAllocate()) || reference.getDeallocator().isConstant()) {\n+                        if (reference != null   || reference.getDeallocator().isConstant()) {\n                             reference.deallocate();\n-                            referenceMap.remove(reference.getId());\n+                            if(reference.get() != null)\n+                                referenceMap.remove(reference.get());\n                         } else {\n-                            referenceMap.remove(reference.getId());\n+                            if(reference.get() != null)\n+                                referenceMap.remove(reference.get());\n                         }\n                     }\n                 } else {\n                     try {\n                         val reference = (DeallocatableReference) queue.remove();\n-                        if (reference == null)\n+                        if (reference == null || reference.getDeallocator().isConstant())\n                             continue;\n \n-                        if( (reference.get() != null && !reference.get().shouldDeAllocate()) || reference.getDeallocator().isConstant())\n-                            continue;\n \n \n                         // invoking deallocator\n                         reference.deallocate();\n-                        referenceMap.remove(reference.getId());\n+                        if(reference.get() != null)\n+                            referenceMap.remove(reference.get());\n                     } catch (InterruptedException e) {\n                         canRun = false;\n                     } catch (Exception e) {",
      "parent_sha": "8d4bd70909b73f7cf828723e8faa002b9adcbe8a"
    }
  },
  {
    "oid": "0527ab8d9827db0d267623a3c666621f68244900",
    "message": "Fix validation (#8059)\n\nSigned-off-by: AlexDBlack <blacka101@gmail.com>",
    "date": "2019-07-29T05:26:18Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/0527ab8d9827db0d267623a3c666621f68244900",
    "details": {
      "sha": "bda0f9c95266969731912b82262a94d9ab6b35eb",
      "filename": "deeplearning4j/deeplearning4j-data/deeplearning4j-datavec-iterators/src/main/java/org/deeplearning4j/datasets/datavec/RecordReaderDataSetIterator.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/0527ab8d9827db0d267623a3c666621f68244900/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datavec-iterators%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Fdatavec%2FRecordReaderDataSetIterator.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/0527ab8d9827db0d267623a3c666621f68244900/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datavec-iterators%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Fdatavec%2FRecordReaderDataSetIterator.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-data%2Fdeeplearning4j-datavec-iterators%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fdatasets%2Fdatavec%2FRecordReaderDataSetIterator.java?ref=0527ab8d9827db0d267623a3c666621f68244900",
      "patch": "@@ -160,12 +160,12 @@ public RecordReaderDataSetIterator(RecordReader recordReader, int batchSize, int\n      */\n     public RecordReaderDataSetIterator(RecordReader recordReader, int batchSize, int labelIndexFrom, int labelIndexTo,\n                                        boolean regression) {\n-        if (!regression) { \n+\t\tthis(recordReader, new SelfWritableConverter(), batchSize, labelIndexFrom, labelIndexTo, -1, -1, regression);\n+\t\tif (!regression) { \n             throw new IllegalArgumentException(\"This constructor is only for creating regression iterators. \" +\n                                                \"If you're doing classification you need to use another constructor that \" + \n                                                \"(implicitly) specifies numPossibleLabels\");\n         }\n-        this(recordReader, new SelfWritableConverter(), batchSize, labelIndexFrom, labelIndexTo, -1, -1, regression);\n     }\n \n ",
      "parent_sha": "87d2b2cd3d118e560b12400d1d856ab8218005dd"
    }
  },
  {
    "oid": "ce9c37297457ed18e018fa6996e1cc2c7463a243",
    "message": "fix pad javadoc and @see links. (#72)\n\nSigned-off-by: Robert Altena <Rob@Ra-ai.com>",
    "date": "2019-08-05T01:11:22Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/ce9c37297457ed18e018fa6996e1cc2c7463a243",
    "details": {
      "sha": "9840c0360891d25d5717ba5ec74d3fd969324652",
      "filename": "nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/factory/Nd4j.java",
      "status": "modified",
      "additions": 3,
      "deletions": 5,
      "changes": 8,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/ce9c37297457ed18e018fa6996e1cc2c7463a243/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/ce9c37297457ed18e018fa6996e1cc2c7463a243/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-api-parent%2Fnd4j-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Ffactory%2FNd4j.java?ref=ce9c37297457ed18e018fa6996e1cc2c7463a243",
      "patch": "@@ -209,7 +209,7 @@ public enum PadMode {\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], PadMode)\n+     * @see #pad(INDArray, int[][], List, PadMode) with zero padding. (zeros for constantValues).\n      */\n     public static INDArray pad(INDArray toPad, int[][] padWidth, PadMode padMode) {\n         return pad(toPad, padWidth, ArrayUtil.zerosMatrix(toPad.shape()), padMode);\n@@ -264,7 +264,7 @@ public static INDArray pad(INDArray toPad, int[][] padWidth, List<double[]> cons\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], PadMode)\n+     * @see #pad(INDArray, int[][], List, PadMode) with a 1D int[] for padWidth.\n      */\n     public static INDArray pad(INDArray toPad, int[] padWidth, List<double[]> constantValues, PadMode padMode) {\n         switch (padMode) {\n@@ -299,17 +299,15 @@ public static INDArray pad(INDArray toPad, int[] padWidth, List<double[]> consta\n                     ret = Nd4j.append(ret, padAfter, afterVal, i);\n \n                 }\n-\n                 return ret;\n \n             default:\n                 throw new UnsupportedOperationException();\n-\n         }\n     }\n \n     /**\n-     * @see #pad(INDArray, int[][], PadMode)\n+     * @see #pad(INDArray, int[][], List, PadMode) with a 1D int[] for padWidth and zero padding.\n      */\n     public static INDArray pad(INDArray toPad, int[] padWidth, PadMode padMode) {\n         return pad(toPad, padWidth, ArrayUtil.zerosMatrix(padWidth), padMode);",
      "parent_sha": "b083c22de51afc95e8815f75f080305d325363ab"
    }
  },
  {
    "oid": "15ab197947d002d5eb074ef4b5c807cfbb17e481",
    "message": "Update AuroraOpExecutioner.java",
    "date": "2021-11-30T12:51:16Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/15ab197947d002d5eb074ef4b5c807cfbb17e481",
    "details": {
      "sha": "632a6621392d7348ed26f1c8239b58e2756ccf6b",
      "filename": "nd4j/nd4j-backends/nd4j-backend-impls/nd4j-aurora/src/main/java/org/nd4j/linalg/aurora/ops/AuroraOpExecutioner.java",
      "status": "modified",
      "additions": 1,
      "deletions": 5,
      "changes": 6,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/15ab197947d002d5eb074ef4b5c807cfbb17e481/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Faurora%2Fops%2FAuroraOpExecutioner.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/15ab197947d002d5eb074ef4b5c807cfbb17e481/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Faurora%2Fops%2FAuroraOpExecutioner.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/nd4j%2Fnd4j-backends%2Fnd4j-backend-impls%2Fnd4j-aurora%2Fsrc%2Fmain%2Fjava%2Forg%2Fnd4j%2Flinalg%2Faurora%2Fops%2FAuroraOpExecutioner.java?ref=15ab197947d002d5eb074ef4b5c807cfbb17e481",
      "patch": "@@ -1929,12 +1929,8 @@ public INDArray[] exec(CustomOp op, @NonNull OpContext context) {\n             }\n */\n             val status = loop.execCustomOp2(null, op.opHash(), context.contextPointer());\n-\n-            if (loop.lastErrorCode() != 0)\n-                throw new RuntimeException(loop.lastErrorMessage());\n-\n             if (status != 0)\n-                throw new RuntimeException(\"Op [\" + op.opName() + \"] execution failed\");\n+                throw new RuntimeException(\"Op [\" + op.opName() + \"] \" +  \"execution failed with message \" + loop.lastErrorMessage());\n \n             if (context.getOutputArrays().isEmpty())\n                 return new INDArray[0];",
      "parent_sha": "ce7e9d2ca9a8912863a34f5b2a3cd8276a42e852"
    }
  },
  {
    "oid": "68aac13f974809e534e644470efdfa01182f56ee",
    "message": "Fix 1.0.0-M1 bug DL4JClassLoading of CuDNN\n\nhttps://github.com/eclipse/deeplearning4j/issues/9331",
    "date": "2021-05-30T17:47:17Z",
    "url": "https://github.com/deeplearning4j/deeplearning4j/commit/68aac13f974809e534e644470efdfa01182f56ee",
    "details": {
      "sha": "300e6aa44efc279fc72a63f8dbb0a84f29a59800",
      "filename": "deeplearning4j/deeplearning4j-common/src/main/java/org/deeplearning4j/common/config/DL4JClassLoading.java",
      "status": "modified",
      "additions": 7,
      "deletions": 2,
      "changes": 9,
      "blob_url": "https://github.com/deeplearning4j/deeplearning4j/blob/68aac13f974809e534e644470efdfa01182f56ee/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "raw_url": "https://github.com/deeplearning4j/deeplearning4j/raw/68aac13f974809e534e644470efdfa01182f56ee/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java",
      "contents_url": "https://api.github.com/repos/deeplearning4j/deeplearning4j/contents/deeplearning4j%2Fdeeplearning4j-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fdeeplearning4j%2Fcommon%2Fconfig%2FDL4JClassLoading.java?ref=68aac13f974809e534e644470efdfa01182f56ee",
      "patch": "@@ -70,8 +70,13 @@ public static <T> Class<T> loadClassByName(String className, boolean initialize,\n         }\n     }\n \n-    public static <T> T createNewInstance(String className, Object... args) {\n-        return createNewInstance(className, Object.class, args);\n+    public static <T> T createNewInstance(String className) {\n+        return createNewInstance(className, Object.class, null);//or new Object[0];\n+    }\n+    \n+    public static <T> T createNewInstance(String className, Object[] args) {\n+       \n+    \treturn createNewInstance(className, Object.class, args);\n     }\n \n     public static <T> T createNewInstance(String className, Class<? super T> superclass) {",
      "parent_sha": "e5d18d6a4767de337bd383564381fff053d557a0"
    }
  }
]