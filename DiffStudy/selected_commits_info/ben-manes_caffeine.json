[
  {
    "oid": "633ad80fcabb6f38e828000e20912809263cfb1c",
    "message": "Re-enable forkjoin pool as probably a memory overuse",
    "date": "2014-12-27T10:15:47Z",
    "url": "https://github.com/ben-manes/caffeine/commit/633ad80fcabb6f38e828000e20912809263cfb1c",
    "details": {
      "sha": "9d11fe48320e4e98c296259cffef41f817bd1552",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/testing/CacheSpec.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/633ad80fcabb6f38e828000e20912809263cfb1c/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/633ad80fcabb6f38e828000e20912809263cfb1c/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java?ref=633ad80fcabb6f38e828000e20912809263cfb1c",
      "patch": "@@ -214,7 +214,7 @@ enum Loader implements CacheLoader<Integer, Integer> {\n \n   /** The executors retrieved from a supplier, each resulting in a new combination. */\n   CacheExecutor[] executor() default {\n-//    CacheExecutor.DEFAULT,\n+    CacheExecutor.DEFAULT,\n     CacheExecutor.DIRECT,\n   };\n ",
      "parent_sha": "3ddc1dc4ac1e1dafe62904d6bc851275e43b9a4e"
    }
  },
  {
    "oid": "016d916d2f0104650cf7e95a5777c784d96bfd96",
    "message": "Don't bother testing eviction, as that allows misses. Just test hits",
    "date": "2014-12-30T09:46:48Z",
    "url": "https://github.com/ben-manes/caffeine/commit/016d916d2f0104650cf7e95a5777c784d96bfd96",
    "details": {
      "sha": "f342f80211a42e62690bd5238426d45bba0d5b5f",
      "filename": "src/jmh/java/com/github/benmanes/caffeine/cache/GetPutBenchmark.java",
      "status": "modified",
      "additions": 4,
      "deletions": 5,
      "changes": 9,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/016d916d2f0104650cf7e95a5777c784d96bfd96/src%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FGetPutBenchmark.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/016d916d2f0104650cf7e95a5777c784d96bfd96/src%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FGetPutBenchmark.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FGetPutBenchmark.java?ref=016d916d2f0104650cf7e95a5777c784d96bfd96",
      "patch": "@@ -34,7 +34,8 @@\n  */\n @State(Scope.Group)\n public class GetPutBenchmark {\n-  private static final int MASK = (2 << 14) - 1;\n+  private static final int SIZE = (2 << 14);\n+  private static final int MASK = SIZE;\n \n   @Param({\n     \"LinkedHashMap_Lru\",\n@@ -44,8 +45,6 @@ public class GetPutBenchmark {\n     \"Guava\",\n   })\n   CacheType cacheType;\n-  @Param(\"10000\")\n-  int sampleSize;\n \n   Map<Integer, Boolean> cache;\n   Integer[] ints;\n@@ -57,8 +56,8 @@ public static class ThreadState {\n \n   @Setup\n   public void setup() {\n-    cache = cacheType.create(5 * sampleSize, 16);\n-    for (int i = 0; i < sampleSize; i++) {\n+    cache = cacheType.create(2 * SIZE, 25);\n+    for (int i = 0; i < SIZE; i++) {\n       cache.put(i, Boolean.TRUE);\n     }\n ",
      "parent_sha": "6a2e8622f4f61140ac50131c4d37f88d442db6b2"
    }
  },
  {
    "oid": "44dc05a3f936c7f6eaa3d9f57d554faaf3dd6c53",
    "message": "Fix some mistakes in the documentation. (#1697)",
    "date": "2024-05-30T22:00:19Z",
    "url": "https://github.com/ben-manes/caffeine/commit/44dc05a3f936c7f6eaa3d9f57d554faaf3dd6c53",
    "details": {
      "sha": "aca9157caa8b0d39d069b740ba108f25ee8da652",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 11,
      "deletions": 11,
      "changes": 22,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/44dc05a3f936c7f6eaa3d9f57d554faaf3dd6c53/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/44dc05a3f936c7f6eaa3d9f57d554faaf3dd6c53/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=44dc05a3f936c7f6eaa3d9f57d554faaf3dd6c53",
      "patch": "@@ -380,16 +380,16 @@ Scheduler getScheduler() {\n    * be used again. For example, the cache may evict an entry because it hasn't been used recently\n    * or very often.\n    * <p>\n-   * When {@code size} is zero, elements will be evicted immediately after being loaded into the\n-   * cache. This can be useful in testing, or to disable caching temporarily without a code change.\n-   * As eviction is scheduled on the configured {@link #executor}, tests may instead prefer\n+   * When {@code maximumSize} is zero, elements will be evicted immediately after being loaded into\n+   * the cache. This can be useful in testing, or to disable caching temporarily without a code\n+   * change. As eviction is scheduled on the configured {@link #executor}, tests may instead prefer\n    * to configure the cache to execute tasks directly on the same thread.\n    * <p>\n    * This feature cannot be used in conjunction with {@link #maximumWeight}.\n    *\n    * @param maximumSize the maximum size of the cache\n    * @return this {@code Caffeine} instance (for chaining)\n-   * @throws IllegalArgumentException if {@code size} is negative\n+   * @throws IllegalArgumentException if {@code maximumSize} is negative\n    * @throws IllegalStateException if a maximum size or weight was already set\n    */\n   @CanIgnoreReturnValue\n@@ -886,8 +886,8 @@ Ticker getTicker() {\n    * {@link ClassCastException} being thrown by a cache operation at some <i>undefined</i> point in\n    * the future.\n    * <p>\n-   * <b>Warning:</b> any exception thrown by {@code listener} will <i>not</i> be propagated to the\n-   * {@code Cache} user, only logged via a {@link Logger}.\n+   * <b>Warning:</b> any exception thrown by {@code evictionListener} will <i>not</i> be propagated\n+   * to the {@code Cache} user, only logged via a {@link Logger}.\n    * <p>\n    * This feature cannot be used in conjunction when {@link #weakKeys()} is combined with\n    * {@link #buildAsync}.\n@@ -941,8 +941,8 @@ public <K1 extends K, V1 extends V> Caffeine<K1, V1> evictionListener(\n    * {@link ClassCastException} being thrown by a cache operation at some <i>undefined</i> point in\n    * the future.\n    * <p>\n-   * <b>Warning:</b> any exception thrown by {@code listener} will <i>not</i> be propagated to the\n-   * {@code Cache} user, only logged via a {@link Logger}.\n+   * <b>Warning:</b> any exception thrown by {@code removalListener} will <i>not</i> be propagated\n+   * to the {@code Cache} user, only logged via a {@link Logger}.\n    *\n    * @param removalListener a listener instance that caches should notify each time an entry is\n    *        removed\n@@ -977,7 +977,7 @@ public <K1 extends K, V1 extends V> Caffeine<K1, V1> removalListener(\n    * Enables the accumulation of {@link CacheStats} during the operation of the cache. Without this\n    * {@link Cache#stats} will return zero for all statistics. Note that recording statistics\n    * requires bookkeeping to be performed with each operation, and thus imposes a performance\n-   * penalty on cache operation.\n+   * penalty on cache operations.\n    *\n    * @return this {@code Caffeine} instance (for chaining)\n    */\n@@ -992,7 +992,7 @@ public Caffeine<K, V> recordStats() {\n    * Enables the accumulation of {@link CacheStats} during the operation of the cache. Without this\n    * {@link Cache#stats} will return zero for all statistics. Note that recording statistics\n    * requires bookkeeping to be performed with each operation, and thus imposes a performance\n-   * penalty on cache operation. Any exception thrown by the supplied {@link StatsCounter} will be\n+   * penalty on cache operations. Any exception thrown by the supplied {@link StatsCounter} will be\n    * suppressed and logged.\n    *\n    * @param statsCounterSupplier a supplier instance that returns a new {@link StatsCounter}\n@@ -1100,7 +1100,7 @@ public <K1 extends K, V1 extends V> LoadingCache<K1, V1> build(\n   public <K1 extends K, V1 extends V> AsyncCache<K1, V1> buildAsync() {\n     requireState(valueStrength == null, \"Weak or soft values can not be combined with AsyncCache\");\n     requireState(isStrongKeys() || (evictionListener == null),\n-        \"Weak keys cannot be combined eviction listener and with AsyncLoadingCache\");\n+        \"Weak keys cannot be combined with eviction listener and AsyncLoadingCache\");\n     requireWeightWithWeigher();\n     requireNonLoadingCache();\n ",
      "parent_sha": "b4cedbc411130b8e78c51effdd527756bdf1ff55"
    }
  },
  {
    "oid": "ebd8efff8c59972591099e1e3c4a9cff2138d8e8",
    "message": "clarify javadoc (fixes #1780)",
    "date": "2024-09-22T04:44:51Z",
    "url": "https://github.com/ben-manes/caffeine/commit/ebd8efff8c59972591099e1e3c4a9cff2138d8e8",
    "details": {
      "sha": "d346ee7be8380173a91d2781dc26d7c0c7b78268",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/stats/StatsCounter.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/ebd8efff8c59972591099e1e3c4a9cff2138d8e8/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/ebd8efff8c59972591099e1e3c4a9cff2138d8e8/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java?ref=ebd8efff8c59972591099e1e3c4a9cff2138d8e8",
      "patch": "@@ -24,7 +24,7 @@\n \n /**\n  * Accumulates statistics during the operation of a {@link Cache} for presentation by\n- * {@link Cache#stats}. This is solely intended for consumption by {@code Cache} implementors.\n+ * {@link Cache#stats}.\n  *\n  * @author ben.manes@gmail.com (Ben Manes)\n  */",
      "parent_sha": "124cf9a3c8d7976e300357b3a203a08276c7a223"
    }
  },
  {
    "oid": "d373882959ecb49df3fc3405b81965ca0e916aa9",
    "message": "Reduction to pass CI kill switch",
    "date": "2014-12-27T10:04:43Z",
    "url": "https://github.com/ben-manes/caffeine/commit/d373882959ecb49df3fc3405b81965ca0e916aa9",
    "details": {
      "sha": "14722e73fdd405eb1dd055fa122c847776025465",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/testing/CacheSpec.java",
      "status": "modified",
      "additions": 1,
      "deletions": 6,
      "changes": 7,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/d373882959ecb49df3fc3405b81965ca0e916aa9/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/d373882959ecb49df3fc3405b81965ca0e916aa9/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java?ref=d373882959ecb49df3fc3405b81965ca0e916aa9",
      "patch": "@@ -21,7 +21,6 @@\n import java.lang.annotation.Retention;\n import java.lang.annotation.Target;\n import java.util.concurrent.Executor;\n-import java.util.concurrent.ForkJoinPool;\n import java.util.concurrent.RejectedExecutionException;\n import java.util.function.Supplier;\n \n@@ -217,20 +216,16 @@ enum Loader implements CacheLoader<Integer, Integer> {\n   CacheExecutor[] executor() default {\n //    CacheExecutor.DEFAULT,\n     CacheExecutor.DIRECT,\n-//    CacheExecutor.FORK_JOIN_COMMON_POOL\n   };\n \n   /** The executors that the cache can be configured with. */\n   enum CacheExecutor implements Supplier<Executor> {\n-    DEFAULT {\n+    DEFAULT { // fork-join common pool\n       @Override public Executor get() { return null; }\n     },\n     DIRECT {\n       @Override public Executor get() { return MoreExecutors.directExecutor(); }\n     },\n-    FORK_JOIN_COMMON_POOL {\n-      @Override public Executor get() { return ForkJoinPool.commonPool(); }\n-    },\n     REJECTING {\n       @Override public Executor get() { throw new RejectedExecutionException(); }\n     };",
      "parent_sha": "3e2199572b0ca625e2ad8909e34a958485b5a788"
    }
  },
  {
    "oid": "46ec7d2310b06419051c2dca94f779c50b1a62de",
    "message": "Add removal notifications for replacements",
    "date": "2014-12-27T04:00:06Z",
    "url": "https://github.com/ben-manes/caffeine/commit/46ec7d2310b06419051c2dca94f779c50b1a62de",
    "details": {
      "sha": "4562517929705c44e8d5f13b8189d0472f9b83e7",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 37,
      "deletions": 8,
      "changes": 45,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/46ec7d2310b06419051c2dca94f779c50b1a62de/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/46ec7d2310b06419051c2dca94f779c50b1a62de/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=46ec7d2310b06419051c2dca94f779c50b1a62de",
      "patch": "@@ -43,6 +43,7 @@\n import java.util.concurrent.locks.Lock;\n import java.util.concurrent.locks.ReentrantLock;\n \n+import javax.annotation.Nullable;\n import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.Immutable;\n import javax.annotation.concurrent.ThreadSafe;\n@@ -484,16 +485,17 @@ boolean tryToRetire(Node<K, V> node, WeightedValue<V> expect) {\n    * <tt>retired</tt> state, if a valid transition.\n    *\n    * @param node the entry in the page replacement policy\n+   * @return the retired weighted value if the transition was successful or null otherwise\n    */\n-  void makeRetired(Node<K, V> node) {\n+  @Nullable WeightedValue<V> makeRetired(Node<K, V> node) {\n     for (;;) {\n       final WeightedValue<V> current = node.get();\n       if (!current.isAlive()) {\n-        return;\n+        return null;\n       }\n       final WeightedValue<V> retired = new WeightedValue<V>(current.value, -current.weight);\n       if (node.compareAndSet(current, retired)) {\n-        return;\n+        return retired;\n       }\n     }\n   }\n@@ -727,6 +729,11 @@ V put(K key, V value, boolean onlyIfAbsent) {\n           } else {\n             afterWrite(new UpdateTask(prior, weightedDifference));\n           }\n+          if (removalListener != null) {\n+            RemovalNotification<K, V> notification = new RemovalNotification<K, V>(\n+                key, oldWeightedValue.value, RemovalCause.REPLACED);\n+            executor.execute(() -> removalListener.onRemoval(notification));\n+          }\n           return oldWeightedValue.value;\n         }\n       }\n@@ -740,8 +747,15 @@ public V remove(Object key) {\n       return null;\n     }\n \n-    makeRetired(node);\n+    WeightedValue<V> retired = makeRetired(node);\n     afterWrite(new RemovalTask(node));\n+\n+    if ((removalListener != null) && (retired != null)) {\n+      @SuppressWarnings(\"unchecked\")\n+      RemovalNotification<K, V> notification = new RemovalNotification<K, V>(\n+          (K) key, retired.value, RemovalCause.EXPLICIT);\n+      executor.execute(() -> removalListener.onRemoval(notification));\n+    }\n     return node.getValue();\n   }\n \n@@ -758,6 +772,11 @@ public boolean remove(Object key, Object value) {\n         if (tryToRetire(node, weightedValue)) {\n           if (data.remove(key, node)) {\n             afterWrite(new RemovalTask(node));\n+\n+            @SuppressWarnings(\"unchecked\")\n+            RemovalNotification<K, V> notification = new RemovalNotification<K, V>(\n+                (K) key, node.getValue(), RemovalCause.EXPLICIT);\n+            executor.execute(() -> removalListener.onRemoval(notification));\n             return true;\n           }\n         } else {\n@@ -797,6 +816,11 @@ public V replace(K key, V value) {\n         } else {\n           afterWrite(new UpdateTask(node, weightedDifference));\n         }\n+        if (removalListener != null) {\n+          RemovalNotification<K, V> notification = new RemovalNotification<K, V>(\n+              key, oldWeightedValue.value, RemovalCause.REPLACED);\n+          executor.execute(() -> removalListener.onRemoval(notification));\n+        }\n         return oldWeightedValue.value;\n       }\n     }\n@@ -816,17 +840,22 @@ public boolean replace(K key, V oldValue, V newValue) {\n       return false;\n     }\n     for (;;) {\n-      final WeightedValue<V> weightedValue = node.get();\n-      if (!weightedValue.isAlive() || !weightedValue.contains(oldValue)) {\n+      final WeightedValue<V> oldWeightedValue = node.get();\n+      if (!oldWeightedValue.isAlive() || !oldWeightedValue.contains(oldValue)) {\n         return false;\n       }\n-      if (node.compareAndSet(weightedValue, newWeightedValue)) {\n-        final int weightedDifference = weight - weightedValue.weight;\n+      if (node.compareAndSet(oldWeightedValue, newWeightedValue)) {\n+        final int weightedDifference = weight - oldWeightedValue.weight;\n         if (weightedDifference == 0) {\n           afterRead(node);\n         } else {\n           afterWrite(new UpdateTask(node, weightedDifference));\n         }\n+        if (removalListener != null) {\n+          RemovalNotification<K, V> notification = new RemovalNotification<K, V>(\n+              key, oldWeightedValue.value, RemovalCause.REPLACED);\n+          executor.execute(() -> removalListener.onRemoval(notification));\n+        }\n         return true;\n       }\n     }",
      "parent_sha": "80e97a64300d1e4fb6052f3a9f94f45e57df0e0c"
    }
  },
  {
    "oid": "4168e8eb211e64dba01ded7b9d38be57a87b7742",
    "message": "Avoid GC skewing the compute benchmark",
    "date": "2015-06-09T17:06:29Z",
    "url": "https://github.com/ben-manes/caffeine/commit/4168e8eb211e64dba01ded7b9d38be57a87b7742",
    "details": {
      "sha": "9a5ea9f54b2b6a08c8270e8fa5b3abd40a96108a",
      "filename": "caffeine/src/jmh/java/com/github/benmanes/caffeine/cache/ComputeBenchmark.java",
      "status": "modified",
      "additions": 8,
      "deletions": 4,
      "changes": 12,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/4168e8eb211e64dba01ded7b9d38be57a87b7742/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FComputeBenchmark.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/4168e8eb211e64dba01ded7b9d38be57a87b7742/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FComputeBenchmark.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FComputeBenchmark.java?ref=4168e8eb211e64dba01ded7b9d38be57a87b7742",
      "patch": "@@ -17,6 +17,7 @@\n \n import java.util.Arrays;\n import java.util.Random;\n+import java.util.concurrent.Callable;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n import java.util.function.Function;\n@@ -40,7 +41,10 @@\n public class ComputeBenchmark {\n   static final int SIZE = (2 << 14);\n   static final int MASK = SIZE - 1;\n+  static final int ITEMS = SIZE / 3;\n   static final Integer COMPUTE_KEY = SIZE / 2;\n+  static final Callable<Boolean> valueLoader = () -> Boolean.TRUE;\n+  static final Function<Integer, Boolean> mappingFunction = any -> Boolean.TRUE;\n \n   @Param({\"ConcurrentHashMap\", \"Caffeine\", \"Guava\"})\n   String computeType;\n@@ -56,7 +60,7 @@ public static class ThreadState {\n \n   public ComputeBenchmark() {\n     ints = new Integer[SIZE];\n-    IntegerGenerator generator = new ScrambledZipfianGenerator(SIZE);\n+    IntegerGenerator generator = new ScrambledZipfianGenerator(ITEMS);\n     for (int i = 0; i < SIZE; i++) {\n       ints[i] = generator.nextInt();\n     }\n@@ -88,20 +92,20 @@ public void compute_spread(ThreadState threadState) {\n \n   private void setupConcurrentHashMap() {\n     ConcurrentMap<Integer, Boolean> map = new ConcurrentHashMap<>();\n-    benchmarkFunction = key -> map.computeIfAbsent(key, any -> Boolean.TRUE);\n+    benchmarkFunction = key -> map.computeIfAbsent(key, mappingFunction);\n   }\n \n   private void setupCaffeine() {\n     Cache<Integer, Boolean> cache = Caffeine.newBuilder().build();\n-    benchmarkFunction = key -> cache.get(key, any -> Boolean.TRUE);\n+    benchmarkFunction = key -> cache.get(key, mappingFunction);\n   }\n \n   private void setupGuava() {\n     com.google.common.cache.Cache<Integer, Boolean> cache =\n         CacheBuilder.newBuilder().concurrencyLevel(64).build();\n     benchmarkFunction = key -> {\n       try {\n-        return cache.get(key, () -> Boolean.TRUE);\n+        return cache.get(key, valueLoader);\n       } catch (Exception e) {\n         throw Throwables.propagate(e);\n       }",
      "parent_sha": "b2b3d1bc4e1e61910a8682dee9847adf2bddb1c9"
    }
  },
  {
    "oid": "cf83eb151b079cdc5394a9b69f4936dc655aa09b",
    "message": "Reorder the operation of reducing size before that of bulk loading (#698)\n\nBulk loading is expected to be a time-consuming operation. During bulk\r\nloading, other threads may invoke the method \"doLoad\" which is\r\nunnecessary, because the queue size is still larger than maxLoadSize.",
    "date": "2022-04-16T18:46:07Z",
    "url": "https://github.com/ben-manes/caffeine/commit/cf83eb151b079cdc5394a9b69f4936dc655aa09b",
    "details": {
      "sha": "de8d3ca7ac13700b1b4223eeaf3e5177323f28eb",
      "filename": "examples/coalescing-bulkloader/src/main/java/com/github/benmanes/caffeine/examples/coalescing/bulkloader/CoalescingBulkloader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/cf83eb151b079cdc5394a9b69f4936dc655aa09b/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/cf83eb151b079cdc5394a9b69f4936dc655aa09b/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java?ref=cf83eb151b079cdc5394a9b69f4936dc655aa09b",
      "patch": "@@ -208,8 +208,8 @@ private synchronized void doLoad() {\n \n       final int taken = maxLoadSize - counter;\n       if (taken > 0) {\n-        bulkLoader.accept(toLoad);\n         size.updateAndGet(oldSize -> oldSize - taken);\n+        bulkLoader.accept(toLoad);\n       }\n \n     } while (size.get() >= maxLoadSize);",
      "parent_sha": "e34797d1c2bd39b8337a66575153a7063db96b1f"
    }
  },
  {
    "oid": "87ef37efb1fa8f46e2f9cb7580fa43010c9f7e60",
    "message": "Fix JavaDoc as refresh is always asynchronous",
    "date": "2015-06-14T10:31:27Z",
    "url": "https://github.com/ben-manes/caffeine/commit/87ef37efb1fa8f46e2f9cb7580fa43010c9f7e60",
    "details": {
      "sha": "0b9a6553248f71066a0b0f6c7c4c0c3acedfb0eb",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/LoadingCache.java",
      "status": "modified",
      "additions": 1,
      "deletions": 2,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/87ef37efb1fa8f46e2f9cb7580fa43010c9f7e60/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLoadingCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/87ef37efb1fa8f46e2f9cb7580fa43010c9f7e60/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLoadingCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLoadingCache.java?ref=87ef37efb1fa8f46e2f9cb7580fa43010c9f7e60",
      "patch": "@@ -99,8 +99,7 @@ public interface LoadingCache<K, V> extends Cache<K, V> {\n    * <p>\n    * Caches loaded by a {@link CacheLoader} will call {@link CacheLoader#reload} if the cache\n    * currently contains a value for {@code key}, and {@link CacheLoader#load} otherwise. Loading is\n-   * asynchronous only if {@link CacheLoader#reload} was overridden with an asynchronous\n-   * implementation.\n+   * asynchronous by delegating to the default executor.\n    *\n    * @param key key with which a value may be associated\n    * @throws NullPointerException if the specified key is null",
      "parent_sha": "07967389f4563151cc241b35b167fcf58f01aa72"
    }
  },
  {
    "oid": "3457bf50994121ad924571e9987a39d672c06e1e",
    "message": "Fix incorrect date format pattern in unit test (#1789)",
    "date": "2024-10-26T23:51:39Z",
    "url": "https://github.com/ben-manes/caffeine/commit/3457bf50994121ad924571e9987a39d672c06e1e",
    "details": {
      "sha": "21bef78bdf453a3306ed1625da09b91f31074d15",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/issues/Issue30Test.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/3457bf50994121ad924571e9987a39d672c06e1e/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fissues%2FIssue30Test.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/3457bf50994121ad924571e9987a39d672c06e1e/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fissues%2FIssue30Test.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fissues%2FIssue30Test.java?ref=3457bf50994121ad924571e9987a39d672c06e1e",
      "patch": "@@ -151,7 +151,7 @@ private static FutureSubject assertThat(String message, CompletableFuture<?> act\n \n   static final class Loader implements AsyncCacheLoader<String, String> {\n     private static final DateTimeFormatter FORMATTER =\n-        DateTimeFormatter.ofPattern(\"hh:MM:ss.SSS\", US);\n+        DateTimeFormatter.ofPattern(\"HH:mm:ss.SSS\", US);\n \n     final ConcurrentMap<String, String> source;\n     final ConcurrentMap<String, Instant> lastLoad;",
      "parent_sha": "0eaf6f21983a042073c89e99a3309dc13fbeadf5"
    }
  },
  {
    "oid": "9eeb53829140d98af8aa1f2a6263b7fac7516978",
    "message": "Clarify method JavaDoc to match class documentation",
    "date": "2017-08-16T20:55:28Z",
    "url": "https://github.com/ben-manes/caffeine/commit/9eeb53829140d98af8aa1f2a6263b7fac7516978",
    "details": {
      "sha": "6478f7f38d1ebe2a25bd070a0e078747060699f8",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/CacheWriter.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/9eeb53829140d98af8aa1f2a6263b7fac7516978/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheWriter.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/9eeb53829140d98af8aa1f2a6263b7fac7516978/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheWriter.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheWriter.java?ref=9eeb53829140d98af8aa1f2a6263b7fac7516978",
      "patch": "@@ -35,8 +35,8 @@ public interface CacheWriter<K, V> {\n \n   /***\n    * Writes the value corresponding to the {@code key} to the external resource. The cache will\n-   * communicate a write when an entry in the cache is inserted or updated explicitly. The implicit\n-   * creation of an entry due to being loaded when absent is not communicated.\n+   * communicate a write when an entry in the cache is created or modified, except when that was\n+   * due to a load or computation.\n    *\n    * @param key the non-null key whose value should be written\n    * @param value the value associated with {@code key} that should be written",
      "parent_sha": "6e61ee5b6ccbab6794146ee329e9fef807ce6042"
    }
  },
  {
    "oid": "f0b784f35291dbb2f6db8eea524e30ef056c19ba",
    "message": "Another experiment to reduce memory usage on CI",
    "date": "2014-12-28T03:50:15Z",
    "url": "https://github.com/ben-manes/caffeine/commit/f0b784f35291dbb2f6db8eea524e30ef056c19ba",
    "details": {
      "sha": "fbfe0f7eea476e37abdb7f355bcae96e5b2c2ebf",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/testing/CacheSpec.java",
      "status": "modified",
      "additions": 6,
      "deletions": 10,
      "changes": 16,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/f0b784f35291dbb2f6db8eea524e30ef056c19ba/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/f0b784f35291dbb2f6db8eea524e30ef056c19ba/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Ftesting%2FCacheSpec.java?ref=f0b784f35291dbb2f6db8eea524e30ef056c19ba",
      "patch": "@@ -68,10 +68,7 @@ public int size() {\n   /** The initial capacities, each resulting in a new combination. */\n   InitialCapacity[] initialCapacity() default {\n     InitialCapacity.DEFAULT,\n-    InitialCapacity.ZERO,\n-    InitialCapacity.ONE,\n     InitialCapacity.FULL,\n-    InitialCapacity.EXCESSIVE\n   };\n \n   /* ---------------- Statistics -------------- */\n@@ -85,6 +82,12 @@ Stats[] stats() default {\n \n   /* ---------------- Maximum size -------------- */\n \n+  /** The maximum size, each resulting in a new combination. */\n+  MaximumSize[] maximumSize() default {\n+    MaximumSize.DISABLED,\n+    MaximumSize.UNREACHABLE\n+  };\n+\n   enum MaximumSize {\n     /** A flag indicating that entries are not evicted due to a maximum size threshold. */\n     DISABLED(Long.MAX_VALUE),\n@@ -108,13 +111,6 @@ public long max() {\n     }\n   }\n \n-  /** The maximum size, each resulting in a new combination. */\n-  MaximumSize[] maximumSize() default {\n-    MaximumSize.DISABLED,\n-    // Disabled while BoundedLocalCache is unstable\n-    MaximumSize.UNREACHABLE\n-  };\n-\n   /* ---------------- Reference-based -------------- */\n \n   /**",
      "parent_sha": "99e5e3bb6d500811aa6c4064ecc0ca72204b85db"
    }
  },
  {
    "oid": "54503f09ec0279ff2c2830459c84176c49654db3",
    "message": "Fix warmup of HIR blocks in LIRS policy\n\nWhen comparing against the output from the C reference version I discovered\nthat the warmup for HIR was incorrectly followed. This change results in the\nsame output for a small sample.\n\nThere is still a mistake as verified by running a large sample, multi1, and\nseeing that S, Q, evictions, and statistics are askew. While this has a very\nsmall impact on the hit rate, we should still try to find the subtle bug\nremaining.\n\nFor ease of comparing outputs, the debug format now matches the reference's.",
    "date": "2015-08-31T06:53:20Z",
    "url": "https://github.com/ben-manes/caffeine/commit/54503f09ec0279ff2c2830459c84176c49654db3",
    "details": {
      "sha": "faa53c970823eac5ef1368e9ed63928f7325bda1",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/irr/LirsPolicy.java",
      "status": "modified",
      "additions": 27,
      "deletions": 16,
      "changes": 43,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/54503f09ec0279ff2c2830459c84176c49654db3/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/54503f09ec0279ff2c2830459c84176c49654db3/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java?ref=54503f09ec0279ff2c2830459c84176c49654db3",
      "patch": "@@ -140,27 +140,35 @@ private void onResidentHir(Node node) {\n   }\n \n   private void onNonResidentHir(Node node) {\n-    // When LIR block set is not full, all the referenced blocks are given an LIR status until its\n-    // size reaches Llirs. After that, HIR status is given to any blocks that are referenced for the\n-    // first time, and to the blocks that have not been referenced for a long time so that they are\n-    // not in stack S any longer.\n+    // When an LIR block set is not full, all the accessed blocks are given LIR status until its\n+    // size reaches Llirs. After that, HIR status is given to any blocks that are accessed for the\n+    // first time and to blocks that have not been accessed for a long time so that currently they\n+    // are not in stack S.\n     policyStats.recordMiss();\n \n     if (sizeHot < maximumHotSize) {\n-      onWarmupMiss(node);\n+      onLirWarmupMiss(node);\n+    } else if (residentSize < maximumSize) {\n+      onHirWarmupMiss(node);\n     } else {\n       onFullMiss(node);\n     }\n     residentSize++;\n   }\n \n   /** Records a miss when the hot set is not full. */\n-  private void onWarmupMiss(Node node) {\n+  private void onLirWarmupMiss(Node node) {\n     node.moveToTop(StackType.S);\n     node.status = Status.LIR;\n     sizeHot++;\n   }\n \n+  /** Records a miss when the cold set is not full. */\n+  private void onHirWarmupMiss(Node node) {\n+    node.status = Status.HIR_RESIDENT;\n+    node.moveToTop(StackType.Q);\n+  }\n+\n   /** Records a miss when the hot set is full. */\n   private void onFullMiss(Node node) {\n     // Upon accessing an HIR non-resident block X. This is a miss. We remove the HIR resident block\n@@ -265,27 +273,30 @@ public void finished() {\n \n   /** Prints out the internal state of the policy. */\n   private void printLirs() {\n-    List<Object> stack = new ArrayList<>(sizeS);\n-    List<Object> queue = new ArrayList<>(sizeQ);\n-\n+    System.out.println(\"** LIRS stack TOP **\");\n     for (Node n = headS.nextS; n != headS; n = n.nextS) {\n       checkState(n.isInS);\n       if (n.status == Status.HIR_NON_RESIDENT) {\n-        stack.add(\"NR_\" + n.key);\n+        System.out.println(\"<NR> \" + n.key);\n       } else if (n.status == Status.HIR_RESIDENT) {\n-        stack.add(\"RH_\" + n.key);\n+        System.out.println(\"<RH> \" + n.key);\n       } else {\n-        stack.add(\"RL_\" + n.key);\n+        System.out.println(\"<RL> \" + n.key);\n       }\n     }\n+    System.out.println(\"** LIRS stack BOTTOM **\");\n+\n+    System.out.println(\"\\n** LIRS queue END **\");\n     for (Node n = headQ.nextQ; n != headQ; n = n.nextQ) {\n       checkState(n.isInQ);\n-      queue.add(n.key);\n+      System.out.println(n.key);\n     }\n+    System.out.println(\"** LIRS queue front **\");\n \n-    System.out.println(\"Stack: \" + stack);\n-    System.out.println(\"Queue: \" + queue);\n-    System.out.println(\"Evicted: \" + evicted);\n+    System.out.println(\"\\nLIRS EVICTED PAGE sequence:\");\n+    for (int i = 0; i < evicted.size(); i++) {\n+      System.out.println(\"<\" + i + \"> \" + evicted.get(i));\n+    }\n   }\n \n   enum Status {",
      "parent_sha": "520487580ddb6b8984705aaa37702de1a2759a68"
    }
  },
  {
    "oid": "a0ff03c75aad74bad327c333b7834ce35ad17e88",
    "message": "Replace CAS with synchronized to handle races with compute methods",
    "date": "2014-12-27T22:39:51Z",
    "url": "https://github.com/ben-manes/caffeine/commit/a0ff03c75aad74bad327c333b7834ce35ad17e88",
    "details": {
      "sha": "7bcc343d93f3790149b82b945f8fb31e2da94a3c",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 53,
      "deletions": 49,
      "changes": 102,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/a0ff03c75aad74bad327c333b7834ce35ad17e88/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/a0ff03c75aad74bad327c333b7834ce35ad17e88/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=a0ff03c75aad74bad327c333b7834ce35ad17e88",
      "patch": "@@ -493,7 +493,12 @@ void drainWriteBuffer() {\n   boolean tryToRetire(Node<K, V> node, WeightedValue<V> expect) {\n     if (expect.isAlive()) {\n       final WeightedValue<V> retired = new WeightedValue<V>(expect.value, -expect.weight);\n-      return node.compareAndSet(expect, retired);\n+      synchronized (node) {\n+        if (node.get() == expect) {\n+          node.lazySet(retired);\n+          return true;\n+        }\n+      }\n     }\n     return false;\n   }\n@@ -506,15 +511,14 @@ boolean tryToRetire(Node<K, V> node, WeightedValue<V> expect) {\n    * @return the retired weighted value if the transition was successful or null otherwise\n    */\n   @Nullable WeightedValue<V> makeRetired(Node<K, V> node) {\n-    for (;;) {\n+    synchronized (node) {\n       final WeightedValue<V> current = node.get();\n       if (!current.isAlive()) {\n         return null;\n       }\n       final WeightedValue<V> retired = new WeightedValue<V>(current.value, -current.weight);\n-      if (node.compareAndSet(current, retired)) {\n-        return retired;\n-      }\n+      node.lazySet(retired);\n+      return retired;\n     }\n   }\n \n@@ -526,7 +530,7 @@ boolean tryToRetire(Node<K, V> node, WeightedValue<V> expect) {\n    */\n   @GuardedBy(\"evictionLock\")\n   void makeDead(Node<K, V> node) {\n-    for (;;) {\n+    synchronized (node) {\n       WeightedValue<V> current = node.get();\n       WeightedValue<V> dead = new WeightedValue<V>(current.value, 0);\n       if (node.compareAndSet(current, dead)) {\n@@ -764,25 +768,25 @@ V put(K key, V value, boolean onlyIfAbsent) {\n         afterRead(prior);\n         return prior.getValue();\n       }\n-      for (;;) {\n-        final WeightedValue<V> oldWeightedValue = prior.get();\n+      WeightedValue<V> oldWeightedValue;\n+      synchronized (prior) {\n+        oldWeightedValue = prior.get();\n         if (!oldWeightedValue.isAlive()) {\n-          break;\n+          continue;\n         }\n+        prior.lazySet(weightedValue);\n+      }\n \n-        if (prior.compareAndSet(oldWeightedValue, weightedValue)) {\n-          final int weightedDifference = weight - oldWeightedValue.weight;\n-          if (weightedDifference == 0) {\n-            afterRead(prior);\n-          } else {\n-            afterWrite(new UpdateTask(prior, weightedDifference));\n-          }\n-          if (hasRemovalListener()) {\n-            notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n-          }\n-          return oldWeightedValue.value;\n-        }\n+      final int weightedDifference = weight - oldWeightedValue.weight;\n+      if (weightedDifference == 0) {\n+        afterRead(prior);\n+      } else {\n+        afterWrite(new UpdateTask(prior, weightedDifference));\n       }\n+      if (hasRemovalListener()) {\n+        notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n+      }\n+      return oldWeightedValue.value;\n     }\n   }\n \n@@ -850,24 +854,24 @@ public V replace(K key, V value) {\n     if (node == null) {\n       return null;\n     }\n-    for (;;) {\n-      final WeightedValue<V> oldWeightedValue = node.get();\n+    WeightedValue<V> oldWeightedValue;\n+    synchronized (node) {\n+      oldWeightedValue = node.get();\n       if (!oldWeightedValue.isAlive()) {\n         return null;\n       }\n-      if (node.compareAndSet(oldWeightedValue, weightedValue)) {\n-        final int weightedDifference = weight - oldWeightedValue.weight;\n-        if (weightedDifference == 0) {\n-          afterRead(node);\n-        } else {\n-          afterWrite(new UpdateTask(node, weightedDifference));\n-        }\n-        if (hasRemovalListener()) {\n-          notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n-        }\n-        return oldWeightedValue.value;\n-      }\n+      node.lazySet(weightedValue);\n+    }\n+    final int weightedDifference = weight - oldWeightedValue.weight;\n+    if (weightedDifference == 0) {\n+      afterRead(node);\n+    } else {\n+      afterWrite(new UpdateTask(node, weightedDifference));\n     }\n+    if (hasRemovalListener()) {\n+      notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n+    }\n+    return oldWeightedValue.value;\n   }\n \n   @Override\n@@ -883,24 +887,24 @@ public boolean replace(K key, V oldValue, V newValue) {\n     if (node == null) {\n       return false;\n     }\n-    for (;;) {\n-      final WeightedValue<V> oldWeightedValue = node.get();\n+    WeightedValue<V> oldWeightedValue;\n+    synchronized (node) {\n+      oldWeightedValue = node.get();\n       if (!oldWeightedValue.isAlive() || !oldWeightedValue.contains(oldValue)) {\n         return false;\n       }\n-      if (node.compareAndSet(oldWeightedValue, newWeightedValue)) {\n-        final int weightedDifference = weight - oldWeightedValue.weight;\n-        if (weightedDifference == 0) {\n-          afterRead(node);\n-        } else {\n-          afterWrite(new UpdateTask(node, weightedDifference));\n-        }\n-        if (hasRemovalListener()) {\n-          notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n-        }\n-        return true;\n-      }\n+      node.lazySet(newWeightedValue);\n+    }\n+    final int weightedDifference = weight - oldWeightedValue.weight;\n+    if (weightedDifference == 0) {\n+      afterRead(node);\n+    } else {\n+      afterWrite(new UpdateTask(node, weightedDifference));\n+    }\n+    if (hasRemovalListener()) {\n+      notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n     }\n+    return true;\n   }\n \n   @Override",
      "parent_sha": "d9a19a5a1795a3314576195f7ce3f86623f2535a"
    }
  },
  {
    "oid": "4e91ece8d73cc344177b16a09abcabf10d688b7a",
    "message": "Update CHM2 to use Doug's instanceof check",
    "date": "2014-12-21T23:17:57Z",
    "url": "https://github.com/ben-manes/caffeine/commit/4e91ece8d73cc344177b16a09abcabf10d688b7a",
    "details": {
      "sha": "7f363ed51b48b49300478e0c43d315c8fb4b28d3",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/ConcurrentHashMap2.java",
      "status": "modified",
      "additions": 87,
      "deletions": 98,
      "changes": 185,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/4e91ece8d73cc344177b16a09abcabf10d688b7a/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FConcurrentHashMap2.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/4e91ece8d73cc344177b16a09abcabf10d688b7a/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FConcurrentHashMap2.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FConcurrentHashMap2.java?ref=4e91ece8d73cc344177b16a09abcabf10d688b7a",
      "patch": "@@ -642,9 +642,6 @@ static class Node<K,V> implements Map.Entry<K,V> {\n         public final V setValue(V value) {\n             throw new UnsupportedOperationException();\n         }\n-        long getThreadId() {\n-            return -1; // invalid thread id; never used\n-        }\n \n         @Override\n         public final boolean equals(Object o) {\n@@ -1717,95 +1714,94 @@ public void replaceAll(BiFunction<? super K, ? super V, ? extends V> function) {\n      */\n     @Override\n     public V computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction) {\n-        if (key == null || mappingFunction == null) {\n-          throw new NullPointerException();\n-        }\n-        int h = spread(key.hashCode());\n-        V val = null;\n-        int binCount = 0;\n-        for (Node<K,V>[] tab = table;;) {\n-            Node<K,V> f; int n, i, fh;\n-            if (tab == null || (n = tab.length) == 0) {\n-              tab = initTable();\n-            } else if ((f = tabAt(tab, i = (n - 1) & h)) == null) {\n-                Node<K,V> r = new ReservationNode<K,V>();\n-                synchronized (r) {\n-                    if (casTabAt(tab, i, null, r)) {\n-                        binCount = 1;\n-                        Node<K,V> node = null;\n-                        try {\n-                            if ((val = mappingFunction.apply(key)) != null) {\n-                              node = new Node<K,V>(h, key, val, null);\n-                            }\n-                        } finally {\n-                            setTabAt(tab, i, node);\n-                        }\n-                    }\n-                }\n-                if (binCount != 0) {\n+      if (key == null || mappingFunction == null) {\n+        throw new NullPointerException();\n+      }\n+      int h = spread(key.hashCode());\n+      V val = null;\n+      int binCount = 0;\n+      for (Node<K,V>[] tab = table;;) {\n+          Node<K,V> f; int n, i, fh;\n+          if (tab == null || (n = tab.length) == 0) {\n+            tab = initTable();\n+          } else if ((f = tabAt(tab, i = (n - 1) & h)) == null) {\n+              Node<K,V> r = new ReservationNode<K,V>();\n+              synchronized (r) {\n+                  if (casTabAt(tab, i, null, r)) {\n+                      binCount = 1;\n+                      Node<K,V> node = null;\n+                      try {\n+                          if ((val = mappingFunction.apply(key)) != null) {\n+                            node = new Node<K,V>(h, key, val, null);\n+                          }\n+                      } finally {\n+                          setTabAt(tab, i, node);\n+                      }\n+                  }\n+              }\n+              if (binCount != 0) {\n+                break;\n+              }\n+          }\n+          else if ((fh = f.hash) == MOVED) {\n+            tab = helpTransfer(tab, f);\n+          } else {\n+              boolean added = false;\n+              synchronized (f) {\n+                  if (tabAt(tab, i) == f) {\n+                      if (fh >= 0) {\n+                          binCount = 1;\n+                          for (Node<K,V> e = f;; ++binCount) {\n+                              K ek; V ev;\n+                              if (e.hash == h &&\n+                                  ((ek = e.key) == key ||\n+                                   (ek != null && key.equals(ek)))) {\n+                                  val = e.val;\n+                                  break;\n+                              }\n+                              Node<K,V> pred = e;\n+                              if ((e = e.next) == null) {\n+                                  if ((val = mappingFunction.apply(key)) != null) {\n+                                      added = true;\n+                                      pred.next = new Node<K,V>(h, key, val, null);\n+                                  }\n+                                  break;\n+                              }\n+                          }\n+                      }\n+                      else if (f instanceof TreeBin) {\n+                          binCount = 2;\n+                          TreeBin<K,V> t = (TreeBin<K,V>)f;\n+                          TreeNode<K,V> r, p;\n+                          if ((r = t.root) != null &&\n+                              (p = r.findTreeNode(h, key, null)) != null) {\n+                            val = p.val;\n+                          } else if ((val = mappingFunction.apply(key)) != null) {\n+                              added = true;\n+                              t.putTreeVal(h, key, val);\n+                          }\n+                      }\n+                      else if (f instanceof ReservationNode) {\n+                        throw new IllegalStateException(\"Recursive update\");\n+                      }\n+                  }\n+              }\n+              if (binCount != 0) {\n+                  if (binCount >= TREEIFY_THRESHOLD) {\n+                    treeifyBin(tab, i);\n+                  }\n+                  if (!added) {\n+                    return val;\n+                  }\n                   break;\n-                }\n-            }\n-            else if ((fh = f.hash) == MOVED) {\n-              tab = helpTransfer(tab, f);\n-            } else {\n-                if (f.getThreadId() == Thread.currentThread().getId()) {\n-                  throw new IllegalStateException(\"Recursive computeIfAbsent\");\n-                }\n-                boolean added = false;\n-                synchronized (f) {\n-                    if (tabAt(tab, i) == f) {\n-                        if (fh >= 0) {\n-                            binCount = 1;\n-                            for (Node<K,V> e = f;; ++binCount) {\n-                                K ek; V ev;\n-                                if (e.hash == h &&\n-                                    ((ek = e.key) == key ||\n-                                     (ek != null && key.equals(ek)))) {\n-                                    val = e.val;\n-                                    break;\n-                                }\n-                                Node<K,V> pred = e;\n-                                if ((e = e.next) == null) {\n-                                    if ((val = mappingFunction.apply(key)) != null) {\n-                                        added = true;\n-                                        pred.next = new Node<K,V>(h, key, val, null);\n-                                    }\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        else if (f instanceof TreeBin) {\n-                            binCount = 2;\n-                            TreeBin<K,V> t = (TreeBin<K,V>)f;\n-                            TreeNode<K,V> r, p;\n-                            if ((r = t.root) != null &&\n-                                (p = r.findTreeNode(h, key, null)) != null) {\n-                              val = p.val;\n-                            } else if ((val = mappingFunction.apply(key)) != null) {\n-                                added = true;\n-                                t.putTreeVal(h, key, val);\n-                            }\n-                        }\n-                    }\n-                }\n-                if (binCount != 0) {\n-                    if (binCount >= TREEIFY_THRESHOLD) {\n-                      treeifyBin(tab, i);\n-                    }\n-                    if (!added) {\n-                      return val;\n-                    }\n-                    break;\n-                }\n-            }\n-        }\n-        if (val != null) {\n-          addCount(1L, binCount);\n-        }\n-        return val;\n-    }\n-\n+              }\n+          }\n+      }\n+      if (val != null) {\n+        addCount(1L, binCount);\n+      }\n+      return val;\n+  }\n     /**\n      * If the value for the specified key is present, attempts to\n      * compute a new mapping given the key and its current mapped\n@@ -2309,22 +2305,15 @@ Node<K,V> find(int h, Object k) {\n      * A place-holder node used in computeIfAbsent and compute\n      */\n     static final class ReservationNode<K,V> extends Node<K,V> {\n-        final long threadId;\n \n         ReservationNode() {\n             super(RESERVED, null, null, null);\n-            threadId = Thread.currentThread().getId();\n         }\n \n         @Override\n         Node<K,V> find(int h, Object k) {\n             return null;\n         }\n-\n-        @Override\n-        long getThreadId() {\n-          return threadId;\n-        }\n     }\n \n     /* ---------------- Table Initialization and Resizing -------------- */",
      "parent_sha": "98451104613fc0e823fd0fdd8bb9ed7b7cf9d1fa"
    }
  },
  {
    "oid": "093f249b30feab167a34a60bf2118005ff2dbc1a",
    "message": "Fix JavaDoc reference",
    "date": "2015-01-14T11:55:16Z",
    "url": "https://github.com/ben-manes/caffeine/commit/093f249b30feab167a34a60bf2118005ff2dbc1a",
    "details": {
      "sha": "ce8450bf48ccd72860884c2c363c4e10ccccb7cf",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/093f249b30feab167a34a60bf2118005ff2dbc1a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/093f249b30feab167a34a60bf2118005ff2dbc1a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=093f249b30feab167a34a60bf2118005ff2dbc1a",
      "patch": "@@ -113,7 +113,7 @@\n  * {@linkplain #weakValues weakValues}, or {@linkplain #softValues softValues} perform periodic\n  * maintenance.\n  * <p>\n- * The caches produced by {@code CacheBuilder} are serializable, and the deserialized caches\n+ * The caches produced by {@code Caffeine} are serializable, and the deserialized caches\n  * retain all the configuration properties of the original cache. Note that the serialized form does\n  * <i>not</i> include cache contents, but only configuration.\n  *",
      "parent_sha": "ff2c1576e26a41982aa2b06abd120b605c62b921"
    }
  },
  {
    "oid": "2ce49a45286ecff1d5a7e967207c04e3b98a11d3",
    "message": "Improved Javadoc for `Cache#invalidate(key)` (fixes #284)",
    "date": "2019-08-04T18:59:03Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2ce49a45286ecff1d5a7e967207c04e3b98a11d3",
    "details": {
      "sha": "dfd63557163c98c179e8270e7576fd9b99275770",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Cache.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2ce49a45286ecff1d5a7e967207c04e3b98a11d3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2ce49a45286ecff1d5a7e967207c04e3b98a11d3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java?ref=2ce49a45286ecff1d5a7e967207c04e3b98a11d3",
      "patch": "@@ -153,7 +153,7 @@ default Map<K, V> getAll(@NonNull Iterable<? extends @NonNull K> keys,\n \n   /**\n    * Discards any cached value for the {@code key}. The behavior of this operation is undefined for\n-   * an entry that is being loaded and is otherwise not present.\n+   * an entry that is being loaded (or reloaded) and is otherwise not present.\n    *\n    * @param key the key whose mapping is to be removed from the cache\n    * @throws NullPointerException if the specified key is null\n@@ -162,7 +162,7 @@ default Map<K, V> getAll(@NonNull Iterable<? extends @NonNull K> keys,\n \n   /**\n    * Discards any cached values for the {@code keys}. The behavior of this operation is undefined\n-   * for an entry that is being loaded and is otherwise not present.\n+   * for an entry that is being loaded (or reloaded) and is otherwise not present.\n    *\n    * @param keys the keys whose associated values are to be removed\n    * @throws NullPointerException if the specified collection is null or contains a null element\n@@ -171,7 +171,7 @@ default Map<K, V> getAll(@NonNull Iterable<? extends @NonNull K> keys,\n \n   /**\n    * Discards all entries in the cache. The behavior of this operation is undefined for an entry\n-   * that is being loaded and is otherwise not present.\n+   * that is being loaded (or reloaded) and is otherwise not present.\n    */\n   void invalidateAll();\n ",
      "parent_sha": "6c72ccd0c538f03e51e19653bf50c00c459bfdfc"
    }
  },
  {
    "oid": "29389bef6351bad4b60e8d432a5d1cb208d2db52",
    "message": "Fix error message",
    "date": "2018-07-18T16:43:00Z",
    "url": "https://github.com/ben-manes/caffeine/commit/29389bef6351bad4b60e8d432a5d1cb208d2db52",
    "details": {
      "sha": "ce8a49da16962650cedb1b71c697ccc807d9c587",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/29389bef6351bad4b60e8d432a5d1cb208d2db52/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/29389bef6351bad4b60e8d432a5d1cb208d2db52/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=29389bef6351bad4b60e8d432a5d1cb208d2db52",
      "patch": "@@ -553,7 +553,7 @@ public Caffeine<K, V> expireAfterWrite(@NonNull Duration duration) {\n   public Caffeine<K, V> expireAfterWrite(@NonNegative long duration, @NonNull TimeUnit unit) {\n     requireState(expireAfterWriteNanos == UNSET_INT,\n         \"expireAfterWrite was already set to %s ns\", expireAfterWriteNanos);\n-    requireState(expiry == null, \"expireAfterAccess may not be used with variable expiration\");\n+    requireState(expiry == null, \"expireAfterWrite may not be used with variable expiration\");\n     requireArgument(duration >= 0, \"duration cannot be negative: %s %s\", duration, unit);\n     this.expireAfterWriteNanos = unit.toNanos(duration);\n     return this;",
      "parent_sha": "e8ff6d3261e7f5666d2b486352cc04b2874d70ed"
    }
  },
  {
    "oid": "757f6d5d99dec825421378db99cd2e8e0869cee3",
    "message": "Fix jmh benchmark for timerWheel",
    "date": "2019-12-23T09:21:56Z",
    "url": "https://github.com/ben-manes/caffeine/commit/757f6d5d99dec825421378db99cd2e8e0869cee3",
    "details": {
      "sha": "509571ee7ce6a77a2b9bf245745b3b8549a9ae98",
      "filename": "caffeine/src/jmh/java/com/github/benmanes/caffeine/cache/TimerWheelBenchmark.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/757f6d5d99dec825421378db99cd2e8e0869cee3/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FTimerWheelBenchmark.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/757f6d5d99dec825421378db99cd2e8e0869cee3/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FTimerWheelBenchmark.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FTimerWheelBenchmark.java?ref=757f6d5d99dec825421378db99cd2e8e0869cee3",
      "patch": "@@ -76,8 +76,9 @@ public void expire(ThreadState threadState) {\n     long time = times[threadState.index++ & MASK];\n     timer.setVariableTime(time);\n     timerWheel.nanos = (time - DELTA);\n-    timerWheel.advance(time);\n+    timerWheel.deschedule(timer);\n     timerWheel.schedule(timer);\n+    timerWheel.advance(time);\n   }\n \n   @Benchmark",
      "parent_sha": "fb4eae754570311d5bbecbd48682eafdc10f5c55"
    }
  },
  {
    "oid": "245ed6a33324a0e4048f6eb220b2e6360f64bb11",
    "message": "Add AsyncLoadingCache versions to RefreshAfterWriteTest",
    "date": "2015-10-12T00:28:19Z",
    "url": "https://github.com/ben-manes/caffeine/commit/245ed6a33324a0e4048f6eb220b2e6360f64bb11",
    "details": {
      "sha": "8c9a449ca29265ee6ef96761bfe178a135a207d8",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/RefreshAfterWriteTest.java",
      "status": "modified",
      "additions": 65,
      "deletions": 1,
      "changes": 66,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/245ed6a33324a0e4048f6eb220b2e6360f64bb11/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRefreshAfterWriteTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/245ed6a33324a0e4048f6eb220b2e6360f64bb11/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRefreshAfterWriteTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRefreshAfterWriteTest.java?ref=245ed6a33324a0e4048f6eb220b2e6360f64bb11",
      "patch": "@@ -17,6 +17,7 @@\n \n import static com.github.benmanes.caffeine.cache.testing.HasRemovalNotifications.hasRemovalNotifications;\n import static com.github.benmanes.caffeine.testing.IsEmptyMap.emptyMap;\n+import static com.github.benmanes.caffeine.testing.IsFutureValue.futureOf;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.is;\n@@ -71,6 +72,20 @@ public void getIfPresent(LoadingCache<Integer, Integer> cache, CacheContext cont\n     assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n   }\n \n+  @CheckNoWriter\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE, loader = Loader.NEGATIVE,\n+      population = { Population.SINGLETON, Population.PARTIAL, Population.FULL })\n+  public void getIfPresent(AsyncLoadingCache<Integer, Integer> cache, CacheContext context) {\n+    context.ticker().advance(30, TimeUnit.SECONDS);\n+    assertThat(cache.getIfPresent(context.middleKey()), is(futureOf(-context.middleKey())));\n+    context.ticker().advance(45, TimeUnit.SECONDS);\n+    assertThat(cache.getIfPresent(context.middleKey()), is(futureOf(-context.middleKey())));\n+\n+    assertThat(cache.synchronous().estimatedSize(), is(context.initialSize()));\n+    assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n+  }\n+\n   @CheckNoWriter\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE,\n@@ -101,6 +116,21 @@ public void get_mappingFun(LoadingCache<Integer, Integer> cache, CacheContext co\n     assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n   }\n \n+  @CheckNoWriter\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE,\n+      population = { Population.PARTIAL, Population.FULL })\n+  public void get_mappingFun(AsyncLoadingCache<Integer, Integer> cache, CacheContext context) {\n+    Function<Integer, Integer> mappingFunction = context.original()::get;\n+    context.ticker().advance(30, TimeUnit.SECONDS);\n+    cache.get(context.firstKey(), mappingFunction);\n+    context.ticker().advance(45, TimeUnit.SECONDS);\n+    cache.get(context.lastKey(), mappingFunction); // refreshed\n+\n+    assertThat(cache.synchronous().estimatedSize(), is(context.initialSize()));\n+    assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n+  }\n+\n   @CheckNoWriter\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE,\n@@ -115,6 +145,20 @@ public void get(LoadingCache<Integer, Integer> cache, CacheContext context) {\n     assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n   }\n \n+  @CheckNoWriter\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE,\n+      population = { Population.PARTIAL, Population.FULL })\n+  public void get(AsyncLoadingCache<Integer, Integer> cache, CacheContext context) {\n+    context.ticker().advance(30, TimeUnit.SECONDS);\n+    cache.get(context.firstKey());\n+    cache.get(context.absentKey());\n+    context.ticker().advance(45, TimeUnit.SECONDS);\n+\n+    assertThat(cache.getIfPresent(context.absentKey()), is(futureOf(-context.absentKey())));\n+    assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n+  }\n+\n   @CheckNoWriter\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE, loader = Loader.IDENTITY,\n@@ -135,6 +179,26 @@ public void getAll(LoadingCache<Integer, Integer> cache, CacheContext context) {\n     assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n   }\n \n+  @CheckNoWriter\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(refreshAfterWrite = Expire.ONE_MINUTE, loader = Loader.IDENTITY,\n+      population = { Population.PARTIAL, Population.FULL })\n+  public void getAll(AsyncLoadingCache<Integer, Integer> cache, CacheContext context) {\n+    List<Integer> keys = ImmutableList.of(context.firstKey(), context.absentKey());\n+    context.ticker().advance(30, TimeUnit.SECONDS);\n+    assertThat(cache.getAll(keys), is(futureOf(ImmutableMap.of(context.firstKey(),\n+        -context.firstKey(), context.absentKey(), context.absentKey()))));\n+\n+    // Trigger a refresh, may return old values\n+    context.ticker().advance(45, TimeUnit.SECONDS);\n+    cache.getAll(keys);\n+\n+    // Ensure new values are present\n+    assertThat(cache.getAll(keys), is(futureOf(ImmutableMap.of(context.firstKey(),\n+        context.firstKey(), context.absentKey(), context.absentKey()))));\n+    assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.REPLACED));\n+  }\n+\n   /* ---------------- Policy -------------- */\n \n   @Test(dataProvider = \"caches\")\n@@ -146,7 +210,7 @@ public void getExpiresAfter(\n \n   @Test(dataProvider = \"caches\")\n   @CacheSpec(implementation = Implementation.Caffeine, refreshAfterWrite = Expire.ONE_MINUTE)\n-  public void setExpiresAfter(Cache<Integer, Integer> cache, CacheContext context,\n+  public void setExpiresAfter(CacheContext context,\n       @RefreshAfterWrite Expiration<Integer, Integer> refreshAfterWrite) {\n     refreshAfterWrite.setExpiresAfter(2, TimeUnit.MINUTES);\n     assertThat(refreshAfterWrite.getExpiresAfter(TimeUnit.MINUTES), is(2L));",
      "parent_sha": "493e9c98d5f36ee6fd10d51afa9c9a24f92b4314"
    }
  },
  {
    "oid": "1986ab81347c7430e3675451d1ef6da6cdc36957",
    "message": "Avoid overflow on LIRS simulation (fixes #377)",
    "date": "2019-12-12T21:16:14Z",
    "url": "https://github.com/ben-manes/caffeine/commit/1986ab81347c7430e3675451d1ef6da6cdc36957",
    "details": {
      "sha": "ad6be10804be306d02b31e0188f9df91b532abca",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/irr/LirsPolicy.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/1986ab81347c7430e3675451d1ef6da6cdc36957/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/1986ab81347c7430e3675451d1ef6da6cdc36957/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Firr%2FLirsPolicy.java?ref=1986ab81347c7430e3675451d1ef6da6cdc36957",
      "patch": "@@ -302,7 +302,7 @@ public void finished() {\n     checkState(sizeHot <= maximumHotSize);\n     checkState(residentSize <= maximumSize);\n     checkState(sizeNR <=  maximumNonResidentSize);\n-    checkState(data.size() <= (maximumSize + maximumNonResidentSize));\n+    checkState(data.size() <= ((long) maximumSize + maximumNonResidentSize));\n     checkState(sizeS == data.values().stream().filter(node -> node.isInS).count());\n     checkState(sizeQ == data.values().stream().filter(node -> node.isInQ).count());\n ",
      "parent_sha": "aa0cdfad2e94e4a39432f7d27f43ff0a3e25755a"
    }
  },
  {
    "oid": "37f6ad303eb4474cd8a644551d528dfda37c5bfc",
    "message": "Optimize entry size when the singleton weigher is used\n\nIn this case the cache acts the same as maximumSize, but the caller\nconstructed using maximumWeight + weigher. The per-entry weight field\nis not needed, so the maximumSize's entry should be used instead. This\nallows optimizing when configured like in [1].\n\n[1] https://gerrit-review.googlesource.com/c/gerrit/+/244612",
    "date": "2019-11-09T20:02:52Z",
    "url": "https://github.com/ben-manes/caffeine/commit/37f6ad303eb4474cd8a644551d528dfda37c5bfc",
    "details": {
      "sha": "96b2db546fa963755d0c9f09e2da2af46662898c",
      "filename": "caffeine/src/javaPoet/java/com/github/benmanes/caffeine/cache/NodeSelectorCode.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/37f6ad303eb4474cd8a644551d528dfda37c5bfc/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeSelectorCode.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/37f6ad303eb4474cd8a644551d528dfda37c5bfc/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeSelectorCode.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeSelectorCode.java?ref=37f6ad303eb4474cd8a644551d528dfda37c5bfc",
      "patch": "@@ -81,7 +81,8 @@ private NodeSelectorCode maximum() {\n     block\n         .beginControlFlow(\"if (builder.evicts())\")\n             .addStatement(\"sb.append('M')\")\n-            .beginControlFlow(\"if ((isAsync && builder.evicts()) || builder.isWeighted())\")\n+            .beginControlFlow(\"if (isAsync \"\n+                + \"|| (builder.isWeighted() && (builder.weigher != Weigher.singletonWeigher())))\")\n                 .addStatement(\"sb.append('W')\")\n             .nextControlFlow(\"else\")\n                 .addStatement(\"sb.append('S')\")",
      "parent_sha": "eda7b1084ebfac76a7e60e8915cc16a23267ff53"
    }
  },
  {
    "oid": "bb8360553392abbdd566a87bbfc7c2c776414dcf",
    "message": "Fix #4 JavaDoc on EliminationStack",
    "date": "2015-01-06T10:51:30Z",
    "url": "https://github.com/ben-manes/caffeine/commit/bb8360553392abbdd566a87bbfc7c2c776414dcf",
    "details": {
      "sha": "8aa3987c36bad61ebe7d5afc466cec9beb40f580",
      "filename": "src/main/java/com/github/benmanes/caffeine/EliminationStack.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/bb8360553392abbdd566a87bbfc7c2c776414dcf/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStack.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/bb8360553392abbdd566a87bbfc7c2c776414dcf/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStack.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStack.java?ref=bb8360553392abbdd566a87bbfc7c2c776414dcf",
      "patch": "@@ -38,7 +38,7 @@\n \n /**\n  * An unbounded thread-safe stack based on linked nodes. This stack orders elements LIFO\n- * (last-in-last-out). The <em>top</em> of the stack is that element that has been on the stack\n+ * (last-in-first-out). The <em>top</em> of the stack is that element that has been on the stack\n  * the shortest time. New elements are inserted at and retrieved from the top of the stack. A\n  * {@code EliminationStack} is an appropriate choice when many threads will exchange elements\n  * through shared access to a common collection. Like most other concurrent collection",
      "parent_sha": "a1a5bf94350aebfbb2bfcd02b7892f1eda35c387"
    }
  },
  {
    "oid": "e34797d1c2bd39b8337a66575153a7063db96b1f",
    "message": "Fix a thread-safe issue of schedule. (#697)\n\nThe variable \"schedule\" is accessed by multiple threads. The usage of\r\nschedule in synchronized block has memory visibility to other threads,\r\nbut the usage out of synchronized does not. Therefore, the variable\r\n\"schedule\" should be decorated with volatile or AtomicReference.",
    "date": "2022-04-16T18:45:48Z",
    "url": "https://github.com/ben-manes/caffeine/commit/e34797d1c2bd39b8337a66575153a7063db96b1f",
    "details": {
      "sha": "4fb14280a1ac73bb99d72d52bf667af650e30653",
      "filename": "examples/coalescing-bulkloader/src/main/java/com/github/benmanes/caffeine/examples/coalescing/bulkloader/CoalescingBulkloader.java",
      "status": "modified",
      "additions": 14,
      "deletions": 9,
      "changes": 23,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/e34797d1c2bd39b8337a66575153a7063db96b1f/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/e34797d1c2bd39b8337a66575153a7063db96b1f/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/examples%2Fcoalescing-bulkloader%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fexamples%2Fcoalescing%2Fbulkloader%2FCoalescingBulkloader.java?ref=e34797d1c2bd39b8337a66575153a7063db96b1f",
      "patch": "@@ -31,6 +31,7 @@\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.ScheduledFuture;\n import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n import java.util.function.Consumer;\n import java.util.function.Function;\n import java.util.stream.Stream;\n@@ -53,7 +54,7 @@ public class CoalescingBulkloader<Key, Value> implements AsyncCacheLoader<Key, V\n   private final long maxDelay; // maximum time between request of a value and loading it\n   private final Queue<WaitingKey<Key, Value>> waitingKeys = new ConcurrentLinkedQueue<>();\n   private final ScheduledExecutorService timer = Executors.newSingleThreadScheduledExecutor();\n-  private ScheduledFuture<?> schedule;\n+  private final AtomicReference<ScheduledFuture<?>> schedule = new AtomicReference<>();\n   // Queue.size() is expensive, so here we keep track of the queue size separately\n   private final AtomicInteger size = new AtomicInteger(0);\n \n@@ -175,16 +176,21 @@ public CompletableFuture<Value> asyncLoad(Key key, Executor executor) {\n \n     if (size.incrementAndGet() >= maxLoadSize) {\n       doLoad();\n-    } else if (schedule == null || schedule.isDone()) {\n-      startWaiting();\n+    } else {\n+      ScheduledFuture<?> existingSchedule = schedule.get();\n+      if (existingSchedule == null || existingSchedule.isDone()) {\n+        startWaiting();\n+      }\n     }\n \n     return waitingKey.future;\n   }\n \n-  private synchronized void startWaiting() {\n-    if (schedule != null) schedule.cancel(false);\n-    schedule = timer.schedule(this::doLoad, maxDelay, MILLISECONDS);\n+  private void startWaiting() {\n+    ScheduledFuture<?> oldSchedule = schedule.getAndSet(timer.schedule(this::doLoad, maxDelay, MILLISECONDS));\n+    if (oldSchedule != null) {\n+      oldSchedule.cancel(false);\n+    }\n   }\n \n   private synchronized void doLoad() {\n@@ -209,11 +215,10 @@ private synchronized void doLoad() {\n     } while (size.get() >= maxLoadSize);\n     final WaitingKey<Key, Value> nextWaitingKey = waitingKeys.peek();\n     if (nextWaitingKey != null) {\n-      schedule =\n-          timer.schedule(\n+      schedule.set(timer.schedule(\n               this::doLoad,\n               nextWaitingKey.waitingSince + maxDelay - System.currentTimeMillis(),\n-              MILLISECONDS);\n+              MILLISECONDS));\n     }\n   }\n }",
      "parent_sha": "949b797638bc3bc27a631c4a62c2a80d687547de"
    }
  },
  {
    "oid": "30ca3d80d9dc7aa20adceacfc5fff1659bbadb8e",
    "message": "A big nasty version of compute() that might actually work!",
    "date": "2014-12-28T00:20:45Z",
    "url": "https://github.com/ben-manes/caffeine/commit/30ca3d80d9dc7aa20adceacfc5fff1659bbadb8e",
    "details": {
      "sha": "96cb612172ec6488cf9e78501c78fd7cbd9cf8fa",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 93,
      "deletions": 54,
      "changes": 147,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/30ca3d80d9dc7aa20adceacfc5fff1659bbadb8e/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/30ca3d80d9dc7aa20adceacfc5fff1659bbadb8e/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=30ca3d80d9dc7aa20adceacfc5fff1659bbadb8e",
      "patch": "@@ -482,6 +482,27 @@ void drainWriteBuffer() {\n     }\n   }\n \n+  /**\n+   * Attempts to transition the node from the <tt>alive</tt> state to the\n+   * <tt>retired</tt> state.\n+   *\n+   * @param node the entry in the page replacement policy\n+   * @param expect the expected weighted value\n+   * @return if successful\n+   */\n+  boolean tryToRetire(Node<K, V> node, WeightedValue<V> expect) {\n+    if (expect.isAlive()) {\n+      final WeightedValue<V> retired = new WeightedValue<V>(expect.value, -expect.weight);\n+      synchronized (node) {\n+        if (node.get() == expect) {\n+          node.lazySet(retired);\n+          return true;\n+        }\n+      }\n+    }\n+    return false;\n+  }\n+\n   /**\n    * Atomically transitions the node from the <tt>alive</tt> state to the\n    * <tt>retired</tt> state, if a valid transition.\n@@ -795,28 +816,29 @@ public boolean remove(Object key, Object value) {\n     }\n \n     WeightedValue<V> weightedValue = node.get();\n-    if (!weightedValue.contains(value) || !weightedValue.isAlive()) {\n-      return false;\n-    }\n-    synchronized (node) {\n-      weightedValue = node.get();\n-      if (!weightedValue.contains(value) || !weightedValue.isAlive()) {\n-        return false;\n-      }\n-      if (!data.remove(key, node)) {\n-        return false;\n+    for (;;) {\n+      if (weightedValue.contains(value)) {\n+        if (tryToRetire(node, weightedValue)) {\n+          if (data.remove(key, node)) {\n+            if (hasRemovalListener()) {\n+              @SuppressWarnings(\"unchecked\")\n+              K castKey = (K) key;\n+              notifyRemoval(castKey, node.getValue(), RemovalCause.EXPLICIT);\n+            }\n+            afterWrite(new RemovalTask(node));\n+            return true;\n+          }\n+        } else {\n+          weightedValue = node.get();\n+          if (weightedValue.isAlive()) {\n+            // retry as an intermediate update may have replaced the value with\n+            // an equal instance that has a different reference identity\n+            continue;\n+          }\n+        }\n       }\n-      final WeightedValue<V> retired = new WeightedValue<V>(\n-          weightedValue.value, -weightedValue.weight);\n-      node.lazySet(retired);\n-    }\n-    if (hasRemovalListener()) {\n-      @SuppressWarnings(\"unchecked\")\n-      K castKey = (K) key;\n-      notifyRemoval(castKey, node.getValue(), RemovalCause.EXPLICIT);\n+      return false;\n     }\n-    afterWrite(new RemovalTask(node));\n-    return true;\n   }\n \n   @Override\n@@ -963,57 +985,74 @@ public V computeIfPresent(K key,\n     return (weightedValue[0] == null) ? null : weightedValue[0].value;\n   }\n \n-  /**\n-     * V oldValue = map.get(key);\n-     * V newValue = remappingFunction.apply(key, oldValue);\n-     * if (oldValue != null ) {\n-     *    if (newValue != null)\n-     *       map.put(key, newValue);\n-     *    else\n-     *       map.remove(key);\n-     * } else {\n-     *    if (newValue != null)\n-     *       map.put(key, newValue);\n-     *    else\n-     *       return null;\n-     * }\n-     * }\n-   */\n   @Override\n   public V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {\n     requireNonNull(remappingFunction);\n \n-    if (true) {\n-      return super.compute(key, remappingFunction);\n-    }\n-\n-    Runnable[] task = new Runnable[0];\n-\n-    Node<K, V> node = data.compute(key, (k, prior) -> {\n+    @SuppressWarnings(\"unchecked\")\n+    V[] newValue = (V[]) new Object[1];\n+    Runnable[] task = new Runnable[2];\n+    data.compute(key, (k, prior) -> {\n       if (prior == null) {\n-        V newValue = remappingFunction.apply(k, null);\n-        if (newValue == null) {\n+        newValue[0] = remappingFunction.apply(k, null);\n+        if (newValue[0] == null) {\n           return null;\n         }\n-        final int weight = weigher.weigh(key, newValue);\n-        final WeightedValue<V> weightedValue = new WeightedValue<V>(newValue, weight);\n+        final int weight = weigher.weigh(key, newValue[0]);\n+        final WeightedValue<V> weightedValue = new WeightedValue<V>(newValue[0], weight);\n         final Node<K, V> newNode = new Node<K, V>(key, weightedValue);\n         task[0] = new AddTask(newNode, weight);\n         return newNode;\n       }\n       synchronized (prior) {\n         WeightedValue<V> oldWeightedValue = prior.get();\n-        if (!oldWeightedValue.isAlive()) {\n-          // conditionally removed\n+        V oldValue;\n+        if (oldWeightedValue.isAlive()) {\n+          oldValue = oldWeightedValue.value;\n+        } else {\n+          // conditionally removed won, but we got the entry lock first\n+          // so help out and pretend like we are inserting a fresh entry\n+          task[1] = new RemovalTask(prior);\n+          if (hasRemovalListener()) {\n+            notifyRemoval(key, oldWeightedValue.value, RemovalCause.EXPLICIT);\n+          }\n+          oldValue = null;\n+        }\n+        newValue[0] = remappingFunction.apply(k, oldValue);\n+        if ((newValue[0] == null) && (oldValue != null)) {\n+          task[0] = new RemovalTask(prior);\n+          if (hasRemovalListener()) {\n+            notifyRemoval(key, oldWeightedValue.value, RemovalCause.EXPLICIT);\n+          }\n           return null;\n         }\n+        final int weight = weigher.weigh(key, newValue[0]);\n+        final WeightedValue<V> weightedValue = new WeightedValue<V>(newValue[0], weight);\n+        Node<K, V> newNode;\n+        if (task[1] == null) {\n+          newNode = prior;\n+          prior.lazySet(weightedValue);\n+          final int weightedDifference = weight - oldWeightedValue.weight;\n+          if (weightedDifference != 0) {\n+            task[0] = new UpdateTask(prior, weightedDifference);\n+          }\n+          if (hasRemovalListener()) {\n+            notifyRemoval(key, oldWeightedValue.value, RemovalCause.REPLACED);\n+          }\n+        } else {\n+          newNode = new Node<>(key, weightedValue);\n+          task[0] = new AddTask(newNode, weight);\n+        }\n+        return prior;\n       }\n-      V newValue = remappingFunction.apply(k, null);\n-\n-      // update\n-      return null;\n     });\n-    return null;\n+    if (task[0] != null) {\n+      afterWrite(task[0]);\n+    }\n+    if (task[1] != null) {\n+      afterWrite(task[1]);\n+    }\n+    return newValue[0];\n   }\n \n   /**",
      "parent_sha": "e91f9d320e9fa9e1d595a5a0307960195b7ab936"
    }
  },
  {
    "oid": "0df8cddd1640150a909faf7d78b88724d00f4068",
    "message": "First proof that multi-threaded SCQ works!",
    "date": "2014-12-16T12:11:08Z",
    "url": "https://github.com/ben-manes/caffeine/commit/0df8cddd1640150a909faf7d78b88724d00f4068",
    "details": {
      "sha": "72a95d6ef8b69afaea2c12582d799b4479529056",
      "filename": "src/test/java/com/github/benmanes/caffeine/SingleConsumerQueueTest.java",
      "status": "modified",
      "additions": 15,
      "deletions": 1,
      "changes": 16,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/0df8cddd1640150a909faf7d78b88724d00f4068/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueueTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/0df8cddd1640150a909faf7d78b88724d00f4068/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueueTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueueTest.java?ref=0df8cddd1640150a909faf7d78b88724d00f4068",
      "patch": "@@ -44,7 +44,9 @@\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n public class SingleConsumerQueueTest {\n-  private static final int POPULATED_SIZE = 5;\n+  private static final int NUM_THREADS = 10;\n+  private static final int POPULATED_SIZE = 100;\n+\n \n   @Test(dataProvider = \"empty\")\n   public void clear_whenEmpty(Queue<?> queue) {\n@@ -375,6 +377,18 @@ public void serializable(Queue<Integer> queue) {\n         elementsEqual(queue.iterator(), copy.iterator()));\n   }\n \n+  /* ---------------- Concurrency -------------- */\n+\n+  @Test(dataProvider = \"empty\")\n+  public void multithreaded(Queue<Integer> queue) {\n+    ConcurrentTestHarness.timeTasks(NUM_THREADS, () -> {\n+      for (int i = 0; i < POPULATED_SIZE; i++) {\n+        queue.add(i);\n+      }\n+    });\n+    assertThat(queue, hasSize(NUM_THREADS * POPULATED_SIZE));\n+  }\n+\n   /* ---------------- Queue providers -------------- */\n \n   @DataProvider(name = \"empty\")",
      "parent_sha": "ac0eab17287acc0310e6d8b656725ba4c30802ba"
    }
  },
  {
    "oid": "db918ed21b9df78b09e609e528a962f317bcca74",
    "message": "getOrDefault tests",
    "date": "2014-12-25T00:46:51Z",
    "url": "https://github.com/ben-manes/caffeine/commit/db918ed21b9df78b09e609e528a962f317bcca74",
    "details": {
      "sha": "355398b7fcf78afd0bb81aa98c7b727a3bfe6354",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/AsMapTest.java",
      "status": "modified",
      "additions": 26,
      "deletions": 3,
      "changes": 29,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/db918ed21b9df78b09e609e528a962f317bcca74/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/db918ed21b9df78b09e609e528a962f317bcca74/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java?ref=db918ed21b9df78b09e609e528a962f317bcca74",
      "patch": "@@ -130,6 +130,12 @@ public void get_null(Map<Integer, Integer> map) {\n     map.get(null);\n   }\n \n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void get_absent(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map.get(context.absentKey()), is(nullValue()));\n+  }\n+\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n       removalListener = { Listener.DEFAULT, Listener.REJECTING })\n@@ -139,10 +145,28 @@ public void get_present(Map<Integer, Integer> map, CacheContext context) {\n     }\n   }\n \n+  /* ---------------- get -------------- */\n+\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(dataProvider = \"caches\", expectedExceptions = NullPointerException.class)\n+  public void getOrDefault_nullKey(Map<Integer, Integer> map) {\n+    map.getOrDefault(null, 1);\n+  }\n+\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void get_absent(Map<Integer, Integer> map, CacheContext context) {\n-    assertThat(map.get(context.absentKey()), is(nullValue()));\n+  public void getOrDefault_default(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map.getOrDefault(context.absentKey(), null), is(nullValue()));\n+    assertThat(map.getOrDefault(context.absentKey(), context.absentKey()), is(context.absentKey()));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n+      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void getOrDefault_present(Map<Integer, Integer> map, CacheContext context) {\n+    for (Integer key : context.firstMiddleLastKeys()) {\n+      assertThat(map.getOrDefault(key, context.absentKey()), is(-key));\n+    }\n   }\n \n   /* ---------------- put -------------- */\n@@ -588,7 +612,6 @@ public void serialize(Map<Integer, Integer> map) {\n   }\n \n   /* ---------------- V8 default methods -------------- */\n-  public void getOrDefault() {}\n   public void forEach() {}\n   public void replaceAll() {}\n   public void computeIfAbsent() {}",
      "parent_sha": "b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2"
    }
  },
  {
    "oid": "c3ac6608a6c6e8d681aaf475e1aed9c931bce2a8",
    "message": "Restore write time on failed refresh\n\nReviewing refresh after @abatkin's inquiry resulted in a few\nobservations worth correcting.\n\nA refresh may be scheduled but an explicit write updates the entry\nbefore it starts. In this race the refresh can be cancelled and should\nno-op.\n\nA refreh that fails should let the entry expire based on its original\ntime-to-live. This was being extended by not reverting back the last\nwrite time.\n\nRefresh is documented to not propogate the exception. Instead it should\nswallow and log it, as done in LoadingCache#refresh(). The exception\nshouldn't reach the executor, which would violate the contract if a\nsame-thread executor was used.\n\nBecause we update the write-time to exclusively trigger a refresh to not\nthrash the executor, expire-after-write is not as strict. If the\nscheduled refresh is queued by the executor for an excessive time or is\nvery slow to complete, then the entry may have expired. Currently the\nold value is returned, but arguably a load should be triggered instead.\nThen either the load or refresh would complete, a fresh value returned,\nand the other thread cancelled.\n\nGuava works around this with its custom computation logic based on\nfutures. Instead of updating the write time, it schedules and checks if\nthe value is being reloaded. As Java 8's compute isn't future based and\nlacks that type of inspection, we would need our own refresh flag per\nentry. That is a poor memory trade-off, so this edge case seems not\nworth covering. Usually we'd steal the sign bit from the write-time,\nbut technically System.nanoTime() may return negative values. So this\ncase is left as wait, see if users complain, and brainstorm how to steal\na bit flag to avoid the waste.",
    "date": "2016-01-03T09:12:12Z",
    "url": "https://github.com/ben-manes/caffeine/commit/c3ac6608a6c6e8d681aaf475e1aed9c931bce2a8",
    "details": {
      "sha": "e059cc9aab8ec79dce798a8f7587582f6ebfda1b",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 11,
      "deletions": 2,
      "changes": 13,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/c3ac6608a6c6e8d681aaf475e1aed9c931bce2a8/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/c3ac6608a6c6e8d681aaf475e1aed9c931bce2a8/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=c3ac6608a6c6e8d681aaf475e1aed9c931bce2a8",
      "patch": "@@ -828,13 +828,22 @@ void refreshIfNeeded(Node<K, V> node, long now) {\n         executor().execute(() -> {\n           K key = node.getKey();\n           if ((key != null) && node.isAlive()) {\n-            computeIfPresent(key, (k, v) -> {\n+            BiFunction<? super K, ? super V, ? extends V> refreshFunction = (k, v) -> {\n+              if (node.getWriteTime() != now) {\n+                return v;\n+              }\n               try {\n                 return cacheLoader().reload(k, v);\n               } catch (Exception e) {\n+                node.setWriteTime(writeTime);\n                 return LocalCache.throwUnchecked(e);\n               }\n-            });\n+            };\n+            try {\n+              computeIfPresent(key, refreshFunction);\n+            } catch (Throwable t) {\n+              logger.log(Level.WARNING, \"Exception thrown during refresh\", t);\n+            }\n           }\n         });\n       } catch (Throwable t) {",
      "parent_sha": "e7912f77808e84dc1633ded248f12705cd28bd66"
    }
  },
  {
    "oid": "750039cadc7790b8343b547edf716846da56364e",
    "message": "compute tests",
    "date": "2014-12-25T04:53:20Z",
    "url": "https://github.com/ben-manes/caffeine/commit/750039cadc7790b8343b547edf716846da56364e",
    "details": {
      "sha": "dbe3723e356099d4f1260f0578bd0eed4d53cc71",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/AsMapTest.java",
      "status": "modified",
      "additions": 102,
      "deletions": 4,
      "changes": 106,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/750039cadc7790b8343b547edf716846da56364e/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/750039cadc7790b8343b547edf716846da56364e/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java?ref=750039cadc7790b8343b547edf716846da56364e",
      "patch": "@@ -763,6 +763,108 @@ public void computeIfPresent_present(Map<Integer, Integer> map, CacheContext con\n     assertThat(map, hasRemovalNotifications(context, count, RemovalCause.REPLACED));\n   }\n \n+  /* ---------------- compute -------------- */\n+\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(dataProvider = \"caches\", expectedExceptions = NullPointerException.class)\n+  public void compute_nullKey(Map<Integer, Integer> map) {\n+    map.compute(null, (key, value) -> -key);\n+  }\n+\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(dataProvider = \"caches\", expectedExceptions = NullPointerException.class)\n+  public void compute_nullMappingFunction(Map<Integer, Integer> map) {\n+    map.computeIfPresent(1, null);\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL })\n+  public void compute_nullValue(Map<Integer, Integer> map, CacheContext context) {\n+    for (Integer key : context.firstMiddleLastKeys()) {\n+      assertThat(map.compute(key, (k, v) -> null), is(nullValue()));\n+    }\n+\n+    int count = context.firstMiddleLastKeys().size();\n+    assertThat(map.size(), is(context.original().size() - count));\n+    assertThat(map, hasRemovalNotifications(context, count, RemovalCause.EXPLICIT));\n+  }\n+\n+  // FIXME: Requires JDK8 release with JDK-8062841 fix\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(enabled = false, dataProvider = \"caches\", expectedExceptions = StackOverflowError.class)\n+  public void compute_recursive(Map<Integer, Integer> map, CacheContext context) {\n+    BiFunction<Integer, Integer, Integer> mappingFunction =\n+        new BiFunction<Integer, Integer, Integer>() {\n+          @Override public Integer apply(Integer key, Integer value) {\n+            return map.compute(key, this);\n+          }\n+        };\n+    map.compute(context.absentKey(), mappingFunction);\n+  }\n+\n+  // FIXME: Requires JDK8 release with JDK-8062841 fix\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n+      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(enabled = false, dataProvider = \"caches\", expectedExceptions = StackOverflowError.class)\n+  public void compute_pingpong(Map<Integer, Integer> map, CacheContext context) {\n+    BiFunction<Integer, Integer, Integer> mappingFunction =\n+        new BiFunction<Integer, Integer, Integer>() {\n+          @Override public Integer apply(Integer key, Integer value) {\n+            return map.computeIfPresent(context.lastKey(), this);\n+          }\n+        };\n+    map.computeIfPresent(context.firstKey(), mappingFunction);\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void compute_error(Map<Integer, Integer> map, CacheContext context) {\n+    try {\n+      map.compute(context.absentKey(), (key, value) -> { throw new Error(); });\n+    } catch (Error e) {}\n+    assertThat(map, is(equalTo(context.original())));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void compute_absent(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map.compute(context.absentKey(), (key, value) -> -key), is(-context.absentKey()));\n+    assertThat(map.get(context.absentKey()), is(-context.absentKey()));\n+    assertThat(map.size(), is(1 + context.original().size()));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL })\n+  public void compute_sameValue(Map<Integer, Integer> map, CacheContext context) {\n+    for (Integer key : context.firstMiddleLastKeys()) {\n+      assertThat(map.compute(key, (k, v) -> -k), is(-key));\n+      assertThat(map.get(key), is(-key));\n+    }\n+    int count = context.firstMiddleLastKeys().size();\n+    assertThat(map.size(), is(context.original().size()));\n+    assertThat(map, hasRemovalNotifications(context, count, RemovalCause.REPLACED));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL })\n+  public void compute_differentValue(Map<Integer, Integer> map, CacheContext context) {\n+    for (Integer key : context.firstMiddleLastKeys()) {\n+      assertThat(map.compute(key, (k, v) -> k), is(key));\n+      assertThat(map.get(key), is(key));\n+    }\n+    int count = context.firstMiddleLastKeys().size();\n+    assertThat(map.size(), is(context.original().size()));\n+    assertThat(map, hasRemovalNotifications(context, count, RemovalCause.REPLACED));\n+  }\n+\n+  /* ---------------- merge -------------- */\n+\n+  public void merge() {}\n+\n+\n+\n+\n+\n   /* ---------------- equals / hashCode -------------- */\n \n   @Test(dataProvider = \"caches\")\n@@ -838,10 +940,6 @@ public void serialize(Map<Integer, Integer> map) {\n     SerializableTester.reserializeAndAssert(map);\n   }\n \n-  /* ---------------- V8 default methods -------------- */\n-  public void compute() {}\n-  public void merge() {}\n-\n   /* ---------------- Key Set -------------- */\n   /* ---------------- Values -------------- */\n   /* ---------------- Entry Set -------------- */",
      "parent_sha": "cb64859e7336563ba2fe4cd5b0924dd8c93c2fd0"
    }
  },
  {
    "oid": "b1d4f8f084e1cd891a1c97821eda72212ebedcb4",
    "message": "Another test",
    "date": "2015-01-12T04:49:20Z",
    "url": "https://github.com/ben-manes/caffeine/commit/b1d4f8f084e1cd891a1c97821eda72212ebedcb4",
    "details": {
      "sha": "b5f7fa26c3d510a72560d55521eaf42be2f60835",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/AsyncLoadingCacheTest.java",
      "status": "modified",
      "additions": 29,
      "deletions": 1,
      "changes": 30,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/b1d4f8f084e1cd891a1c97821eda72212ebedcb4/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/b1d4f8f084e1cd891a1c97821eda72212ebedcb4/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java?ref=b1d4f8f084e1cd891a1c97821eda72212ebedcb4",
      "patch": "@@ -294,8 +294,8 @@ public void put_insert_fail(AsyncLoadingCache<Integer, Integer> cache, CacheCont\n     assertThat(cache.synchronous().estimatedSize(), is(context.initialSize()));\n   }\n \n+  @CacheSpec\n   @Test(dataProvider = \"caches\")\n-  @CacheSpec(executor = CacheExecutor.DEFAULT)\n   public void put_insert_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n       CacheContext context) {\n     AtomicBoolean ready = new AtomicBoolean();\n@@ -328,6 +328,34 @@ public void put_insert(AsyncLoadingCache<Integer, Integer> cache, CacheContext c\n     assertThat(cache.synchronous().getIfPresent(context.absentKey()), is(context.absentValue()));\n   }\n \n+  @CacheSpec\n+  @Test(dataProvider = \"caches\")\n+  public void put_replace_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n+      CacheContext context) {\n+    AtomicBoolean ready = new AtomicBoolean();\n+    CompletableFuture<Integer> failedFuture = CompletableFuture.supplyAsync(() -> {\n+      await().untilTrue(ready);\n+      throw new IllegalStateException();\n+    });\n+\n+    Integer key = context.absentKey();\n+    cache.put(key, failedFuture);\n+\n+    CompletableFuture<Integer> successFuture =\n+        CompletableFuture.completedFuture(context.absentValue());\n+\n+    cache.put(key, successFuture);\n+    ready.set(true);\n+\n+    try {\n+      failedFuture.get();\n+    } catch (Exception ignored) {}\n+    assertThat(cache.synchronous().getIfPresent(key), is(context.absentValue()));\n+\n+    assertThat(context, both(hasMissCount(0)).and(hasHitCount(0)));\n+    assertThat(context, both(hasLoadSuccessCount(1)).and(hasLoadFailureCount(1)));\n+  }\n+\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL })\n   public void put_replace(AsyncLoadingCache<Integer, Integer> cache, CacheContext context) {",
      "parent_sha": "7538582f6c2d74086e5b336fa88c522a8d29434d"
    }
  },
  {
    "oid": "689b72607e9639261c21fb39cfc2072ee3e741d9",
    "message": "Specify when and how StatsCounter#recordLoadSuccess and recordLoadFailure events are recorded more precisely",
    "date": "2018-05-02T08:22:10Z",
    "url": "https://github.com/ben-manes/caffeine/commit/689b72607e9639261c21fb39cfc2072ee3e741d9",
    "details": {
      "sha": "753e325f9e6733a453c0c321bc0a3442487e3f84",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/stats/StatsCounter.java",
      "status": "modified",
      "additions": 10,
      "deletions": 7,
      "changes": 17,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/689b72607e9639261c21fb39cfc2072ee3e741d9/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/689b72607e9639261c21fb39cfc2072ee3e741d9/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fstats%2FStatsCounter.java?ref=689b72607e9639261c21fb39cfc2072ee3e741d9",
      "patch": "@@ -15,6 +15,8 @@\n  */\n package com.github.benmanes.caffeine.cache.stats;\n \n+import java.util.Map;\n+\n import javax.annotation.Nonnegative;\n import javax.annotation.Nonnull;\n import javax.annotation.concurrent.ThreadSafe;\n@@ -50,19 +52,20 @@ public interface StatsCounter {\n   void recordMisses(@Nonnegative int count);\n \n   /**\n-   * Records the successful load of a new entry. This should be called when a cache request causes\n-   * an entry to be loaded, and the loading completes successfully. In contrast to\n-   * {@link #recordMisses}, this method should only be called by the loading thread.\n+   * Records the successful load of a new entry. This method should be called when a cache request\n+   * causes an entry to be loaded (such as by {@link Cache#get} or {@link Map#computeIfAbsent}) and\n+   * the loading completes successfully. In contrast to {@link #recordMisses}, this method should\n+   * only be called by the loading thread.\n    *\n    * @param loadTime the number of nanoseconds the cache spent computing or retrieving the new value\n    */\n   void recordLoadSuccess(@Nonnegative long loadTime);\n \n   /**\n-   * Records the failed load of a new entry. This should be called when a cache request causes an\n-   * entry to be loaded, but either no value is found or an exception is thrown while loading the\n-   * entry. In contrast to {@link #recordMisses}, this method should only be called by the loading\n-   * thread.\n+   * Records the failed load of a new entry. This method should be called when a cache request\n+   * causes an entry to be loaded (such as by {@link Cache#get} or {@link Map#computeIfAbsent}), but\n+   * an exception is thrown while loading the entry or the loading function returns null. In\n+   * contrast to {@link #recordMisses}, this method should only be called by the loading thread.\n    *\n    * @param loadTime the number of nanoseconds the cache spent computing or retrieving the new value\n    *        prior to discovering the value doesn't exist or an exception being thrown",
      "parent_sha": "916407ea56bbb19567640da7b79ac27104bd45be"
    }
  },
  {
    "oid": "b71c63871fddcb33be848605b3010187bdf78224",
    "message": "Fix toString",
    "date": "2014-12-29T07:11:33Z",
    "url": "https://github.com/ben-manes/caffeine/commit/b71c63871fddcb33be848605b3010187bdf78224",
    "details": {
      "sha": "6f5292646e72bf49e2eb1e303b06ed680a583e55",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 15,
      "deletions": 10,
      "changes": 25,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/b71c63871fddcb33be848605b3010187bdf78224/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/b71c63871fddcb33be848605b3010187bdf78224/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=b71c63871fddcb33be848605b3010187bdf78224",
      "patch": "@@ -678,31 +678,36 @@ private void checkWeightWithWeigher() {\n    */\n   @Override\n   public String toString() {\n-    StringBuilder s = new StringBuilder();\n+    StringBuilder s = new StringBuilder(64);\n+    s.append(getClass().getSimpleName()).append('{');\n+    int baseLength = s.length();\n     if (initialCapacity != UNSET_INT) {\n-      s.append(\"initialCapacity=\").append(initialCapacity);\n+      s.append(\"initialCapacity=\").append(initialCapacity).append(',');\n     }\n     if (maximumSize != UNSET_INT) {\n-      s.append(\"maximumSize\").append(maximumSize);\n+      s.append(\"maximumSize\").append(maximumSize).append(',');\n     }\n     if (maximumWeight != UNSET_INT) {\n-      s.append(\"maximumWeight\").append(maximumWeight);\n+      s.append(\"maximumWeight\").append(maximumWeight).append(',');\n     }\n     if (expireAfterWriteNanos != UNSET_INT) {\n-      s.append(\"expireAfterWrite\").append(expireAfterWriteNanos).append(\"ns\");\n+      s.append(\"expireAfterWrite\").append(expireAfterWriteNanos).append(\"ns,\");\n     }\n     if (expireAfterAccessNanos != UNSET_INT) {\n-      s.append(\"expireAfterAccess\").append(expireAfterAccessNanos).append(\"ns\");\n+      s.append(\"expireAfterAccess\").append(expireAfterAccessNanos).append(\"ns,\");\n     }\n     if (keyStrength != null) {\n-      s.append(\"keyStrength\").append(keyStrength.toString().toLowerCase());\n+      s.append(\"keyStrength\").append(keyStrength.toString().toLowerCase()).append(',');\n     }\n     if (valueStrength != null) {\n-      s.append(\"valueStrength\").append(valueStrength.toString().toLowerCase());\n+      s.append(\"valueStrength\").append(valueStrength.toString().toLowerCase()).append(',');\n     }\n     if (removalListener != null) {\n-      s.append(\"removalListener\");\n+      s.append(\"removalListener\").append(',');\n     }\n-    return s.toString();\n+    if (s.length() > baseLength) {\n+      s.deleteCharAt(s.length() - 1);\n+    }\n+    return s.append('}').toString();\n   }\n }",
      "parent_sha": "c4adfed1893d1ebef84dc018812d6f8891d36a39"
    }
  },
  {
    "oid": "94337ab04e22e831d55bac71bdff1e88b8d7301f",
    "message": "Fix getIfPresent to record a miss if the value was collected",
    "date": "2018-05-13T01:57:26Z",
    "url": "https://github.com/ben-manes/caffeine/commit/94337ab04e22e831d55bac71bdff1e88b8d7301f",
    "details": {
      "sha": "9d9b93dbf3611120cb17efe0149ec90846723ca9",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 6,
      "deletions": 6,
      "changes": 12,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/94337ab04e22e831d55bac71bdff1e88b8d7301f/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/94337ab04e22e831d55bac71bdff1e88b8d7301f/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=94337ab04e22e831d55bac71bdff1e88b8d7301f",
      "patch": "@@ -1540,22 +1540,22 @@ public boolean containsValue(Object value) {\n       }\n       return null;\n     }\n+\n+    V value = node.getValue();\n     long now = expirationTicker().read();\n-    if (hasExpired(node, now)) {\n+    if (hasExpired(node, now) || (collectValues() && (value == null))) {\n       if (recordStats) {\n         statsCounter().recordMisses(1);\n       }\n       scheduleDrainBuffers();\n       return null;\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n-    K castedKey = (K) key;\n-    V value = node.getValue();\n-\n     if (!isComputingAsync(node)) {\n-      setVariableTime(node, expireAfterRead(node, castedKey, value, expiry(), now));\n+      @SuppressWarnings(\"unchecked\")\n+      K castedKey = (K) key;\n       setAccessTime(node, now);\n+      setVariableTime(node, expireAfterRead(node, castedKey, value, expiry(), now));\n     }\n     afterRead(node, now, recordStats);\n     return value;",
      "parent_sha": "c9d9f36ee503a0f9304e33b45328a75005ab7b25"
    }
  },
  {
    "oid": "1836b0f7476e4eeea80ce450d5b5bef28d8e7413",
    "message": "adjust when explicit puts discard a refresh\n\nReviewing this code, I don't recall exactly why it was safe to discard the\nrefresh prior to the synchronized block. Likely it was because those other\nconditions covered insert and putIfAbsent overwriting an expired entry,\nwhereas a live update will necessarily overwrite the value. Yet if a\nputIfAbsent is overwriting an expired entry, that implies that it beat an\neviction which did not discard that in-flight future. As synchronization\nmight be delayed, it would still seem like an ABA style problem could\noccur in a worst case scenario.\n\nIn all other updates the refresh is discarded within the synchronized\nblock. The refresh callback validate itself under this lock by removing\nits future and, if successful, checking the results are consistent. It\nseems safer to maintain this pattern on put, even if an unlikely or\nperhaps impossible race, if only for consistency and avoid having to\nrethink it all anew every few years when reviewing the code.",
    "date": "2022-10-21T03:47:11Z",
    "url": "https://github.com/ben-manes/caffeine/commit/1836b0f7476e4eeea80ce450d5b5bef28d8e7413",
    "details": {
      "sha": "d1324258bcd113b2949e17b3d0d069cde07e4cfd",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/1836b0f7476e4eeea80ce450d5b5bef28d8e7413/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/1836b0f7476e4eeea80ce450d5b5bef28d8e7413/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=1836b0f7476e4eeea80ce450d5b5bef28d8e7413",
      "patch": "@@ -2247,8 +2247,6 @@ public void putAll(Map<? extends K, ? extends V> map) {\n           afterRead(prior, now, /* recordHit */ false);\n           return currentValue;\n         }\n-      } else {\n-        discardRefresh(prior.getKeyReference());\n       }\n \n       V oldValue;\n@@ -2286,6 +2284,8 @@ public void putAll(Map<? extends K, ? extends V> map) {\n           prior.setValue(value, valueReferenceQueue());\n           prior.setWeight(newWeight);\n           setWriteTime(prior, now);\n+\n+          discardRefresh(prior.getKeyReference());\n         }\n \n         setVariableTime(prior, varTime);",
      "parent_sha": "749916080318067cca8428c61668eaa97157c119"
    }
  },
  {
    "oid": "7a78372b596f07bcb73fbc88b8ba6b5fc4ef5b9a",
    "message": "Fix PMD warning",
    "date": "2019-12-09T17:35:49Z",
    "url": "https://github.com/ben-manes/caffeine/commit/7a78372b596f07bcb73fbc88b8ba6b5fc4ef5b9a",
    "details": {
      "sha": "e49949e730d8b213a0459cf2f20adda69cfdc1a9",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/product/CaffeinePolicy.java",
      "status": "modified",
      "additions": 2,
      "deletions": 4,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/7a78372b596f07bcb73fbc88b8ba6b5fc4ef5b9a/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FCaffeinePolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/7a78372b596f07bcb73fbc88b8ba6b5fc4ef5b9a/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FCaffeinePolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FCaffeinePolicy.java?ref=7a78372b596f07bcb73fbc88b8ba6b5fc4ef5b9a",
      "patch": "@@ -38,18 +38,16 @@\n public final class CaffeinePolicy implements Policy {\n   private final Cache<Long, AccessEvent> cache;\n   private final PolicyStats policyStats;\n-  private final int maximumSize;\n \n   public CaffeinePolicy(Config config) {\n     policyStats = new PolicyStats(\"product.Caffeine\");\n     BasicSettings settings = new BasicSettings(config);\n-    maximumSize = settings.maximumSize();\n     cache = Caffeine.newBuilder()\n         .removalListener((Long key, AccessEvent value, RemovalCause cause) ->\n             policyStats.recordEviction())\n         .weigher((key, value) -> value.weight())\n-        .initialCapacity(maximumSize)\n-        .maximumWeight(maximumSize)\n+        .initialCapacity(settings.maximumSize())\n+        .maximumWeight(settings.maximumSize())\n         .executor(Runnable::run)\n         .build();\n   }",
      "parent_sha": "1ffb8fda8125109b8e8fb90714f383f985ddc115"
    }
  },
  {
    "oid": "c106fde749e82581d2bf332e3d4abb08f9f6e765",
    "message": "Try to avoid race within test",
    "date": "2015-02-22T02:59:45Z",
    "url": "https://github.com/ben-manes/caffeine/commit/c106fde749e82581d2bf332e3d4abb08f9f6e765",
    "details": {
      "sha": "db61fd09b09b39945fd7dd6deabeb8cbd48eee95",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/AsyncLoadingCacheTest.java",
      "status": "modified",
      "additions": 16,
      "deletions": 20,
      "changes": 36,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/c106fde749e82581d2bf332e3d4abb08f9f6e765/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/c106fde749e82581d2bf332e3d4abb08f9f6e765/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCacheTest.java?ref=c106fde749e82581d2bf332e3d4abb08f9f6e765",
      "patch": "@@ -128,12 +128,12 @@ public void getFunc_absent_null_async(AsyncLoadingCache<Integer, Integer> cache,\n       Awaits.await().untilTrue(ready);\n       return null;\n     });\n-    valueFuture.whenComplete((r, e) -> done.set(true));\n+    valueFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     ready.set(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 5, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -168,14 +168,12 @@ public void getFunc_absent_failure_async(AsyncLoadingCache<Integer, Integer> cac\n       Awaits.await().untilTrue(ready);\n       throw new IllegalStateException();\n     });\n-    valueFuture.whenComplete((r, e) -> done.set(true));\n+    valueFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     ready.set(true);\n     Awaits.await().untilTrue(done);\n-    Awaits.await().until(() -> valueFuture.getNumberOfDependents(), is(0));\n-\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -194,12 +192,12 @@ public void getFunc_absent_cancelled(AsyncLoadingCache<Integer, Integer> cache,\n       Awaits.await().until(() -> done.get());\n       return null;\n     });\n-    valueFuture.whenComplete((r, e) -> done.set(true));\n+    valueFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n     valueFuture.cancel(true);\n \n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -313,14 +311,14 @@ public void getBiFunc_absent_failure_async(AsyncLoadingCache<Integer, Integer> c\n       Awaits.await().untilTrue(ready);\n       throw new IllegalStateException();\n     });\n-    failedFuture.whenComplete((r, e) -> done.set(true));\n+    failedFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     Integer key = context.absentKey();\n     CompletableFuture<Integer> valueFuture = cache.get(key, (k, executor) -> failedFuture);\n     ready.set(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -338,14 +336,14 @@ public void getBiFunc_absent_cancelled(AsyncLoadingCache<Integer, Integer> cache\n       Awaits.await().untilTrue(done);\n       return null;\n     });\n-    failedFuture.whenComplete((r, e) -> done.set(true));\n+    failedFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     Integer key = context.absentKey();\n     CompletableFuture<Integer> valueFuture = cache.get(key, (k, executor) -> failedFuture);\n     valueFuture.cancel(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -407,16 +405,14 @@ public void get_absent_failure(AsyncLoadingCache<Integer, Integer> cache, CacheC\n   @CacheSpec(executor = CacheExecutor.SINGLE, loader = Loader.EXCEPTIONAL)\n   public void get_absent_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n       CacheContext context) throws InterruptedException {\n-    AtomicBoolean ready = new AtomicBoolean();\n     AtomicBoolean done = new AtomicBoolean();\n     Integer key = context.absentKey();\n     CompletableFuture<Integer> valueFuture = cache.get(key);\n-    valueFuture.whenComplete((r, e) -> done.set(true));\n+    valueFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n-    ready.set(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(1)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -590,14 +586,14 @@ public void put_insert_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n       Awaits.await().untilTrue(ready);\n       throw new IllegalStateException();\n     });\n-    failedFuture.whenComplete((r, e) -> done.set(true));\n+    failedFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     Integer key = context.absentKey();\n     cache.put(key, failedFuture);\n     ready.set(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(0)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(0)).and(hasLoadFailureCount(1)));\n@@ -626,7 +622,7 @@ public void put_replace_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n       Awaits.await().untilTrue(ready);\n       throw new IllegalStateException();\n     });\n-    failedFuture.whenComplete((r, e) -> done.set(true));\n+    failedFuture.whenCompleteAsync((r, e) -> done.set(true), context.executor());\n \n     Integer key = context.absentKey();\n     cache.put(key, failedFuture);\n@@ -638,7 +634,7 @@ public void put_replace_failure_async(AsyncLoadingCache<Integer, Integer> cache,\n     ready.set(true);\n     Awaits.await().untilTrue(done);\n     MoreExecutors.shutdownAndAwaitTermination(\n-        (ExecutorService) context.executor(), 1, TimeUnit.SECONDS);\n+        (ExecutorService) context.executor(), 1, TimeUnit.MINUTES);\n \n     assertThat(context, both(hasMissCount(0)).and(hasHitCount(0)));\n     assertThat(context, both(hasLoadSuccessCount(1)).and(hasLoadFailureCount(1)));",
      "parent_sha": "9b4d1ad4f33dbfde1a57e0d4c95d677da1212497"
    }
  },
  {
    "oid": "f6c6568187ff9a691cbe8c059e2e1abf3be61bf2",
    "message": "Stabilize Guava test due to internal randomness\n\nThis Guava test probably choses keys that hashed to different\nsegments and relied on LRU ordering. Caffeine is not segmented, is\nnot LRU, and has randomness to protect from HashDoS attacks. The\ntest now doesn't assume which keys are present in its operations.",
    "date": "2017-03-22T01:07:51Z",
    "url": "https://github.com/ben-manes/caffeine/commit/f6c6568187ff9a691cbe8c059e2e1abf3be61bf2",
    "details": {
      "sha": "94748874058ba7b0873ba31c84fd99ad814e3fa6",
      "filename": "guava/src/test/java/com/google/common/cache/CacheBuilderGwtTest.java",
      "status": "modified",
      "additions": 18,
      "deletions": 13,
      "changes": 31,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/f6c6568187ff9a691cbe8c059e2e1abf3be61bf2/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheBuilderGwtTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/f6c6568187ff9a691cbe8c059e2e1abf3be61bf2/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheBuilderGwtTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheBuilderGwtTest.java?ref=f6c6568187ff9a691cbe8c059e2e1abf3be61bf2",
      "patch": "@@ -33,6 +33,7 @@\n import com.google.common.annotations.GwtCompatible;\n import com.google.common.collect.ImmutableMap;\n import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n import com.google.common.collect.Sets;\n import com.google.common.testing.FakeTicker;\n import com.google.common.util.concurrent.MoreExecutors;\n@@ -299,27 +300,31 @@ public void onRemoval(Integer key, Integer value, RemovalCause cause) {\n     Arrays.fill(stats, 0);\n \n     // Add more than two elements to increment size removals.\n-    cache.put(3, 20);\n-    cache.put(6, 2);\n-    cache.put(98, 45);\n-    cache.put(56, 76);\n-    cache.put(23, 84);\n+    cache.put(1, 10);\n+    cache.put(2, 20);\n+    cache.put(3, 30);\n+    cache.put(4, 40);\n+    cache.put(5, 50);\n \n     // Replace the two present elements.\n-    cache.put(23, 20);\n-    cache.put(3, 49);\n-    cache.put(23, 2);\n-    cache.put(3, 4);\n+    Integer key1 = Iterables.get(cache.asMap().keySet(), 0);\n+    Integer key2 = Iterables.get(cache.asMap().keySet(), 1);\n+    cache.put(key1, 60);\n+    cache.put(key2, 70);\n+    cache.put(key1, 80);\n+    cache.put(key2, 90);\n \n     // Expire the two present elements.\n+    key1 = Iterables.get(cache.asMap().keySet(), 0);\n+    key2 = Iterables.get(cache.asMap().keySet(), 1);\n     fakeTicker.advance(1001, TimeUnit.MILLISECONDS);\n \n-    cache.getIfPresent(23);\n-    cache.getIfPresent(56);\n+    cache.getIfPresent(key1);\n+    cache.getIfPresent(key2);\n \n     // Add two elements and invalidate them.\n-    cache.put(1, 4);\n-    cache.put(2, 8);\n+    cache.put(6, 100);\n+    cache.put(7, 200);\n \n     cache.invalidateAll();\n ",
      "parent_sha": "f010484ebbbdeef99a38e7693dd1b384939645ce"
    }
  },
  {
    "oid": "7673954b414b7d7f7328d1cf80fab4ec030d17c0",
    "message": "Fix JCache expiry for access bug\n\nThe expiration time was accidentally set to the current time, not the\nnext expiration time (current + expiry). @marknorkin discovered this\nissue (see http://stackoverflow.com/q/34814622/19450) and now passes\nhis test.\n\nThe TCK does not verify the expiration times so the next priority must\nbe to add our own test cases. Caffeine's core expiration is well tested,\nbut JCache uses an incompatible approach requiring a custom feature. It\nmay also be worthwhile reviewing `CaffeineConfiguration` which @marknorkin\nfound confusing (http://stackoverflow.com/q/34809817/19450).",
    "date": "2016-01-16T01:07:29Z",
    "url": "https://github.com/ben-manes/caffeine/commit/7673954b414b7d7f7328d1cf80fab4ec030d17c0",
    "details": {
      "sha": "fb6146a0a5f6eba6f4ed95acbfb63d1505797509",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/CacheProxy.java",
      "status": "modified",
      "additions": 8,
      "deletions": 6,
      "changes": 14,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/7673954b414b7d7f7328d1cf80fab4ec030d17c0/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/7673954b414b7d7f7328d1cf80fab4ec030d17c0/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java?ref=7673954b414b7d7f7328d1cf80fab4ec030d17c0",
      "patch": "@@ -162,14 +162,14 @@ public V get(K key) {\n         dispatcher.awaitSynchronous();\n         statistics.recordMisses(1L);\n         return null;\n-      }      \n+      }\n     } else if (statsEnabled) {\n       start = ticker.read();\n       millis = nanosToMillis(start);\n     } else {\n       start = millis = 0L;\n     }\n-    \n+\n     setAccessExpirationTime(expirable, millis);\n     V value = copyValue(expirable);\n     if (statsEnabled) {\n@@ -1044,7 +1044,7 @@ protected static long nanosToMillis(long nanos) {\n   }\n \n   /**\n-   * Sets the expiration time based on the supplied expiration function.\n+   * Sets the access expiration time.\n    *\n    * @param expirable the entry that was operated on\n    * @param currentTimeMS the current time, or 0 if not read yet\n@@ -1059,10 +1059,12 @@ protected final void setAccessExpirationTime(Expirable<?> expirable, long curren\n         expirable.setExpireTimeMS(0L);\n       } else if (duration.isEternal()) {\n         expirable.setExpireTimeMS(Long.MAX_VALUE);\n-      } else if (currentTimeMS == 0L) {\n-        expirable.setExpireTimeMS(ticker.read());\n       } else {\n-        expirable.setExpireTimeMS(currentTimeMS);\n+        if (currentTimeMS == 0) {\n+          currentTimeMS = ticker.read();\n+        }\n+        long expireTimeMS = duration.getAdjustedTime(currentTimeMS);\n+        expirable.setExpireTimeMS(expireTimeMS);\n       }\n     } catch (Exception e) {\n       logger.log(Level.WARNING, \"Failed to set the entry's expiration time\", e);",
      "parent_sha": "abacef9a5f658a54facfb78f060cf75402e14d10"
    }
  },
  {
    "oid": "5a91bbe1dac1810d329c22d7ac914a76966b3b32",
    "message": "Change Caffeine default cache size to 64\n\nCaffeine uses a ConcurrentHashMap under the hood. The way this works is that there are a number of bins, and the bins contain nodes (which contain 0 or more k/v pairs).\r\n\r\nWhen I do a compute or computeIfAbsent, I look for the bin my node should be in, and if it does not exist, I put a placeholder bin there, compute, and then put the value there. If it does exist, I lock the bin, do whatever checks I need to do, put the value if necessary and unlock.\r\n\r\nWhen I am done, I grow the map if necessary (generally increasing it by powers of 2).\r\n\r\nCaffeine's default map size is 0, which cases the ConcurrentHashMap to be created with no table. This is cheap, but has the drawback of Caffeine starting off with only 2 buckets.\r\n\r\nThe issue here is that when I do a computeIfAbsent call, it synchronizes with every other computeIfAbsent call currently in progress (a bigger problem if the compute function is expensive).\r\n\r\nFor a pathological case, if all of my keys are ending up in one bucket, they will linearize (and end up in either a linked list or a red-black tree). This is expected, and one would anticipate the ConcurrentHashMap to compensate, and indeed it immediately tries to.\r\n\r\nHowever, in order to transfer the node to a new table, (so far as I can read) it joins the synchronization bandwagon which is currently trying to add data to the node. Eventually the transfer should be able to happen (although I suppose synchronization is unfair?), but until this is the case, the transfer cannot complete.\r\n\r\nSo, this means that you can get some pretty brutal throughput characteristics if you dump a load of contention onto a Caffeine cache with no warmup period.\r\n\r\nFor example, if I have 1000 threads try and concurrently hammer the same Caffeine loading cache, sleeping for 100ms in their loading function, I get throughput of roughly 10 writes a second. This eventually will grow, but it will take a very long time.\r\n\r\nIn our case, this ended up with something approaching a deadlock; a low-capacity cache (we think almost empty, with only a few historical inputs) received concurrently some small number of unexpectedly expensive requests between 0 and 60, which each took (say) a minute. In general the system is easily able to deal with such requests - the cache deduplicates such requests, and there are only a few queries that could take this long. However, in this case they caused us to enter a death spiral; they locked all the buckets and stopped any of the other (far cheaper) requests from being served.\r\n\r\nTo compensate for this, this PR presizes the cache to 64 elements. It uses something like 256 additional bytes of memory for each cache created, but pretty much removes this pathological case.\r\n\r\nHope this makes sense! I may have misunderstood some stuff about ConcurrentHashMap here though.",
    "date": "2018-02-02T22:24:18Z",
    "url": "https://github.com/ben-manes/caffeine/commit/5a91bbe1dac1810d329c22d7ac914a76966b3b32",
    "details": {
      "sha": "4289a21934f7aa786c9e15939a6c5ba28997dd00",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/5a91bbe1dac1810d329c22d7ac914a76966b3b32/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/5a91bbe1dac1810d329c22d7ac914a76966b3b32/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=5a91bbe1dac1810d329c22d7ac914a76966b3b32",
      "patch": "@@ -139,7 +139,7 @@ public final class Caffeine<K, V> {\n   enum Strength { WEAK, SOFT }\n   static final int UNSET_INT = -1;\n \n-  static final int DEFAULT_INITIAL_CAPACITY = 0;\n+  static final int DEFAULT_INITIAL_CAPACITY = 64;\n   static final int DEFAULT_EXPIRATION_NANOS = 0;\n   static final int DEFAULT_REFRESH_NANOS = 0;\n ",
      "parent_sha": "7c0e23508c66bbf376892a0945decd8ee8813862"
    }
  },
  {
    "oid": "b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2",
    "message": "toString",
    "date": "2014-12-25T00:28:42Z",
    "url": "https://github.com/ben-manes/caffeine/commit/b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2",
    "details": {
      "sha": "0af5f93d640106ebf708e7d7574fe1a6eb7bd947",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/AsMapTest.java",
      "status": "modified",
      "additions": 88,
      "deletions": 62,
      "changes": 150,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java?ref=b31c0d7465cbdfaae84ae67af3d9ddfba60f8ba2",
      "patch": "@@ -19,6 +19,7 @@\n import static com.github.benmanes.caffeine.matchers.IsEmptyMap.emptyMap;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasToString;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.not;\n import static org.hamcrest.Matchers.nullValue;\n@@ -39,6 +40,7 @@\n import com.github.benmanes.caffeine.cache.testing.CacheSpec.Population;\n import com.github.benmanes.caffeine.cache.testing.CacheValidationListener;\n import com.google.common.collect.ImmutableMap;\n+import com.google.common.testing.SerializableTester;\n \n /**\n  * The test cases for the {@link Cache#asMap()} view and its serializability. These tests do not\n@@ -76,64 +78,6 @@ public void clear(Map<Integer, Integer> map, CacheContext context) {\n         (int) context.initialSize(), RemovalCause.EXPLICIT));\n   }\n \n-  /* ---------------- equals / hashCode -------------- */\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void equals_null(Map<Integer, Integer> map) {\n-    assertThat(map.equals(null), is(false));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void equals_self(Map<Integer, Integer> map) {\n-    assertThat(map.equals(map), is(true));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void equals(Map<Integer, Integer> map, CacheContext context) {\n-    assertThat(map.equals(context.original()), is(true));\n-    assertThat(context.original().equals(map), is(true));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void hashCode(Map<Integer, Integer> map, CacheContext context) {\n-    assertThat(map.hashCode(), is(equalTo(context.original().hashCode())));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void hashCode_self(Map<Integer, Integer> map) {\n-    assertThat(map.hashCode(), is(equalTo(map.hashCode())));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(population = Population.EMPTY,\n-      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void equalsAndHashCodeFail_empty(Map<Integer, Integer> map) {\n-    Map<Integer, Integer> other = ImmutableMap.of(1, -1, 2, -2, 3, -3);\n-    assertThat(map.equals(other), is(false));\n-    assertThat(other.equals(map), is(false));\n-    assertThat(map.hashCode(), is(not(equalTo(other.hashCode()))));\n-  }\n-\n-  @Test(dataProvider = \"caches\")\n-  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n-      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n-  public void equalsAndHashCodeFail_present(Map<Integer, Integer> map) {\n-    Map<Integer, Integer> other = ImmutableMap.of(1, -1, 2, -2, 3, -3);\n-    assertThat(map.equals(other), is(false));\n-    assertThat(other.equals(map), is(false));\n-    assertThat(map.hashCode(), is(not(equalTo(other.hashCode()))));\n-\n-    Map<Integer, Integer> empty = ImmutableMap.of();\n-    assertThat(map.equals(empty), is(false));\n-    assertThat(empty.equals(map), is(false));\n-    assertThat(map.hashCode(), is(not(equalTo(empty.hashCode()))));\n-  }\n-\n   /* ---------------- contains -------------- */\n \n   @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n@@ -568,10 +512,92 @@ public void replaceConditionally_differentValue(Map<Integer, Integer> map, Cache\n     assertThat(map, hasRemovalNotifications(context, count, RemovalCause.REPLACED));\n   }\n \n+  /* ---------------- equals / hashCode -------------- */\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void equals_null(Map<Integer, Integer> map) {\n+    assertThat(map.equals(null), is(false));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void equals_self(Map<Integer, Integer> map) {\n+    assertThat(map.equals(map), is(true));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void equals(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map.equals(context.original()), is(true));\n+    assertThat(context.original().equals(map), is(true));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void hashCode(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map.hashCode(), is(equalTo(context.original().hashCode())));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void hashCode_self(Map<Integer, Integer> map) {\n+    assertThat(map.hashCode(), is(equalTo(map.hashCode())));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = Population.EMPTY,\n+      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void equalsAndHashCodeFail_empty(Map<Integer, Integer> map) {\n+    Map<Integer, Integer> other = ImmutableMap.of(1, -1, 2, -2, 3, -3);\n+    assertThat(map.equals(other), is(false));\n+    assertThat(other.equals(map), is(false));\n+    assertThat(map.hashCode(), is(not(equalTo(other.hashCode()))));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n+      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void equalsAndHashCodeFail_present(Map<Integer, Integer> map) {\n+    Map<Integer, Integer> other = ImmutableMap.of(1, -1, 2, -2, 3, -3);\n+    assertThat(map.equals(other), is(false));\n+    assertThat(other.equals(map), is(false));\n+    assertThat(map.hashCode(), is(not(equalTo(other.hashCode()))));\n+\n+    Map<Integer, Integer> empty = ImmutableMap.of();\n+    assertThat(map.equals(empty), is(false));\n+    assertThat(empty.equals(map), is(false));\n+    assertThat(map.hashCode(), is(not(equalTo(empty.hashCode()))));\n+  }\n+\n+  /* ---------------- toString -------------- */\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void toString_empty(Map<Integer, Integer> map, CacheContext context) {\n+    assertThat(map, hasToString(context.original().toString()));\n+  }\n+\n+  /* ---------------- serialize -------------- */\n+\n+  // FIXME(ben)\n+  @Test(enabled = false, dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void serialize(Map<Integer, Integer> map) {\n+    SerializableTester.reserializeAndAssert(map);\n+  }\n+\n   /* ---------------- V8 default methods -------------- */\n-  /* ---------------- V8 default methods -------------- */\n-  /* ---------------- V8 default methods -------------- */\n-  /* ---------------- V8 default methods -------------- */\n-  /* ---------------- V8 default methods -------------- */\n+  public void getOrDefault() {}\n+  public void forEach() {}\n+  public void replaceAll() {}\n+  public void computeIfAbsent() {}\n+  public void computeIfPresent() {}\n+  public void compute() {}\n+  public void merge() {}\n+\n+  /* ---------------- Key Set -------------- */\n+  /* ---------------- Values -------------- */\n+  /* ---------------- Entry Set -------------- */\n \n }",
      "parent_sha": "5b5030fb37c14c9091c274c18cb3895c3bf557d9"
    }
  },
  {
    "oid": "d966e611a281d7d4dc8386f44e3db10cf18d00a0",
    "message": "Restore executor dispatch",
    "date": "2014-12-24T00:15:33Z",
    "url": "https://github.com/ben-manes/caffeine/commit/d966e611a281d7d4dc8386f44e3db10cf18d00a0",
    "details": {
      "sha": "80c9e8f713c9e0a901026e83f5e4aa1762fcfb59",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/AbstractLocalCache.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/d966e611a281d7d4dc8386f44e3db10cf18d00a0/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAbstractLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/d966e611a281d7d4dc8386f44e3db10cf18d00a0/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAbstractLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAbstractLocalCache.java?ref=d966e611a281d7d4dc8386f44e3db10cf18d00a0",
      "patch": "@@ -51,7 +51,7 @@ protected void notifyRemoval(RemovalCause cause, K key, @Nullable V value) {\n \n   protected void notifyRemoval(RemovalNotification<K, V> notification) {\n     requireNonNull(removalListener, \"Notification should be guarded with a check\");\n-    removalListener.onRemoval(notification);\n+    executor.execute(() -> removalListener.onRemoval(notification));\n   }\n \n   protected boolean hasRemovalListener() {",
      "parent_sha": "59b7d149f2cb9a25542a85244a350a86d9933f73"
    }
  },
  {
    "oid": "cf3b600cab7f3c5755c5395607433a388d3bf0dd",
    "message": "assigning ticker to build after builder creation (fixes #313)",
    "date": "2019-04-22T16:32:50Z",
    "url": "https://github.com/ben-manes/caffeine/commit/cf3b600cab7f3c5755c5395607433a388d3bf0dd",
    "details": {
      "sha": "d50f6d69512847772856d113fd36ffde78bbfe13",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/CacheFactory.java",
      "status": "modified",
      "additions": 4,
      "deletions": 2,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/cf3b600cab7f3c5755c5395607433a388d3bf0dd/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheFactory.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/cf3b600cab7f3c5755c5395607433a388d3bf0dd/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheFactory.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheFactory.java?ref=cf3b600cab7f3c5755c5395607433a388d3bf0dd",
      "patch": "@@ -21,14 +21,15 @@\n import java.util.concurrent.Executor;\n import java.util.concurrent.TimeUnit;\n \n-import org.checkerframework.checker.nullness.qual.Nullable;\n import javax.cache.CacheManager;\n import javax.cache.configuration.CompleteConfiguration;\n import javax.cache.configuration.Configuration;\n import javax.cache.configuration.Factory;\n import javax.cache.expiry.ExpiryPolicy;\n import javax.cache.integration.CacheLoader;\n \n+import org.checkerframework.checker.nullness.qual.Nullable;\n+\n import com.github.benmanes.caffeine.cache.Caffeine;\n import com.github.benmanes.caffeine.cache.Expiry;\n import com.github.benmanes.caffeine.cache.Ticker;\n@@ -139,6 +140,7 @@ private final class Builder<K, V> {\n       this.expiryPolicy = config.getExpiryPolicyFactory().create();\n       this.dispatcher = new EventDispatcher<>(executor);\n \n+      caffeine.ticker(ticker);\n       caffeine.executor(executor);\n       config.getCacheEntryListenerConfigurations().forEach(dispatcher::register);\n     }\n@@ -233,7 +235,7 @@ private boolean configureExpireAfterAccess() {\n       return config.getExpireAfterAccess().isPresent();\n     }\n \n-    /** Configures the write expiration and returns if set. */\n+    /** Configures the custom expiration and returns if set. */\n     private boolean configureExpireVariably() {\n       config.getExpiryFactory().ifPresent(factory -> {\n         Expiry<K, V> expiry = factory.create();",
      "parent_sha": "91eec88be93f16549ce82dd2f17959fd8eba75dd"
    }
  },
  {
    "oid": "cff8ab848357b5c940d11be10a6b399bb9023f2e",
    "message": "Unifying computeIfPresent, compute, and merge\n\nThe previous implementation of remap methods was complex due to how it\nhandled GC and expiration, old assumptions of synchronization ordering,\nnotifying early, and other quirks. The rewrites to add CacheWriter\nsupport provided an opportunity to better share code now that the\nsurrounding implementation matured.",
    "date": "2015-06-18T16:41:58Z",
    "url": "https://github.com/ben-manes/caffeine/commit/cff8ab848357b5c940d11be10a6b399bb9023f2e",
    "details": {
      "sha": "042fd62689938340d11440ecf4e138d96834ca83",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 79,
      "deletions": 116,
      "changes": 195,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/cff8ab848357b5c940d11be10a6b399bb9023f2e/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/cff8ab848357b5c940d11be10a6b399bb9023f2e/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=cff8ab848357b5c940d11be10a6b399bb9023f2e",
      "patch": "@@ -1135,16 +1135,16 @@ public V computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction\n     requireNonNull(mappingFunction);\n     long now = ticker().read();\n \n-    // An optimistic fast path due to computeIfAbsent always locking\n-    Object keyRef = nodeFactory.newLookupKey(key);\n-    Node<K, V> node = data.get(keyRef);\n+    // An optimistic fast path to avoid unnecessary locking\n+    Node<K, V> node = data.get(nodeFactory.newLookupKey(key));\n     if (node != null) {\n       V value = node.getValue();\n       if ((value != null) && !hasExpired(node, now)) {\n         afterRead(node, true);\n         return value;\n       }\n     }\n+    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n     return doComputeIfAbsent(key, keyRef, mappingFunction, isAsync, now);\n   }\n \n@@ -1186,8 +1186,8 @@ V doComputeIfAbsent(K key, Object keyRef, Function<? super K, ? extends V> mappi\n           return n;\n         }\n \n-        writer.delete(nodeKey[0], oldValue[0], cause[0]);\n         newValue[0] = statsAware(mappingFunction, isAsync).apply(key);\n+        writer.delete(nodeKey[0], oldValue[0], cause[0]);\n         if (newValue[0] == null) {\n           removed[0] = n;\n           n.retire();\n@@ -1229,16 +1229,67 @@ V doComputeIfAbsent(K key, Object keyRef, Function<? super K, ? extends V> mappi\n   @Override\n   public V computeIfPresent(K key,\n       BiFunction<? super K, ? super V, ? extends V> remappingFunction) {\n+    requireNonNull(key);\n     requireNonNull(remappingFunction);\n-    long now = ticker().read();\n \n-    // An optimistic fast path due to computeIfPresent always locking\n+    // A optimistic fast path to avoid unnecessary locking\n     Object keyRef = nodeFactory.newLookupKey(key);\n     Node<K, V> node = data.get(keyRef);\n-    if ((node == null) || (node.getValue() == null) || hasExpired(node, now)) {\n+    long now;\n+    if ((node == null) || (node.getValue() == null) || hasExpired(node, (now = ticker().read()))) {\n       return null;\n     }\n \n+    boolean computeIfAbsent = false;\n+    BiFunction<? super K, ? super V, ? extends V> statsAwareRemappingFunction =\n+        statsAware(remappingFunction, false, false);\n+    return remap(key, keyRef, statsAwareRemappingFunction, now, computeIfAbsent);\n+  }\n+\n+  @Override\n+  public V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction,\n+      boolean recordMiss, boolean isAsync) {\n+    requireNonNull(key);\n+    requireNonNull(remappingFunction);\n+\n+    long now = ticker().read();\n+    boolean computeIfAbsent = true;\n+    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n+    BiFunction<? super K, ? super V, ? extends V> statsAwareRemappingFunction =\n+        statsAware(remappingFunction, recordMiss, isAsync);\n+    return remap(key, keyRef, statsAwareRemappingFunction, now, computeIfAbsent);\n+  }\n+\n+  @Override\n+  public V merge(K key, V value, BiFunction<? super V, ? super V, ? extends V> remappingFunction) {\n+    requireNonNull(key);\n+    requireNonNull(value);\n+    requireNonNull(remappingFunction);\n+\n+    long now = ticker().read();\n+    boolean computeIfAbsent = true;\n+    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n+    BiFunction<? super K, ? super V, ? extends V> mergeFunction = (k, oldValue) ->\n+        (oldValue == null) ? value : statsAware(remappingFunction).apply(oldValue, value);\n+    return remap(key, keyRef, mergeFunction, now, computeIfAbsent);\n+  }\n+\n+  /**\n+   * Attempts to compute a mapping for the specified key and its current mapped value (or\n+   * {@code null} if there is no current mapping).\n+   * <p>\n+   * An entry that has expired or been reference collected is evicted and the computation continues\n+   * as if the entry had not been present. This method does not pre-screen and does not wrap the\n+   * remappingFuntion to be statistics aware.\n+   *\n+   * @param key key with which the specified value is to be associated\n+   * @param remappingFunction the function to compute a value\n+   * @param now the current time, according to the ticker\n+   * @param computeIfAbsent if an absent entry can be computed\n+   * @return the new value associated with the specified key, or null if none\n+   */\n+  V remap(K key, Object keyRef, BiFunction<? super K, ? super V, ? extends V> remappingFunction,\n+      long now, boolean computeIfAbsent) {\n     @SuppressWarnings(\"unchecked\")\n     K[] nodeKey = (K[]) new Object[1];\n     @SuppressWarnings(\"unchecked\")\n@@ -1248,12 +1299,23 @@ public V computeIfPresent(K key,\n     @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n     Node<K, V>[] removed = new Node[1];\n \n-    int[] weight = new int[2];\n+    int[] weight = new int[2]; // old, new\n     RemovalCause[] cause = new RemovalCause[1];\n \n-    node = data.compute(keyRef, (kr, n) -> {\n+    Node<K, V> node = data.compute(keyRef, (kr, n) -> {\n       if (n == null) {\n-        return null;\n+        if (!computeIfAbsent) {\n+          return null;\n+        }\n+        newValue[0] = remappingFunction.apply(key, null);\n+        if (newValue[0] == null) {\n+          return null;\n+        }\n+        writer.write(key, newValue[0]);\n+        weight[1] = weigher.weigh(key, newValue[0]);\n+        tracer().recordWrite(id, key, weight[1]);\n+        return nodeFactory.newNode(keyRef, newValue[0],\n+            valueReferenceQueue(), weight[1], now);\n       }\n \n       synchronized (n) {\n@@ -1263,6 +1325,8 @@ public V computeIfPresent(K key,\n           cause[0] = RemovalCause.COLLECTED;\n         } else if (hasExpired(n, now)) {\n           cause[0] = RemovalCause.EXPIRED;\n+          n.setAccessTime(now);\n+          n.setWriteTime(now);\n         }\n         if (cause[0] != null) {\n           writer.delete(nodeKey[0], oldValue[0], cause[0]);\n@@ -1271,7 +1335,7 @@ public V computeIfPresent(K key,\n           return null;\n         }\n \n-        newValue[0] = statsAware(remappingFunction, false, false).apply(nodeKey[0], oldValue[0]);\n+        newValue[0] = remappingFunction.apply(nodeKey[0], oldValue[0]);\n         if (newValue[0] == null) {\n           writer.delete(nodeKey[0], oldValue[0], cause[0]);\n           cause[0] = RemovalCause.EXPLICIT;\n@@ -1310,7 +1374,10 @@ public V computeIfPresent(K key,\n       if (oldValue[0] != null) {\n         tracer().recordDelete(id, nodeKey[0]);\n       }\n-    } else if (oldValue[0] != null) {\n+    } else if (oldValue[0] == null) {\n+      afterWrite(node, new AddTask(node, weight[1]));\n+      tracer().recordWrite(id, key, weight[1]);\n+    } else {\n       int weightedDifference = weight[0] - weight[1];\n       if (weightedDifference == 0) {\n         afterRead(node, false);\n@@ -1323,110 +1390,6 @@ public V computeIfPresent(K key,\n     return newValue[0];\n   }\n \n-  @Override\n-  public V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction,\n-      boolean recordMiss, boolean isAsync) {\n-    requireNonNull(remappingFunction);\n-    return remap(key, statsAware(remappingFunction, recordMiss, isAsync));\n-  }\n-\n-  /**\n-   * A {@link Map#compute(Object, BiFunction)} that does not directly record any cache statistics.\n-   *\n-   * @param key key with which the specified value is to be associated\n-   * @param remappingFunction the function to compute a value\n-   * @return the new value associated with the specified key, or null if none\n-   */\n-  V remap(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {\n-    requireNonNull(key);\n-    requireNonNull(remappingFunction);\n-\n-    @SuppressWarnings(\"unchecked\")\n-    V[] newValue = (V[]) new Object[1];\n-    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n-    Runnable[] task = new Runnable[2];\n-    Node<K, V> node = data.compute(keyRef, (k, prior) -> {\n-      if (prior == null) {\n-        newValue[0] = remappingFunction.apply(key, null);\n-        if (newValue[0] == null) {\n-          tracer().recordDelete(id, key);\n-          return null;\n-        }\n-        final long now = ticker().read();\n-        final int weight = weigher.weigh(key, newValue[0]);\n-        final Node<K, V> newNode = nodeFactory.newNode(\n-            keyRef, newValue[0], valueReferenceQueue(), weight, now);\n-        task[0] = new AddTask(newNode, weight);\n-        tracer().recordWrite(id, key, weight);\n-        return newNode;\n-      }\n-      synchronized (prior) {\n-        V oldValue = null;\n-        if (prior.isAlive()) {\n-          oldValue = prior.getValue();\n-        } else {\n-          // conditionally removed won, but we got the entry lock first\n-          // so help out and pretend like we are inserting a fresh entry\n-          task[1] = new RemovalTask(prior);\n-          if (hasRemovalListener()) {\n-            V value = prior.getValue();\n-            if (value == null) {\n-              notifyRemoval(key, value, RemovalCause.COLLECTED);\n-            } else {\n-              notifyRemoval(key, value, RemovalCause.EXPLICIT);\n-            }\n-          }\n-        }\n-        newValue[0] = remappingFunction.apply(key, oldValue);\n-        if ((newValue[0] == null) && (oldValue != null)) {\n-          task[0] = new RemovalTask(prior);\n-          if (hasRemovalListener()) {\n-            notifyRemoval(key, oldValue, RemovalCause.EXPLICIT);\n-          }\n-          tracer().recordDelete(id, key);\n-          return null;\n-        }\n-        final int oldWeight = prior.getWeight();\n-        final int newWeight = weigher.weigh(key, newValue[0]);\n-        if (task[1] == null) {\n-          prior.setWeight(newWeight);\n-          prior.setValue(newValue[0], valueReferenceQueue());\n-          final int weightedDifference = newWeight - oldWeight;\n-          if (weightedDifference != 0) {\n-            task[0] = new UpdateTask(prior, weightedDifference);\n-          }\n-          if (hasRemovalListener() && (newValue[0] != oldValue)) {\n-            notifyRemoval(key, oldValue, RemovalCause.REPLACED);\n-          }\n-          tracer().recordWrite(id, key, newWeight);\n-          return prior;\n-        } else {\n-          final long now = ticker().read();\n-          Node<K, V> newNode = nodeFactory.newNode(\n-              keyRef, newValue[0], valueReferenceQueue(), newWeight, now);\n-          task[0] = new AddTask(newNode, newWeight);\n-          return newNode;\n-        }\n-      }\n-    });\n-    if (task[0] != null) {\n-      afterWrite(node, task[0]);\n-    }\n-    if (task[1] != null) {\n-      afterWrite(node, task[1]);\n-    }\n-    return newValue[0];\n-  }\n-\n-  @Override\n-  public V merge(K key, V value, BiFunction<? super V, ? super V, ? extends V> remappingFunction) {\n-    requireNonNull(remappingFunction);\n-    requireNonNull(value);\n-\n-    return remap(key, (k, oldValue) ->\n-        (oldValue == null) ? value : statsAware(remappingFunction).apply(oldValue, value));\n-  }\n-\n   @Override\n   public Set<K> keySet() {\n     final Set<K> ks = keySet;",
      "parent_sha": "3449b7ffe59f845a2d00cc707fc94e921ca9d8c8"
    }
  },
  {
    "oid": "d368e8f8962ca82dd93f29856e968e3ec552452b",
    "message": "JavaDoc fixes",
    "date": "2015-01-18T03:44:53Z",
    "url": "https://github.com/ben-manes/caffeine/commit/d368e8f8962ca82dd93f29856e968e3ec552452b",
    "details": {
      "sha": "2afd6581666d46d98b2824595933db35bc7c511e",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/AsyncLoadingCache.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/d368e8f8962ca82dd93f29856e968e3ec552452b/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/d368e8f8962ca82dd93f29856e968e3ec552452b/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java?ref=d368e8f8962ca82dd93f29856e968e3ec552452b",
      "patch": "@@ -40,7 +40,7 @@ public interface AsyncLoadingCache<K, V> {\n \n   /**\n    * Returns the future associated with {@code key} in this cache, obtaining that value from\n-   * {@link CacheLoader#asyncLoad} if necessary. This method provides a simple substitute for the\n+   * {@code mappingFunction} if necessary. This method provides a simple substitute for the\n    * conventional \"if cached, return; otherwise create, cache and return\" pattern.\n    * <p>\n    * If the specified key is not already associated with a value, attempts to compute its value\n@@ -59,7 +59,7 @@ CompletableFuture<V> get(@Nonnull K key,\n \n   /**\n    * Returns the future associated with {@code key} in this cache, obtaining that value from\n-   * {@link CacheLoader#asyncLoad} if necessary. This method provides a simple substitute for the\n+   * {@code mappingFunction} if necessary. This method provides a simple substitute for the\n    * conventional \"if cached, return; otherwise create, cache and return\" pattern.\n    * <p>\n    * If the specified key is not already associated with a value, attempts to compute its value",
      "parent_sha": "55a056538372b13f69c2389ed51e5f1497ed6577"
    }
  },
  {
    "oid": "22a0e83a7df535260d36e39c0139d8aa051db92f",
    "message": "currentTimeMillis() was returning microseconds,\nshould divide by 1000000 (>> 20 => 1048576) not 1000 (>> 10 => 1024)",
    "date": "2015-12-13T20:44:38Z",
    "url": "https://github.com/ben-manes/caffeine/commit/22a0e83a7df535260d36e39c0139d8aa051db92f",
    "details": {
      "sha": "4f2c499a0184d142b8744407d926e22fac892c0f",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/CacheProxy.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/22a0e83a7df535260d36e39c0139d8aa051db92f/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/22a0e83a7df535260d36e39c0139d8aa051db92f/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2FCacheProxy.java?ref=22a0e83a7df535260d36e39c0139d8aa051db92f",
      "patch": "@@ -954,7 +954,7 @@ protected Map<K, V> copyMap(Map<K, Expirable<V>> map) {\n \n   /** @return an approximate of the current time in milliseconds */\n   protected long currentTimeMillis() {\n-    return ticker.read() >> 10;\n+    return ticker.read() >> 20;\n   }\n \n   /**",
      "parent_sha": "53ae2f952c7201641ea7e3ba42e78c5f4a619211"
    }
  },
  {
    "oid": "bf43349f31252c2816bd98a4d75b9d3b2fd4c2be",
    "message": "Make linked policies simulation weigth-aware",
    "date": "2019-12-17T20:45:16Z",
    "url": "https://github.com/ben-manes/caffeine/commit/bf43349f31252c2816bd98a4d75b9d3b2fd4c2be",
    "details": {
      "sha": "95bc3c17b9de2b31a038f889c4922ffda31c61fb",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/linked/LinkedPolicy.java",
      "status": "modified",
      "additions": 45,
      "deletions": 15,
      "changes": 60,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/bf43349f31252c2816bd98a4d75b9d3b2fd4c2be/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Flinked%2FLinkedPolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/bf43349f31252c2816bd98a4d75b9d3b2fd4c2be/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Flinked%2FLinkedPolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Flinked%2FLinkedPolicy.java?ref=bf43349f31252c2816bd98a4d75b9d3b2fd4c2be",
      "patch": "@@ -18,17 +18,23 @@\n import static java.util.Locale.US;\n import static java.util.stream.Collectors.toSet;\n \n+import java.util.Objects;\n+\n+import static com.github.benmanes.caffeine.cache.simulator.policy.Policy.Characteristic.WEIGHTED;\n+\n import java.util.Set;\n \n import org.apache.commons.lang3.StringUtils;\n \n import com.github.benmanes.caffeine.cache.simulator.BasicSettings;\n import com.github.benmanes.caffeine.cache.simulator.admission.Admission;\n import com.github.benmanes.caffeine.cache.simulator.admission.Admittor;\n+import com.github.benmanes.caffeine.cache.simulator.policy.AccessEvent;\n import com.github.benmanes.caffeine.cache.simulator.policy.Policy;\n-import com.github.benmanes.caffeine.cache.simulator.policy.Policy.KeyOnlyPolicy;\n+import com.github.benmanes.caffeine.cache.simulator.policy.Policy.Characteristic;\n import com.github.benmanes.caffeine.cache.simulator.policy.PolicyStats;\n import com.google.common.base.MoreObjects;\n+import com.google.common.collect.Sets;\n import com.typesafe.config.Config;\n \n import it.unimi.dsi.fastutil.longs.Long2ObjectMap;\n@@ -40,12 +46,13 @@\n  *\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n-public final class LinkedPolicy implements KeyOnlyPolicy {\n+public final class LinkedPolicy implements Policy {\n   final Long2ObjectMap<Node> data;\n   final PolicyStats policyStats;\n   final EvictionPolicy policy;\n   final Admittor admittor;\n   final int maximumSize;\n+  int currentSize;\n   final Node sentinel;\n \n   public LinkedPolicy(Admission admission, EvictionPolicy policy, Config config) {\n@@ -66,19 +73,31 @@ public static Set<Policy> policies(Config config, EvictionPolicy policy) {\n     ).collect(toSet());\n   }\n \n+  @Override\n+  public Set<Characteristic> characteristics() {\n+    return Sets.immutableEnumSet(WEIGHTED);  \n+  }\n+\n   @Override\n   public PolicyStats stats() {\n     return policyStats;\n   }\n-\n+  \n   @Override\n-  public void record(long key) {\n+  public void record(AccessEvent event) {\n+    final int weight = event.weight();\n+    final long key = hashCode(event.key(), weight);\n     Node old = data.get(key);\n     admittor.record(key);\n     if (old == null) {\n-      Node node = new Node(key, sentinel);\n       policyStats.recordMiss();\n+      if (weight > maximumSize) {\n+        policyStats.recordOperation();\n+        return;\n+      }\n+      Node node = new Node(key, weight, sentinel);\n       data.put(key, node);\n+      currentSize += node.weight;\n       node.appendToTail();\n       evict(node);\n     } else {\n@@ -89,22 +108,25 @@ public void record(long key) {\n \n   /** Evicts while the map exceeds the maximum capacity. */\n   private void evict(Node candidate) {\n-    if (data.size() > maximumSize) {\n-      Node victim = policy.findVictim(sentinel, policyStats);\n-      policyStats.recordEviction();\n-\n-      boolean admit = admittor.admit(candidate.key, victim.key);\n-      if (admit) {\n-        evictEntry(victim);\n-      } else {\n-        evictEntry(candidate);\n+    if (currentSize > maximumSize) {\n+      while (currentSize > maximumSize) {\n+        Node victim = policy.findVictim(sentinel, policyStats);\n+        policyStats.recordEviction();\n+  \n+        boolean admit = admittor.admit(candidate.key, victim.key);\n+        if (admit) {\n+          evictEntry(victim);\n+        } else {\n+          evictEntry(candidate);\n+        }\n       }\n     } else {\n       policyStats.recordOperation();\n     }\n   }\n \n   private void evictEntry(Node node) {\n+    currentSize -= node.weight;\n     data.remove(node.key);\n     node.remove();\n   }\n@@ -191,6 +213,7 @@ static final class Node {\n     Node prev;\n     Node next;\n     long key;\n+    int weight;\n \n     /** Creates a new sentinel node. */\n     public Node() {\n@@ -201,9 +224,10 @@ public Node() {\n     }\n \n     /** Creates a new, unlinked node. */\n-    public Node(long key, Node sentinel) {\n+    public Node(long key, int weight, Node sentinel) {\n       this.sentinel = sentinel;\n       this.key = key;\n+      this.weight = weight;\n     }\n \n     /** Appends the node to the tail of the list. */\n@@ -240,8 +264,14 @@ public void moveToTail() {\n     public String toString() {\n       return MoreObjects.toStringHelper(this)\n           .add(\"key\", key)\n+          .add(\"weight\", weight)\n           .add(\"marked\", marked)\n           .toString();\n     }\n   }\n+  \n+  /** Cantor pairing function. */\n+  private long hashCode(long key, int weight) {\n+    return (key + weight) * (key + weight + 1) / 2 + weight;\n+  }\n }",
      "parent_sha": "f98efd29b0029119ee18e850b37b5530c2d6c5ca"
    }
  },
  {
    "oid": "2befdb17e793848da0fba95683d4a041ada5c5e0",
    "message": "Add @Nullable annotation in Cache2k (#1831)",
    "date": "2025-02-09T00:43:56Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2befdb17e793848da0fba95683d4a041ada5c5e0",
    "details": {
      "sha": "288d81ab6830a285b3bfa5725a133a1bf2d73616",
      "filename": "caffeine/src/jmh/java/com/github/benmanes/caffeine/cache/impl/Cache2k.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2befdb17e793848da0fba95683d4a041ada5c5e0/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fimpl%2FCache2k.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2befdb17e793848da0fba95683d4a041ada5c5e0/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fimpl%2FCache2k.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fimpl%2FCache2k.java?ref=2befdb17e793848da0fba95683d4a041ada5c5e0",
      "patch": "@@ -18,6 +18,7 @@\n import org.cache2k.Cache;\n import org.cache2k.Cache2kBuilder;\n import org.cache2k.config.Cache2kConfig;\n+import org.jspecify.annotations.Nullable;\n \n import com.github.benmanes.caffeine.cache.BasicCache;\n \n@@ -34,7 +35,7 @@ public Cache2k(int maximumSize) {\n   }\n \n   @Override\n-  public V get(K key) {\n+  public @Nullable V get(K key) {\n     return cache.peek(key);\n   }\n ",
      "parent_sha": "18c03d20e82f8fa53d6a9a1db4ce8328cd8fe3c0"
    }
  },
  {
    "oid": "25bfa45de1ec6852ea31a6b2a4fa308768c18917",
    "message": "Support small caches in WindowTinyCachePolicy\n\nA divide by zero error occurs for caches lte 64 due to a divide\nby zero error. Disables the window if it can't be supported due\nto the size constraint.",
    "date": "2015-11-16T18:00:08Z",
    "url": "https://github.com/ben-manes/caffeine/commit/25bfa45de1ec6852ea31a6b2a4fa308768c18917",
    "details": {
      "sha": "1dbccc923f5188fdd05b8e04b3193d346ca54e26",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/sketch/tinycache/WindowTinyCachePolicy.java",
      "status": "modified",
      "additions": 8,
      "deletions": 4,
      "changes": 12,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/25bfa45de1ec6852ea31a6b2a4fa308768c18917/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Ftinycache%2FWindowTinyCachePolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/25bfa45de1ec6852ea31a6b2a4fa308768c18917/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Ftinycache%2FWindowTinyCachePolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Ftinycache%2FWindowTinyCachePolicy.java?ref=25bfa45de1ec6852ea31a6b2a4fa308768c18917",
      "patch": "@@ -37,8 +37,12 @@ public WindowTinyCachePolicy(Config config) {\n     BasicSettings settings = new BasicSettings(config);\n     this.policyStats = new PolicyStats(\"sketch.WindowTinyCache\");\n     int maxSize = settings.maximumSize();\n-    window = new TinyCache(1, 64, 0);\n-    maxSize -= 64;\n+    if (maxSize <= 64) {\n+      window = null;\n+    } else {\n+      maxSize -= 64;\n+      window = new TinyCache(1, 64, 0);\n+    }\n     tinyCache = new TinyCacheWithGhostCache((int) Math.ceil(maxSize / 64.0),\n         64, settings.randomSeed());\n   }\n@@ -50,12 +54,12 @@ public static Set<Policy> policies(Config config) {\n \n   @Override\n   public void record(long key) {\n-    if (tinyCache.contains(key) || window.contains(key)) {\n+    if (tinyCache.contains(key) || ((window != null) && window.contains(key))) {\n       tinyCache.recordItem(key);\n       policyStats.recordHit();\n     } else {\n       boolean evicted = tinyCache.addItem(key);\n-      if (!evicted) {\n+      if (!evicted && (window != null)) {\n         evicted = window.addItem(key);\n       }\n       tinyCache.recordItem(key);",
      "parent_sha": "05bd8bf8e675fb11a742850dfe45f8a6451978ab"
    }
  },
  {
    "oid": "f107fbc8b93883ec5513916c6c7fb5a819e6b498",
    "message": "Fix climber configuration parsing",
    "date": "2018-08-26T21:53:20Z",
    "url": "https://github.com/ben-manes/caffeine/commit/f107fbc8b93883ec5513916c6c7fb5a819e6b498",
    "details": {
      "sha": "24d57a8b2202197d4b809941eaec884b0f61bcd2",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/sketch/climbing/SimpleClimber.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/f107fbc8b93883ec5513916c6c7fb5a819e6b498/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Fclimbing%2FSimpleClimber.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/f107fbc8b93883ec5513916c6c7fb5a819e6b498/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Fclimbing%2FSimpleClimber.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fsketch%2Fclimbing%2FSimpleClimber.java?ref=f107fbc8b93883ec5513916c6c7fb5a819e6b498",
      "patch": "@@ -100,7 +100,7 @@ public double percentSample() {\n       return config().getDouble(BASE_PATH + \"percent-sample\");\n     }\n     public double tolerance() {\n-      return config().getInt(BASE_PATH + \"tolerance\");\n+      return config().getDouble(BASE_PATH + \"tolerance\");\n     }\n   }\n }",
      "parent_sha": "29389bef6351bad4b60e8d432a5d1cb208d2db52"
    }
  },
  {
    "oid": "8bdfb0d95db523d15c2560f05a228468ecdbe98d",
    "message": "Fixed typo",
    "date": "2020-01-27T07:23:14Z",
    "url": "https://github.com/ben-manes/caffeine/commit/8bdfb0d95db523d15c2560f05a228468ecdbe98d",
    "details": {
      "sha": "11039cc468f90fb8df932649d4a74cf776704db1",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/configuration/CaffeineConfiguration.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/8bdfb0d95db523d15c2560f05a228468ecdbe98d/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fconfiguration%2FCaffeineConfiguration.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/8bdfb0d95db523d15c2560f05a228468ecdbe98d/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fconfiguration%2FCaffeineConfiguration.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fconfiguration%2FCaffeineConfiguration.java?ref=8bdfb0d95db523d15c2560f05a228468ecdbe98d",
      "patch": "@@ -366,7 +366,7 @@ public void setExpiryFactory(Optional<Factory<? extends Expiry<K, V>>> factory)\n   }\n \n   /**\n-   * Set the maximum weight.\n+   * Set the maximum size.\n    *\n    * @param maximumSize the maximum size\n    */\n@@ -377,7 +377,7 @@ public void setMaximumSize(OptionalLong maximumSize) {\n   }\n \n   /**\n-   * Returns the maximum weight to be used for the cache.\n+   * Returns the maximum size to be used for the cache.\n    *\n    * @return the maximum size\n    */",
      "parent_sha": "abdc478f60d1af60b4b9f99ec5bff4f91fa772b9"
    }
  },
  {
    "oid": "46bd35cdc9eda18870ac7b9f8e95fd425f269a2f",
    "message": "Disable soft ref test as unstable",
    "date": "2015-01-07T04:42:35Z",
    "url": "https://github.com/ben-manes/caffeine/commit/46bd35cdc9eda18870ac7b9f8e95fd425f269a2f",
    "details": {
      "sha": "649dc6eacf408ea88d4025160340fe7ff83fda15",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/ReferenceTest.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/46bd35cdc9eda18870ac7b9f8e95fd425f269a2f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/46bd35cdc9eda18870ac7b9f8e95fd425f269a2f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java?ref=46bd35cdc9eda18870ac7b9f8e95fd425f269a2f",
      "patch": "@@ -63,7 +63,7 @@ public void evict_weakValues(Cache<Integer, Integer> cache, CacheContext context\n     cleanUp(cache, context, 0);\n   }\n \n-  @Test(dataProvider = \"caches\")\n+  @Test(enabled = false, dataProvider = \"caches\")\n   @CacheSpec(values = ReferenceType.SOFT, population = Population.FULL)\n   public void evict_softValues(Cache<Integer, Integer> cache, CacheContext context) {\n     context.clear();",
      "parent_sha": "08a2fe1e20f220ce7927a4b7e38c18e2411d99b9"
    }
  },
  {
    "oid": "7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a",
    "message": "Perform replace() in compute block\n\nA similar issue to resurrecting an expired value occurs with weights of\nzero. An atomic change of the weight should have to be performed in a\ncompute block so that the proper fix can be applied. The non-compute\nversion of replace & put come from CLHM, which didn't have that feature\nand was pre-JDK8.\n\nThis issue remains for put(), but that has proven harder to solve so this\nis going in alone. A fixed put() is almost the same as a compute() via\nremap(). That reuse doesn't quite work due to small differences, such as\nasserting the negative weight should happen prior to calling the writer.\nSo the fix may either be a modified copy of remap(), more flags on\nremap(), or the current logic transformed to a compute call.\n\nAfter fixing put, adding the resurrection and zero weight handling to\nevictMain() are required. A unit test would be good, if possible.",
    "date": "2015-10-07T03:28:00Z",
    "url": "https://github.com/ben-manes/caffeine/commit/7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a",
    "details": {
      "sha": "f91cf4279510a43cce29286c16cd80cf52a4119b",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 59,
      "deletions": 55,
      "changes": 114,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a",
      "patch": "@@ -1299,47 +1299,49 @@ public V replace(K key, V value) {\n     requireNonNull(key);\n     requireNonNull(value);\n \n-    final int weight = weigher.weigh(key, value);\n-    final Node<K, V> node = data.get(nodeFactory.newLookupKey(key));\n+    int[] oldWeight = new int[1];\n+    @SuppressWarnings(\"unchecked\")\n+    K[] nodeKey = (K[]) new Object[1];\n+    @SuppressWarnings(\"unchecked\")\n+    V[] oldValue = (V[]) new Object[1];\n+    long now = expirationTicker().read();\n+    int weight = weigher.weigh(key, value);\n     tracer().recordWrite(id, key, weight);\n-    if (node == null) {\n-      return null;\n-    }\n+    Node<K, V> node = data.computeIfPresent(nodeFactory.newLookupKey(key), (k, n) -> {\n+      synchronized (n) {\n+        nodeKey[0] = n.getKey();\n+        oldValue[0] = n.getValue();\n+        oldWeight[0] = n.getWeight();\n+        if ((nodeKey[0] == null) || (oldValue[0] == null) || hasExpired(n, now)) {\n+          oldValue[0] = null;\n+          return n;\n+        }\n \n-    K oldKey;\n-    V oldValue;\n-    int oldWeight;\n-    long now = expirationTicker().read();\n-    synchronized (node) {\n-      if (!node.isAlive()) {\n-        return null;\n-      }\n-      oldKey = node.getKey();\n-      oldValue = node.getValue();\n-      oldWeight = node.getWeight();\n-      if ((oldKey == null) || (oldValue == null) || hasExpired(node, now)) {\n-        return null;\n+        if (value != oldValue[0]) {\n+          writer.write(nodeKey[0], value);\n+        }\n+        n.setValue(value, valueReferenceQueue());\n+        n.setWriteTime(now);\n+        n.setWeight(weight);\n+        return n;\n       }\n+    });\n \n-      if (value != oldValue) {\n-        writer.write(key, value);\n-      }\n-      node.setValue(value, valueReferenceQueue());\n-      node.setWeight(weight);\n+    if (oldValue[0] == null) {\n+      return null;\n     }\n \n-    int weightedDifference = (weight - oldWeight);\n+    int weightedDifference = (weight - oldWeight[0]);\n     if (expiresAfterWrite() || (weightedDifference != 0)) {\n       afterWrite(node, new UpdateTask(node, weightedDifference), now);\n     } else {\n-      node.setWriteTime(now);\n       afterRead(node, now, false);\n     }\n \n-    if (hasRemovalListener() && (value != oldValue)) {\n-      notifyRemoval(oldKey, oldValue, RemovalCause.REPLACED);\n+    if (hasRemovalListener() && (value != oldValue[0])) {\n+      notifyRemoval(nodeKey[0], oldValue[0], RemovalCause.REPLACED);\n     }\n-    return oldValue;\n+    return oldValue[0];\n   }\n \n   @Override\n@@ -1349,46 +1351,48 @@ public boolean replace(K key, V oldValue, V newValue) {\n     requireNonNull(newValue);\n \n     final int weight = weigher.weigh(key, newValue);\n-    final Node<K, V> node = data.get(nodeFactory.newLookupKey(key));\n     tracer().recordWrite(id, key, weight);\n-    if (node == null) {\n-      return false;\n-    }\n-\n-    K oldKey;\n-    V prevValue;\n-    int oldWeight;\n+    boolean[] replaced = new boolean[1];\n+    @SuppressWarnings(\"unchecked\")\n+    K[] nodeKey = (K[]) new Object[1];\n+    @SuppressWarnings(\"unchecked\")\n+    V[] prevValue = (V[]) new Object[1];\n+    int[] oldWeight = new int[1];\n     long now = expirationTicker().read();\n-    synchronized (node) {\n-      if (!node.isAlive()) {\n-        return false;\n-      }\n+    Node<K, V> node = data.computeIfPresent(nodeFactory.newLookupKey(key), (k, n) -> {\n+      synchronized (n) {\n+        nodeKey[0] = n.getKey();\n+        prevValue[0] = n.getValue();\n+        oldWeight[0] = n.getWeight();\n+        if ((nodeKey[0] == null) || (prevValue[0] == null)\n+            || hasExpired(n, now) || !n.containsValue(oldValue)) {\n+          return n;\n+        }\n \n-      oldKey = node.getKey();\n-      prevValue = node.getValue();\n-      oldWeight = node.getWeight();\n-      if ((oldKey == null) || (prevValue == null) || hasExpired(node, now)\n-          || !node.containsValue(oldValue)) {\n-        return false;\n+        if (newValue != prevValue[0]) {\n+          writer.write(key, newValue);\n+        }\n+        n.setValue(newValue, valueReferenceQueue());\n+        n.setWeight(weight);\n+        n.setWriteTime(now);\n+        replaced[0] = true;\n       }\n+      return n;\n+    });\n \n-      if (newValue != prevValue) {\n-        writer.write(key, newValue);\n-      }\n-      node.setValue(newValue, valueReferenceQueue());\n-      node.setWeight(weight);\n+    if (!replaced[0]) {\n+      return false;\n     }\n \n-    int weightedDifference = (weight - oldWeight);\n+    int weightedDifference = (weight - oldWeight[0]);\n     if (expiresAfterWrite() || (weightedDifference != 0)) {\n       afterWrite(node, new UpdateTask(node, weightedDifference), now);\n     } else {\n-      node.setWriteTime(now);\n       afterRead(node, now, false);\n     }\n \n     if (hasRemovalListener() && (oldValue != newValue)) {\n-      notifyRemoval(oldKey, prevValue, RemovalCause.REPLACED);\n+      notifyRemoval(nodeKey[0], prevValue[0], RemovalCause.REPLACED);\n     }\n     return true;\n   }\n@@ -1452,8 +1456,8 @@ V doComputeIfAbsent(K key, Object keyRef, Function<? super K, ? extends V> mappi\n           return n;\n         }\n \n-        newValue[0] = statsAware(mappingFunction, isAsync).apply(key);\n         writer.delete(nodeKey[0], oldValue[0], cause[0]);\n+        newValue[0] = statsAware(mappingFunction, isAsync).apply(key);\n         if (newValue[0] == null) {\n           removed[0] = n;\n           n.retire();",
      "parent_sha": "41561862d29e007153a0729267d46847461cbc40"
    }
  },
  {
    "oid": "ea0b2f6f7239a6fe4b09914e362b712438e5b645",
    "message": "Add one-shot read buffer",
    "date": "2015-02-09T02:12:44Z",
    "url": "https://github.com/ben-manes/caffeine/commit/ea0b2f6f7239a6fe4b09914e362b712438e5b645",
    "details": {
      "sha": "bf9ea41c680aee3fc3a84b0926088c54d7c7694e",
      "filename": "caffeine/src/jmh/java/com/github/benmanes/caffeine/cache/ReadBufferBenchmark.java",
      "status": "modified",
      "additions": 70,
      "deletions": 4,
      "changes": 74,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/ea0b2f6f7239a6fe4b09914e362b712438e5b645/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReadBufferBenchmark.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/ea0b2f6f7239a6fe4b09914e362b712438e5b645/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReadBufferBenchmark.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fjmh%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReadBufferBenchmark.java?ref=ea0b2f6f7239a6fe4b09914e362b712438e5b645",
      "patch": "@@ -28,6 +28,8 @@\n import org.openjdk.jmh.annotations.Setup;\n import org.openjdk.jmh.annotations.State;\n \n+import com.github.benmanes.caffeine.base.UnsafeAccess;\n+\n /**\n  * A concurrent benchmark for read buffer implementation options. A read buffer may be a lossy,\n  * bounded, non-blocking, multiple-producer / single-consumer unordered queue. These buffers are\n@@ -77,23 +79,25 @@ interface Buffer {\n \n   public enum BufferType {\n     LOSSY { @Override public Buffer create() { return new LossyBuffer(); } },\n+    ONE_SHOT { @Override public Buffer create() { return new OneShotBuffer(); } },\n     CLQ { @Override public Buffer create() { return new QueueBuffer(); } };\n \n     public abstract Buffer create();\n   }\n \n+  /** A bounded buffer that uses lossy writes and may race with the reader. */\n   static final class LossyBuffer implements Buffer {\n-    final AtomicReference<Boolean>[] buffer;\n+    final RelaxedAtomic<Boolean>[] buffer;\n     final AtomicInteger writeCounter;\n     final AtomicInteger readCounter;\n \n     @SuppressWarnings(\"unchecked\")\n     LossyBuffer() {\n       readCounter = new AtomicInteger();\n       writeCounter = new AtomicInteger();\n-      buffer = new AtomicReference[READ_BUFFER_SIZE];\n+      buffer = new RelaxedAtomic[READ_BUFFER_SIZE];\n       for (int i = 0; i < READ_BUFFER_SIZE; i++) {\n-        buffer[i] = new AtomicReference<Boolean>();\n+        buffer[i] = new RelaxedAtomic<Boolean>();\n       }\n     }\n \n@@ -109,7 +113,7 @@ public void drain() {\n       int readCount = readCounter.get();\n       for (int i = 0; i < READ_BUFFER_SIZE; i++) {\n         int index = readCount & READ_BUFFER_INDEX_MASK;\n-        Boolean value = buffer[index].get();\n+        Boolean value = buffer[index].getRelaxed();\n         if (value == null) {\n           break;\n         }\n@@ -120,6 +124,47 @@ public void drain() {\n     }\n   }\n \n+  /** A bounded buffer that attempts to record once. */\n+  static final class OneShotBuffer implements Buffer {\n+    final RelaxedAtomic<Boolean>[] buffer;\n+    final AtomicInteger writeCounter;\n+    final AtomicInteger readCounter;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    OneShotBuffer() {\n+      readCounter = new AtomicInteger();\n+      writeCounter = new AtomicInteger();\n+      buffer = new RelaxedAtomic[READ_BUFFER_SIZE];\n+      for (int i = 0; i < READ_BUFFER_SIZE; i++) {\n+        buffer[i] = new RelaxedAtomic<Boolean>();\n+      }\n+    }\n+\n+    @Override\n+    public void record() {\n+      final int writeCount = writeCounter.get();\n+      final int index = writeCount & READ_BUFFER_INDEX_MASK;\n+      if ((buffer[index].getRelaxed() == null) && buffer[index].compareAndSet(null, Boolean.TRUE)) {\n+        writeCounter.lazySet(writeCount + 1);\n+      }\n+    }\n+\n+    @Override\n+    public void drain() {\n+      int readCount = readCounter.get();\n+      for (int i = 0; i < READ_BUFFER_SIZE; i++) {\n+        int index = readCount & READ_BUFFER_INDEX_MASK;\n+        Boolean value = buffer[index].getRelaxed();\n+        if (value == null) {\n+          break;\n+        }\n+        buffer[index].lazySet(null);\n+        readCount++;\n+      }\n+      readCounter.lazySet(readCount);\n+    }\n+  }\n+\n   static final class QueueBuffer implements Buffer {\n     final Queue<Boolean> buffer = new ConcurrentLinkedQueue<>();\n \n@@ -133,4 +178,25 @@ public void drain() {\n       while (buffer.poll() != null) {}\n     }\n   }\n+\n+  /** An {@link AtomicReference} like holder that supports relaxed reads. */\n+  static final class RelaxedAtomic<E> {\n+    static final long VALUE_OFFSET = UnsafeAccess.objectFieldOffset(RelaxedAtomic.class, \"value\");\n+\n+    @SuppressWarnings(\"unused\")\n+    private volatile E value;\n+\n+    @SuppressWarnings(\"unchecked\")\n+    public E getRelaxed() {\n+      return (E) UnsafeAccess.UNSAFE.getObject(this, VALUE_OFFSET);\n+    }\n+\n+    public boolean compareAndSet(E expect, E update) {\n+      return UnsafeAccess.UNSAFE.compareAndSwapObject(this, VALUE_OFFSET, expect, update);\n+    }\n+\n+    public final void lazySet(E newValue) {\n+      UnsafeAccess.UNSAFE.putOrderedObject(this, VALUE_OFFSET, newValue);\n+    }\n+  }\n }",
      "parent_sha": "0704e4df7b3c9844ac5d4ba62c61bdc7985464a2"
    }
  },
  {
    "oid": "2736608cd9acea673c1d365c41b1b03723597de3",
    "message": "Rewrite put() to use compute\n\nAs discussed in the previous commit, this is needed for resurrecting\nan entry about to be evicted but lost the race that set weight=0. This\nalso is in some ways a simpler version to verify correctness and is\na lighter variant of remap(). The changes do lose some optimizations,\nbut those probably didn't help much due to writes dominated by other\nfactors.",
    "date": "2015-10-08T04:05:05Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2736608cd9acea673c1d365c41b1b03723597de3",
    "details": {
      "sha": "d435309b0707b0745b40c5bc694bb81f0ab092d7",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 57,
      "deletions": 59,
      "changes": 116,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2736608cd9acea673c1d365c41b1b03723597de3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2736608cd9acea673c1d365c41b1b03723597de3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=2736608cd9acea673c1d365c41b1b03723597de3",
      "patch": "@@ -1134,79 +1134,77 @@ V put(K key, V value, boolean notifyWriter, boolean onlyIfAbsent) {\n     requireNonNull(key);\n     requireNonNull(value);\n \n-    Node<K, V> node = null;\n+    @SuppressWarnings(\"unchecked\")\n+    K[] nodeKey = (K[]) new Object[1];\n+    @SuppressWarnings(\"unchecked\")\n+    V[] oldValue = (V[]) new Object[1];\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    RemovalCause[] cause = new RemovalCause[1];\n     long now = expirationTicker().read();\n-    int weight = weigher.weigh(key, value);\n-    tracer().recordWrite(id, key, weight);\n \n-    for (;;) {\n-      Node<K, V> prior = data.get(nodeFactory.newLookupKey(key));\n-      if (prior == null) {\n-        if (node == null) {\n-          node = nodeFactory.newNode(key, keyReferenceQueue(),\n-              value, valueReferenceQueue(), weight, now);\n-        }\n-        Node<K, V> computed = node;\n-        prior = data.computeIfAbsent(node.getKeyReference(), k -> {\n-          if (notifyWriter) {\n-            writer.write(key, value);\n-          }\n-          return computed;\n-        });\n-        if (prior == node) {\n-          afterWrite(node, new AddTask(node, weight), now);\n-          return null;\n+    int[] oldWeight = new int[1];\n+    int newWeight = weigher.weigh(key, value);\n+    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n+    Node<K, V> node = data.compute(keyRef, (kr, n) -> {\n+      if (n == null) {\n+        if (notifyWriter) {\n+          writer.write(key, value);\n         }\n+        return nodeFactory.newNode(kr, value, valueReferenceQueue(), newWeight, now);\n       }\n \n-      V oldValue;\n-      int oldWeight;\n-      boolean expired = false;\n-      boolean mayUpdate = true;\n-      synchronized (prior) {\n-        if (!prior.isAlive()) {\n-          continue;\n+      synchronized (n) {\n+        nodeKey[0] = n.getKey();\n+        oldValue[0] = n.getValue();\n+        oldWeight[0] = n.getWeight();\n+        if ((nodeKey == null) || (oldValue[0] == null)) {\n+          cause[0] = RemovalCause.COLLECTED;\n+        } else if (hasExpired(n, now)) {\n+          cause[0] = RemovalCause.EXPIRED;\n         }\n-        oldValue = prior.getValue();\n-        oldWeight = prior.getWeight();\n-        if (oldValue == null) {\n-          writer.delete(key, null, RemovalCause.COLLECTED);\n-        } else if (hasExpired(prior, now)) {\n-          writer.delete(key, oldValue, RemovalCause.EXPIRED);\n-          expired = true;\n-        } else if (onlyIfAbsent) {\n-          mayUpdate = false;\n+        if (cause[0] != null) {\n+          writer.delete(nodeKey[0], oldValue[0], cause[0]);\n+        } else if (onlyIfAbsent && (oldValue[0] != null)) {\n+          return n;\n         }\n \n-        if (notifyWriter && (expired || (mayUpdate && (value != oldValue)))) {\n-          writer.write(key, value);\n-        }\n-        if (mayUpdate) {\n-          prior.setValue(value, valueReferenceQueue());\n-          prior.setWeight(weight);\n+        if (value != oldValue[0]) {\n+          if (cause[0] == null) {\n+            cause[0] = RemovalCause.REPLACED;\n+          }\n+          if (notifyWriter) {\n+            writer.write(key, value);\n+          }\n         }\n-      }\n \n-      if (hasRemovalListener()) {\n-        if (expired) {\n-          notifyRemoval(key, oldValue, RemovalCause.EXPIRED);\n-        } else if (oldValue == null) {\n-          notifyRemoval(key, oldValue, RemovalCause.COLLECTED);\n-        } else if (mayUpdate && (value != oldValue)) {\n-          notifyRemoval(key, oldValue, RemovalCause.REPLACED);\n-        }\n+        n.setValue(value, valueReferenceQueue());\n+        n.setWeight(newWeight);\n+        n.setAccessTime(now);\n+        n.setWriteTime(now);\n+        return n;\n       }\n+    });\n \n-      int weightedDifference = mayUpdate ? (weight - oldWeight) : 0;\n-      if ((oldValue == null) || (weightedDifference != 0) || expired\n-          || (!onlyIfAbsent && (oldValue != null) && expiresAfterWrite())) {\n-        afterWrite(prior, new UpdateTask(prior, weightedDifference), now);\n-      } else {\n-        afterRead(prior, now, false);\n+    if (cause[0] != null) {\n+      if (cause[0].wasEvicted()) {\n+        statsCounter().recordEviction();\n       }\n+      if (hasRemovalListener()) {\n+        notifyRemoval(nodeKey[0], oldValue[0], cause[0]);\n+      }\n+    }\n \n-      return expired ? null : oldValue;\n+    if ((oldValue[0] == null) && (cause[0] == null)) {\n+      afterWrite(node, new AddTask(node, newWeight), now);\n+    } else if (onlyIfAbsent && (oldValue[0] != null) && (cause[0] == null)) {\n+      afterRead(node, now, false);\n+    } else {\n+      int weightedDifference = newWeight - oldWeight[0];\n+      afterWrite(node, new UpdateTask(node, weightedDifference), now);\n     }\n+\n+    tracer().recordWrite(id, key, newWeight);\n+    return (cause[0] == null) || (cause[0] == RemovalCause.REPLACED) ? oldValue[0] : null;\n   }\n \n   @Override\n@@ -1625,7 +1623,7 @@ V remap(K key, Object keyRef, BiFunction<? super K, ? super V, ? extends V> rema\n         n.setWeight(weight[1]);\n         n.setWriteTime(now);\n         n.setAccessTime(now);\n-        if ((cause[0] == null) && (newValue[0] != oldValue)) {\n+        if ((cause[0] == null) && (newValue[0] != oldValue[0])) {\n           cause[0] = RemovalCause.REPLACED;\n         }\n         return n;",
      "parent_sha": "7ba750b5f3fea4232bc4f6cbf84f25d09ba9c81a"
    }
  },
  {
    "oid": "bd19a3cf3c5b10fe1214026b3ef6e3272f1e1800",
    "message": "Verify maximumWeight before setting",
    "date": "2020-11-02T15:40:21Z",
    "url": "https://github.com/ben-manes/caffeine/commit/bd19a3cf3c5b10fe1214026b3ef6e3272f1e1800",
    "details": {
      "sha": "3712ccd07c7916d37475ccc4e8c3a7dae0356c9a",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/bd19a3cf3c5b10fe1214026b3ef6e3272f1e1800/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/bd19a3cf3c5b10fe1214026b3ef6e3272f1e1800/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=bd19a3cf3c5b10fe1214026b3ef6e3272f1e1800",
      "patch": "@@ -407,8 +407,8 @@ public Caffeine<K, V> maximumWeight(@NonNegative long maximumWeight) {\n         \"maximum weight was already set to %s\", this.maximumWeight);\n     requireState(this.maximumSize == UNSET_INT,\n         \"maximum size was already set to %s\", this.maximumSize);\n-    this.maximumWeight = maximumWeight;\n     requireArgument(maximumWeight >= 0, \"maximum weight must not be negative\");\n+    this.maximumWeight = maximumWeight;\n     return this;\n   }\n ",
      "parent_sha": "e6c1225aa4ab9e13fe696c1e93a058d7e3efa26e"
    }
  },
  {
    "oid": "a29ac994e0537c4c399901bb47ac4b287f64bb0f",
    "message": "filter invalid event in object store trace (#814)",
    "date": "2022-11-08T18:31:11Z",
    "url": "https://github.com/ben-manes/caffeine/commit/a29ac994e0537c4c399901bb47ac4b287f64bb0f",
    "details": {
      "sha": "3309a3b4ad47ea65de5136dc9e488fd6f0603990",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/parser/snia/keyvalue/ObjectStoreTraceReader.java",
      "status": "modified",
      "additions": 5,
      "deletions": 2,
      "changes": 7,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/a29ac994e0537c4c399901bb47ac4b287f64bb0f/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/a29ac994e0537c4c399901bb47ac4b287f64bb0f/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java?ref=a29ac994e0537c4c399901bb47ac4b287f64bb0f",
      "patch": "@@ -48,7 +48,7 @@ public Stream<AccessEvent> events() {\n     return lines()\n         .map(line -> line.split(\" \"))\n         .filter(array -> array[1].equals(\"REST.GET.OBJECT\"))\n-        .map(array -> {\n+        .flatMap(array -> {\n           long key = new BigInteger(array[2], 16).longValue();\n           int weight;\n           if (array.length == 3) {\n@@ -58,7 +58,10 @@ public Stream<AccessEvent> events() {\n             long end = Long.parseLong(array[5]);\n             weight = Ints.saturatedCast(end - start);\n           }\n-          return AccessEvent.forKeyAndWeight(key, weight);\n+          if (weight < 0) {\n+              return Stream.empty();\n+          }\n+          return Stream.of(AccessEvent.forKeyAndWeight(key, weight));\n         });\n   }\n }",
      "parent_sha": "75e9f52114dbf64843b5c9bfa09255f03984000b"
    }
  },
  {
    "oid": "45c2745c1b64cf057fef6536082786d317925da6",
    "message": "Try to stabilize the test case",
    "date": "2015-01-22T23:20:50Z",
    "url": "https://github.com/ben-manes/caffeine/commit/45c2745c1b64cf057fef6536082786d317925da6",
    "details": {
      "sha": "1cff5eb01934bcc80d6421dc0661790b0fafbb56",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/ReferenceTest.java",
      "status": "modified",
      "additions": 11,
      "deletions": 14,
      "changes": 25,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/45c2745c1b64cf057fef6536082786d317925da6/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/45c2745c1b64cf057fef6536082786d317925da6/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FReferenceTest.java?ref=45c2745c1b64cf057fef6536082786d317925da6",
      "patch": "@@ -22,7 +22,7 @@\n import java.lang.ref.SoftReference;\n import java.util.ArrayList;\n import java.util.List;\n-import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n \n import org.testng.annotations.Listeners;\n import org.testng.annotations.Test;\n@@ -50,19 +50,16 @@ public final class ReferenceTest {\n   @Test(dataProvider = \"caches\")\n   @CacheSpec(keys = ReferenceType.WEAK, population = Population.EMPTY)\n   public void evict_weakKeys(Cache<Integer, Integer> cache, CacheContext context) {\n-    context.original().clear();\n-    cache.put(new Random().nextInt(), 0);\n-    GcFinalization.awaitFullGc();\n-    cleanUp(cache, context, 0);\n+    cache.put(Integer.MIN_VALUE + ThreadLocalRandom.current().nextInt(), 0);\n+    cleanUpUntilEmpty(cache, context);\n     assertThat(cache, hasRemovalNotifications(context, 1, RemovalCause.COLLECTED));\n   }\n \n   @Test(dataProvider = \"caches\")\n   @CacheSpec(values = ReferenceType.WEAK, population = Population.FULL)\n   public void evict_weakValues(Cache<Integer, Integer> cache, CacheContext context) {\n     context.original().clear();\n-    GcFinalization.awaitFullGc();\n-    cleanUp(cache, context, 0);\n+    cleanUpUntilEmpty(cache, context);\n     assertThat(cache, hasRemovalNotifications(\n         context, context.initialSize(), RemovalCause.COLLECTED));\n   }\n@@ -72,21 +69,21 @@ public void evict_weakValues(Cache<Integer, Integer> cache, CacheContext context\n   public void evict_softValues(Cache<Integer, Integer> cache, CacheContext context) {\n     context.clear();\n     awaitSoftRefGc();\n-    cleanUp(cache, context, 0);\n+    cleanUpUntilEmpty(cache, context);\n     assertThat(cache, hasRemovalNotifications(\n         context, context.initialSize(), RemovalCause.COLLECTED));\n   }\n \n-  static void cleanUp(Cache<Integer, Integer> cache, CacheContext context, long finalSize) {\n+  static void cleanUpUntilEmpty(Cache<Integer, Integer> cache, CacheContext context) {\n     // As clean-up is amortized, pretend that the increment count may be as low as per entry\n-    for (int i = 0; i < context.population().size(); i++) {\n+    int i = 0;\n+    do {\n+      GcFinalization.awaitFullGc();\n       cache.cleanUp();\n-      if (cache.estimatedSize() == finalSize) {\n+      if (cache.asMap().isEmpty()) {\n         return; // passed\n       }\n-    }\n-    GcFinalization.awaitFullGc();\n-    cache.cleanUp();\n+    } while (i++ < context.population().size());\n     assertThat(cache.estimatedSize(), is(0L));\n   }\n ",
      "parent_sha": "c8a9aa79dc739d84e022ab74d6a451b8bf118db5"
    }
  },
  {
    "oid": "3713aa8aa6e6c4eb3a5832154f4e1f55106fd088",
    "message": "Fix typo in error message\n\nFix typo in error message.",
    "date": "2016-08-10T19:27:48Z",
    "url": "https://github.com/ben-manes/caffeine/commit/3713aa8aa6e6c4eb3a5832154f4e1f55106fd088",
    "details": {
      "sha": "e3837dc259d77753feac16950a4263b10377cc7b",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/LocalAsyncLoadingCache.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/3713aa8aa6e6c4eb3a5832154f4e1f55106fd088/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalAsyncLoadingCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/3713aa8aa6e6c4eb3a5832154f4e1f55106fd088/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalAsyncLoadingCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalAsyncLoadingCache.java?ref=3713aa8aa6e6c4eb3a5832154f4e1f55106fd088",
      "patch": "@@ -139,7 +139,7 @@ CompletableFuture<V> get(K key,\n         long loadTime = cache.statsTicker().read() - startTime;\n         if (value == null) {\n           if (error != null) {\n-            logger.log(Level.WARNING, \"Exception thrown during asynchonous load\", error);\n+            logger.log(Level.WARNING, \"Exception thrown during asynchronous load\", error);\n           }\n           cache.statsCounter().recordLoadFailure(loadTime);\n           cache.remove(key, result[0]);\n@@ -241,7 +241,7 @@ public void put(K key, CompletableFuture<V> valueFuture) {\n       long loadTime = cache.statsTicker().read() - startTime;\n       if (value == null) {\n         if (error != null) {\n-          logger.log(Level.WARNING, \"Exception thrown during asynchonous load\", error);\n+          logger.log(Level.WARNING, \"Exception thrown during asynchronous load\", error);\n         }\n         cache.remove(key, valueFuture);\n         cache.statsCounter().recordLoadFailure(loadTime);\n@@ -281,7 +281,7 @@ public void accept(Map<K, V> result, Throwable error) {\n           entry.getValue().obtrudeException(error);\n         }\n         cache.statsCounter().recordLoadFailure(loadTime);\n-        logger.log(Level.WARNING, \"Exception thrown during asynchonous load\", error);\n+        logger.log(Level.WARNING, \"Exception thrown during asynchronous load\", error);\n       } else {\n         fillProxies(result);\n         addNewEntries(result);",
      "parent_sha": "00bc8959d1ddbaebdab27a93779c1d7ebb45b402"
    }
  },
  {
    "oid": "4119f9c026d8ebb5bf59d9005b4c08428b0e9189",
    "message": "Fix IllegalStateException being thrown for all event types.",
    "date": "2017-07-04T03:03:40Z",
    "url": "https://github.com/ben-manes/caffeine/commit/4119f9c026d8ebb5bf59d9005b4c08428b0e9189",
    "details": {
      "sha": "ed7620e8fabd994acf56e796d46fe08f71afb3d2",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/event/EventTypeAwareListener.java",
      "status": "modified",
      "additions": 4,
      "deletions": 4,
      "changes": 8,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/4119f9c026d8ebb5bf59d9005b4c08428b0e9189/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fevent%2FEventTypeAwareListener.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/4119f9c026d8ebb5bf59d9005b4c08428b0e9189/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fevent%2FEventTypeAwareListener.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fevent%2FEventTypeAwareListener.java?ref=4119f9c026d8ebb5bf59d9005b4c08428b0e9189",
      "patch": "@@ -66,16 +66,16 @@ public void dispatch(@Nonnull JCacheEntryEvent<K, V> event) {\n       switch (event.getEventType()) {\n         case CREATED:\n           onCreated(event);\n-          break;\n+          return;\n         case UPDATED:\n           onUpdated(event);\n-          break;\n+          return;\n         case REMOVED:\n           onRemoved(event);\n-          break;\n+          return;\n         case EXPIRED:\n           onExpired(event);\n-          break;\n+          return;\n       }\n       throw new IllegalStateException(\"Unknown event type: \" + event.getEventType());\n     } catch (Exception e) {",
      "parent_sha": "3f8054d16842478de3139780bda339e04e5ed770"
    }
  },
  {
    "oid": "b1a18626488ca9be6cbed60c3900445d87c4cf85",
    "message": "Guard against the worst case random seed\n\nMultiplying by zero would trigger all collisions. An XOR would have\na worse of 0xFFFFFFFF, so not much better. Instead we can bound the\nint range to be above zero and optionally make negative.",
    "date": "2015-10-13T16:52:28Z",
    "url": "https://github.com/ben-manes/caffeine/commit/b1a18626488ca9be6cbed60c3900445d87c4cf85",
    "details": {
      "sha": "95acf79606721f4501147e1afce7932d10614f71",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/FrequencySketch.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/b1a18626488ca9be6cbed60c3900445d87c4cf85/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/b1a18626488ca9be6cbed60c3900445d87c4cf85/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java?ref=b1a18626488ca9be6cbed60c3900445d87c4cf85",
      "patch": "@@ -84,10 +84,12 @@ final class FrequencySketch<E> {\n    * @param maximumSize the maximum size of the cache\n    */\n   public FrequencySketch(@Nonnegative long maximumSize) {\n-    this(maximumSize, ThreadLocalRandom.current().nextInt());\n+    this(maximumSize, (ThreadLocalRandom.current().nextBoolean() ? 1 : -1)\n+        * ThreadLocalRandom.current().nextInt(1, Integer.MAX_VALUE));\n   }\n \n   FrequencySketch(@Nonnegative long maximumSize, int randomSeed) {\n+    Caffeine.requireArgument(randomSeed != 0);\n     this.randomSeed = randomSeed;\n     ensureCapacity(maximumSize);\n   }",
      "parent_sha": "c669421de9b70fcdae1c20aa7d5eb34967614190"
    }
  },
  {
    "oid": "9d7173c06be21cf72fa1eea9ad657b63741966b3",
    "message": "Guava tests fail on CI",
    "date": "2015-01-07T12:02:07Z",
    "url": "https://github.com/ben-manes/caffeine/commit/9d7173c06be21cf72fa1eea9ad657b63741966b3",
    "details": {
      "sha": "d508b211450c84f7f2e6237fd6b475f0cee41fb4",
      "filename": "guava/src/test/java/com/google/common/cache/CacheLoadingTest.java",
      "status": "modified",
      "additions": 17,
      "deletions": 16,
      "changes": 33,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/9d7173c06be21cf72fa1eea9ad657b63741966b3/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheLoadingTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/9d7173c06be21cf72fa1eea9ad657b63741966b3/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheLoadingTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/guava%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgoogle%2Fcommon%2Fcache%2FCacheLoadingTest.java?ref=9d7173c06be21cf72fa1eea9ad657b63741966b3",
      "patch": "@@ -25,6 +25,21 @@\n import static java.util.Arrays.asList;\n import static java.util.concurrent.TimeUnit.MILLISECONDS;\n \n+import java.io.IOException;\n+import java.lang.ref.WeakReference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReferenceArray;\n+import java.util.logging.LogRecord;\n+\n+import junit.framework.TestCase;\n+\n import com.google.common.cache.CacheLoader.InvalidCacheLoadException;\n import com.google.common.cache.TestingCacheLoaders.CountingLoader;\n import com.google.common.cache.TestingCacheLoaders.IdentityLoader;\n@@ -41,21 +56,6 @@\n import com.google.common.util.concurrent.ListenableFuture;\n import com.google.common.util.concurrent.UncheckedExecutionException;\n \n-import junit.framework.TestCase;\n-\n-import java.io.IOException;\n-import java.lang.ref.WeakReference;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ConcurrentMap;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicReferenceArray;\n-import java.util.logging.LogRecord;\n-\n /**\n  * Tests relating to cache loading: concurrent loading, exceptions during loading, etc.\n  *\n@@ -2413,7 +2413,8 @@ public void run() {\n     assertEquals(\"barfoo\", cache.getUnchecked(key));\n   }\n \n-  public void testExpandDuringRefresh() throws InterruptedException, ExecutionException {\n+  // FIXME(ben): Fails on TravisCI\n+  public void disabled_testExpandDuringRefresh() throws InterruptedException, ExecutionException {\n     final AtomicInteger callCount = new AtomicInteger();\n     // tells the computing thread when to start computing\n     final CountDownLatch computeSignal = new CountDownLatch(1);",
      "parent_sha": "6f71e6222372b723ce3855a12741ab4de3966e86"
    }
  },
  {
    "oid": "c9d9f36ee503a0f9304e33b45328a75005ab7b25",
    "message": "Fix flaky test by enforcing the random seeds\n\nThe EvictionTest.evict_weighted() would fail spuriously with an async\ncache. This was because the random seeds were not being set to known\nvalues, causing a different entry to be evicted. Now handles both\nsynchronous and asynchronous cache wrappers to the underlying bounded\nmap.",
    "date": "2018-05-13T00:54:05Z",
    "url": "https://github.com/ben-manes/caffeine/commit/c9d9f36ee503a0f9304e33b45328a75005ab7b25",
    "details": {
      "sha": "58b8009a9c9414f181a6d25f6bf7e74b11c507b6",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/RandomSeedEnforcer.java",
      "status": "modified",
      "additions": 17,
      "deletions": 3,
      "changes": 20,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/c9d9f36ee503a0f9304e33b45328a75005ab7b25/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRandomSeedEnforcer.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/c9d9f36ee503a0f9304e33b45328a75005ab7b25/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRandomSeedEnforcer.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FRandomSeedEnforcer.java?ref=c9d9f36ee503a0f9304e33b45328a75005ab7b25",
      "patch": "@@ -16,12 +16,15 @@\n package com.github.benmanes.caffeine.cache;\n \n import java.lang.reflect.Field;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import javax.annotation.Nullable;\n \n import com.github.benmanes.caffeine.base.UnsafeAccess;\n import com.google.common.base.Throwables;\n \n /**\n- * A hook to enforce a predictable random seed is used by Caffeine's caches.\n+ * A hook to enforce that a predictable random seed is used by Caffeine's caches.\n  *\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n@@ -34,17 +37,28 @@ private RandomSeedEnforcer() {}\n \n   /** Force the random seed to a predictable value. */\n   public static void ensureRandomSeed(Cache<?, ?> cache) {\n-    if (!(cache.asMap() instanceof BoundedLocalCache<?, ?>)) {\n+    BoundedLocalCache<?, ?> map = unwrap(cache);\n+    if (map == null) {\n       return;\n     }\n \n-    BoundedLocalCache<?, ?> map = (BoundedLocalCache<?, ?>) cache.asMap();\n     resetThreadLocalRandom();\n     if (map.evicts()) {\n       ensureRandomSeed(map.frequencySketch());\n     }\n   }\n \n+  /** Returns the underlying bounded cache, or null if not applicable. */\n+  private static @Nullable BoundedLocalCache<?, ?> unwrap(Cache<?, ?> cache) {\n+    ConcurrentMap<?, ?> map = cache.asMap();\n+    if (map instanceof LocalAsyncLoadingCache.AsMapView<?, ?>) {\n+      map = ((LocalAsyncLoadingCache.AsMapView<?, ?>) cache.asMap()).delegate;\n+    }\n+    return (map instanceof BoundedLocalCache<?, ?>)\n+        ? (BoundedLocalCache<?, ?>) map\n+        : null;\n+  }\n+\n   /** Forces the eviction jitter to be predictable. */\n   private static void resetThreadLocalRandom() {\n     UnsafeAccess.UNSAFE.putInt(Thread.currentThread(), PROBE, 0x9e3779b9);",
      "parent_sha": "a595c2c47a75344316e6c905fcdb058d60590ab5"
    }
  },
  {
    "oid": "259e4fe7dacc583db4dd56f30aa318af32a7e740",
    "message": "Fix a couple of typos in `Cache.getAll` javadoc",
    "date": "2021-01-11T10:39:15Z",
    "url": "https://github.com/ben-manes/caffeine/commit/259e4fe7dacc583db4dd56f30aa318af32a7e740",
    "details": {
      "sha": "618b912ba278afd99230cec15bb859e13e524a05",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Cache.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/259e4fe7dacc583db4dd56f30aa318af32a7e740/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/259e4fe7dacc583db4dd56f30aa318af32a7e740/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCache.java?ref=259e4fe7dacc583db4dd56f30aa318af32a7e740",
      "patch": "@@ -103,7 +103,7 @@ public interface Cache<K, V> {\n    * present in the cache. All entries returned by {@code mappingFunction} will be stored in the\n    * cache, over-writing any previously cached values. If another call to {@link #get} tries to load\n    * the value for a key in {@code keys}, implementations may either have that thread load the entry\n-   * or simply wait for this thread to finish and returns the loaded value. In the case of\n+   * or simply wait for this thread to finish and return the loaded value. In the case of\n    * overlapping non-blocking loads, the last load to complete will replace the existing entry. Note\n    * that multiple threads can concurrently load values for distinct keys.\n    * <p>\n@@ -114,7 +114,7 @@ public interface Cache<K, V> {\n    * @param mappingFunction the function to compute the values\n    * @return an unmodifiable mapping of keys to values for the specified keys in this cache\n    * @throws NullPointerException if the specified collection is null or contains a null element, or\n-   *         if the mao returned by the mappingFunction is null\n+   *         if the map returned by the mappingFunction is null\n    * @throws RuntimeException or Error if the mappingFunction does so, in which case the mapping is\n    *         left unestablished\n    */",
      "parent_sha": "9c1c9a78ae32905f6e7faab9d5a5005f789ae3d6"
    }
  },
  {
    "oid": "9536f65ba829fdaa74ce87a202b73d4aa5960854",
    "message": "fix object trace reader",
    "date": "2022-11-09T18:52:46Z",
    "url": "https://github.com/ben-manes/caffeine/commit/9536f65ba829fdaa74ce87a202b73d4aa5960854",
    "details": {
      "sha": "efc124d4c8497eea6e3d18d162a086f83cbf97eb",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/parser/snia/keyvalue/ObjectStoreTraceReader.java",
      "status": "modified",
      "additions": 3,
      "deletions": 8,
      "changes": 11,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/9536f65ba829fdaa74ce87a202b73d4aa5960854/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/9536f65ba829fdaa74ce87a202b73d4aa5960854/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fparser%2Fsnia%2Fkeyvalue%2FObjectStoreTraceReader.java?ref=9536f65ba829fdaa74ce87a202b73d4aa5960854",
      "patch": "@@ -50,14 +50,9 @@ public Stream<AccessEvent> events() {\n         .filter(array -> array[1].equals(\"REST.GET.OBJECT\"))\n         .flatMap(array -> {\n           long key = new BigInteger(array[2], 16).longValue();\n-          int weight;\n-          if (array.length == 3) {\n-            weight = Integer.parseInt(array[3]);\n-          } else {\n-            long start = Long.parseLong(array[4]);\n-            long end = Long.parseLong(array[5]);\n-            weight = Ints.saturatedCast(end - start);\n-          }\n+          long start = Long.parseLong(array[4]);\n+          long end = Long.parseLong(array[5]);\n+          int  weight = Ints.saturatedCast(end - start);\n           if (weight < 0) {\n               return Stream.empty();\n           }",
      "parent_sha": "24da0f842fffe9d6854832a1490264fcf531ca0f"
    }
  },
  {
    "oid": "317e64708539a7b86fceab6c25592465f035354d",
    "message": "Fix typo in Javadoc",
    "date": "2021-09-03T08:51:46Z",
    "url": "https://github.com/ben-manes/caffeine/commit/317e64708539a7b86fceab6c25592465f035354d",
    "details": {
      "sha": "334a5df65a3b35bef01c3e36a40c0ba65e9bdcc9",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Policy.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/317e64708539a7b86fceab6c25592465f035354d/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FPolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/317e64708539a7b86fceab6c25592465f035354d/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FPolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FPolicy.java?ref=317e64708539a7b86fceab6c25592465f035354d",
      "patch": "@@ -45,7 +45,7 @@ public interface Policy<K extends Object, V extends Object> {\n   /**\n    * Returns the value associated with the {@code key} in this cache, or {@code null} if there is no\n    * cached value for the {@code key}. Unlike {@link Cache#getIfPresent(Object)}, this method does\n-   * not produce any side effects such as updating statistics, the eviction policy, reseting the\n+   * not produce any side effects such as updating statistics, the eviction policy, resetting the\n    * expiration time, or triggering a refresh.\n    *\n    * @param key the key whose associated value is to be returned",
      "parent_sha": "16283e545199d68773bf1137e8e6016b53584d29"
    }
  },
  {
    "oid": "e784a9be401df54324d81048775431d3fdc574df",
    "message": "Fix JavaDoc code example",
    "date": "2016-02-19T22:07:29Z",
    "url": "https://github.com/ben-manes/caffeine/commit/e784a9be401df54324d81048775431d3fdc574df",
    "details": {
      "sha": "71348fd1f84949d260bc5027f3cc5369b371c63b",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/AsyncCacheLoader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/e784a9be401df54324d81048775431d3fdc574df/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncCacheLoader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/e784a9be401df54324d81048775431d3fdc574df/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncCacheLoader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncCacheLoader.java?ref=e784a9be401df54324d81048775431d3fdc574df",
      "patch": "@@ -33,7 +33,7 @@\n  * <pre>{@code\n  *   AsyncCacheLoader<Key, Graph> loader = (key, executor) ->\n  *       createExpensiveGraphAsync(key, executor);\n- *   AsyncLoadingCache<Key, Graph> cache = Caffeine.newBuilder().build(loader);\n+ *   AsyncLoadingCache<Key, Graph> cache = Caffeine.newBuilder().buildAsync(loader);\n  * }</pre>\n  *\n  * @author ben.manes@gmail.com (Ben Manes)",
      "parent_sha": "6cfbd44fe2a0b091bd65b5f61459b3ce0ac3d929"
    }
  },
  {
    "oid": "f5fc7d927257cef7258e64272c6874e1bf230883",
    "message": "Remove reminder as invalid, due to remove blocking. Synchronizing\nwill be necessary in eviction to handle concurrent updates and\nthat penalty will be small.",
    "date": "2015-01-23T11:29:56Z",
    "url": "https://github.com/ben-manes/caffeine/commit/f5fc7d927257cef7258e64272c6874e1bf230883",
    "details": {
      "sha": "b2dbcf5befc0cd4aea3e1a9ce1a518ce60858d6c",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Node.java",
      "status": "modified",
      "additions": 2,
      "deletions": 6,
      "changes": 8,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/f5fc7d927257cef7258e64272c6874e1bf230883/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNode.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/f5fc7d927257cef7258e64272c6874e1bf230883/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNode.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNode.java?ref=f5fc7d927257cef7258e64272c6874e1bf230883",
      "patch": "@@ -52,20 +52,16 @@ interface Node<K, V> extends AccessOrder<Node<K, V>>, WriteOrder<Node<K, V>> {\n \n   /* ---------------- Access order -------------- */\n \n-  // FIXME: Reading and writing weights may be unsafe if the node is not synchronized on by both\n-  // update operations and when evicting. However, synchronizing when evicting may not be ideal\n-  // because a computation may be in progress, blocking the eviction from progressing. Instead\n-  // the weight could be updated by a CAS to emulate the old state machine. That puts the penalty\n-  // on all writes, but at least is non-blocking on eviction. Flush out ideas for optimal handling.\n-\n   /** Returns the weight of this entry. */\n   @Nonnegative\n+  @GuardedBy(\"this\")\n   default int getWeight() {\n     throw new UnsupportedOperationException();\n   }\n \n   /** Sets the weight. */\n   @Nonnegative\n+  @GuardedBy(\"this\")\n   default void setWeight(int weight) {\n     throw new UnsupportedOperationException();\n   }",
      "parent_sha": "b72e43306aa1604dc939ef4001e67b00d0ed3dfd"
    }
  },
  {
    "oid": "39e6295fa33b5fe734ba16b6969737930cec27bf",
    "message": "JavaDoc that failed entries are automatically removed",
    "date": "2015-01-12T01:37:11Z",
    "url": "https://github.com/ben-manes/caffeine/commit/39e6295fa33b5fe734ba16b6969737930cec27bf",
    "details": {
      "sha": "ffe2a51521bed0815652908048611aefe96caa78",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/AsyncLoadingCache.java",
      "status": "modified",
      "additions": 8,
      "deletions": 4,
      "changes": 12,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/39e6295fa33b5fe734ba16b6969737930cec27bf/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/39e6295fa33b5fe734ba16b6969737930cec27bf/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java?ref=39e6295fa33b5fe734ba16b6969737930cec27bf",
      "patch": "@@ -43,7 +43,8 @@ public interface AsyncLoadingCache<K, V> {\n    * <p>\n    * If the specified key is not already associated with a value, attempts to compute its value\n    * asynchronously and enters it into this cache unless {@code null}. The entire method invocation\n-   * is performed atomically, so the function is applied at most once per key.\n+   * is performed atomically, so the function is applied at most once per key. If the asynchronous\n+   * computation fails, the entry will be automatically removed.\n    *\n    * @param key key with which the specified value is to be associated\n    * @param mappingFunction the function to asynchronously compute a value\n@@ -58,7 +59,8 @@ CompletableFuture<V> get(@Nonnull K key,\n \n   /**\n    * Returns the future associated with {@code key} in this cache, obtaining that value from\n-   * {@link CacheLoader#asyncLoad} if necessary.\n+   * {@link CacheLoader#asyncLoad} if necessary. If the asynchronous computation fails, the entry\n+   * will be automatically removed.\n    * <p>\n    * If the specified key is not already associated with a value, attempts to compute its value\n    * asynchronously and enters it into this cache unless {@code null}. The entire method invocation\n@@ -76,7 +78,8 @@ CompletableFuture<V> get(@Nonnull K key,\n   /**\n    * Returns the future of a map of the values associated with {@code keys}, creating or retrieving\n    * those values if necessary. The returned map contains entries that were already cached, combined\n-   * with newly loaded entries; it will never contain null keys or values.\n+   * with newly loaded entries; it will never contain null keys or values. If the any of the\n+   * asynchronous computations fail, those entries will be automatically removed.\n    * <p>\n    * Caches loaded by a {@link CacheLoader} will issue a single request to\n    * {@link CacheLoader#asyncLoadAll} for all keys which are not already present in the cache. If\n@@ -100,7 +103,8 @@ CompletableFuture<V> get(@Nonnull K key,\n \n   /**\n    * Associates {@code value} with {@code key} in this cache. If the cache previously contained a\n-   * value associated with {@code key}, the old value is replaced by {@code value}.\n+   * value associated with {@code key}, the old value is replaced by {@code value}. If the\n+   * asynchronous computation fails, the entry will be automatically removed.\n    * <p>\n    * Prefer {@link #get(Object, Function)} when using the conventional \"if cached, return; otherwise\n    * create, cache and return\" pattern.",
      "parent_sha": "e75d5d133da62e5fa45db96ed0146e43554ce80d"
    }
  },
  {
    "oid": "53a5f223aa541a19f84b8929c80f56ceff79b1bb",
    "message": "Fix eager return causing the lock to not be released",
    "date": "2015-10-14T05:42:49Z",
    "url": "https://github.com/ben-manes/caffeine/commit/53a5f223aa541a19f84b8929c80f56ceff79b1bb",
    "details": {
      "sha": "b1ed8bc97bc57e40cd98c5ce63f60cdeed055128",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/53a5f223aa541a19f84b8929c80f56ceff79b1bb/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/53a5f223aa541a19f84b8929c80f56ceff79b1bb/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=53a5f223aa541a19f84b8929c80f56ceff79b1bb",
      "patch": "@@ -800,10 +800,10 @@ void afterWrite(@Nullable Node<K, V> node, Runnable task, long now) {\n    */\n   void scheduleDrainBuffers() {\n     if (evictionLock.tryLock()) {\n-      if (drainStatus() == PROCESSING) {\n-        return;\n-      }\n       try {\n+        if (drainStatus() == PROCESSING) {\n+          return;\n+        }\n         lazySetDrainStatus(PROCESSING);\n         executor().execute(drainBuffersTask);\n       } catch (Throwable t) {",
      "parent_sha": "eeb50200cfd298f4ebe7b6b99ba6ca7cd6c2237d"
    }
  },
  {
    "oid": "a8af2a29f81e919c787e9ee0d2577339707fa3c3",
    "message": "Drop `transitive` from annotations Caffeine requires",
    "date": "2021-06-04T19:56:11Z",
    "url": "https://github.com/ben-manes/caffeine/commit/a8af2a29f81e919c787e9ee0d2577339707fa3c3",
    "details": {
      "sha": "a257871517e574b57be1eadac7c091c4f7a34634",
      "filename": "caffeine/src/main/java/module-info.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/a8af2a29f81e919c787e9ee0d2577339707fa3c3/caffeine%2Fsrc%2Fmain%2Fjava%2Fmodule-info.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/a8af2a29f81e919c787e9ee0d2577339707fa3c3/caffeine%2Fsrc%2Fmain%2Fjava%2Fmodule-info.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fmodule-info.java?ref=a8af2a29f81e919c787e9ee0d2577339707fa3c3",
      "patch": "@@ -2,6 +2,6 @@\n   exports com.github.benmanes.caffeine.cache;\n   exports com.github.benmanes.caffeine.cache.stats;\n \n-  requires static transitive com.google.errorprone.annotations;\n-  requires static transitive org.checkerframework.checker.qual;\n+  requires static com.google.errorprone.annotations;\n+  requires static org.checkerframework.checker.qual;\n }",
      "parent_sha": "56bf6392a2e52e0630581b1dda35bb337b5755af"
    }
  },
  {
    "oid": "ee8a21f76f56beb2d74cc2831f197773101c04b5",
    "message": "Enable lru test",
    "date": "2015-01-10T08:21:06Z",
    "url": "https://github.com/ben-manes/caffeine/commit/ee8a21f76f56beb2d74cc2831f197773101c04b5",
    "details": {
      "sha": "00ae9aebd7c46c5bf6074f12a5ae340aaab09e5e",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/EvictionTest.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/ee8a21f76f56beb2d74cc2831f197773101c04b5/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FEvictionTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/ee8a21f76f56beb2d74cc2831f197773101c04b5/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FEvictionTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FEvictionTest.java?ref=ee8a21f76f56beb2d74cc2831f197773101c04b5",
      "patch": "@@ -94,9 +94,9 @@ public void evict(Cache<Integer, Integer> cache, CacheContext context,\n     assertThat(cache, hasRemovalNotifications(context, count, RemovalCause.SIZE));\n   }\n \n-  @Test(enabled = false, dataProvider = \"caches\")\n-  @CacheSpec(implementation = Implementation.Caffeine,\n-      population = Population.EMPTY, maximumSize = { MaximumSize.FULL })\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(implementation = Implementation.Caffeine, population = Population.EMPTY,\n+      maximumSize = { MaximumSize.ZERO, MaximumSize.ONE, MaximumSize.FULL })\n   public void evict_lru(Cache<Integer, Integer> cache, CacheContext context) {\n     int[] evicted = new int[1];\n     Map<Integer, Integer> lru = new LinkedHashMap<Integer, Integer>(1, 0.75f, true) {",
      "parent_sha": "1717689ed0aee1cbd57e6a18d37116c2fc9e7671"
    }
  },
  {
    "oid": "9188e5a04c04541f87ef136072e163c0185c0ab1",
    "message": "Prevent GC nepotism in write buffer's linked list\n\nAs described in [1], this scenario was not covered in the write buffer\n(SingleConsumerQueue). This optimization only applies to the optimistic\nqueue (as used by the cache). The linearizable version cannot prevent\nit due to needing to walk the chain to notify completion. It can reduce\nit by observing that the node has been consumed and break the chain.\n\n[1] http://psy-lob-saw.blogspot.com/2016/03/gc-nepotism-and-linked-queues.html",
    "date": "2016-04-02T18:47:28Z",
    "url": "https://github.com/ben-manes/caffeine/commit/9188e5a04c04541f87ef136072e163c0185c0ab1",
    "details": {
      "sha": "0f5ef4be64872b8330d1cdeef0f0b5a009b2aefd",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/SingleConsumerQueue.java",
      "status": "modified",
      "additions": 17,
      "deletions": 2,
      "changes": 19,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/9188e5a04c04541f87ef136072e163c0185c0ab1/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueue.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/9188e5a04c04541f87ef136072e163c0185c0ab1/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueue.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FSingleConsumerQueue.java?ref=9188e5a04c04541f87ef136072e163c0185c0ab1",
      "patch": "@@ -115,6 +115,9 @@ public final class SingleConsumerQueue<E> extends SCQHeader.HeadAndTailRef<E>\n   /** The mask value for indexing into the arena. */\n   static final int ARENA_MASK = ARENA_LENGTH - 1;\n \n+  /** The factory for creating an optimistic node. */\n+  static final Function<?, ?> OPTIMISIC = Node<Object>::new;\n+\n   /**\n    * The number of times to spin (doing nothing except polling a memory location) before giving up\n    * while waiting to eliminate an operation. Should be zero on uniprocessors. On multiprocessors,\n@@ -160,7 +163,9 @@ private SingleConsumerQueue(Function<E, Node<E>> factory) {\n    *         another producing thread's\n    */\n   public static <E> SingleConsumerQueue<E> optimistic() {\n-    return new SingleConsumerQueue<>(Node<E>::new);\n+    @SuppressWarnings(\"unchecked\")\n+    Function<E, Node<E>> factory = (Function<E, Node<E>>) OPTIMISIC;\n+    return new SingleConsumerQueue<>(factory);\n   }\n \n   /**\n@@ -247,6 +252,9 @@ public E poll() {\n     E e = next.value;\n     next.value = null;\n     head = next;\n+    if (factory == OPTIMISIC) {\n+      h.next = null; // prevent nepotism\n+    }\n     return e;\n   }\n \n@@ -285,12 +293,19 @@ void append(@Nonnull Node<E> first, @Nonnull Node<E> last) {\n       Node<E> t = tail;\n       if (casTail(t, last)) {\n         t.lazySetNext(first);\n+        if (factory == OPTIMISIC) {\n+          return;\n+        }\n         for (;;) {\n           first.complete();\n           if (first == last) {\n             return;\n           }\n-          first = first.getNextRelaxed();\n+          Node<E> next = first.getNextRelaxed();\n+          if (next.value == null) {\n+            first.next = null; // reduce nepotism\n+          }\n+          first = next;\n         }\n       }\n       Node<E> node = transferOrCombine(first, last);",
      "parent_sha": "776ca5884b8df892884ba23060bbbd1396970446"
    }
  },
  {
    "oid": "0c3786fdf7f56312802f123231243d01c2a59056",
    "message": "Minor Javadoc fix",
    "date": "2019-08-07T03:23:48Z",
    "url": "https://github.com/ben-manes/caffeine/commit/0c3786fdf7f56312802f123231243d01c2a59056",
    "details": {
      "sha": "864c2d83467dd79c31d9d0e2c77b4911ac49a1ad",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Scheduler.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/0c3786fdf7f56312802f123231243d01c2a59056/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FScheduler.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/0c3786fdf7f56312802f123231243d01c2a59056/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FScheduler.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FScheduler.java?ref=0c3786fdf7f56312802f123231243d01c2a59056",
      "patch": "@@ -66,13 +66,13 @@ public interface Scheduler {\n   /**\n    * Returns a scheduler that uses the system-wide scheduling thread if available, or else returns\n    * {@link #disabledScheduler()} if not present. This scheduler is provided in Java 9 or above\n-   * by using {@code CompletableFuture} {@code delayedExecutor}.\n+   * by using {@link CompletableFuture} {@code delayedExecutor}.\n    *\n    * @return a scheduler that uses the system-wide scheduling thread if available, or else a\n    *         disabled scheduler\n    */\n   static @NonNull Scheduler systemScheduler() {\n-    return SystemScheduler.isPresent() ? SystemScheduler.INSTANCE : disabledScheduler() ;\n+    return SystemScheduler.isPresent() ? SystemScheduler.INSTANCE : disabledScheduler();\n   }\n \n   /**",
      "parent_sha": "fb89d910bc4199ef63b621bb3772d6dcf7d26045"
    }
  },
  {
    "oid": "2430a95a24bb30152e4c72db79dc6745e10ebb03",
    "message": "Faster writes for weighted entries\n\nThis restores writes of weighted entries to the optimal unless the new\nweight is zero. The faster, but incorrect in that case, put() is used\nif possible. Otherwise the slower, but strict, put() is used.",
    "date": "2015-10-15T16:41:59Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2430a95a24bb30152e4c72db79dc6745e10ebb03",
    "details": {
      "sha": "adcb746005d35c1733571109fa74e5b93aecd659",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 32,
      "deletions": 24,
      "changes": 56,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2430a95a24bb30152e4c72db79dc6745e10ebb03/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2430a95a24bb30152e4c72db79dc6745e10ebb03/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=2430a95a24bb30152e4c72db79dc6745e10ebb03",
      "patch": "@@ -1241,43 +1241,47 @@ public Map<K, V> getAllPresent(Iterable<?> keys) {\n \n   @Override\n   public V put(K key, V value) {\n-    return (weigher == Weigher.singleton())\n-        ? putSingletonWeigher(key, value, true, false)\n-        : putCustomWeigher(key, value, true, false);\n+    int weight = weigher.weigh(key, value);\n+    return (weight > 0)\n+        ? putFast(key, value, weight, true, false)\n+        : putSlow(key, value, weight, true, false);\n   }\n \n   @Override\n   public V put(K key, V value, boolean notifyWriter) {\n-    return (weigher == Weigher.singleton())\n-        ? putSingletonWeigher(key, value, notifyWriter, false)\n-        : putCustomWeigher(key, value, notifyWriter, false);\n+    int weight = weigher.weigh(key, value);\n+    return (weight > 0)\n+        ? putFast(key, value, weight, notifyWriter, false)\n+        : putSlow(key, value, weight, notifyWriter, false);\n   }\n \n   @Override\n   public V putIfAbsent(K key, V value) {\n-    return (weigher == Weigher.singleton())\n-        ? putSingletonWeigher(key, value, true, true)\n-        : putCustomWeigher(key, value, true, true);\n+    int weight = weigher.weigh(key, value);\n+    return (weight > 0)\n+        ? putFast(key, value, weight, true, true)\n+        : putSlow(key, value, weight, true, true);\n   }\n \n   /**\n    * Adds a node to the list and the data store. If an existing node is found, then its value is\n    * updated if allowed.\n    *\n-   * This implementation is optimized for the default weigher, as it does not provide correctness if\n-   * the weight is allowed to change to zero and be concurrently evicted. This assumption allows it\n-   * to use a cheap read, falling back to a short computation for an insert, and perform an update\n-   * without creating garbage on the heap (e.g. lambda).\n+   * This implementation is optimized for writing values with a non-zero weight. A zero weight is\n+   * incompatible due to the potential for the update to race with eviction, where the entry should\n+   * no longer be eligible if the update was successful. This implementation is ~50% faster than\n+   * {@link #putSlow} due to not incurring the penalty of a compute and lambda in the common case.\n    *\n    * @param key key with which the specified value is to be associated\n    * @param value value to be associated with the specified key\n    * @param notifyWriter if the writer should be notified for an inserted or updated entry\n    * @param onlyIfAbsent a write is performed only if the key is not already associated with a value\n    * @return the prior value in the data store or null if no mapping was found\n    */\n-  V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent) {\n+  V putFast(K key, V value, int newWeight, boolean notifyWriter, boolean onlyIfAbsent) {\n     requireNonNull(key);\n     requireNonNull(value);\n+    requireState(newWeight != 0);\n \n     Node<K, V> node = null;\n     long now = expirationTicker().read();\n@@ -1287,7 +1291,7 @@ V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent\n       if (prior == null) {\n         if (node == null) {\n           node = nodeFactory.newNode(key, keyReferenceQueue(),\n-              value, valueReferenceQueue(), 1, now);\n+              value, valueReferenceQueue(), newWeight, now);\n         }\n         Node<K, V> computed = node;\n         prior = data.computeIfAbsent(node.getKeyReference(), k -> {\n@@ -1297,19 +1301,21 @@ V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent\n           return computed;\n         });\n         if (prior == node) {\n-          afterWrite(node, new AddTask(node, 1), now);\n+          afterWrite(node, new AddTask(node, newWeight), now);\n           return null;\n         }\n       }\n \n       V oldValue;\n+      int oldWeight;\n       boolean expired = false;\n       boolean mayUpdate = true;\n       synchronized (prior) {\n         if (!prior.isAlive()) {\n           continue;\n         }\n         oldValue = prior.getValue();\n+        oldWeight = prior.getWeight();\n         if (oldValue == null) {\n           writer.delete(key, null, RemovalCause.COLLECTED);\n         } else if (hasExpired(prior, now)) {\n@@ -1324,6 +1330,7 @@ V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent\n         }\n         if (mayUpdate) {\n           prior.setValue(value, valueReferenceQueue());\n+          prior.setWeight(newWeight);\n         }\n       }\n \n@@ -1337,9 +1344,10 @@ V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent\n         }\n       }\n \n-      if ((oldValue == null) || expired\n+      int weightedDifference = mayUpdate ? (newWeight - oldWeight) : 0;\n+      if ((oldValue == null) || (weightedDifference != 0) || expired\n           || (!onlyIfAbsent && (oldValue != null) && expiresAfterWrite())) {\n-        afterWrite(prior, new UpdateTask(prior, 0), now);\n+        afterWrite(prior, new UpdateTask(prior, weightedDifference), now);\n       } else {\n         afterRead(prior, now, false);\n       }\n@@ -1350,18 +1358,19 @@ V putSingletonWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent\n \n   /**\n    * Adds a node to the list and the data store. If an existing node is found, then its value is\n-   * updated if allowed. This implementation is strict by using a compute to block other writers\n-   * to that entry. This guards against an eviction trying to discard an entry concurrently updated\n-   * to have a zero weight, making it ineligible. The penalty is 50% of the throughput when\n-   * compared to {@link #putSingletonWeigher}.\n+   * updated if allowed.\n+   *\n+   * This implementation is strict by using a compute to block other writers to that entry. This\n+   * guards against an eviction trying to discard an entry concurrently (and successfully) updated\n+   * to have a zero weight. The penalty is 50% of the throughput when compared to {@link #putFast}.\n    *\n    * @param key key with which the specified value is to be associated\n    * @param value value to be associated with the specified key\n    * @param notifyWriter if the writer should be notified for an inserted or updated entry\n    * @param onlyIfAbsent a write is performed only if the key is not already associated with a value\n    * @return the prior value in the data store or null if no mapping was found\n    */\n-  V putCustomWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent) {\n+  V putSlow(K key, V value, int newWeight, boolean notifyWriter, boolean onlyIfAbsent) {\n     requireNonNull(key);\n     requireNonNull(value);\n \n@@ -1374,7 +1383,6 @@ V putCustomWeigher(K key, V value, boolean notifyWriter, boolean onlyIfAbsent) {\n     long now = expirationTicker().read();\n \n     int[] oldWeight = new int[1];\n-    int newWeight = weigher.weigh(key, value);\n     Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n     Node<K, V> node = data.compute(keyRef, (kr, n) -> {\n       if (n == null) {",
      "parent_sha": "1b977750aac5053d9ae818858aae6aacd40ae519"
    }
  },
  {
    "oid": "8ceaf81f7743d9d8faaa5aa524f925383f04b244",
    "message": "Use spaces (vs object padding) for ring buffers\n\nPadding is used to avoid false sharing of the cache lines. Previously\nthe bloat of an object (header, etc) was used as filler, which is a\nlittle better on a laptop. On a server-class machine, spacing the value\nout in a primitive array is more efficient. So favoring large machine\nover small, but the difference is not significant to bother anyone in\npractice.",
    "date": "2015-11-09T06:10:56Z",
    "url": "https://github.com/ben-manes/caffeine/commit/8ceaf81f7743d9d8faaa5aa524f925383f04b244",
    "details": {
      "sha": "ca29ef92d0acb4a9c8982657aae7ea7f3f7737ec",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedBuffer.java",
      "status": "modified",
      "additions": 20,
      "deletions": 22,
      "changes": 42,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/8ceaf81f7743d9d8faaa5aa524f925383f04b244/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedBuffer.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/8ceaf81f7743d9d8faaa5aa524f925383f04b244/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedBuffer.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedBuffer.java?ref=8ceaf81f7743d9d8faaa5aa524f925383f04b244",
      "patch": "@@ -15,7 +15,7 @@\n  */\n package com.github.benmanes.caffeine.cache;\n \n-import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.atomic.AtomicReferenceArray;\n import java.util.function.Consumer;\n \n import com.github.benmanes.caffeine.base.UnsafeAccess;\n@@ -47,40 +47,39 @@ final class BoundedBuffer<E> extends StripedBuffer<E> {\n    */\n \n   /** The maximum number of elements per buffer. */\n-  static final int BUFFER_SIZE = 32;\n+  static final int BUFFER_SIZE = 16;\n \n-  /** Mask value for indexing into the ring buffer. */\n-  static final int BUFFER_MASK = BUFFER_SIZE - 1;\n+  // Assume 4-byte references and 64-byte cache line (16 elements per line)\n+  static final int SPACED_SIZE = BUFFER_SIZE << 4;\n+  static final int SPACED_MASK = SPACED_SIZE - 1;\n+  static final int OFFSET = 16;\n \n   @Override\n   protected Buffer<E> create(E e) {\n     return new RingBuffer<>(e);\n   }\n \n   static final class RingBuffer<E> extends BBHeader.ReadAndWriteCounterRef implements Buffer<E> {\n-    final AtomicReference<E>[] buffer;\n+    final AtomicReferenceArray<E> buffer;\n \n     @SuppressWarnings({\"unchecked\", \"cast\", \"rawtypes\"})\n     public RingBuffer(E e) {\n-      super(1);\n-      buffer = new AtomicReference[BUFFER_SIZE];\n-      for (int i = 0; i < BUFFER_SIZE; i++) {\n-        buffer[i] = new AtomicReference<>();\n-      }\n-      buffer[0].lazySet(e);\n+      super(OFFSET);\n+      buffer = new AtomicReferenceArray<>(SPACED_SIZE);\n+      buffer.lazySet(0, e);\n     }\n \n     @Override\n     public int offer(E e) {\n       long head = readCounter;\n       long tail = relaxedWriteCounter();\n       long size = (tail - head);\n-      if (size >= BUFFER_SIZE) {\n+      if (size >= SPACED_SIZE) {\n         return Buffer.FULL;\n       }\n-      if (casWriteCounter(tail, tail + 1)) {\n-        int index = (int) (tail & BUFFER_MASK);\n-        buffer[index].lazySet(e);\n+      if (casWriteCounter(tail, tail + OFFSET)) {\n+        int index = (int) (tail & SPACED_MASK);\n+        buffer.lazySet(index, e);\n         return Buffer.SUCCESS;\n       }\n       return Buffer.FAILED;\n@@ -95,28 +94,27 @@ public void drainTo(Consumer<E> consumer) {\n         return;\n       }\n       do {\n-        int index = (int) (head & BUFFER_MASK);\n-        AtomicReference<E> slot = buffer[index];\n-        E e = slot.get();\n+        int index = (int) (head & SPACED_MASK);\n+        E e = buffer.get(index);\n         if (e == null) {\n           // not published yet\n           break;\n         }\n-        slot.lazySet(null);\n+        buffer.lazySet(index, null);\n         consumer.accept(e);\n-        head++;\n+        head += OFFSET;\n       } while (head != tail);\n       lazySetReadCounter(head);\n     }\n \n     @Override\n     public int reads() {\n-      return (int) readCounter;\n+      return (int) readCounter / OFFSET;\n     }\n \n     @Override\n     public int writes() {\n-      return (int) writeCounter;\n+      return (int) writeCounter / OFFSET;\n     }\n   }\n }",
      "parent_sha": "4b73c14ba75d8cfbbff8602a0f3af9dc289e16b5"
    }
  },
  {
    "oid": "86ec6a9e1c6b3e41d2bff4ffcecc3755799070b1",
    "message": "Replace switch with reflection in generated code\n\nThis patch expands on the suggestion in\nhttps://github.com/ben-manes/caffeine/issues/110#issuecomment-238676087\n\nInstead of the proposed numeric code the name of factory is used as the\nclassname to instantiate using reflection.\nThis reduces the class size with 21K bringing the jar size to 786K.",
    "date": "2017-11-02T18:49:04Z",
    "url": "https://github.com/ben-manes/caffeine/commit/86ec6a9e1c6b3e41d2bff4ffcecc3755799070b1",
    "details": {
      "sha": "15a3e3704909425197d4aef6532abdb6716b8cf2",
      "filename": "caffeine/src/javaPoet/java/com/github/benmanes/caffeine/cache/LocalCacheSelectorCode.java",
      "status": "modified",
      "additions": 14,
      "deletions": 11,
      "changes": 25,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/86ec6a9e1c6b3e41d2bff4ffcecc3755799070b1/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalCacheSelectorCode.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/86ec6a9e1c6b3e41d2bff4ffcecc3755799070b1/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalCacheSelectorCode.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FLocalCacheSelectorCode.java?ref=86ec6a9e1c6b3e41d2bff4ffcecc3755799070b1",
      "patch": "@@ -15,6 +15,7 @@\n  */\n package com.github.benmanes.caffeine.cache;\n \n+import java.lang.reflect.Constructor;\n import java.util.Set;\n \n import com.squareup.javapoet.CodeBlock;\n@@ -88,16 +89,18 @@ private LocalCacheSelectorCode expires() {\n     return this;\n   }\n \n-  private LocalCacheSelectorCode selector(Set<String> classNames) {\n-    CodeBlock.Builder switchBuilder = CodeBlock.builder();\n-    switchBuilder.beginControlFlow(\"switch (sb.toString())\");\n-    for (String className : classNames) {\n-      switchBuilder.addStatement(\n-          \"case $S: return new $N<>(builder, cacheLoader, async)\", className, className);\n-    }\n-    switchBuilder.addStatement(\"default: throw new $T(sb.toString())\", IllegalStateException.class);\n-    switchBuilder.endControlFlow();\n-    block.add(switchBuilder.build());\n+  private LocalCacheSelectorCode selector() {\n+    CodeBlock.Builder reflectBuilder = CodeBlock.builder();\n+    reflectBuilder.add(\"try {\\n\"\n+            + \"  Class<?> cls = LocalCacheFactory.class.getClassLoader()\\n\"\n+            + \"    .loadClass(\\\"com.github.benmanes.caffeine.cache.LocalCacheFactory$$\\\" + sb.toString());\\n\"\n+            + \"  $T<?> ctor = cls.getDeclaredConstructor(Caffeine.class, CacheLoader.class, boolean.class);\\n\"\n+            + \"  return (BoundedLocalCache<K, V>) ctor.newInstance(builder, cacheLoader, async);\\n\"\n+            + \"} catch (ReflectiveOperationException e) {\\n\"\n+            + \"  throw new IllegalStateException(sb.toString());\\n\"\n+            + \"}\\n\"\n+            + \"\\n\", Constructor.class);\n+    block.add(reflectBuilder.build());\n     return this;\n   }\n \n@@ -113,7 +116,7 @@ public static CodeBlock get(Set<String> classNames) {\n         .stats()\n         .maximum()\n         .expires()\n-        .selector(classNames)\n+        .selector()\n         .build();\n   }\n }",
      "parent_sha": "992a03579e141092dc05a04c120379491a8c6563"
    }
  },
  {
    "oid": "ceea49e33658b73e839ea47f78b36786db63c1f5",
    "message": "Minor cleanup before release",
    "date": "2016-04-03T09:11:42Z",
    "url": "https://github.com/ben-manes/caffeine/commit/ceea49e33658b73e839ea47f78b36786db63c1f5",
    "details": {
      "sha": "eb02abe9e5fe17ef22ad03475be076a10a228ed1",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 3,
      "deletions": 6,
      "changes": 9,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/ceea49e33658b73e839ea47f78b36786db63c1f5/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/ceea49e33658b73e839ea47f78b36786db63c1f5/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=ceea49e33658b73e839ea47f78b36786db63c1f5",
      "patch": "@@ -2852,8 +2852,7 @@ final class BoundedExpireAfterAccess implements Expiration<K, V> {\n       @Override public void setExpiresAfter(long duration, TimeUnit unit) {\n         Caffeine.requireArgument(duration >= 0);\n         cache.setExpiresAfterAccessNanos(unit.toNanos(duration));\n-        cache.drainBuffersTask.reinitialize();\n-        cache.executor().execute(cache.drainBuffersTask);\n+        cache.scheduleAfterWrite();\n       }\n       @Override public Map<K, V> oldest(int limit) {\n         return cache.expireAfterAcessOrder(limit, transformer, true);\n@@ -2881,8 +2880,7 @@ final class BoundedExpireAfterWrite implements Expiration<K, V> {\n       @Override public void setExpiresAfter(long duration, TimeUnit unit) {\n         Caffeine.requireArgument(duration >= 0);\n         cache.setExpiresAfterWriteNanos(unit.toNanos(duration));\n-        cache.drainBuffersTask.reinitialize();\n-        cache.executor().execute(cache.drainBuffersTask);\n+        cache.scheduleAfterWrite();\n       }\n       @Override public Map<K, V> oldest(int limit) {\n         return cache.expireAfterWriteOrder(limit, transformer, true);\n@@ -2910,8 +2908,7 @@ final class BoundedRefreshAfterWrite implements Expiration<K, V> {\n       @Override public void setExpiresAfter(long duration, TimeUnit unit) {\n         Caffeine.requireArgument(duration >= 0);\n         cache.setRefreshAfterWriteNanos(unit.toNanos(duration));\n-        cache.drainBuffersTask.reinitialize();\n-        cache.executor().execute(cache.drainBuffersTask);\n+        cache.scheduleAfterWrite();\n       }\n       @SuppressWarnings(\"PMD.SimplifiedTernary\") // false positive (#1424)\n       @Override public Map<K, V> oldest(int limit) {",
      "parent_sha": "d40f0a129f8e1fd4929bdf2d77db0b5c2f2b146b"
    }
  },
  {
    "oid": "fa2aab54c2204bb8716850a99181d2b41e021ca0",
    "message": "Try to trick TCache to be synchronous\n\nThis only kind of works. It doesn't spin forever but the policies don't\nmatch the ideal. Sometimes higher, sometimes lower. I think that is due\nto the estimated time source, so its hard to pin it down to realistic\nbehavior.",
    "date": "2015-10-16T02:11:07Z",
    "url": "https://github.com/ben-manes/caffeine/commit/fa2aab54c2204bb8716850a99181d2b41e021ca0",
    "details": {
      "sha": "fb54136542f947a237f465cd41c5edf23e724c5f",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/product/TCachePolicy.java",
      "status": "modified",
      "additions": 30,
      "deletions": 10,
      "changes": 40,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/fa2aab54c2204bb8716850a99181d2b41e021ca0/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FTCachePolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/fa2aab54c2204bb8716850a99181d2b41e021ca0/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FTCachePolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fproduct%2FTCachePolicy.java?ref=fa2aab54c2204bb8716850a99181d2b41e021ca0",
      "patch": "@@ -18,9 +18,13 @@\n import com.github.benmanes.caffeine.cache.simulator.BasicSettings;\n import com.github.benmanes.caffeine.cache.simulator.policy.Policy;\n import com.github.benmanes.caffeine.cache.simulator.policy.PolicyStats;\n-import com.trivago.triava.tcache.EvictionPolicy;\n+import com.trivago.triava.tcache.JamPolicy;\n import com.trivago.triava.tcache.TCacheFactory;\n-import com.trivago.triava.tcache.eviction.Cache;\n+import com.trivago.triava.tcache.core.Builder;\n+import com.trivago.triava.tcache.core.EvictionInterface;\n+import com.trivago.triava.tcache.eviction.CacheLimit;\n+import com.trivago.triava.tcache.eviction.LFUEviction;\n+import com.trivago.triava.tcache.eviction.LRUEviction;\n import com.typesafe.config.Config;\n \n /**\n@@ -29,23 +33,23 @@\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n public final class TCachePolicy implements Policy {\n-  private final Cache<Object, Object> cache;\n+  private final SyncCache<Object, Object> cache;\n   private final PolicyStats policyStats;\n   private final int maximumSize;\n \n   public TCachePolicy(String name, Config config) {\n     TCacheSettings settings = new TCacheSettings(config);\n     maximumSize = settings.maximumSize();\n     policyStats = new PolicyStats(name);\n-    cache = TCacheFactory.standardFactory().builder()\n-        .setEvictionPolicy(settings.policy())\n+    cache = new SyncCache<>(TCacheFactory.standardFactory().builder()\n+        .setEvictionClass(settings.policy())\n         .setExpectedMapSize(maximumSize)\n-        .build();\n+        .setJamPolicy(JamPolicy.DROP));\n   }\n \n   @Override\n   public void record(long key) {\n-    while (cache.size() > maximumSize) {\n+    while (!cache.ensureFreeCapacity() || (cache.size() > maximumSize)) {\n       // spin\n     }\n     Object value = cache.get(key);\n@@ -65,13 +69,29 @@ public PolicyStats stats() {\n     return policyStats;\n   }\n \n+  static final class SyncCache<K, V> extends CacheLimit<K, V> {\n+    public SyncCache(Builder<K, V> builder) {\n+      super(builder);\n+    }\n+    @Override public boolean ensureFreeCapacity() {\n+      return super.ensureFreeCapacity();\n+    }\n+  }\n+\n   static final class TCacheSettings extends BasicSettings {\n     public TCacheSettings(Config config) {\n       super(config);\n     }\n-    public EvictionPolicy policy() {\n-      String policy = config().getString(\"tcache.policy\").toUpperCase();\n-      return EvictionPolicy.valueOf(policy);\n+    public <K, V> EvictionInterface<K, V> policy() {\n+      String policy = config().getString(\"tcache.policy\").toLowerCase();\n+      switch (policy) {\n+        case \"lfu\":\n+          return new LFUEviction<>();\n+        case \"lru\":\n+          return new LRUEviction<>();\n+        default:\n+          throw new IllegalArgumentException(\"Unknown policy type: \" + policy);\n+      }\n     }\n   }\n }",
      "parent_sha": "6c043ecbdb1b086c72af3b4a9e7167fc1aae6d20"
    }
  },
  {
    "oid": "07ea131788fedb12146d6b8aed705d5e26cc018f",
    "message": "computeIfAbsent tests",
    "date": "2014-12-25T02:56:53Z",
    "url": "https://github.com/ben-manes/caffeine/commit/07ea131788fedb12146d6b8aed705d5e26cc018f",
    "details": {
      "sha": "09819f2cef9d0ed31ae3657d5a94b59559ac42d0",
      "filename": "src/test/java/com/github/benmanes/caffeine/cache/AsMapTest.java",
      "status": "modified",
      "additions": 72,
      "deletions": 1,
      "changes": 73,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/07ea131788fedb12146d6b8aed705d5e26cc018f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/07ea131788fedb12146d6b8aed705d5e26cc018f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsMapTest.java?ref=07ea131788fedb12146d6b8aed705d5e26cc018f",
      "patch": "@@ -591,6 +591,78 @@ public void replaceAll_differentValue(Map<Integer, Integer> map, CacheContext co\n     assertThat(map, hasRemovalNotifications(context, map.size(), RemovalCause.REPLACED));\n   }\n \n+  /* ---------------- V8 default methods -------------- */\n+\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(dataProvider = \"caches\", expectedExceptions = NullPointerException.class)\n+  public void computeIfAbsent_nullKey(Map<Integer, Integer> map) {\n+    map.computeIfAbsent(null, key -> -key);\n+  }\n+\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(dataProvider = \"caches\", expectedExceptions = NullPointerException.class)\n+  public void computeIfAbsent_nullMappingFunction(Map<Integer, Integer> map, CacheContext context) {\n+    map.computeIfAbsent(context.absentKey(), null);\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void computeIfAbsent_nullValue(Map<Integer, Integer> map, CacheContext context) {\n+    map.computeIfAbsent(context.absentKey(), key -> null);\n+    assertThat(map.size(), is(context.original().size()));\n+  }\n+\n+  // FIXME: Requires JDK8 release with JDK-8062841 fix\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(enabled = false, dataProvider = \"caches\", expectedExceptions = IllegalStateException.class)\n+  public void computeIfAbsent_recursive(Map<Integer, Integer> map, CacheContext context) {\n+    Function<Integer, Integer> mappingFunction = new Function<Integer, Integer>() {\n+      @Override public Integer apply(Integer key) {\n+        return map.computeIfAbsent(key, this);\n+      }\n+    };\n+    map.computeIfAbsent(context.absentKey(), mappingFunction);\n+  }\n+\n+  // FIXME: Requires JDK8 release with JDK-8062841 fix\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  @Test(enabled = false, dataProvider = \"caches\", expectedExceptions = IllegalStateException.class)\n+  public void computeIfAbsent_deadlock(Map<Integer, Integer> map, CacheContext context) {\n+    Function<Integer, Integer> mappingFunction = new Function<Integer, Integer>() {\n+      @Override public Integer apply(Integer key) {\n+        return map.computeIfAbsent(-key, this);\n+      }\n+    };\n+    map.computeIfAbsent(context.absentKey(), mappingFunction);\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void computeIfAbsent_error(Map<Integer, Integer> map, CacheContext context) {\n+    try {\n+      map.computeIfAbsent(context.absentKey(), key -> { throw new Error(); });\n+    } catch (Error e) {}\n+    assertThat(map, is(equalTo(context.original())));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(population = { Population.SINGLETON, Population.PARTIAL, Population.FULL },\n+      removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void computeIfAbsent_present(Map<Integer, Integer> map, CacheContext context) {\n+    for (Integer key : context.firstMiddleLastKeys()) {\n+      map.computeIfAbsent(key, k -> { throw new AssertionError(); });\n+    }\n+    assertThat(map.size(), is(context.original().size()));\n+  }\n+\n+  @Test(dataProvider = \"caches\")\n+  @CacheSpec(removalListener = { Listener.DEFAULT, Listener.REJECTING })\n+  public void computeIfAbsent_absent(Map<Integer, Integer> map, CacheContext context) {\n+    map.computeIfAbsent(context.absentKey(), key -> -key);\n+    assertThat(map.get(context.absentKey()), is(-context.absentKey()));\n+    assertThat(map.size(), is(1 + context.original().size()));\n+  }\n+\n   /* ---------------- equals / hashCode -------------- */\n \n   @Test(dataProvider = \"caches\")\n@@ -667,7 +739,6 @@ public void serialize(Map<Integer, Integer> map) {\n   }\n \n   /* ---------------- V8 default methods -------------- */\n-  public void computeIfAbsent() {}\n   public void computeIfPresent() {}\n   public void compute() {}\n   public void merge() {}",
      "parent_sha": "4dbd22925d70e2379f5361d9a17d6ca2abd6c986"
    }
  },
  {
    "oid": "dd0e660a5cd644cdd9e667f745a5ca64455da1ec",
    "message": "Improve AsyncLoadingCache#getAll JavaDoc",
    "date": "2015-01-13T13:39:33Z",
    "url": "https://github.com/ben-manes/caffeine/commit/dd0e660a5cd644cdd9e667f745a5ca64455da1ec",
    "details": {
      "sha": "0b8417537672c85a147af9bff944ebb355b21637",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/AsyncLoadingCache.java",
      "status": "modified",
      "additions": 5,
      "deletions": 3,
      "changes": 8,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/dd0e660a5cd644cdd9e667f745a5ca64455da1ec/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/dd0e660a5cd644cdd9e667f745a5ca64455da1ec/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FAsyncLoadingCache.java?ref=dd0e660a5cd644cdd9e667f745a5ca64455da1ec",
      "patch": "@@ -102,11 +102,13 @@ CompletableFuture<V> get(@Nonnull K key,\n    * with newly loaded entries; it will never contain null keys or values. If the any of the\n    * asynchronous computations fail, those entries will be automatically removed.\n    * <p>\n-   * Caches loaded by a {@link CacheLoader} will issue a single request to\n+   * Caches loaded by a {@link CacheLoader} supporting bulk loading will issue a single request to\n    * {@link CacheLoader#asyncLoadAll} for all keys which are not already present in the cache. If\n    * another call to {@link #get} is tries to load the value for a key in {@code keys}, that thread\n-   * simply waits for this thread to finish and returns the loaded value. Note that multiple threads\n-   * can concurrently load values for distinct keys.\n+   * simply waits for this thread to finish and returns the loaded value. Caches that do not use a\n+   * {@link CacheLoader} with an optimized bulk load implementation will sequentially load each\n+   * key by making individual {@link CacheLoader#asyncLoad} calls. Note that multiple threads can\n+   * concurrently load values for distinct keys.\n    * <p>\n    * Note that duplicate elements in {@code keys}, as determined by {@link Object#equals}, will be\n    * ignored.",
      "parent_sha": "1749fdb70f2b66d379c3ad1141a8e23ad67dd7a3"
    }
  },
  {
    "oid": "d9f132cefe9a0833686354bd9986832e4f7d6beb",
    "message": "add tests for Interner's specialized map",
    "date": "2022-04-14T01:27:18Z",
    "url": "https://github.com/ben-manes/caffeine/commit/d9f132cefe9a0833686354bd9986832e4f7d6beb",
    "details": {
      "sha": "70b2dc8619280a065d334fc7a114c14e0331415d",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/InternerTest.java",
      "status": "modified",
      "additions": 27,
      "deletions": 1,
      "changes": 28,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/d9f132cefe9a0833686354bd9986832e4f7d6beb/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FInternerTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/d9f132cefe9a0833686354bd9986832e4f7d6beb/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FInternerTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FInternerTest.java?ref=d9f132cefe9a0833686354bd9986832e4f7d6beb",
      "patch": "@@ -22,19 +22,45 @@\n import static com.google.common.truth.Truth.assertThat;\n \n import java.lang.ref.WeakReference;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Set;\n \n import org.testng.Assert;\n import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n import com.github.benmanes.caffeine.testing.Int;\n+import com.google.common.collect.testing.SetTestSuiteBuilder;\n+import com.google.common.collect.testing.TestStringSetGenerator;\n+import com.google.common.collect.testing.features.CollectionFeature;\n+import com.google.common.collect.testing.features.CollectionSize;\n import com.google.common.testing.GcFinalization;\n import com.google.common.testing.NullPointerTester;\n \n+import junit.framework.TestCase;\n+import junit.framework.TestSuite;\n+\n /**\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n-public final class InternerTest {\n+public final class InternerTest extends TestCase {\n+\n+  public static TestSuite suite() {\n+    return SetTestSuiteBuilder\n+        .using(new TestStringSetGenerator() {\n+          @Override protected Set<String> create(String[] elements) {\n+            var set = Collections.newSetFromMap(new WeakInterner<String>().cache);\n+            set.addAll(Arrays.asList(elements));\n+            return set;\n+          }\n+        })\n+        .named(\"Interner\")\n+        .withFeatures(\n+            CollectionSize.ANY,\n+            CollectionFeature.GENERAL_PURPOSE)\n+        .createTestSuite();\n+  }\n \n   @Test(dataProvider = \"interners\", expectedExceptions = NullPointerException.class)\n   public void intern_null(Interner<Int> interner) {",
      "parent_sha": "702f15951e4a965734adcecfba2d0d89cf3bda74"
    }
  },
  {
    "oid": "113a3321ff6dd55d0a72ad68986cd50580aeb9e5",
    "message": "doc fixes",
    "date": "2015-11-26T05:57:11Z",
    "url": "https://github.com/ben-manes/caffeine/commit/113a3321ff6dd55d0a72ad68986cd50580aeb9e5",
    "details": {
      "sha": "ba4bc6c2dce3e2ab966e33bffa03f34175982137",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 6,
      "deletions": 5,
      "changes": 11,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/113a3321ff6dd55d0a72ad68986cd50580aeb9e5/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/113a3321ff6dd55d0a72ad68986cd50580aeb9e5/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=113a3321ff6dd55d0a72ad68986cd50580aeb9e5",
      "patch": "@@ -105,18 +105,19 @@ abstract class BoundedLocalCache<K, V> extends BLCHeader.DrainStatusRef<K, V>\n    * represented by a sentinel key that should not be used for map lookups.\n    *\n    * Expiration is implemented in O(1) time complexity. The time-to-idle policy uses an access-order\n-   * queue and the time-to-live policy uses a write-order queue. This allows peeking at oldest entry\n-   * in the queue to see if it is expired and, if it is not then the younger entries must not be\n-   * too.\n+   * queue and the time-to-live policy uses a write-order queue. This allows peeking at the oldest\n+   * entry in the queue to see if it has expired and, if it has not, then the younger entries must\n+   * not have too. If a maximum size is set then expiration will share the queues in order to\n+   * minimize the per-entry footprint.\n    *\n    * Maximum size is implemented using the Window TinyLfu policy due to its high hit rate, O(1) time\n    * complexity, and small footprint. A new entry starts in the eden space and remains there as long\n    * as it has high temporal locality. Eventually an entry will slip from the eden space into the\n    * main space. If the main space is already full, then a historic frequency filter determines\n    * whether to evict the newly admitted entry or the victim entry chosen by main space's policy.\n    * This process ensures that the entries in the main space have both a high recency and frequency.\n-   * The windowing allows the policy to have a high hit rate when entries exhibit a bursty high\n-   * temporal but low frequency access pattern. The eden space uses LRU and the main space uses\n+   * The windowing allows the policy to have a high hit rate when entries exhibit a bursty (high\n+   * temporal, low frequency) access pattern. The eden space uses LRU and the main space uses\n    * Segmented LRU.\n    */\n ",
      "parent_sha": "ff2f754073ea233a7e35fcd08b1b4db757d1ddc7"
    }
  },
  {
    "oid": "15b72307fd1dc47e03ab7ab351c98c95bd3b9ba2",
    "message": "Fix build due to broken clear() change",
    "date": "2015-06-15T14:57:52Z",
    "url": "https://github.com/ben-manes/caffeine/commit/15b72307fd1dc47e03ab7ab351c98c95bd3b9ba2",
    "details": {
      "sha": "f51b624ee3e5d60692e98ad9b2c381afb48b0475",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/15b72307fd1dc47e03ab7ab351c98c95bd3b9ba2/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/15b72307fd1dc47e03ab7ab351c98c95bd3b9ba2/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=15b72307fd1dc47e03ab7ab351c98c95bd3b9ba2",
      "patch": "@@ -812,8 +812,9 @@ void removeNode(Node<K, V> node) {\n       if (hasRemovalListener()) {\n         notifyRemoval(key, value, cause);\n       }\n-      makeDead(node);\n     }\n+\n+    makeDead(node);\n   }\n \n   @Override",
      "parent_sha": "c25d137fe28fcff7c58890fc007304ad3d7bf965"
    }
  },
  {
    "oid": "969fc10050896c7d2bc53831f083fa551aed885f",
    "message": "minor touchup",
    "date": "2021-03-29T07:49:18Z",
    "url": "https://github.com/ben-manes/caffeine/commit/969fc10050896c7d2bc53831f083fa551aed885f",
    "details": {
      "sha": "057353eaf3232e6c88e197263d77d904322d0fe1",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/StripedBuffer.java",
      "status": "modified",
      "additions": 51,
      "deletions": 52,
      "changes": 103,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/969fc10050896c7d2bc53831f083fa551aed885f/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FStripedBuffer.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/969fc10050896c7d2bc53831f083fa551aed885f/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FStripedBuffer.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FStripedBuffer.java?ref=969fc10050896c7d2bc53831f083fa551aed885f",
      "patch": "@@ -72,7 +72,7 @@ abstract class StripedBuffer<E> implements Buffer<E> {\n    * thread were bound to a CPU, there would exist a perfect hash function mapping threads to slots\n    * that eliminates collisions. When we reach capacity, we search for this mapping by varying the\n    * hash codes of colliding threads. Because search is random, and collisions only become known via\n-   * CAS failures, convergence can be slow, and because threads are typically not bound to CPUS\n+   * CAS failures, convergence can be slow, and because threads are typically not bound to CPUs\n    * forever, may not occur at all. However, despite these limitations, observed contention rates\n    * are typically low in these cases.\n    *\n@@ -115,79 +115,35 @@ final boolean casTableBusy() {\n \n   @Override\n   public int offer(E e) {\n+    long z = mix64(Thread.currentThread().getId());\n+    int increment = (int) (z >>> 32) | 1;\n+    int h = (int) z;\n+\n     int mask;\n     int result;\n     Buffer<E> buffer;\n     boolean uncontended = true;\n     Buffer<E>[] buffers = table;\n-\n-    long z = mix64(Thread.currentThread().getId());\n-    int increment = (int) (z >>> 32) | 1;\n-    int h = (int) z;\n     if ((buffers == null)\n         || ((mask = buffers.length - 1) < 0)\n         || ((buffer = buffers[h & mask]) == null)\n         || !(uncontended = ((result = buffer.offer(e)) != Buffer.FAILED))) {\n-      return expandOrRetry(e, h + increment, increment, uncontended);\n+      return expandOrRetry(e, h, increment, uncontended);\n     }\n     return result;\n   }\n \n-  @Override\n-  public void drainTo(Consumer<E> consumer) {\n-    Buffer<E>[] buffers = table;\n-    if (buffers == null) {\n-      return;\n-    }\n-    for (Buffer<E> buffer : buffers) {\n-      if (buffer != null) {\n-        buffer.drainTo(consumer);\n-      }\n-    }\n-  }\n-\n-  @Override\n-  public long reads() {\n-    Buffer<E>[] buffers = table;\n-    if (buffers == null) {\n-      return 0;\n-    }\n-    long reads = 0;\n-    for (Buffer<E> buffer : buffers) {\n-      if (buffer != null) {\n-        reads += buffer.reads();\n-      }\n-    }\n-    return reads;\n-  }\n-\n-  @Override\n-  public long writes() {\n-    Buffer<E>[] buffers = table;\n-    if (buffers == null) {\n-      return 0;\n-    }\n-    long writes = 0;\n-    for (Buffer<E> buffer : buffers) {\n-      if (buffer != null) {\n-        writes += buffer.writes();\n-      }\n-    }\n-    return writes;\n-  }\n-\n   /**\n    * Handles cases of updates involving initialization, resizing, creating new Buffers, and/or\n    * contention. See above for explanation. This method suffers the usual non-modularity problems of\n    * optimistic retry code, relying on rechecked sets of reads.\n    *\n    * @param e the element to add\n-   * @param h the element's hash\n+   * @param h the thread's hash\n    * @param increment the amount to increment by when rehashing\n-   * @param wasUncontended false if CAS failed before call\n+   * @param wasUncontended false if CAS failed before this call\n    * @return {@code Buffer.SUCCESS}, {@code Buffer.FAILED}, or {@code Buffer.FULL}\n    */\n-  @SuppressWarnings(\"PMD.ConfusingTernary\")\n   final int expandOrRetry(E e, int h, int increment, boolean wasUncontended) {\n     int result = Buffer.FAILED;\n     boolean collide = false; // True if last slot nonempty\n@@ -257,6 +213,49 @@ final int expandOrRetry(E e, int h, int increment, boolean wasUncontended) {\n     return result;\n   }\n \n+  @Override\n+  public void drainTo(Consumer<E> consumer) {\n+    Buffer<E>[] buffers = table;\n+    if (buffers == null) {\n+      return;\n+    }\n+    for (Buffer<E> buffer : buffers) {\n+      if (buffer != null) {\n+        buffer.drainTo(consumer);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public long reads() {\n+    Buffer<E>[] buffers = table;\n+    if (buffers == null) {\n+      return 0;\n+    }\n+    long reads = 0;\n+    for (Buffer<E> buffer : buffers) {\n+      if (buffer != null) {\n+        reads += buffer.reads();\n+      }\n+    }\n+    return reads;\n+  }\n+\n+  @Override\n+  public long writes() {\n+    Buffer<E>[] buffers = table;\n+    if (buffers == null) {\n+      return 0;\n+    }\n+    long writes = 0;\n+    for (Buffer<E> buffer : buffers) {\n+      if (buffer != null) {\n+        writes += buffer.writes();\n+      }\n+    }\n+    return writes;\n+  }\n+\n   /** Computes Stafford variant 13 of 64-bit mix function. */\n   static long mix64(long z) {\n     z = (z ^ (z >>> 30)) * 0xbf58476d1ce4e5b9L;",
      "parent_sha": "4db9e8e360d838d979b9ee10f8a86bcb3b77f045"
    }
  },
  {
    "oid": "b15d7ce797048c22f115379ddf010a51156ab809",
    "message": "Fix CacheLoader JavaDoc",
    "date": "2015-02-14T00:33:53Z",
    "url": "https://github.com/ben-manes/caffeine/commit/b15d7ce797048c22f115379ddf010a51156ab809",
    "details": {
      "sha": "e87c5fc95597a13c142660e9063cec9e812f87df",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/CacheLoader.java",
      "status": "modified",
      "additions": 14,
      "deletions": 11,
      "changes": 25,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/b15d7ce797048c22f115379ddf010a51156ab809/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheLoader.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/b15d7ce797048c22f115379ddf010a51156ab809/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheLoader.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCacheLoader.java?ref=b15d7ce797048c22f115379ddf010a51156ab809",
      "patch": "@@ -25,7 +25,8 @@\n import javax.annotation.Nonnull;\n \n /**\n- * Computes or retrieves values, based on a key, for use in populating a {@link LoadingCache}.\n+ * Computes or retrieves values, based on a key, for use in populating a {@link LoadingCache} or\n+ * {@link AsyncLoadingCache}.\n  * <p>\n  * Most implementations will only need to implement {@link #load}. Other methods may be\n  * overridden as desired.\n@@ -45,7 +46,7 @@ public interface CacheLoader<K, V> {\n    * Computes or retrieves the value corresponding to {@code key}.\n    *\n    * @param key the non-null key whose value should be loaded\n-   * @return the value associated with {@code key}\n+   * @return the value associated with {@code key} or {@code null} if not found\n    */\n   @CheckForNull\n   V load(@Nonnull K key);\n@@ -55,9 +56,9 @@ public interface CacheLoader<K, V> {\n    * {@link LoadingCache#getAll}.\n    * <p>\n    * If the returned map doesn't contain all requested {@code keys} then the entries it does contain\n-   * will be cached, but {@code getAll} will throw an exception. If the returned map contains extra\n-   * keys not present in {@code keys} then all returned entries will be cached, but only the entries\n-   * for {@code keys} will be returned from {@code getAll}.\n+   * will be cached {@code getAll} will return the partial results. If the returned map contains\n+   * extra keys not present in {@code keys} then all returned entries will be cached, but only the\n+   * entries for {@code keys} will be returned from {@code getAll}.\n    * <p>\n    * This method should be overriden when bulk retrieval is significantly more efficient than many\n    * individual lookups. Note that {@link LoadingCache#getAll} will defer to individual calls to\n@@ -92,9 +93,9 @@ default CompletableFuture<V> asyncLoad(@Nonnull K key, @Nonnull Executor executo\n    * called by {@link AsyncLoadingCache#getAll}.\n    * <p>\n    * If the returned map doesn't contain all requested {@code keys} then the entries it does contain\n-   * will be cached, but {@code getAll} will throw an exception. If the returned map contains extra\n-   * keys not present in {@code keys} then all returned entries will be cached, but only the entries\n-   * for {@code keys} will be returned from {@code getAll}.\n+   * will be cached {@code getAll} will return the partial results. If the returned map contains\n+   * extra keys not present in {@code keys} then all returned entries will be cached, but only the\n+   * entries for {@code keys} will be returned from {@code getAll}.\n    * <p>\n    * This method should be overridden when bulk retrieval is significantly more efficient than many\n    * individual lookups. Note that {@link AsyncLoadingCache#getAll} will defer to individual calls\n@@ -115,15 +116,17 @@ default CompletableFuture<Map<K, V>> asyncLoadAll(\n   }\n \n   /**\n-   * Computes or retrieves a replacement value corresponding to an already-cached {@code key}. This\n-   * method is called when an existing cache entry is refreshed by\n+   * Computes or retrieves a replacement value corresponding to an already-cached {@code key}. If\n+   * the replacement value is not found then the mapping will be removed if {@code null} is\n+   * returned. This method is called when an existing cache entry is refreshed by\n    * {@link Caffeine#refreshAfterWrite}, or through a call to {@link LoadingCache#refresh}.\n    * <p>\n    * <b>Note:</b> <i>all exceptions thrown by this method will be logged and then swallowed</i>.\n    *\n    * @param key the non-null key whose value should be loaded\n    * @param oldValue the non-null old value corresponding to {@code key}\n-   * @return the new value associated with {@code key}, or null if none\n+   * @return the new value associated with {@code key}, or {@code null} if the mapping is to be\n+   *         removed\n    * @throws RuntimeException or Error, in which case the mapping is unchanged\n    */\n   @CheckForNull",
      "parent_sha": "ea0b2f6f7239a6fe4b09914e362b712438e5b645"
    }
  },
  {
    "oid": "564b57aa1585d6d693e14e0a2f9faa2d9c2c076f",
    "message": "Fix naming",
    "date": "2014-12-17T01:44:50Z",
    "url": "https://github.com/ben-manes/caffeine/commit/564b57aa1585d6d693e14e0a2f9faa2d9c2c076f",
    "details": {
      "sha": "26c3359927fe40f0e73ee30087363f99bdd6b07b",
      "filename": "src/test/java/com/github/benmanes/caffeine/EliminationStackTest.java",
      "status": "modified",
      "additions": 48,
      "deletions": 48,
      "changes": 96,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/564b57aa1585d6d693e14e0a2f9faa2d9c2c076f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStackTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/564b57aa1585d6d693e14e0a2f9faa2d9c2c076f/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStackTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2FEliminationStackTest.java?ref=564b57aa1585d6d693e14e0a2f9faa2d9c2c076f",
      "patch": "@@ -44,106 +44,106 @@\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n public final class EliminationStackTest {\n-  static final int WARMED_SIZE = 100;\n+  static final int POPULATED_SIZE = 100;\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void clear_whenEmpty(EliminationStack<Integer> stack) {\n     stack.clear();\n     assertThat(stack.isEmpty(), is(true));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void clear_whenPopulated(EliminationStack<Integer> stack) {\n     stack.clear();\n     assertThat(stack.isEmpty(), is(true));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void isEmpty_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.isEmpty(), is(true));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void isEmpty_whenPopulated(EliminationStack<Integer> stack) {\n     assertThat(stack.isEmpty(), is(false));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void size_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.size(), is(0));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void size_whenPopulated(EliminationStack<Integer> stack) {\n-    assertThat(stack.size(), is(WARMED_SIZE));\n+    assertThat(stack.size(), is(POPULATED_SIZE));\n   }\n \n-  @Test(dataProvider = \"emptyStack\", expectedExceptions = NullPointerException.class)\n+  @Test(dataProvider = \"empty\", expectedExceptions = NullPointerException.class)\n   public void contains_withNull(EliminationStack<Integer> stack) {\n     stack.contains(null);\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void contains_whenFound(EliminationStack<Integer> stack) {\n     assertThat(stack.contains(1), is(true));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void contains_whenNotFound(EliminationStack<Integer> stack) {\n     assertThat(stack.contains(-1), is(false));\n   }\n \n-  @Test(dataProvider = \"emptyStack\", expectedExceptions = NullPointerException.class)\n+  @Test(dataProvider = \"empty\", expectedExceptions = NullPointerException.class)\n   public void push_withNull(EliminationStack<Integer> stack) {\n     stack.push(null);\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void push_whenEmpty(EliminationStack<Integer> stack) {\n     stack.push(1);\n     assertThat(stack.peek(), is(1));\n     assertThat(stack.size(), is(1));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void push_whenPopulated(EliminationStack<Integer> stack) {\n     stack.push(1);\n     assertThat(stack.peek(), is(1));\n-    assertThat(stack.size(), is(WARMED_SIZE + 1));\n+    assertThat(stack.size(), is(POPULATED_SIZE + 1));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void peek_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.peek(), is(nullValue()));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void peek_whenPopulated(EliminationStack<Integer> stack) {\n-    assertThat(stack.peek(), is(WARMED_SIZE - 1));\n+    assertThat(stack.peek(), is(POPULATED_SIZE - 1));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void peek_deadNode(EliminationStack<Integer> stack) {\n     Iterator<Integer> it = stack.iterator();\n     it.next();\n     it.remove();\n-    assertThat(stack.peek(), is(WARMED_SIZE - 2));\n+    assertThat(stack.peek(), is(POPULATED_SIZE - 2));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void pop_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.pop(), is(nullValue()));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void pop_whenPopulated(EliminationStack<Integer> stack) {\n     Integer first = stack.peek();\n     assertThat(stack.pop(), is(first));\n     assertThat(stack, not(contains(first)));\n-    assertThat(stack.size(), is(WARMED_SIZE - 1));\n+    assertThat(stack.size(), is(POPULATED_SIZE - 1));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void pop_toEmpty(EliminationStack<Integer> stack) {\n     while (!stack.isEmpty()) {\n       Integer value = stack.pop();\n@@ -152,19 +152,19 @@ public void pop_toEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.isEmpty(), is(true));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void remove_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.remove(123), is(false));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void remove_whenPopulated(EliminationStack<Integer> stack) {\n     assertThat(stack.remove(10), is(true));\n     assertThat(stack, not(contains(10)));\n-    assertThat(stack.size(), is(WARMED_SIZE - 1));\n+    assertThat(stack.size(), is(POPULATED_SIZE - 1));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void remove_toEmpty(EliminationStack<Integer> stack) {\n     while (!stack.isEmpty()) {\n       Integer value = stack.peek();\n@@ -174,7 +174,7 @@ public void remove_toEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.isEmpty(), is(true));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void concurrent(final EliminationStack<Integer> stack) throws Exception {\n     final LongAdder pushed = new LongAdder();\n     final LongAdder popped = new LongAdder();\n@@ -194,7 +194,7 @@ public void concurrent(final EliminationStack<Integer> stack) throws Exception {\n     assertThat(pushed.intValue(), is(equalTo(stack.size() + popped.intValue())));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void scanAndTransfer(final EliminationStack<String> stack) {\n     final AtomicBoolean started = new AtomicBoolean();\n     final AtomicBoolean done = new AtomicBoolean();\n@@ -222,7 +222,7 @@ public void scanAndTransfer(final EliminationStack<String> stack) {\n     }\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void awaitExchange(final EliminationStack<String> stack) {\n     final AtomicBoolean started = new AtomicBoolean();\n     final AtomicBoolean done = new AtomicBoolean();\n@@ -250,7 +250,7 @@ public void awaitExchange(final EliminationStack<String> stack) {\n     }\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void scanAndMatch(final EliminationStack<String> stack) {\n     final AtomicBoolean started = new AtomicBoolean();\n     final AtomicBoolean done = new AtomicBoolean();\n@@ -278,61 +278,61 @@ public void scanAndMatch(final EliminationStack<String> stack) {\n     }\n   }\n \n-  @Test(dataProvider = \"emptyStack\", expectedExceptions = NoSuchElementException.class)\n+  @Test(dataProvider = \"empty\", expectedExceptions = NoSuchElementException.class)\n   public void iterator_noMoreElements(EliminationStack<Integer> stack) {\n     stack.iterator().next();\n   }\n \n-  @Test(dataProvider = \"warmedStack\", expectedExceptions = IllegalStateException.class)\n+  @Test(dataProvider = \"populated\", expectedExceptions = IllegalStateException.class)\n   public void iterator_removal_unread(EliminationStack<Integer> stack) {\n     stack.iterator().remove();\n   }\n \n-  @Test(dataProvider = \"warmedStack\", expectedExceptions = IllegalStateException.class)\n+  @Test(dataProvider = \"populated\", expectedExceptions = IllegalStateException.class)\n   public void iterator_removal_duplicate(EliminationStack<Integer> stack) {\n     Iterator<Integer> it = stack.iterator();\n     it.next();\n     it.remove();\n     it.remove();\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void iterator_whenEmpty(EliminationStack<Integer> stack) {\n     assertThat(stack.iterator().hasNext(), is(false));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n-  public void iterator_whenWarmed(EliminationStack<Integer> stack) {\n+  @Test(dataProvider = \"populated\")\n+  public void iterator_whenPopulated(EliminationStack<Integer> stack) {\n     List<Integer> list = new ArrayList<>();\n-    populate(list, WARMED_SIZE);\n+    populate(list, POPULATED_SIZE);\n     Collections.reverse(list);\n     assertThat(String.format(\"\\nExpected: %s%n     but: %s\", stack, list),\n         elementsEqual(stack.iterator(), list.iterator()));\n   }\n \n-  @Test(dataProvider = \"emptyStack\", expectedExceptions = IllegalStateException.class)\n+  @Test(dataProvider = \"empty\", expectedExceptions = IllegalStateException.class)\n   public void iterator_removalWhenEmpty(EliminationStack<Integer> stack) {\n     stack.iterator().remove();\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void iterator_removalWhenPopulated(EliminationStack<Integer> stack) {\n     Iterator<Integer> it = stack.iterator();\n     Integer first = stack.peek();\n     it.next();\n     it.remove();\n     assertThat(stack, not(contains(first)));\n-    assertThat(stack.size(), is(WARMED_SIZE - 1));\n+    assertThat(stack.size(), is(POPULATED_SIZE - 1));\n   }\n \n-  @Test(dataProvider = \"emptyStack\")\n+  @Test(dataProvider = \"empty\")\n   public void serialize_whenEmpty(EliminationStack<Integer> stack) {\n     List<Integer> expected = new ArrayList<>(stack);\n     List<Integer> actual = new ArrayList<>(SerializableTester.reserialize(stack));\n     assertThat(expected, is(equalTo(actual)));\n   }\n \n-  @Test(dataProvider = \"warmedStack\")\n+  @Test(dataProvider = \"populated\")\n   public void serialize_whenPopulated(EliminationStack<Integer> stack) {\n     List<Integer> expected = new ArrayList<>(stack);\n     List<Integer> actual = new ArrayList<>(SerializableTester.reserialize(stack));\n@@ -347,13 +347,13 @@ public Object[][] emptyStack() {\n   }\n \n   @DataProvider\n-  public Object[][] warmedStack() {\n-    return new Object[][] {{ newWarmedStack() }};\n+  public Object[][] populatedStack() {\n+    return new Object[][] {{ newPopulatedStack() }};\n   }\n \n-  EliminationStack<Integer> newWarmedStack() {\n+  EliminationStack<Integer> newPopulatedStack() {\n     EliminationStack<Integer> stack = new EliminationStack<Integer>();\n-    populate(stack, WARMED_SIZE);\n+    populate(stack, POPULATED_SIZE);\n     return stack;\n   }\n ",
      "parent_sha": "04b2ae4b2197423d6772440a48f4e99095de576b"
    }
  },
  {
    "oid": "c25d137fe28fcff7c58890fc007304ad3d7bf965",
    "message": "BoundedLocalCache#computeIfAbsent with CacheWriter\n\nPreviously the prescreening was doing all of the validation and cleaning\nup if an entry needed to be evicted (expired, GC'd). This really should\nhave been done within the computeIfAbsent, but it had to be refactored\nto use a map.compute() handle present but invalid nodes. This is now done\nto provide correctness and straightforward CacheWriter integration",
    "date": "2015-06-15T05:30:13Z",
    "url": "https://github.com/ben-manes/caffeine/commit/c25d137fe28fcff7c58890fc007304ad3d7bf965",
    "details": {
      "sha": "851e96d4e9a1f7492ac42b195c9d2c04ef359539",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 68,
      "deletions": 69,
      "changes": 137,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/c25d137fe28fcff7c58890fc007304ad3d7bf965/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/c25d137fe28fcff7c58890fc007304ad3d7bf965/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=c25d137fe28fcff7c58890fc007304ad3d7bf965",
      "patch": "@@ -1132,106 +1132,105 @@ public V computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction\n       boolean isAsync) {\n     requireNonNull(key);\n     requireNonNull(mappingFunction);\n-\n     long now = ticker().read();\n-    V value = prescreen(key, mappingFunction, now);\n-    return (value == null) ? doComputeIfAbsent(key, mappingFunction, isAsync, now) : value;\n-  }\n \n-  /**\n-   * An optimistic fast path due to computeIfAbsent always locking. This is leveraged to evict\n-   * if the entry is present but has expired or its key/value has been garbage collected.\n-   */\n-  V prescreen(K key, Function<? super K, ? extends V> mappingFunction, long now) {\n+    // An optimistic fast path due to computeIfAbsent always locking\n     Node<K, V> node = data.get(nodeFactory.newLookupKey(key));\n-    if (node == null) {\n-      return null;\n+    if (node != null) {\n+      V value = node.getValue();\n+      if ((value == null) && !hasExpired(node, now)) {\n+        return value;\n+      }\n     }\n \n-    K nodeKey = node.getKey();\n+    return doComputeIfAbsent(key, mappingFunction, isAsync, now);\n+  }\n+\n+  /** Returns the current value from a computeIfAbsent invocation. */\n+  V doComputeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction,\n+      boolean isAsync, long now) {\n+    int[] weight = new int[1];\n+    @SuppressWarnings(\"unchecked\")\n+    V[] oldValue = (V[]) new Object[1];\n     @SuppressWarnings(\"unchecked\")\n-    V[] value = (V[]) new Object[] { node.getValue() };\n+    V[] newValue = (V[]) new Object[1];\n+    @SuppressWarnings(\"unchecked\")\n+    K[] nodeKey = (K[]) new Object[1];\n+    @SuppressWarnings(\"unchecked\")\n+    Node<K, V>[] removed = new Node[1];\n     RemovalCause[] cause = new RemovalCause[1];\n-    if ((nodeKey == null) || (value[0] == null)) {\n-      cause[0] = RemovalCause.COLLECTED;\n-    } else if (hasExpired(node, now)) {\n-      cause[0] = RemovalCause.EXPIRED;\n-    }\n+    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n \n-    if (cause[0] == null) {\n-      afterRead(node, true);\n-      if (Tracer.isEnabled()) {\n-        tracer().recordWrite(id, key, weigher.weigh(nodeKey, value[0]));\n+    Node<K, V> node = data.compute(keyRef, (k, n) -> {\n+      if (n == null) {\n+        newValue[0] = statsAware(mappingFunction, isAsync).apply(key);\n+        if (newValue[0] == null) {\n+          return null;\n+        }\n+        weight[0] = weigher.weigh(key, newValue[0]);\n+        return nodeFactory.newNode(key, keyReferenceQueue(),\n+            newValue[0], valueReferenceQueue(), weight[0], now);\n       }\n-      return value[0];\n-    }\n \n-    boolean[] removed = new boolean[1];\n-    data.computeIfPresent(node.getKeyReference(), (k, n) -> {\n-      if (n != node) {\n-        return n;\n-      }\n       synchronized (n) {\n-        value[0] = n.getValue();\n-        if (value[0] == null) {\n+        nodeKey[0] = n.getKey();\n+        oldValue[0] = n.getValue();\n+        if ((nodeKey == null) || (oldValue[0] == null)) {\n           cause[0] = RemovalCause.COLLECTED;\n+        } else if (hasExpired(n, now)) {\n+          cause[0] = RemovalCause.EXPIRED;\n+          n.setAccessTime(now);\n+          n.setWriteTime(now);\n+        } else {\n+          return n;\n         }\n-        writer.delete(nodeKey, value[0], cause[0]);\n-        removed[0] = true;\n-        n.retire();\n-        return null;\n+\n+        writer.delete(nodeKey[0], oldValue[0], cause[0]);\n+        newValue[0] = statsAware(mappingFunction, isAsync).apply(key);\n+        if (newValue[0] == null) {\n+          removed[0] = n;\n+          n.retire();\n+          return null;\n+        }\n+        weight[0] = weigher.weigh(key, newValue[0]);\n+        n.setValue(newValue[0], valueReferenceQueue());\n+        return n;\n       }\n     });\n \n-    if (removed[0]) {\n+    if (node == null) {\n+      afterWrite(node, new RemovalTask(removed[0]));\n+      return null;\n+    }\n+    if (cause[0] != null) {\n       if (hasRemovalListener()) {\n-        notifyRemoval(key, value[0], cause[0]);\n+        notifyRemoval(nodeKey[0], oldValue[0], cause[0]);\n       }\n       statsCounter().recordEviction();\n-      afterWrite(node, new RemovalTask(node));\n-    }\n-    return null;\n-  }\n-\n-  /** Returns the current value from a computeIfAbsent invocation. */\n-  V doComputeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction,\n-      boolean isAsync, long now) {\n-    int[] weight = new int[1];\n-    @SuppressWarnings(\"unchecked\")\n-    V[] value = (V[]) new Object[1];\n-    Object keyRef = nodeFactory.newReferenceKey(key, keyReferenceQueue());\n-    Node<K, V> node = data.computeIfAbsent(keyRef, k -> {\n-      value[0] = statsAware(mappingFunction, isAsync).apply(key);\n-      if (value[0] == null) {\n-        return null;\n-      }\n-      weight[0] = weigher.weigh(key, value[0]);\n-      return nodeFactory.newNode(key, keyReferenceQueue(),\n-          value[0], valueReferenceQueue(), weight[0], now);\n-    });\n-    if (node == null) {\n-      return null;\n     }\n-    V val;\n-    if (value[0] == null) {\n-      val = node.getValue();\n+    if (newValue[0] == null) {\n+      tracer().recordRead(id, key);\n       afterRead(node, true);\n-    } else {\n-      val = value[0];\n+      return oldValue[0];\n+    }\n+    if (oldValue[0] == null) {\n       afterWrite(node, new AddTask(node, weight[0]));\n+    } else {\n+      afterRead(node, true);\n     }\n-    if (Tracer.isEnabled() && (val != null)) {\n-      tracer().recordWrite(id, key, weigher.weigh(key, val));\n+    if (Tracer.isEnabled()) {\n+      tracer().recordWrite(id, key, weigher.weigh(nodeKey[0], newValue[0]));\n     }\n-    return val;\n+\n+    return newValue[0];\n   }\n \n   @Override\n   public V computeIfPresent(K key,\n       BiFunction<? super K, ? super V, ? extends V> remappingFunction) {\n     requireNonNull(remappingFunction);\n \n-    // An optimistic fast path due to computeIfAbsent always locking\n+    // An optimistic fast path due to computeIfPresent always locking\n     Object ref = nodeFactory.newLookupKey(key);\n     if (!data.containsKey(ref)) {\n       return null;",
      "parent_sha": "cc21a1b046bfaca881396b0d9b82df1cc3c36e1b"
    }
  },
  {
    "oid": "27dfec3f1226631aed065bfe086dcf1526582ab3",
    "message": "Fix weighted SLRU demotion when decrementing the region's size\n\nThe protected space's size was decremented by the promoted entry's\nweight, rather than the demoted entry's. When entries have the same\nweight, e.g. maximumSize, this is the same. The cache will still evict\nwhen the overall capacity has been reached, so this only caused the\nwrong accounting.\n\nThe test EvictionTest#evict_weighted was known to fail on CI, though\nseemed to be flaky. The assumption was this was due to the randomness\nin the seeds, though recently making those stable seemed to fix it\nuntil it reappeared yesterday. The mistake was discovered when working\non the adaptive policy, so a fortunate coincidence.\n\nSince this failure is difficult to trigger, hopefully not seeing the\ntest case fail will mean we've fixed it.",
    "date": "2018-02-06T19:19:24Z",
    "url": "https://github.com/ben-manes/caffeine/commit/27dfec3f1226631aed065bfe086dcf1526582ab3",
    "details": {
      "sha": "7a472eaf7c98173a4ac8fac41b48b25fe65fec63",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/27dfec3f1226631aed065bfe086dcf1526582ab3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/27dfec3f1226631aed065bfe086dcf1526582ab3/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=27dfec3f1226631aed065bfe086dcf1526582ab3",
      "patch": "@@ -1229,7 +1229,7 @@ void reorderProbation(Node<K, V> node) {\n       }\n       demoted.makeMainProbation();\n       accessOrderProbationDeque().add(demoted);\n-      mainProtectedWeightedSize -= node.getPolicyWeight();\n+      mainProtectedWeightedSize -= demoted.getPolicyWeight();\n     }\n \n     lazySetMainProtectedWeightedSize(mainProtectedWeightedSize);",
      "parent_sha": "e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a"
    }
  },
  {
    "oid": "410edf36d846547d47bc168138c78c76c63b8416",
    "message": "Remove dead / duplicated code",
    "date": "2014-12-27T01:47:08Z",
    "url": "https://github.com/ben-manes/caffeine/commit/410edf36d846547d47bc168138c78c76c63b8416",
    "details": {
      "sha": "ca2ff2154f9ebcd0f01992f6e08011b2398b63c1",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/clhm/ConcurrentLinkedHashMap.java",
      "status": "modified",
      "additions": 2,
      "deletions": 52,
      "changes": 54,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/410edf36d846547d47bc168138c78c76c63b8416/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fclhm%2FConcurrentLinkedHashMap.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/410edf36d846547d47bc168138c78c76c63b8416/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fclhm%2FConcurrentLinkedHashMap.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fclhm%2FConcurrentLinkedHashMap.java?ref=410edf36d846547d47bc168138c78c76c63b8416",
      "patch": "@@ -18,7 +18,6 @@\n import static com.github.benmanes.caffeine.cache.clhm.ConcurrentLinkedHashMap.DrainStatus.IDLE;\n import static com.github.benmanes.caffeine.cache.clhm.ConcurrentLinkedHashMap.DrainStatus.PROCESSING;\n import static com.github.benmanes.caffeine.cache.clhm.ConcurrentLinkedHashMap.DrainStatus.REQUIRED;\n-import static java.util.Collections.emptyList;\n import static java.util.Collections.unmodifiableMap;\n import static java.util.Collections.unmodifiableSet;\n import static java.util.Objects.requireNonNull;\n@@ -28,7 +27,6 @@\n import java.io.Serializable;\n import java.util.AbstractCollection;\n import java.util.AbstractMap;\n-import java.util.AbstractQueue;\n import java.util.AbstractSet;\n import java.util.Collection;\n import java.util.HashMap;\n@@ -43,7 +41,6 @@\n import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.Executor;\n import java.util.concurrent.ForkJoinPool;\n-import java.util.concurrent.atomic.AtomicLong;\n import java.util.concurrent.atomic.AtomicReference;\n import java.util.concurrent.locks.Lock;\n import java.util.concurrent.locks.ReentrantLock;\n@@ -52,6 +49,8 @@\n import javax.annotation.concurrent.Immutable;\n import javax.annotation.concurrent.ThreadSafe;\n \n+import com.github.benmanes.caffeine.atomic.PaddedAtomicLong;\n+import com.github.benmanes.caffeine.atomic.PaddedAtomicReference;\n import com.github.benmanes.caffeine.cache.RemovalCause;\n import com.github.benmanes.caffeine.cache.RemovalListener;\n import com.github.benmanes.caffeine.cache.RemovalNotification;\n@@ -178,9 +177,6 @@ public final class ConcurrentLinkedHashMap<K, V> extends AbstractMap<K, V>\n   /** The maximum number of write operations to perform per amortized drain. */\n   static final int WRITE_BUFFER_DRAIN_THRESHOLD = 16;\n \n-  /** A queue that discards all entries. */\n-  static final Queue<?> DISCARDING_QUEUE = new DiscardingQueue();\n-\n   static int ceilingNextPowerOfTwo(int x) {\n     // From Hacker's Delight, Chapter 3, Harry S. Warren Jr.\n     return 1 << (Integer.SIZE - Integer.numberOfLeadingZeros(x - 1));\n@@ -1393,52 +1389,6 @@ Object writeReplace() {\n     }\n   }\n \n-  /** A queue that discards all additions and is always empty. */\n-  static final class DiscardingQueue extends AbstractQueue<Object> {\n-    @Override public boolean add(Object e) { return true; }\n-    @Override public boolean offer(Object e) { return true; }\n-    @Override public Object poll() { return null; }\n-    @Override public Object peek() { return null; }\n-    @Override public int size() { return 0; }\n-    @Override public Iterator<Object> iterator() { return emptyList().iterator(); }\n-  }\n-\n-  /**\n-   * An AtomicReference with heuristic padding to lessen cache effects of this\n-   * heavily CAS'ed location. While the padding adds noticeable space, the\n-   * improved throughput outweighs using extra space.\n-   */\n-  static class PaddedAtomicReference<T> extends AtomicReference<T> {\n-    private static final long serialVersionUID = 1L;\n-\n-    // Improve likelihood of isolation on <= 64 byte cache lines\n-    long q0, q1, q2, q3, q4, q5, q6, q7, q8, q9, qa, qb, qc, qd, qe;\n-\n-    PaddedAtomicReference() {}\n-\n-    PaddedAtomicReference(T value) {\n-      super(value);\n-    }\n-  }\n-\n-  /**\n-   * An AtomicLong with heuristic padding to lessen cache effects of this\n-   * heavily CAS'ed location. While the padding adds noticeable space, the\n-   * improved throughput outweighs using extra space.\n-   */\n-  static class PaddedAtomicLong extends AtomicLong {\n-    private static final long serialVersionUID = 1L;\n-\n-    // Improve likelihood of isolation on <= 64 byte cache lines\n-    long q0, q1, q2, q3, q4, q5, q6, q7, q8, q9, qa, qb, qc, qd, qe;\n-\n-    PaddedAtomicLong() {}\n-\n-    PaddedAtomicLong(long value) {\n-      super(value);\n-    }\n-  }\n-\n   /* ---------------- Serialization Support -------------- */\n \n   static final long serialVersionUID = 1;",
      "parent_sha": "de26be211f9cde52ae88591aafc69c608f5dde6b"
    }
  },
  {
    "oid": "f99022b06fc241be6e27e1f4020258c8852939ab",
    "message": "Improve variable name (was inverted to logic)\n\nhttps://github.com/ben-manes/caffeine/issues/436#issuecomment-65474064",
    "date": "2020-07-07T18:37:36Z",
    "url": "https://github.com/ben-manes/caffeine/commit/f99022b06fc241be6e27e1f4020258c8852939ab",
    "details": {
      "sha": "69093d90e4a6a908cfeee7dbc3e732bbf267575f",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/f99022b06fc241be6e27e1f4020258c8852939ab/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/f99022b06fc241be6e27e1f4020258c8852939ab/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=f99022b06fc241be6e27e1f4020258c8852939ab",
      "patch": "@@ -2027,7 +2027,7 @@ public Map<K, V> getAllPresent(Iterable<?> keys) {\n       int oldWeight;\n       boolean expired = false;\n       boolean mayUpdate = true;\n-      boolean withinTolerance = true;\n+      boolean exceedsTolerance = true;\n       synchronized (prior) {\n         if (!prior.isAlive()) {\n           continue;\n@@ -2052,7 +2052,7 @@ public Map<K, V> getAllPresent(Iterable<?> keys) {\n           writer.write(key, value);\n         }\n         if (mayUpdate) {\n-          withinTolerance = ((now - prior.getWriteTime()) > EXPIRE_WRITE_TOLERANCE);\n+          exceedsTolerance = ((now - prior.getWriteTime()) > EXPIRE_WRITE_TOLERANCE);\n \n           setWriteTime(prior, now);\n           prior.setWeight(newWeight);\n@@ -2076,7 +2076,7 @@ public Map<K, V> getAllPresent(Iterable<?> keys) {\n       int weightedDifference = mayUpdate ? (newWeight - oldWeight) : 0;\n       if ((oldValue == null) || (weightedDifference != 0) || expired) {\n         afterWrite(new UpdateTask(prior, weightedDifference));\n-      } else if (!onlyIfAbsent && expiresAfterWrite() && withinTolerance) {\n+      } else if (!onlyIfAbsent && expiresAfterWrite() && exceedsTolerance) {\n         afterWrite(new UpdateTask(prior, weightedDifference));\n       } else {\n         if (mayUpdate) {",
      "parent_sha": "40f2d1b2894df96e866b3d3719bb5420ba241bcc"
    }
  },
  {
    "oid": "db0e225986f72fff933b99ca2b29780c09cf9a6e",
    "message": "Minor refinements to the simulator's bloom filter\n\nThis simple optimization combines the shift and mask into a single\noperation. Since the table size is a power-of-two, we shift the top\nmost bits to get an index. The bottom most bits are used to index\ninto the long to find the bit.",
    "date": "2016-05-29T04:52:43Z",
    "url": "https://github.com/ben-manes/caffeine/commit/db0e225986f72fff933b99ca2b29780c09cf9a6e",
    "details": {
      "sha": "0a617df67d6a7de6e85ce0eb22183b82c9a3d9fb",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/membership/bloom/BloomFilter.java",
      "status": "modified",
      "additions": 11,
      "deletions": 13,
      "changes": 24,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/db0e225986f72fff933b99ca2b29780c09cf9a6e/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fmembership%2Fbloom%2FBloomFilter.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/db0e225986f72fff933b99ca2b29780c09cf9a6e/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fmembership%2Fbloom%2FBloomFilter.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fmembership%2Fbloom%2FBloomFilter.java?ref=db0e225986f72fff933b99ca2b29780c09cf9a6e",
      "patch": "@@ -42,14 +42,15 @@ public final class BloomFilter implements Membership {\n \n   final int randomSeed;\n \n-  int tableMask;\n+  int tableShift;\n   long[] table;\n \n   /**\n    * Creates a lazily initialized frequency sketch, requiring {@link #ensureCapacity} be called\n    * when the expected number of insertions is determined.\n    *\n    * @param expectedInsertions the number of expected insertions\n+   * @param fpp the false positive probability, where 0.0 > fpp < 1.0\n    * @param randomSeed the smear to protect against hash flooding, adjusted to an odd value\n    */\n   public BloomFilter(@Nonnegative long expectedInsertions,\n@@ -64,22 +65,24 @@ public BloomFilter(@Nonnegative long expectedInsertions,\n    * number of insertions. This operation forgets all previous memberships when resizing.\n    *\n    * @param expectedInsertions the number of expected insertions\n+   * @param fpp the false positive probability, where 0.0 > fpp < 1.0\n    */\n   void ensureCapacity(@Nonnegative long expectedInsertions, @Nonnegative double fpp) {\n     checkArgument(expectedInsertions >= 0);\n-    checkArgument(fpp > 0);\n+    checkArgument(fpp > 0 && fpp < 1);\n \n     double optimalBitsFactor = -Math.log(fpp) / (Math.log(2) * Math.log(2));\n     int optimalNumberOfBits = (int) (expectedInsertions * optimalBitsFactor);\n     int optimalSize = optimalNumberOfBits >>> BITS_PER_LONG_SHIFT;\n     if ((table != null) && (table.length >= optimalSize)) {\n       return;\n     } else if (optimalSize == 0) {\n+      tableShift = Integer.SIZE - 1;\n       table = new long[1];\n-      tableMask = 0;\n     } else {\n-      table = new long[ceilingPowerOfTwo(optimalSize)];\n-      tableMask = table.length - 1;\n+      int powerOfTwoShift = Integer.SIZE - Integer.numberOfLeadingZeros(optimalSize - 1);\n+      tableShift = Integer.SIZE - powerOfTwoShift;\n+      table = new long[1 << powerOfTwoShift];\n     }\n   }\n \n@@ -88,7 +91,7 @@ public boolean mightContain(long e) {\n     int item = spread(Long.hashCode(e));\n     for (int i = 0; i < 4; i++) {\n       int hash = seeded(item, i);\n-      int index = hash & tableMask;\n+      int index = (hash >>> tableShift);\n       if ((table[index] & bitmask(hash)) == 0L) {\n         return false;\n       }\n@@ -118,7 +121,7 @@ public void put(long e) {\n    */\n   void setAt(int item, int seedIndex) {\n     int hash = seeded(item, seedIndex);\n-    int index = hash & tableMask;\n+    int index = (hash >>> tableShift);\n     table[index] |= bitmask(hash);\n   }\n \n@@ -152,11 +155,6 @@ static int seeded(int item, int i) {\n    * @return the mask to the bit\n    */\n   static long bitmask(int hash) {\n-    return 1L << ((hash >>> 24) & BITS_PER_LONG_MASK);\n-  }\n-\n-  static int ceilingPowerOfTwo(int x) {\n-    // From Hacker's Delight, Chapter 3, Harry S. Warren Jr.\n-    return 1 << -Integer.numberOfLeadingZeros(x - 1);\n+    return 1L << (hash & BITS_PER_LONG_MASK);\n   }\n }",
      "parent_sha": "6451e58b8c45991ea7c35f7f061bba1ff6841b29"
    }
  },
  {
    "oid": "abdc478f60d1af60b4b9f99ec5bff4f91fa772b9",
    "message": "Prefer the thread context classloader in jcache (fixes #387)\n\nIt seems that the Spring + Hibernate JCache support loads classes\nby the current thread's context classloader, which differs from the\nprovider class's classloader. Now closer matches to Ehcache which wrote\nHibernate's integration and differs only by avoiding redundant work\nwhen the two classloaders match.",
    "date": "2020-01-26T03:04:31Z",
    "url": "https://github.com/ben-manes/caffeine/commit/abdc478f60d1af60b4b9f99ec5bff4f91fa772b9",
    "details": {
      "sha": "3c7eaf7e3104127871da50b151c75f34daaa3c3f",
      "filename": "jcache/src/main/java/com/github/benmanes/caffeine/jcache/spi/CaffeineCachingProvider.java",
      "status": "modified",
      "additions": 77,
      "deletions": 1,
      "changes": 78,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/abdc478f60d1af60b4b9f99ec5bff4f91fa772b9/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fspi%2FCaffeineCachingProvider.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/abdc478f60d1af60b4b9f99ec5bff4f91fa772b9/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fspi%2FCaffeineCachingProvider.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/jcache%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fjcache%2Fspi%2FCaffeineCachingProvider.java?ref=abdc478f60d1af60b4b9f99ec5bff4f91fa772b9",
      "patch": "@@ -17,9 +17,16 @@\n \n import static javax.cache.configuration.OptionalFeature.STORE_BY_REFERENCE;\n \n+import java.io.IOException;\n import java.net.URI;\n+import java.net.URL;\n+import java.security.AccessController;\n+import java.security.PrivilegedAction;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Enumeration;\n import java.util.HashMap;\n+import java.util.List;\n import java.util.Map;\n import java.util.Properties;\n import java.util.WeakHashMap;\n@@ -29,6 +36,8 @@\n import javax.cache.configuration.OptionalFeature;\n import javax.cache.spi.CachingProvider;\n \n+import org.checkerframework.checker.nullness.qual.Nullable;\n+\n import com.github.benmanes.caffeine.jcache.CacheManagerImpl;\n import com.google.errorprone.annotations.concurrent.GuardedBy;\n \n@@ -45,6 +54,9 @@\n  * @author ben.manes@gmail.com (Ben Manes)\n  */\n public final class CaffeineCachingProvider implements CachingProvider {\n+  private static final ClassLoader DEFAULT_CLASS_LOADER = AccessController.doPrivileged(\n+      (PrivilegedAction<ClassLoader>) JCacheClassLoader::new);\n+\n   @GuardedBy(\"itself\")\n   private final Map<ClassLoader, Map<URI, CacheManager>> cacheManagers;\n \n@@ -54,7 +66,7 @@ public CaffeineCachingProvider() {\n \n   @Override\n   public ClassLoader getDefaultClassLoader() {\n-    return getClass().getClassLoader();\n+    return DEFAULT_CLASS_LOADER;\n   }\n \n   @Override\n@@ -146,4 +158,68 @@ private URI getManagerUri(URI uri) {\n   private ClassLoader getManagerClassLoader(ClassLoader classLoader) {\n     return (classLoader == null) ? getDefaultClassLoader() : classLoader;\n   }\n+\n+  /**\n+   * A {@link ClassLoader} that combines {@code Thread.currentThread().getContextClassLoader()}\n+   * and {@code getClass().getClassLoader()}.\n+   */\n+  private static final class JCacheClassLoader extends ClassLoader {\n+\n+    @Override\n+    public Class<?> loadClass(String name) throws ClassNotFoundException {\n+      ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+      ClassNotFoundException error = null;\n+      if (contextClassLoader != null) {\n+        try {\n+          return contextClassLoader.loadClass(name);\n+        } catch (ClassNotFoundException e) {\n+          error = e;\n+        }\n+      }\n+\n+      ClassLoader classClassLoader = getClass().getClassLoader();\n+      if ((classClassLoader != null) && (classClassLoader != contextClassLoader)) {\n+        return classClassLoader.loadClass(name);\n+      }\n+      throw (error == null) ? new ClassNotFoundException(name) : error;\n+    }\n+\n+    @Override\n+    public @Nullable URL getResource(String name) {\n+      ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+      if (contextClassLoader != null) {\n+        URL resource = contextClassLoader.getResource(name);\n+        if (resource != null) {\n+          return resource;\n+        }\n+      }\n+\n+      ClassLoader classClassLoader = Thread.currentThread().getContextClassLoader();\n+      if ((classClassLoader != null) && (classClassLoader != contextClassLoader)) {\n+        URL resource = classClassLoader.getResource(name);\n+        if (resource != null) {\n+          return resource;\n+        }\n+      }\n+\n+      return null;\n+    }\n+\n+    @Override\n+    public Enumeration<URL> getResources(String name) throws IOException {\n+      List<URL> resources = new ArrayList<>();\n+\n+      ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+      if (contextClassLoader != null) {\n+        resources.addAll(Collections.list(contextClassLoader.getResources(name)));\n+      }\n+\n+      ClassLoader classClassLoader = Thread.currentThread().getContextClassLoader();\n+      if ((classClassLoader != null) && (classClassLoader != contextClassLoader)) {\n+        resources.addAll(Collections.list(classClassLoader.getResources(name)));\n+      }\n+\n+      return Collections.enumeration(resources);\n+    }\n+  }\n }",
      "parent_sha": "ddae49649b87b87542e7fe1cff9781b09815cff8"
    }
  },
  {
    "oid": "2d5528dea3ff1e6af2a9f682d1e12122837aa4a4",
    "message": "Update the Javadocs of `refreshAfterWrite` to reflect the actual behavior for IllegalArgumentException",
    "date": "2019-09-23T09:08:17Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2d5528dea3ff1e6af2a9f682d1e12122837aa4a4",
    "details": {
      "sha": "25bf334adf4a07cd823ff3d01f370d4d73f6d99d",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2d5528dea3ff1e6af2a9f682d1e12122837aa4a4/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2d5528dea3ff1e6af2a9f682d1e12122837aa4a4/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=2d5528dea3ff1e6af2a9f682d1e12122837aa4a4",
      "patch": "@@ -740,7 +740,7 @@ boolean expiresVariable() {\n    * @param duration the length of time after an entry is created that it should be considered\n    *     stale, and thus eligible for refresh\n    * @return this {@code Caffeine} instance (for chaining)\n-   * @throws IllegalArgumentException if {@code duration} is negative\n+   * @throws IllegalArgumentException if {@code duration} is zero or negative\n    * @throws IllegalStateException if the refresh interval was already set\n    * @throws ArithmeticException for durations greater than +/- approximately 292 years\n    */",
      "parent_sha": "19f0911a78fa8096a4f610a24b756741dd4ed984"
    }
  },
  {
    "oid": "0ef0f31618d20ebeded74a3cd7161c4bf3070238",
    "message": "refine assertion for broken equality log message (#900)",
    "date": "2023-04-07T16:05:43Z",
    "url": "https://github.com/ben-manes/caffeine/commit/0ef0f31618d20ebeded74a3cd7161c4bf3070238",
    "details": {
      "sha": "9328ac697dc6f09972071b2bf3e62b81ff118f72",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/BoundedLocalCacheTest.java",
      "status": "modified",
      "additions": 16,
      "deletions": 14,
      "changes": 30,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/0ef0f31618d20ebeded74a3cd7161c4bf3070238/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCacheTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/0ef0f31618d20ebeded74a3cd7161c4bf3070238/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCacheTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCacheTest.java?ref=0ef0f31618d20ebeded74a3cd7161c4bf3070238",
      "patch": "@@ -2359,10 +2359,8 @@ public void brokenEquality_eviction(BoundedLocalCache<Object, Int> cache,\n     assertThat(cache.estimatedSize()).isEqualTo(1);\n \n     var event = Iterables.getOnlyElement(TestLoggerFactory.getLoggingEvents());\n-    assertThat(event.getFormattedMessage()).containsMatch(\n-        \"An invalid state was detected.*\\\\(key: \\\\d+, key type: MutableInt.*\\\\)\");\n-    assertThat(event.getThrowable().orElseThrow())\n-        .isInstanceOf(IllegalStateException.class);\n+    assertThat(event.getThrowable().orElseThrow()).isInstanceOf(IllegalStateException.class);\n+    checkBrokenEqualityMessage(cache, key, event.getFormattedMessage());\n     assertThat(event.getLevel()).isEqualTo(ERROR);\n \n     cache.data.clear();\n@@ -2390,10 +2388,8 @@ public void brokenEquality_expiration(\n     assertThat(cache.estimatedSize()).isEqualTo(1);\n \n     var event = Iterables.getOnlyElement(TestLoggerFactory.getLoggingEvents());\n-    assertThat(event.getFormattedMessage()).containsMatch(\n-        \"An invalid state was detected.*\\\\(key: \\\\d+, key type: MutableInt.*\\\\)\");\n-    assertThat(event.getThrowable().orElseThrow())\n-        .isInstanceOf(IllegalStateException.class);\n+    assertThat(event.getThrowable().orElseThrow()).isInstanceOf(IllegalStateException.class);\n+    checkBrokenEqualityMessage(cache, key, event.getFormattedMessage());\n     assertThat(event.getLevel()).isEqualTo(ERROR);\n \n     cache.data.clear();\n@@ -2414,10 +2410,8 @@ public void brokenEquality_clear(BoundedLocalCache<Object, Int> cache, CacheCont\n     assertThat(cache.estimatedSize()).isEqualTo(1);\n \n     var event = Iterables.getOnlyElement(TestLoggerFactory.getLoggingEvents());\n-    assertThat(event.getFormattedMessage()).containsMatch(\n-        \"An invalid state was detected.*\\\\(key: \\\\d+, key type: MutableInt.*\\\\)\");\n-    assertThat(event.getThrowable().orElseThrow())\n-        .isInstanceOf(IllegalStateException.class);\n+    assertThat(event.getThrowable().orElseThrow()).isInstanceOf(IllegalStateException.class);\n+    checkBrokenEqualityMessage(cache, key, event.getFormattedMessage());\n     assertThat(event.getLevel()).isEqualTo(ERROR);\n \n     cache.data.clear();\n@@ -2499,12 +2493,20 @@ private static void testForBrokenEquality(BoundedLocalCache<MutableInt, Int> cac\n     key.decrement();\n \n     var e = assertThrows(IllegalStateException.class, () -> task.accept(key));\n-    assertThat(e).hasMessageThat().containsMatch(\n-        \"An invalid state was detected.*\\\\(key: \\\\d+, key type: MutableInt.*\\\\)\");\n+    checkBrokenEqualityMessage(cache, key, e.getMessage());\n \n     cache.data.clear();\n   }\n \n+  private static void checkBrokenEqualityMessage(\n+      BoundedLocalCache<?, ?> cache, Object key, String msg) {\n+    assertThat(msg).contains(\"An invalid state was detected\");\n+    assertThat(msg).contains(\"cache type: \" + cache.getClass().getSimpleName());\n+    assertThat(msg).contains(\"node type: \" + cache.nodeFactory.getClass().getSimpleName());\n+    assertThat(msg).contains(\"key type: \" + key.getClass().getSimpleName());\n+    assertThat(msg).contains(\"key: \" + key);\n+  }\n+\n   /* --------------- Miscellaneous --------------- */\n \n   @Test",
      "parent_sha": "1eb57acfc7ae9bed04d6f43061dd3246956aaea2"
    }
  },
  {
    "oid": "e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a",
    "message": "Update to 16 - the default ConcurrentHashMap size",
    "date": "2018-02-02T23:07:10Z",
    "url": "https://github.com/ben-manes/caffeine/commit/e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a",
    "details": {
      "sha": "5a127dc2ba55ee0b4c9cf1b35b1ecc61410a63b0",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FCaffeine.java?ref=e84866fd6ad5bf9ab8c5a798df63b6f31f5e684a",
      "patch": "@@ -139,7 +139,7 @@ public final class Caffeine<K, V> {\n   enum Strength { WEAK, SOFT }\n   static final int UNSET_INT = -1;\n \n-  static final int DEFAULT_INITIAL_CAPACITY = 64;\n+  static final int DEFAULT_INITIAL_CAPACITY = 16;\n   static final int DEFAULT_EXPIRATION_NANOS = 0;\n   static final int DEFAULT_REFRESH_NANOS = 0;\n ",
      "parent_sha": "5a91bbe1dac1810d329c22d7ac914a76966b3b32"
    }
  },
  {
    "oid": "d201f529ffc9b3b2741dd258dbbdd5b563656e95",
    "message": "fix flaky test case due to off-by-one time advancement",
    "date": "2020-06-29T05:55:39Z",
    "url": "https://github.com/ben-manes/caffeine/commit/d201f529ffc9b3b2741dd258dbbdd5b563656e95",
    "details": {
      "sha": "4a3399179a02da1d75b4cbb338fb3b13296933dc",
      "filename": "caffeine/src/test/java/com/github/benmanes/caffeine/cache/ExpirationTest.java",
      "status": "modified",
      "additions": 13,
      "deletions": 8,
      "changes": 21,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/d201f529ffc9b3b2741dd258dbbdd5b563656e95/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FExpirationTest.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/d201f529ffc9b3b2741dd258dbbdd5b563656e95/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FExpirationTest.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Ftest%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FExpirationTest.java?ref=d201f529ffc9b3b2741dd258dbbdd5b563656e95",
      "patch": "@@ -23,13 +23,15 @@\n import static com.github.benmanes.caffeine.cache.testing.HasRemovalNotifications.hasRemovalNotifications;\n import static com.github.benmanes.caffeine.testing.IsFutureValue.futureOf;\n import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.aMapWithSize;\n import static org.hamcrest.Matchers.anEmptyMap;\n import static org.hamcrest.Matchers.both;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.lessThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n import static org.hamcrest.Matchers.not;\n import static org.hamcrest.Matchers.nullValue;\n import static org.mockito.ArgumentMatchers.any;\n@@ -185,26 +187,29 @@ public void schedule_delay(Cache<Integer, Duration> cache, CacheContext context)\n         .thenReturn(Futures.immediateFuture(null));\n \n     Integer key1 = 1;\n-    cache.put(key1, Duration.ofNanos(context.ticker().read()));\n+    Duration value1 = Duration.ofNanos(context.ticker().read());\n+    cache.put(key1, value1);\n \n     Duration insertDelay = Duration.ofMillis(10);\n     context.ticker().advance(insertDelay);\n \n     Integer key2 = 2;\n-    cache.put(key2, Duration.ofNanos(context.ticker().read()));\n+    Duration value2 = Duration.ofNanos(context.ticker().read());\n+    cache.put(key2, value2);\n \n-    Duration expireKey1 = Duration.ofNanos(delay.getValue()).minus(insertDelay);\n+    Duration expireKey1 = Duration.ofNanos(1 + delay.getValue()).minus(insertDelay);\n     context.ticker().advance(expireKey1);\n     task.getValue().run();\n \n-    Duration expireKey2 = Duration.ofNanos(delay.getValue());\n+    Duration expireKey2 = Duration.ofNanos(1 + delay.getValue());\n     context.ticker().advance(expireKey2);\n     task.getValue().run();\n \n-    Duration maxExpirationPeriod = Duration.ofNanos(Pacer.TOLERANCE)\n-        .plusNanos(context.expiryTime().timeNanos());\n-    assertThat(actualExpirationPeriods.get(key1), lessThan(maxExpirationPeriod));\n-    assertThat(actualExpirationPeriods.get(key2), lessThan(maxExpirationPeriod));\n+    Duration maxExpirationPeriod = Duration.ofNanos(\n+        context.expiryTime().timeNanos() + Pacer.TOLERANCE);\n+    assertThat(actualExpirationPeriods, is(aMapWithSize(2)));\n+    assertThat(actualExpirationPeriods.get(key1), is(lessThanOrEqualTo(maxExpirationPeriod)));\n+    assertThat(actualExpirationPeriods.get(key2), is(lessThanOrEqualTo(maxExpirationPeriod)));\n   }\n \n   /* --------------- Cache --------------- */",
      "parent_sha": "29ec4a0bdace83103946fe6e626c1095c1558533"
    }
  },
  {
    "oid": "c510499bbd706585d2713eb9a30deaec9753408b",
    "message": "Add draining support for reference collection",
    "date": "2015-01-04T02:27:43Z",
    "url": "https://github.com/ben-manes/caffeine/commit/c510499bbd706585d2713eb9a30deaec9753408b",
    "details": {
      "sha": "294d5b3c3baffe7588987042eaf894ddc21f2e5e",
      "filename": "src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java",
      "status": "modified",
      "additions": 53,
      "deletions": 11,
      "changes": 64,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/c510499bbd706585d2713eb9a30deaec9753408b/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/c510499bbd706585d2713eb9a30deaec9753408b/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/src%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FBoundedLocalCache.java?ref=c510499bbd706585d2713eb9a30deaec9753408b",
      "patch": "@@ -416,6 +416,7 @@ void evict(Node<K, V> node, RemovalCause cause) {\n       notifyRemoval(node.key, node.getValue(), cause);\n     }\n \n+    accessOrderDeque.remove(node);\n     writeOrderDeque.remove(node);\n   }\n \n@@ -555,6 +556,30 @@ void drainBuffers() {\n     drainReadBuffers();\n     drainWriteBuffer();\n     expire();\n+\n+    drainKeyReferences();\n+  }\n+\n+  void drainKeyReferences() {\n+    Reference<? extends K> keyRef;\n+    while ((keyRef = keyReferenceQueue.poll()) != null) {\n+      Node<K, V> node = data.get(keyRef);\n+      if (node != null) {\n+        evict(node, RemovalCause.COLLECTED);\n+      }\n+    }\n+  }\n+\n+  void drainValueReferences() {\n+    Reference<? extends V> valueRef;\n+    while ((valueRef = valueReferenceQueue.poll()) != null) {\n+      @SuppressWarnings(\"unchecked\")\n+      InternalReference<V> ref = (InternalReference<V>) valueRef;\n+      Node<K, V> node = data.get(ref.getKeyReference());\n+      if (node != null) {\n+        evict(node, RemovalCause.COLLECTED);\n+      }\n+    }\n   }\n \n   /** Drains the read buffers, each up to an amortized threshold. */\n@@ -1967,7 +1992,7 @@ enum ReferenceStrategy {\n       @Override <K> Object referenceKey(K key, ReferenceQueue<K> queue) {\n         return key;\n       }\n-      @Override <V> Object referenceValue(V value, ReferenceQueue<V> queue) {\n+      @Override <V> Object referenceValue(Object keyReference, V value, ReferenceQueue<V> queue) {\n         return value;\n       }\n       @Override <K> Object dereferenceKey(Object referent) {\n@@ -1981,8 +2006,8 @@ enum ReferenceStrategy {\n       @Override <K> Object referenceKey(K key, ReferenceQueue<K> queue) {\n         return new WeakKeyReference<K>(key, queue);\n       }\n-      @Override <V> Object referenceValue(V value, ReferenceQueue<V> queue) {\n-        return new WeakValueReference<V>(value, queue);\n+      @Override <V> Object referenceValue(Object keyReference, V value, ReferenceQueue<V> queue) {\n+        return new WeakValueReference<V>(keyReference, value, queue);\n       }\n       @Override <K> Object dereferenceKey(Object referent) {\n         @SuppressWarnings(\"unchecked\")\n@@ -1999,8 +2024,8 @@ enum ReferenceStrategy {\n       @Override <K> Object referenceKey(K key, ReferenceQueue<K> queue) {\n         throw new UnsupportedOperationException();\n       }\n-      @Override <V> Object referenceValue(V value, ReferenceQueue<V> queue) {\n-        return new SoftValueReference<V>(value, queue);\n+      @Override <V> Object referenceValue(Object keyReference, V value, ReferenceQueue<V> queue) {\n+        return new SoftValueReference<V>(keyReference, value, queue);\n       }\n       @Override <K> Object dereferenceKey(Object referent) {\n         @SuppressWarnings(\"unchecked\")\n@@ -2016,7 +2041,7 @@ enum ReferenceStrategy {\n \n     abstract <K> Object referenceKey(K key, ReferenceQueue<K> queue);\n \n-    abstract <V> Object referenceValue(V value, ReferenceQueue<V> queue);\n+    abstract <V> Object referenceValue(Object keyReference, V value, ReferenceQueue<V> queue);\n \n     abstract <K> Object dereferenceKey(Object reference);\n \n@@ -2045,6 +2070,9 @@ static final class Ref<E> implements InternalReference<E> {\n     @Override public E get() {\n       return e;\n     }\n+    @Override public Object getKeyReference() {\n+      return this;\n+    }\n     @Override public int hashCode() {\n       return System.identityHashCode(e);\n     }\n@@ -2057,6 +2085,8 @@ interface InternalReference<E> {\n \n     E get();\n \n+    Object getKeyReference();\n+\n     default boolean referenceEquals(Reference<?> reference, Object object) {\n       if (object == reference) {\n         return true;\n@@ -2077,6 +2107,9 @@ public WeakKeyReference(K key, ReferenceQueue<K> queue) {\n       super(key, queue);\n       hashCode = System.identityHashCode(key);\n     }\n+    @Override public Object getKeyReference() {\n+      return this;\n+    }\n     @Override public int hashCode() {\n       return hashCode;\n     }\n@@ -2087,22 +2120,31 @@ public WeakKeyReference(K key, ReferenceQueue<K> queue) {\n \n   static final class WeakValueReference<V>\n       extends WeakReference<V> implements InternalReference<V> {\n-    public WeakValueReference(V value, ReferenceQueue<V> queue) {\n+    final Object keyReference;\n+\n+    public WeakValueReference(Object keyReference, V value, ReferenceQueue<V> queue) {\n       super(value, queue);\n+      this.keyReference = keyReference;\n     }\n-    @Override\n-    public boolean equals(Object object) {\n+    @Override public Object getKeyReference() {\n+      return keyReference;\n+    }\n+    @Override public boolean equals(Object object) {\n       return referenceEquals(this, object);\n     }\n   }\n \n   static final class SoftValueReference<V>\n       extends SoftReference<V> implements InternalReference<V> {\n+    final Object keyReference;\n \n-    public SoftValueReference(V value, ReferenceQueue<V> queue) {\n+    public SoftValueReference(Object keyReference, V value, ReferenceQueue<V> queue) {\n       super(value, queue);\n+      this.keyReference = keyReference;\n     }\n-    @Override public boolean equals(Object object) {\n+    @Override public Object getKeyReference() {\n+      return keyReference;\n+    } @Override public boolean equals(Object object) {\n       return referenceEquals(this, object);\n     }\n   }",
      "parent_sha": "3692075d1f0cf8692a1e302e8f0a10396ff8fbc5"
    }
  },
  {
    "oid": "2dc9fbea1fe6d8799db020102174786f7f891006",
    "message": "Fix charactor encoding problem on Windows",
    "date": "2015-09-29T18:59:23Z",
    "url": "https://github.com/ben-manes/caffeine/commit/2dc9fbea1fe6d8799db020102174786f7f891006",
    "details": {
      "sha": "e112e9d3a9e6b1bba07ee065826b02a0f23df96b",
      "filename": "caffeine/src/main/java/com/github/benmanes/caffeine/cache/FrequencySketch.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/2dc9fbea1fe6d8799db020102174786f7f891006/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/2dc9fbea1fe6d8799db020102174786f7f891006/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FFrequencySketch.java?ref=2dc9fbea1fe6d8799db020102174786f7f891006",
      "patch": "@@ -42,7 +42,8 @@ final class FrequencySketch<E> {\n    * fixed depth of four balances the accuracy and cost, resulting in a width of four times the\n    * length of the array. To retain an accurate estimation the array's length equals the maximum\n    * number of entries in the cache, increased to the closest power-of-two to exploit more efficient\n-   * bit masking. This configuration results in a confidence of 93.75% and error bound of \u2107 / width.\n+   * bit masking. This configuration results in a confidence of 93.75% and error bound of\n+   * epsilon / width.\n    *\n    * The frequency of all entries is aged periodically using a sampling window based on the maximum\n    * number of entries in the cache. This is referred to as the reset operation by TinyLfu and keeps",
      "parent_sha": "b863bb6680c93353500b8f36cd6a4a7ad5808f8c"
    }
  },
  {
    "oid": "557489fdc7bab544e6661b2cefb0313fd8ff4bee",
    "message": "Generate toString method",
    "date": "2015-01-26T05:09:04Z",
    "url": "https://github.com/ben-manes/caffeine/commit/557489fdc7bab544e6661b2cefb0313fd8ff4bee",
    "details": {
      "sha": "1a85428672cab3833e5abef6f793c666d1995617",
      "filename": "caffeine/src/javaPoet/java/com/github/benmanes/caffeine/cache/NodeGenerator.java",
      "status": "modified",
      "additions": 29,
      "deletions": 1,
      "changes": 30,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/557489fdc7bab544e6661b2cefb0313fd8ff4bee/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeGenerator.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/557489fdc7bab544e6661b2cefb0313fd8ff4bee/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeGenerator.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/caffeine%2Fsrc%2FjavaPoet%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2FNodeGenerator.java?ref=557489fdc7bab544e6661b2cefb0313fd8ff4bee",
      "patch": "@@ -93,7 +93,8 @@ public TypeSpec.Builder createNodeType() {\n \n     return nodeSubtype\n         .addMethod(constructorByKey.build())\n-        .addMethod(constructorByKeyRef.build());\n+        .addMethod(constructorByKeyRef.build())\n+        .addMethod(newToString());\n   }\n \n   private void makeNodeSubtype() {\n@@ -404,4 +405,31 @@ private MethodSpec newSetter(Type varType, String varName, Visibility visibility\n \n     return setter.build();\n   }\n+\n+  public MethodSpec newToString() {\n+    StringBuilder start = new StringBuilder();\n+    StringBuilder end = new StringBuilder();\n+    start.append(\"return String.format(\\\"%s=[key=%s, value=%s\");\n+    end.append(\"]\\\",\\ngetClass().getSimpleName(), getKey(), getValue()\");\n+    if (weighed) {\n+      start.append(\", weight=%d\");\n+      end.append(\", getWeight()\");\n+    }\n+    if (expireAfterAccess) {\n+      start.append(\", accessTimeNS=%,d\");\n+      end.append(\", getAccessTime()\");\n+    }\n+    if (expireAfterWrite) {\n+      start.append(\", writeTimeNS=%,d\");\n+      end.append(\", getWriteTime()\");\n+    }\n+    end.append(\")\");\n+\n+    return MethodSpec.methodBuilder(\"toString\")\n+        .addModifiers(Modifier.PUBLIC)\n+        .addAnnotation(Override.class)\n+        .returns(String.class)\n+        .addStatement(start.toString() + end.toString())\n+        .build();\n+  }\n }",
      "parent_sha": "7adc18d8f9cc2ba286f17b23fb5f6204fbcf5fee"
    }
  },
  {
    "oid": "fb4eae754570311d5bbecbd48682eafdc10f5c55",
    "message": "Weighted stats for UnboundedPolicy",
    "date": "2019-12-22T21:06:40Z",
    "url": "https://github.com/ben-manes/caffeine/commit/fb4eae754570311d5bbecbd48682eafdc10f5c55",
    "details": {
      "sha": "536fc5dd34a7febd5ae66a0291599ef177e9d67d",
      "filename": "simulator/src/main/java/com/github/benmanes/caffeine/cache/simulator/policy/opt/UnboundedPolicy.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/ben-manes/caffeine/blob/fb4eae754570311d5bbecbd48682eafdc10f5c55/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fopt%2FUnboundedPolicy.java",
      "raw_url": "https://github.com/ben-manes/caffeine/raw/fb4eae754570311d5bbecbd48682eafdc10f5c55/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fopt%2FUnboundedPolicy.java",
      "contents_url": "https://api.github.com/repos/ben-manes/caffeine/contents/simulator%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fbenmanes%2Fcaffeine%2Fcache%2Fsimulator%2Fpolicy%2Fopt%2FUnboundedPolicy.java?ref=fb4eae754570311d5bbecbd48682eafdc10f5c55",
      "patch": "@@ -63,9 +63,9 @@ public PolicyStats stats() {\n   public void record(AccessEvent event) {\n     policyStats.recordOperation();\n     if (data.add(event.key().longValue())) {\n-      policyStats.recordMiss();\n+      policyStats.recordWeightedMiss(event.weight());\n     } else {\n-      policyStats.recordHit();\n+      policyStats.recordWeightedHit(event.weight());\n     }\n   }\n }",
      "parent_sha": "af9523756e72422f2e25daec717deb96be0d407f"
    }
  }
]