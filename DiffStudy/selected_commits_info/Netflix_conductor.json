[
  {
    "oid": "8f27aa0088af36be15fbd0b4822a28ccf9fc12c8",
    "message": "during sub wf operations (restart, retry etc), the parent wf is pushed to the decider queue only if it's not present.",
    "date": "2022-02-01T20:24:12Z",
    "url": "https://github.com/Netflix/conductor/commit/8f27aa0088af36be15fbd0b4822a28ccf9fc12c8",
    "details": {
      "sha": "5166a67801cafc246158293f006f01164a932306",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 8,
      "deletions": 3,
      "changes": 11,
      "blob_url": "https://github.com/Netflix/conductor/blob/8f27aa0088af36be15fbd0b4822a28ccf9fc12c8/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/8f27aa0088af36be15fbd0b4822a28ccf9fc12c8/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=8f27aa0088af36be15fbd0b4822a28ccf9fc12c8",
      "patch": "@@ -702,13 +702,19 @@ private void retry(WorkflowModel workflow) {\n         // This should load Workflow from archive, if archived.\n         workflow.setStatus(WorkflowModel.Status.RUNNING);\n         workflow.setLastRetriedTime(System.currentTimeMillis());\n+        String lastReasonForIncompletion = workflow.getReasonForIncompletion();\n+        workflow.setReasonForIncompletion(null);\n         // Add to decider queue\n         queueDAO.push(\n                 Utils.DECIDER_QUEUE,\n                 workflow.getWorkflowId(),\n                 workflow.getPriority(),\n                 properties.getWorkflowOffsetTimeout().getSeconds());\n         executionDAOFacade.updateWorkflow(workflow);\n+        LOGGER.info(\n+                \"Workflow {} that failed due to '{}' was retried\",\n+                workflow.toShortString(),\n+                lastReasonForIncompletion);\n \n         // taskToBeRescheduled would set task `retried` to true, and hence it's important to\n         // updateTasks after obtaining task copy from taskToBeRescheduled.\n@@ -1980,10 +1986,9 @@ private void executeSubworkflowTaskAndSyncData(\n \n     /** Pushes parent workflow id into the decider queue with a priority. */\n     private void pushParentWorkflow(String parentWorkflowId) {\n-        if (queueDAO.containsMessage(Utils.DECIDER_QUEUE, parentWorkflowId)) {\n-            queueDAO.postpone(Utils.DECIDER_QUEUE, parentWorkflowId, PARENT_WF_PRIORITY, 0);\n-        } else {\n+        if (!queueDAO.containsMessage(Utils.DECIDER_QUEUE, parentWorkflowId)) {\n             queueDAO.push(Utils.DECIDER_QUEUE, parentWorkflowId, PARENT_WF_PRIORITY, 0);\n+            LOGGER.info(\"Pushed parent workflow {} to {}\", parentWorkflowId, Utils.DECIDER_QUEUE);\n         }\n     }\n }",
      "parent_sha": "cd528e126ed36abedf38ac0eab07e18e1d476dad"
    }
  },
  {
    "oid": "62638df1a9e99f4846e661ead47c88992ffce71e",
    "message": "Rename dao event request meter name to prevent duplicates",
    "date": "2021-07-28T08:04:01Z",
    "url": "https://github.com/Netflix/conductor/commit/62638df1a9e99f4846e661ead47c88992ffce71e",
    "details": {
      "sha": "c01e99f521755e355d7259147cb06471e2e54f78",
      "filename": "core/src/main/java/com/netflix/conductor/metrics/Monitors.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/62638df1a9e99f4846e661ead47c88992ffce71e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmetrics%2FMonitors.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/62638df1a9e99f4846e661ead47c88992ffce71e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmetrics%2FMonitors.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmetrics%2FMonitors.java?ref=62638df1a9e99f4846e661ead47c88992ffce71e",
      "patch": "@@ -295,7 +295,7 @@ public static void recordDaoRequests(String dao, String action, String taskType,\n     }\n \n     public static void recordDaoEventRequests(String dao, String action, String event) {\n-        counter(classQualifier, \"dao_requests\", \"dao\", dao, \"action\", action, \"event\", event);\n+        counter(classQualifier, \"dao_event_requests\", \"dao\", dao, \"action\", action, \"event\", event);\n     }\n \n     public static void recordDaoPayloadSize(String dao, String action, int size) {",
      "parent_sha": "5545e31843113c795dbe267765a6e9b9f4173a85"
    }
  },
  {
    "oid": "9b915e349e145bba6399793bd65447b53f92d869",
    "message": "Introduce properties that control event processing and event queues.",
    "date": "2020-12-17T17:56:06Z",
    "url": "https://github.com/Netflix/conductor/commit/9b915e349e145bba6399793bd65447b53f92d869",
    "details": {
      "sha": "ce3c31764ec6c9e832b74f27e2c07377593f36e1",
      "filename": "core/src/main/java/com/netflix/conductor/core/config/EventConfiguration.java",
      "status": "modified",
      "additions": 22,
      "deletions": 8,
      "changes": 30,
      "blob_url": "https://github.com/Netflix/conductor/blob/9b915e349e145bba6399793bd65447b53f92d869/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fconfig%2FEventConfiguration.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/9b915e349e145bba6399793bd65447b53f92d869/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fconfig%2FEventConfiguration.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fconfig%2FEventConfiguration.java?ref=9b915e349e145bba6399793bd65447b53f92d869",
      "patch": "@@ -27,6 +27,7 @@\n import com.netflix.conductor.dao.QueueDAO;\n import com.netflix.conductor.service.ExecutionService;\n import com.netflix.conductor.service.MetadataService;\n+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\n import org.springframework.context.annotation.Bean;\n import org.springframework.context.annotation.Configuration;\n import rx.Scheduler;\n@@ -36,37 +37,50 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.ThreadFactory;\n \n+/**\n+ * Default event processing configuration that is enabled by default.\n+ *\n+ * <p>Set <code>workflow.event.processing.enabled=false</code> to <i>disable</i> event processing.</p>\n+ */\n @Configuration(proxyBeanMethods = false)\n+@ConditionalOnProperty(prefix = \"workflow\", name = \"event.processing.enabled\", havingValue = \"true\", matchIfMissing = true)\n public class EventConfiguration {\n \n     @Bean\n     public ActionProcessor actionProcessor(WorkflowExecutor workflowExecutor, ParametersUtils parametersUtils,\n-        JsonUtils jsonUtils) {\n+                                           JsonUtils jsonUtils) {\n         return new SimpleActionProcessor(workflowExecutor, parametersUtils, jsonUtils);\n     }\n \n     @Bean\n     public EventProcessor eventProcessor(ExecutionService executionService, MetadataService metadataService,\n-        ActionProcessor actionProcessor, EventQueues eventQueues, JsonUtils jsonUtils, ConductorProperties properties,\n-        ObjectMapper objectMapper) {\n+                                         ActionProcessor actionProcessor, EventQueues eventQueues, JsonUtils jsonUtils, ConductorProperties properties,\n+                                         ObjectMapper objectMapper) {\n         return new SimpleEventProcessor(executionService, metadataService, actionProcessor, eventQueues, jsonUtils,\n-            properties, objectMapper);\n+                properties, objectMapper);\n     }\n \n     @Bean\n     public Scheduler scheduler(ConductorProperties properties) {\n         ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setNameFormat(\"event-queue-poll-scheduler-thread-%d\")\n-            .build();\n+                .setNameFormat(\"event-queue-poll-scheduler-thread-%d\")\n+                .build();\n         Executor executorService = Executors\n-            .newFixedThreadPool(properties.getEventSchedulerPollThreadCount(), threadFactory);\n+                .newFixedThreadPool(properties.getEventSchedulerPollThreadCount(), threadFactory);\n \n         return Schedulers.from(executorService);\n     }\n \n+    /**\n+     * Default provider for {@link com.netflix.conductor.core.events.queue.ObservableQueue}\n+     * that listens on the <i>conductor</i> queue prefix.\n+     *\n+     * <p><code>Set workflow.default.event.queue.enabled=false</code> to disable the default queue.</p>\n+     */\n     @Bean\n+    @ConditionalOnProperty(prefix = \"workflow\", name = \"default.event.queue.enabled\", havingValue = \"true\", matchIfMissing = true)\n     public EventQueueProvider conductorEventQueueProvider(QueueDAO queueDAO, ConductorProperties properties,\n-        Scheduler scheduler) {\n+                                                          Scheduler scheduler) {\n         return new ConductorEventQueueProvider(queueDAO, properties, scheduler);\n     }\n }",
      "parent_sha": "17754477138bbc750a8dd9bba838184106b81914"
    }
  },
  {
    "oid": "48e23efbf5f4e70d13eeabace832c272ee85b040",
    "message": "Lazy evaluate workflow only in case of task is successful.",
    "date": "2023-06-15T13:41:14Z",
    "url": "https://github.com/Netflix/conductor/commit/48e23efbf5f4e70d13eeabace832c272ee85b040",
    "details": {
      "sha": "9adf28a9a2a545282e6a73a915c3158c1aa7f58c",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/48e23efbf5f4e70d13eeabace832c272ee85b040/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/48e23efbf5f4e70d13eeabace832c272ee85b040/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=48e23efbf5f4e70d13eeabace832c272ee85b040",
      "patch": "@@ -925,10 +925,10 @@ boolean isLazyEvaluateWorkflow(WorkflowDef workflowDef, TaskModel task) {\n                         .collect(Collectors.toList());\n \n         if (forkTasks.stream().anyMatch(fork -> fork.has(taskRefName))) {\n-            return joinTasks.stream().anyMatch(join -> join.getJoinOn().contains(taskRefName));\n+            return joinTasks.stream().anyMatch(join -> join.getJoinOn().contains(taskRefName)) && task.getStatus().isSuccessful();\n         }\n \n-        return workflowTasks.stream().noneMatch(t -> t.getTaskReferenceName().equals(taskRefName));\n+        return workflowTasks.stream().noneMatch(t -> t.getTaskReferenceName().equals(taskRefName)) && task.getStatus().isSuccessful();\n     }\n \n     public TaskModel getTask(String taskId) {",
      "parent_sha": "878fcd933a7a9051eca770c22c9f71544ffe55da"
    }
  },
  {
    "oid": "64d98c07f89905b5b6571ad6f0dceafce4ca6d46",
    "message": "different logging for testing",
    "date": "2023-09-13T14:51:44Z",
    "url": "https://github.com/Netflix/conductor/commit/64d98c07f89905b5b6571ad6f0dceafce4ca6d46",
    "details": {
      "sha": "a485582f6ddf7636991445fff88543bffda2ba8e",
      "filename": "java-sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowCreationTests.java",
      "status": "modified",
      "additions": 6,
      "deletions": 3,
      "changes": 9,
      "blob_url": "https://github.com/Netflix/conductor/blob/64d98c07f89905b5b6571ad6f0dceafce4ca6d46/java-sdk%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fsdk%2Fworkflow%2Fdef%2FWorkflowCreationTests.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/64d98c07f89905b5b6571ad6f0dceafce4ca6d46/java-sdk%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fsdk%2Fworkflow%2Fdef%2FWorkflowCreationTests.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/java-sdk%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fsdk%2Fworkflow%2Fdef%2FWorkflowCreationTests.java?ref=64d98c07f89905b5b6571ad6f0dceafce4ca6d46",
      "patch": "@@ -27,6 +27,8 @@\n import org.junit.jupiter.api.AfterAll;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import com.netflix.conductor.common.metadata.tasks.TaskType;\n import com.netflix.conductor.common.metadata.workflow.WorkflowDef;\n@@ -43,6 +45,8 @@\n \n public class WorkflowCreationTests {\n \n+    private static final Logger LOGGER = LoggerFactory.getLogger(WorkflowCreationTests.class);\n+\n     private static WorkflowExecutor executor;\n \n     private static WorkflowTestRunner runner;\n@@ -157,16 +161,15 @@ public void verifyCreatedWorkflow() {\n     @Test\n     public void verifyInlineWorkflowExecution() throws ValidationError {\n         var test = new ScriptEngineManager().getEngineFactories();\n-        System.out.println(\"TESTING SCRIPT ENGINES: \");\n-        System.out.println(test);\n+        LOGGER.error(\"TESTING SCRIPT ENGINES: \");\n+        LOGGER.error(test.toString());\n         TestWorkflowInput workflowInput = new TestWorkflowInput(\"username\", \"10121\", \"US\");\n         try {\n             Workflow run = registerTestWorkflow().execute(workflowInput).get(10, TimeUnit.SECONDS);\n             assertEquals(\n                     Workflow.WorkflowStatus.COMPLETED,\n                     run.getStatus(),\n                     run.getReasonForIncompletion());\n-            System.out.println(\"TESTING\");\n         } catch (Exception e) {\n             e.printStackTrace();\n             fail(e.getMessage());",
      "parent_sha": "a723f1699723c00a5123938f33569887ade0a609"
    }
  },
  {
    "oid": "6a6b7eaf6a4a2212325b676c881387e8a1f74307",
    "message": "add an ability to specify caller app namd and username",
    "date": "2018-12-18T22:31:51Z",
    "url": "https://github.com/Netflix/conductor/commit/6a6b7eaf6a4a2212325b676c881387e8a1f74307",
    "details": {
      "sha": "c56c2e9bc947eafbcf05bd2dda36dc8af4b01856",
      "filename": "core/src/main/java/com/netflix/conductor/core/WorkflowContext.java",
      "status": "modified",
      "additions": 19,
      "deletions": 8,
      "changes": 27,
      "blob_url": "https://github.com/Netflix/conductor/blob/6a6b7eaf6a4a2212325b676c881387e8a1f74307/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2FWorkflowContext.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/6a6b7eaf6a4a2212325b676c881387e8a1f74307/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2FWorkflowContext.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2FWorkflowContext.java?ref=6a6b7eaf6a4a2212325b676c881387e8a1f74307",
      "patch": "@@ -1,5 +1,5 @@\n /**\n- * Copyright 2016 Netflix, Inc.\n+ * Copyright 2018 Netflix, Inc.\n  *\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\n  * you may not use this file except in compliance with the License.\n@@ -18,20 +18,25 @@\n  */\n package com.netflix.conductor.core;\n \n-\n /**\n- * @author Viren\n- *\n+ * Store the authentication context, app or user name or both\n  */\n public class WorkflowContext {\n \n-\tpublic static final ThreadLocal<WorkflowContext> threadLocal = InheritableThreadLocal.withInitial(() -> new WorkflowContext(\"\"));\n+\tpublic static final ThreadLocal<WorkflowContext> threadLocal = InheritableThreadLocal.withInitial(() -> new WorkflowContext(\"\", \"\"));\n \t\n \tprivate String clientApp;\n-    \n-\t\n+\n+\tprivate String userName;\n+\n \tpublic WorkflowContext(String clientApp){\n \t\tthis.clientApp = clientApp;\n+\t\tthis.userName = null;\n+\t}\n+\n+\tpublic WorkflowContext(String clientApp, String userName){\n+\t\tthis.clientApp = clientApp;\n+\t\tthis.userName = userName;\n \t}\n \t\n \tpublic static WorkflowContext get(){\n@@ -47,11 +52,17 @@ public static void unset(){\n \t}\n \n \t/**\n-\t * todo: rename to more generic callerName\n \t * @return the clientApp\n \t */\n \tpublic String getClientApp() {\n \t\treturn clientApp;\n \t}\n+\n+\t/**\n+\t * @return the username\n+\t */\n+\tpublic String getUserName() {\n+\t\treturn userName;\n+\t}\n \t\n }",
      "parent_sha": "b86280d5e72f7507b2a0a61c6b6dac613fac9395"
    }
  },
  {
    "oid": "1d3330fb1407a0fd2c920e33b2aebade9dba728b",
    "message": "handle null",
    "date": "2017-04-05T19:37:53Z",
    "url": "https://github.com/Netflix/conductor/commit/1d3330fb1407a0fd2c920e33b2aebade9dba728b",
    "details": {
      "sha": "4ecad00eb2d4ea1917b7b7528b473b41309c116b",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/1d3330fb1407a0fd2c920e33b2aebade9dba728b/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1d3330fb1407a0fd2c920e33b2aebade9dba728b/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java?ref=1d3330fb1407a0fd2c920e33b2aebade9dba728b",
      "patch": "@@ -81,7 +81,9 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo\n \t\t\ttaskIO.put(\"input\", task.getInputData());\n \t\t\ttaskIO.put(\"output\", task.getOutputData());\n \t\t\ttaskIO.put(\"taskType\", task.getTaskType());\n-\t\t\ttaskIO.put(\"status\", task.getStatus().toString());\t\t\t\n+\t\t\tif(task.getStatus() != null) {\n+\t\t\t\ttaskIO.put(\"status\", task.getStatus().toString());\n+\t\t\t}\n \t\t\ttaskIO.put(\"referenceTaskName\", task.getReferenceTaskName());\n \t\t\ttaskIO.put(\"retryCount\", task.getRetryCount());\n \t\t\ttaskIO.put(\"correlationId\", task.getCorrelationId());",
      "parent_sha": "dcbca3e38ea1e3598aa1bdb9d10a49a2a154dc8f"
    }
  },
  {
    "oid": "5ed49dfec320d3a3915bddf03d6037add5d8c91b",
    "message": "if asyncIndexing, only index tasks if workflow is in terminal state",
    "date": "2020-04-22T11:24:02Z",
    "url": "https://github.com/Netflix/conductor/commit/5ed49dfec320d3a3915bddf03d6037add5d8c91b",
    "details": {
      "sha": "782fa6d81ce1e6075ceae005f1a64050868894ad",
      "filename": "core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/5ed49dfec320d3a3915bddf03d6037add5d8c91b/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/5ed49dfec320d3a3915bddf03d6037add5d8c91b/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java?ref=5ed49dfec320d3a3915bddf03d6037add5d8c91b",
      "patch": "@@ -225,7 +225,9 @@ public String updateWorkflow(Workflow workflow) {\n             } else {\n                 indexDAO.asyncIndexWorkflow(workflow);\n             }\n-            workflow.getTasks().forEach(indexDAO::asyncIndexTask);\n+\t\t\tif (workflow.getStatus().isTerminal()) {\n+\t\t\t\tworkflow.getTasks().forEach(indexDAO::asyncIndexTask);\n+\t\t\t}\n         } else {\n             indexDAO.indexWorkflow(workflow);\n         }",
      "parent_sha": "81b9ee0f2046ae0695f0a68fbfbea9a2e517ac07"
    }
  },
  {
    "oid": "d4fabb4a183a1f820739f77324c28d501d5290a3",
    "message": "Incorporate review comment. Add a warn log statement when workflow is null and remove unnecessary check",
    "date": "2022-10-13T20:12:00Z",
    "url": "https://github.com/Netflix/conductor/commit/d4fabb4a183a1f820739f77324c28d501d5290a3",
    "details": {
      "sha": "335b8fbd79790232b0e93af4f14bfa6b8794219d",
      "filename": "core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java",
      "status": "modified",
      "additions": 3,
      "deletions": 10,
      "changes": 13,
      "blob_url": "https://github.com/Netflix/conductor/blob/d4fabb4a183a1f820739f77324c28d501d5290a3/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowSweeper.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/d4fabb4a183a1f820739f77324c28d501d5290a3/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowSweeper.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowSweeper.java?ref=d4fabb4a183a1f820739f77324c28d501d5290a3",
      "patch": "@@ -24,7 +24,6 @@\n import com.netflix.conductor.annotations.VisibleForTesting;\n import com.netflix.conductor.common.metadata.tasks.TaskDef;\n import com.netflix.conductor.common.metadata.tasks.TaskType;\n-import com.netflix.conductor.common.metadata.workflow.WorkflowTask;\n import com.netflix.conductor.core.WorkflowContext;\n import com.netflix.conductor.core.config.ConductorProperties;\n import com.netflix.conductor.core.exception.NotFoundException;\n@@ -99,6 +98,9 @@ public void sweep(String workflowId) {\n         if (workflow != null) {\n             unack(workflow);\n         } else {\n+            LOGGER.warn(\n+                    \"Workflow with {} id can not be found. Attempting to unack using the id\",\n+                    workflowId);\n             queueDAO.setUnackTimeout(\n                     DECIDER_QUEUE, workflowId, properties.getWorkflowOffsetTimeout().toMillis());\n         }\n@@ -125,15 +127,6 @@ void unack(WorkflowModel workflowModel) {\n             }\n             if (taskModel.getStatus() == Status.SCHEDULED) {\n                 Optional<TaskDef> taskDefinition = taskModel.getTaskDefinition();\n-                if (taskDefinition.isEmpty()) {\n-                    taskDefinition =\n-                            Optional.ofNullable(\n-                                            workflowModel\n-                                                    .getWorkflowDefinition()\n-                                                    .getTaskByRefName(\n-                                                            taskModel.getReferenceTaskName()))\n-                                    .map(WorkflowTask::getTaskDefinition);\n-                }\n                 if (taskDefinition.isPresent()) {\n                     TaskDef taskDef = taskDefinition.get();\n                     if (taskDef.getPollTimeoutSeconds() != null",
      "parent_sha": "7a328dd1ae56337c8379e1469b508a5ae180ecd9"
    }
  },
  {
    "oid": "8d5eee316e75fc5b1626aea9d2a6237020ab8e98",
    "message": "#2926 added a null check for TaskModel",
    "date": "2022-04-20T04:53:34Z",
    "url": "https://github.com/Netflix/conductor/commit/8d5eee316e75fc5b1626aea9d2a6237020ab8e98",
    "details": {
      "sha": "5b905a2853ce72efdb1d1515e82abd9c0d8e6688",
      "filename": "core/src/main/java/com/netflix/conductor/core/dal/ExecutionDAOFacade.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/8d5eee316e75fc5b1626aea9d2a6237020ab8e98/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fdal%2FExecutionDAOFacade.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/8d5eee316e75fc5b1626aea9d2a6237020ab8e98/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fdal%2FExecutionDAOFacade.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fdal%2FExecutionDAOFacade.java?ref=8d5eee316e75fc5b1626aea9d2a6237020ab8e98",
      "patch": "@@ -449,7 +449,9 @@ public List<Task> getTasksForWorkflow(String workflowId) {\n \n     public TaskModel getTaskModel(String taskId) {\n         TaskModel taskModel = getTaskFromDatastore(taskId);\n-        populateTaskData(taskModel);\n+        if (taskModel != null) {\n+            populateTaskData(taskModel);\n+        }\n         return taskModel;\n     }\n ",
      "parent_sha": "4ad982a281c9dc46b3aad317070ed3de9a327ce0"
    }
  },
  {
    "oid": "9b6cf324dcc945a2b7130891848d1a0b1cc5eea7",
    "message": "added SCHEDULED status for the backward compatibility.",
    "date": "2017-02-24T19:10:28Z",
    "url": "https://github.com/Netflix/conductor/commit/9b6cf324dcc945a2b7130891848d1a0b1cc5eea7",
    "details": {
      "sha": "f7c1ba308325b8aad8d2c5e690a406e60a632700",
      "filename": "common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/9b6cf324dcc945a2b7130891848d1a0b1cc5eea7/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskResult.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/9b6cf324dcc945a2b7130891848d1a0b1cc5eea7/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskResult.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskResult.java?ref=9b6cf324dcc945a2b7130891848d1a0b1cc5eea7",
      "patch": "@@ -30,7 +30,7 @@ public class TaskResult {\n \n \tpublic enum Status {\n \n-\t\tIN_PROGRESS, FAILED, COMPLETED;\n+\t\tIN_PROGRESS, FAILED, COMPLETED, SCHEDULED;\t\t//SCHEDULED is added for the backward compatibility and should NOT be used when updating the task result\n \t};\n \n \tprivate String workflowInstanceId;",
      "parent_sha": "c9aeffc470a7c973973e57af73b6149aac6015ff"
    }
  },
  {
    "oid": "8d24ce520124d63c7e40f6dbea3da93073cb5ec5",
    "message": "DO_WHILE improvement - Check only for current iteration task to get completed. (#2804)\n\n* Wait and check only for current iteration task to get completed.\r\n\r\nWait and check only for current iteration task to get completed.\r\n\r\n* format plugin",
    "date": "2022-03-14T22:17:41Z",
    "url": "https://github.com/Netflix/conductor/commit/8d24ce520124d63c7e40f6dbea3da93073cb5ec5",
    "details": {
      "sha": "58366fdcf737b5895059cbb9f9fede4dfd4aeba0",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java",
      "status": "modified",
      "additions": 7,
      "deletions": 2,
      "changes": 9,
      "blob_url": "https://github.com/Netflix/conductor/blob/8d24ce520124d63c7e40f6dbea3da93073cb5ec5/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/8d24ce520124d63c7e40f6dbea3da93073cb5ec5/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java?ref=8d24ce520124d63c7e40f6dbea3da93073cb5ec5",
      "patch": "@@ -70,15 +70,20 @@ public boolean execute(\n         for (TaskModel t : workflow.getTasks()) {\n             if (task.getWorkflowTask()\n                             .has(TaskUtils.removeIterationFromTaskRefName(t.getReferenceTaskName()))\n-                    && !task.getReferenceTaskName().equals(t.getReferenceTaskName())) {\n+                    && !task.getReferenceTaskName().equals(t.getReferenceTaskName())\n+                    && task.getIteration() == t.getIteration()) {\n                 relevantTask = relevantTasks.get(t.getReferenceTaskName());\n                 if (relevantTask == null || t.getRetryCount() > relevantTask.getRetryCount()) {\n                     relevantTasks.put(t.getReferenceTaskName(), t);\n                 }\n             }\n         }\n         Collection<TaskModel> loopOver = relevantTasks.values();\n-\n+        LOGGER.debug(\n+                \"Workflow {} waiting for tasks {} to complete iteration {}\",\n+                workflow.getWorkflowId(),\n+                loopOver.stream().map(TaskModel::getReferenceTaskName).collect(Collectors.toList()),\n+                task.getIteration());\n         for (TaskModel loopOverTask : loopOver) {\n             TaskModel.Status taskStatus = loopOverTask.getStatus();\n             hasFailures = !taskStatus.isSuccessful();",
      "parent_sha": "8d42cc3eaf205f4865f0c702491455044b68ef59"
    }
  },
  {
    "oid": "2b03f8c2606e4807af8b0a8d8f31fdf667ad405e",
    "message": "unit test fix.",
    "date": "2019-06-03T06:09:08Z",
    "url": "https://github.com/Netflix/conductor/commit/2b03f8c2606e4807af8b0a8d8f31fdf667ad405e",
    "details": {
      "sha": "f3b80c85a8ab79b65732a1b311a867b15be23af4",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/2b03f8c2606e4807af8b0a8d8f31fdf667ad405e/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/2b03f8c2606e4807af8b0a8d8f31fdf667ad405e/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java?ref=2b03f8c2606e4807af8b0a8d8f31fdf667ad405e",
      "patch": "@@ -81,7 +81,7 @@ public void setup() {\n         loopTask.setTaskType(TaskType.DO_WHILE.name());\n         loopWorkflowTask = new WorkflowTask();\n         loopWorkflowTask.setTaskReferenceName(\"loopWorkflowTask\");\n-        loopWorkflowTask.setLoopCondition(\"if ($.task1 + $.task2 > 10) { false; } else { true; }\");\n+        loopWorkflowTask.setLoopCondition(\"if ($.task1['task1'] + $.task2['task2'] > 10) { false; } else { true; }\");\n         loopWorkflowTask.setLoopOver(Arrays.asList(task1.getWorkflowTask(), task2.getWorkflowTask()));\n         loopTask.setWorkflowTask(loopWorkflowTask);\n         doWhile = new DoWhile();",
      "parent_sha": "b1d01f0774aaaf0c39489f5dd5f1fd67469939e9"
    }
  },
  {
    "oid": "7910eee4872b64876652511afe9bd3cedc6d1287",
    "message": "removed unnecessary syncronization in shutdown()",
    "date": "2018-07-13T22:08:09Z",
    "url": "https://github.com/Netflix/conductor/commit/7910eee4872b64876652511afe9bd3cedc6d1287",
    "details": {
      "sha": "fe0b97c0125ad8401f31f4bdc460ba1f0ae70498",
      "filename": "client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/7910eee4872b64876652511afe9bd3cedc6d1287/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/7910eee4872b64876652511afe9bd3cedc6d1287/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java?ref=7910eee4872b64876652511afe9bd3cedc6d1287",
      "patch": "@@ -273,7 +273,7 @@ public synchronized void init() {\n \t\t});\n \t}\n \n-    public synchronized void shutdown() throws InterruptedException {\n+    public void shutdown() throws InterruptedException {\n         this.scheduledExecutorService.shutdown();\n         this.executorService.shutdown();\n ",
      "parent_sha": "dae5417b8b3f41c8f787639bae0340b7725e0cb0"
    }
  },
  {
    "oid": "6845a77fbca74c686442e28f83735988d2006af4",
    "message": "javadoc fixes",
    "date": "2016-12-09T02:09:50Z",
    "url": "https://github.com/Netflix/conductor/commit/6845a77fbca74c686442e28f83735988d2006af4",
    "details": {
      "sha": "56a9703e5dddf8b6d3f9ae68c8a7e477ad982550",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoJedisClient.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/6845a77fbca74c686442e28f83735988d2006af4/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2Fqueue%2FDynoJedisClient.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/6845a77fbca74c686442e28f83735988d2006af4/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2Fqueue%2FDynoJedisClient.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2Fqueue%2FDynoJedisClient.java?ref=6845a77fbca74c686442e28f83735988d2006af4",
      "patch": "@@ -3176,7 +3176,7 @@ public long pfcount(final byte[] key)  {\n      * NOT SUPPORTED ! Use {@link #dyno_scan(CursorBasedResult, String...)}\n      * instead.\n      *\n-     * @param cursor\n+     * @param cursor cursor\n      * @return nothing -- throws UnsupportedOperationException when invoked\n      * @see #dyno_scan(CursorBasedResult, String...)\n      */\n@@ -3189,7 +3189,7 @@ public ScanResult<String> scan(int cursor) {\n      * NOT SUPPORTED ! Use {@link #dyno_scan(CursorBasedResult, String...)}\n      * instead.\n      *\n-     * @param cursor\n+     * @param cursor cursor\n      * @return nothing -- throws UnsupportedOperationException when invoked\n      * @see #dyno_scan(CursorBasedResult, String...)\n      */",
      "parent_sha": "57ef358fc2d83a944a054ce6ec1e4a7090ba303d"
    }
  },
  {
    "oid": "04268d61b191cd845ead16f5e2841e1cda5bd925",
    "message": "always return 0 for the responsetimeout.  This property has been deprecated and using it is known to cause issues with long running tasks.",
    "date": "2017-09-22T14:54:02Z",
    "url": "https://github.com/Netflix/conductor/commit/04268d61b191cd845ead16f5e2841e1cda5bd925",
    "details": {
      "sha": "3fb984379f3516595b93e9fa3d9f230c64d5059a",
      "filename": "common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/04268d61b191cd845ead16f5e2841e1cda5bd925/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/04268d61b191cd845ead16f5e2841e1cda5bd925/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTask.java?ref=04268d61b191cd845ead16f5e2841e1cda5bd925",
      "patch": "@@ -393,8 +393,9 @@ public void setTaskDefName(String taskDefName) {\n \t * \n \t * @return the timeout for task to send response.  After this timeout, the task will be re-queued\n \t */\n+\t@Deprecated\n \tpublic int getResponseTimeoutSeconds() {\n-\t\treturn responseTimeoutSeconds;\n+\t\treturn 0;\n \t}\n \t\n \t/**",
      "parent_sha": "77c5d9b817b12dcb00fb7c0c14f5927e1d536dad"
    }
  },
  {
    "oid": "c538151efae82939ff06a5a0f06c18c1001a519e",
    "message": "change nonterminal task statuses to SKIPPED when a TERMINATE task executes (#1608)\n\n* change non-terminal task statuses to SKIPPED when a TERMINATE task executes\r\n\r\n* handle subworkflows that are still running when TERMINATE task executes in parent workflow\r\n\r\n* added subworkflow testing to the terminate task testcase\r\n\r\n* added testing that the subworkflow has a valid status and its task also has a valid statusin the terminate task testcase\r\n\r\n* for terminate task testing, add simple task to subworkflow and make the join task wait on the terminate task\r\n\r\n* complete/fail workflow quicker (bypass decider) on a TERMINATE task\r\n\r\n* complete/fail workflow quicker (bypass decider) on a TERMINATE task\r\n\r\n* complete/fail workflow quicker (bypass decider) on a TERMINATE task\r\n\r\n* complete/fail workflow quicker (bypass decider) on a TERMINATE task\r\n\r\n* add workflow defs\r\n\r\n* deleted sample json files\r\n\r\n* prepare for merge of current dev\r\n\r\n* fix subworkflows when TERMINATE task is executed and there is a nonterminal subworkflow\r\n\r\n* Added back ending curly brace - not sure how it got deleted\r\n\r\n* add logging to see what test failed\r\n\r\n* remove logging to see what test failed\r\n\r\n* alter the test for a failure workflow where the workflow was terminated with a TERMINATE task\r\n\r\n* changed the way to terminate the parent workflow and added back the failureWorkflow tests\r\n\r\n* prepare for merge\r\n\r\nCo-authored-by: u447 <rick.fishman@bcbsfl.com>",
    "date": "2020-07-09T17:26:00Z",
    "url": "https://github.com/Netflix/conductor/commit/c538151efae82939ff06a5a0f06c18c1001a519e",
    "details": {
      "sha": "762ca72e160e29ffe3904aa2cbfd87c7b5f23c93",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/c538151efae82939ff06a5a0f06c18c1001a519e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/c538151efae82939ff06a5a0f06c18c1001a519e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=c538151efae82939ff06a5a0f06c18c1001a519e",
      "patch": "@@ -1642,4 +1642,4 @@ protected boolean updateParentWorkflow(Task subWorkflowTask, Workflow subWorkflo\n         }\n         return false;\n     }\n-}\n+}\n\\ No newline at end of file",
      "parent_sha": "7f48d5390a9c584375c8405a89fd7a6b56f78729"
    }
  },
  {
    "oid": "57b5d8f8ac0feccffa43e8e13ac13b27d1853c89",
    "message": "fix the issue with workflow getting marked as completed when the last task fails which is part of a decision task and the failed task has retries set.",
    "date": "2017-05-06T00:59:40Z",
    "url": "https://github.com/Netflix/conductor/commit/57b5d8f8ac0feccffa43e8e13ac13b27d1853c89",
    "details": {
      "sha": "f062006e96c11f2b186f2ee9e97fc52072dc8e6a",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java",
      "status": "modified",
      "additions": 13,
      "deletions": 5,
      "changes": 18,
      "blob_url": "https://github.com/Netflix/conductor/blob/57b5d8f8ac0feccffa43e8e13ac13b27d1853c89/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FDeciderService.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/57b5d8f8ac0feccffa43e8e13ac13b27d1853c89/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FDeciderService.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FDeciderService.java?ref=57b5d8f8ac0feccffa43e8e13ac13b27d1853c89",
      "patch": "@@ -160,8 +160,8 @@ private DeciderOutcome decide(final WorkflowDef def, final Workflow workflow, Li\n \t\t\tlogger.debug(\"Scheduling Tasks \" + unScheduledTasks.stream().map(t -> t.getTaskDefName()).collect(Collectors.toList()));\n \t\t\toutcome.tasksToBeScheduled.addAll(unScheduledTasks);\n \t\t}\n-\n-\t\tif (checkForWorkflowCompletion(def, workflow)) {\n+\t\tupdateOutput(def, workflow);\n+\t\tif (outcome.tasksToBeScheduled.isEmpty() && checkForWorkflowCompletion(def, workflow)) {\n \t\t\tlogger.debug(\"Marking workflow as complete.  workflow=\" + workflow.getWorkflowId() + \", tasks=\" + workflow.getTasks());\n \t\t\toutcome.isComplete = true;\n \t\t}\n@@ -207,11 +207,11 @@ private List<Task> startWorkflow(Workflow workflow, WorkflowDef def) throws Term\n \t\n \t}\n \n-\tprivate boolean checkForWorkflowCompletion(final WorkflowDef def, final Workflow workflow) throws TerminateWorkflow {\n+\tprivate void updateOutput(final WorkflowDef def, final Workflow workflow) {\n \n \t\tList<Task> allTasks = workflow.getTasks();\n \t\tif (allTasks.isEmpty()) {\n-\t\t\treturn false;\n+\t\t\treturn;\n \t\t}\n \n \t\tTask last = null;\n@@ -224,7 +224,15 @@ private boolean checkForWorkflowCompletion(final WorkflowDef def, final Workflow\n \t\t\toutput = getTaskInput(def.getOutputParameters(), workflow, null, null);\n \t\t}\n \t\tworkflow.setOutput(output);\n+\t}\n+\t\n+\tprivate boolean checkForWorkflowCompletion(final WorkflowDef def, final Workflow workflow) throws TerminateWorkflow {\n \n+\t\tList<Task> allTasks = workflow.getTasks();\n+\t\tif (allTasks.isEmpty()) {\n+\t\t\treturn false;\n+\t\t}\n+\t\t\n \t\tMap<String, Status> taskStatusMap = new HashMap<>();\n \t\tworkflow.getTasks().forEach(task -> taskStatusMap.put(task.getReferenceTaskName(), task.getStatus()));\n \n@@ -314,7 +322,7 @@ private Task retry(TaskDef taskDef, WorkflowTask workflowTask, Task task, Workfl\n \t\trescheduled.setStatus(Status.SCHEDULED);\n \t\trescheduled.setPollCount(0);\n \t\t\n-\t\tif(workflowTask != null && workflow.getSchemaVersion() > 1) {\t\t//This is a valid case, for the dynamic fork/join\n+\t\tif(workflowTask != null && workflow.getSchemaVersion() > 1) {\n \t\t\tMap<String, Object> taskInput = pu.getTaskInputV2(workflowTask.getInputParameters(), workflow, rescheduled.getTaskId(), taskDef);\n \t\t\trescheduled.setInputData(taskInput);\n \t\t}\t",
      "parent_sha": "6161a51f646cb5bbd3490aeae314bfd9f0dc921d"
    }
  },
  {
    "oid": "31f9a7e1675f78b9533aa2c6ba7fc40b40793231",
    "message": "allow terminated as a valid status",
    "date": "2023-04-23T19:34:00Z",
    "url": "https://github.com/Netflix/conductor/commit/31f9a7e1675f78b9533aa2c6ba7fc40b40793231",
    "details": {
      "sha": "230ab82c21361d0983ca06ebecea866117444b3a",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/Terminate.java",
      "status": "modified",
      "additions": 4,
      "deletions": 3,
      "changes": 7,
      "blob_url": "https://github.com/Netflix/conductor/blob/31f9a7e1675f78b9533aa2c6ba7fc40b40793231/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FTerminate.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/31f9a7e1675f78b9533aa2c6ba7fc40b40793231/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FTerminate.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FTerminate.java?ref=31f9a7e1675f78b9533aa2c6ba7fc40b40793231",
      "patch": "@@ -22,8 +22,7 @@\n import com.netflix.conductor.model.WorkflowModel;\n \n import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_TERMINATE;\n-import static com.netflix.conductor.common.run.Workflow.WorkflowStatus.COMPLETED;\n-import static com.netflix.conductor.common.run.Workflow.WorkflowStatus.FAILED;\n+import static com.netflix.conductor.common.run.Workflow.WorkflowStatus.*;\n \n /**\n  * Task that can terminate a workflow with a given status and modify the workflow's output with a\n@@ -94,7 +93,9 @@ public static String getTerminationWorkflowOutputParameter() {\n     }\n \n     public static Boolean validateInputStatus(String status) {\n-        return COMPLETED.name().equals(status) || FAILED.name().equals(status);\n+        return COMPLETED.name().equals(status)\n+                || FAILED.name().equals(status)\n+                || TERMINATED.name().equals(status);\n     }\n \n     @SuppressWarnings(\"unchecked\")",
      "parent_sha": "368e6dbe674f28f0e97ee5336094c29f2a09c793"
    }
  },
  {
    "oid": "907de072a7de3c6144adadee1694d175eb68add3",
    "message": "fix(api): change the return to APPLICATION_JSON for /workflow/{name}/correlated resource",
    "date": "2018-08-21T01:44:50Z",
    "url": "https://github.com/Netflix/conductor/commit/907de072a7de3c6144adadee1694d175eb68add3",
    "details": {
      "sha": "31dfd92b12111d9aa6a3f36818b6ca3bc86b7ad9",
      "filename": "jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/907de072a7de3c6144adadee1694d175eb68add3/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FWorkflowResource.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/907de072a7de3c6144adadee1694d175eb68add3/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FWorkflowResource.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FWorkflowResource.java?ref=907de072a7de3c6144adadee1694d175eb68add3",
      "patch": "@@ -97,7 +97,7 @@ public List<Workflow> getWorkflows(@PathParam(\"name\") String name,\n     @POST\n     @Path(\"/{name}/correlated\")\n     @ApiOperation(\"Lists workflows for the given correlation id list\")\n-    @Consumes(MediaType.WILDCARD)\n+    @Consumes(MediaType.APPLICATION_JSON)\n     public Map<String, List<Workflow>> getWorkflows(@PathParam(\"name\") String name,\n                                                     @QueryParam(\"includeClosed\") @DefaultValue(\"false\") boolean includeClosed,\n                                                     @QueryParam(\"includeTasks\") @DefaultValue(\"false\") boolean includeTasks,",
      "parent_sha": "477e45f224ab4a2d4d3b82feda867be9b95af731"
    }
  },
  {
    "oid": "fca70482e0c062474f1c92e8d87fd1db07d03a92",
    "message": "es: Do not close a null ElasticSearch instance",
    "date": "2018-07-10T14:03:42Z",
    "url": "https://github.com/Netflix/conductor/commit/fca70482e0c062474f1c92e8d87fd1db07d03a92",
    "details": {
      "sha": "9fec326b1272d66964a36df719c2fac989d9881e",
      "filename": "es5-persistence/src/main/java/com/netflix/conductor/elasticsearch/es5/EmbeddedElasticSearchV5.java",
      "status": "modified",
      "additions": 6,
      "deletions": 7,
      "changes": 13,
      "blob_url": "https://github.com/Netflix/conductor/blob/fca70482e0c062474f1c92e8d87fd1db07d03a92/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Felasticsearch%2Fes5%2FEmbeddedElasticSearchV5.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/fca70482e0c062474f1c92e8d87fd1db07d03a92/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Felasticsearch%2Fes5%2FEmbeddedElasticSearchV5.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Felasticsearch%2Fes5%2FEmbeddedElasticSearchV5.java?ref=fca70482e0c062474f1c92e8d87fd1db07d03a92",
      "patch": "@@ -77,16 +77,15 @@ public synchronized void start(String clusterName, String host, int port) throws\n         logger.info(\"Starting ElasticSearch for cluster {} \", settings.get(\"cluster.name\"));\n         instance = new PluginConfigurableNode(settings, singletonList(Netty4Plugin.class));\n         instance.start();\n-        Runtime.getRuntime().addShutdownHook(new Thread() {\n-            @Override\n-            public void run() {\n-                try {\n+        Runtime.getRuntime().addShutdownHook(new Thread(() -> {\n+            try {\n+                if (instance != null) {\n                     instance.close();\n-                } catch (IOException e) {\n-                    logger.error(\"Error closing ElasticSearch\");\n                 }\n+            } catch (IOException e) {\n+                logger.error(\"Error closing ElasticSearch\");\n             }\n-        });\n+        }));\n         logger.info(\"ElasticSearch cluster {} started in local mode on port {}\", instance.settings().get(\"cluster.name\"), getPort());\n     }\n ",
      "parent_sha": "b0a0747cb326e792adc5ebe6e50ff349555c8233"
    }
  },
  {
    "oid": "74727d3ee48581a52e5ac547f77f3f544ff92aa4",
    "message": "better error logging",
    "date": "2018-03-15T05:11:28Z",
    "url": "https://github.com/Netflix/conductor/commit/74727d3ee48581a52e5ac547f77f3f544ff92aa4",
    "details": {
      "sha": "1383eb816f12dc76c06f32c273213b903c5332bb",
      "filename": "contribs/src/main/java/com/netflix/conductor/contribs/http/HttpTask.java",
      "status": "modified",
      "additions": 4,
      "deletions": 8,
      "changes": 12,
      "blob_url": "https://github.com/Netflix/conductor/blob/74727d3ee48581a52e5ac547f77f3f544ff92aa4/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FHttpTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/74727d3ee48581a52e5ac547f77f3f544ff92aa4/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FHttpTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FHttpTask.java?ref=74727d3ee48581a52e5ac547f77f3f544ff92aa4",
      "patch": "@@ -136,11 +136,10 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) throw\n \t\t\t}\n \t\t\t\n \t\t}catch(Exception e) {\n-\t\t\t\n-\t\t\tlogger.error(e.getMessage(), e);\n+\t\t\tlogger.error(String.format(\"Failed to invoke http task - uri: %s, vipAddress: %s\", input.getUri(), input.getVipAddress()), e);\n \t\t\ttask.setStatus(Status.FAILED);\n-\t\t\ttask.setReasonForIncompletion(e.getMessage());\n-\t\t\ttask.getOutputData().put(\"response\", e.getMessage());\n+\t\t\ttask.setReasonForIncompletion(\"Failed to invoke http task due to: \" + e.toString());\n+\t\t\ttask.getOutputData().put(\"response\", e.toString());\n \t\t}\n \t}\n \n@@ -182,19 +181,16 @@ protected HttpResponse httpCall(Input input) throws Exception {\n \t\t\treturn response;\n \n \t\t} catch(UniformInterfaceException ex) {\n-\t\t\tlogger.error(ex.getMessage(), ex);\n \t\t\tClientResponse cr = ex.getResponse();\n-\t\t\tlogger.error(\"Status Code: {}\", cr.getStatus());\n+\t\t\tlogger.error(String.format(\"Got unexpected http response - uri: %s, vipAddress: %s, status code: %s\", input.getUri(), input.getVipAddress(), cr.getStatus()), ex);\n \t\t\tif(cr.getStatus() > 199 && cr.getStatus() < 300) {\n-\t\t\t\t\n \t\t\t\tif(cr.getStatus() != 204 && cr.hasEntity()) {\n \t\t\t\t\tresponse.body = extractBody(cr);\n \t\t\t\t}\n \t\t\t\tresponse.headers = cr.getHeaders();\n \t\t\t\tresponse.statusCode = cr.getStatus();\n \t\t\t\tresponse.reasonPhrase = cr.getStatusInfo().getReasonPhrase();\n \t\t\t\treturn response;\n-\t\t\t\t\n \t\t\t}else {\n \t\t\t\tString reason = cr.getEntity(String.class);\n \t\t\t\tlogger.error(reason, ex);",
      "parent_sha": "0dd471f8786c934c7727c4ada7474f9e1b825711"
    }
  },
  {
    "oid": "934a35dd559e8236f7997c5a07f59056f6648a2e",
    "message": "removed redundant fields and validation annotations",
    "date": "2021-02-04T20:11:27Z",
    "url": "https://github.com/Netflix/conductor/commit/934a35dd559e8236f7997c5a07f59056f6648a2e",
    "details": {
      "sha": "b1cc135aa09cced78549964adf90e4abfe0d7f4b",
      "filename": "core/src/main/java/com/netflix/conductor/service/AdminServiceImpl.java",
      "status": "modified",
      "additions": 2,
      "deletions": 27,
      "changes": 29,
      "blob_url": "https://github.com/Netflix/conductor/blob/934a35dd559e8236f7997c5a07f59056f6648a2e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fservice%2FAdminServiceImpl.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/934a35dd559e8236f7997c5a07f59056f6648a2e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fservice%2FAdminServiceImpl.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fservice%2FAdminServiceImpl.java?ref=934a35dd559e8236f7997c5a07f59056f6648a2e",
      "patch": "@@ -21,10 +21,8 @@\n import com.netflix.conductor.dao.QueueDAO;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import org.springframework.beans.factory.annotation.Autowired;\n import org.springframework.stereotype.Service;\n \n-import javax.validation.constraints.NotEmpty;\n import java.util.List;\n import java.util.Map;\n \n@@ -41,31 +39,12 @@ public class AdminServiceImpl implements AdminService {\n     private final QueueDAO queueDAO;\n     private final WorkflowRepairService workflowRepairService;\n \n-    private String version;\n-    private String buildDate;\n-\n-    @Autowired\n     public AdminServiceImpl(ConductorProperties properties, ExecutionService executionService, QueueDAO queueDAO,\n         WorkflowRepairService workflowRepairService) {\n         this.properties = properties;\n         this.executionService = executionService;\n         this.queueDAO = queueDAO;\n         this.workflowRepairService = workflowRepairService;\n-        this.version = \"UNKNOWN\";\n-        this.buildDate = \"UNKNOWN\";\n-\n-        // SBMTODO: remove\n-//        try (\n-//            InputStream propertiesIs = this.getClass().getClassLoader()\n-//                .getResourceAsStream(\"META-INF/conductor-core.properties\")\n-//        ) {\n-//            Properties prop = new Properties();\n-//            prop.load(propertiesIs);\n-//            this.version = prop.getProperty(\"Implementation-Version\");\n-//            this.buildDate = prop.getProperty(\"Build-Date\");\n-//        } catch (Exception e) {\n-//            LOGGER.error(\"Error loading properties\", e);\n-//        }\n     }\n \n     /**\n@@ -74,10 +53,7 @@ public AdminServiceImpl(ConductorProperties properties, ExecutionService executi\n      * @return all the configuration parameters.\n      */\n     public Map<String, Object> getAllConfig() {\n-        Map<String, Object> map = properties.getAll();\n-        map.put(\"version\", version);\n-        map.put(\"buildDate\", buildDate);\n-        return map;\n+        return properties.getAll();\n     }\n \n     /**\n@@ -99,8 +75,7 @@ public List<Task> getListOfPendingTask(String taskType, Integer start, Integer c\n     }\n \n     @Override\n-    public boolean verifyAndRepairWorkflowConsistency(\n-        @NotEmpty(message = \"WorkflowId cannot be null or empty.\") String workflowId) {\n+    public boolean verifyAndRepairWorkflowConsistency(String workflowId) {\n         return workflowRepairService.verifyAndRepairWorkflow(workflowId, true);\n     }\n ",
      "parent_sha": "5805e935e6da0a57d4249e78a6f9a846f8bb7572"
    }
  },
  {
    "oid": "c07b79fbfb505d566730231192a7e06926dbe63e",
    "message": "Improve message for payload size threshold (#3075)\n\nCo-authored-by: Fl\u00e1vio Schuindt <flavio.schuindt@ge.com>",
    "date": "2022-06-30T23:28:38Z",
    "url": "https://github.com/Netflix/conductor/commit/c07b79fbfb505d566730231192a7e06926dbe63e",
    "details": {
      "sha": "53a2246e26c1481ecb7c2d63f710bc6c23d89a25",
      "filename": "core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java",
      "status": "modified",
      "additions": 5,
      "deletions": 4,
      "changes": 9,
      "blob_url": "https://github.com/Netflix/conductor/blob/c07b79fbfb505d566730231192a7e06926dbe63e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Futils%2FExternalPayloadStorageUtils.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/c07b79fbfb505d566730231192a7e06926dbe63e/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Futils%2FExternalPayloadStorageUtils.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Futils%2FExternalPayloadStorageUtils.java?ref=c07b79fbfb505d566730231192a7e06926dbe63e",
      "patch": "@@ -122,23 +122,24 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {\n             byte[] payloadBytes = byteArrayOutputStream.toByteArray();\n             long payloadSize = payloadBytes.length;\n \n-            if (payloadSize > maxThreshold * 1024) {\n+            final long maxThresholdInBytes = maxThreshold * 1024;\n+            if (payloadSize > maxThresholdInBytes) {\n                 if (entity instanceof TaskModel) {\n                     String errorMsg =\n                             String.format(\n                                     \"The payload size: %d of task: %s in workflow: %s  is greater than the permissible limit: %d bytes\",\n                                     payloadSize,\n                                     ((TaskModel) entity).getTaskId(),\n                                     ((TaskModel) entity).getWorkflowInstanceId(),\n-                                    maxThreshold);\n+                                    maxThresholdInBytes);\n                     failTask(((TaskModel) entity), payloadType, errorMsg);\n                 } else {\n                     String errorMsg =\n                             String.format(\n-                                    \"The output payload size: %dB of workflow: %s is greater than the permissible limit: %d bytes\",\n+                                    \"The payload size: %d of workflow: %s is greater than the permissible limit: %d bytes\",\n                                     payloadSize,\n                                     ((WorkflowModel) entity).getWorkflowId(),\n-                                    maxThreshold);\n+                                    maxThresholdInBytes);\n                     failWorkflow(((WorkflowModel) entity), payloadType, errorMsg);\n                 }\n             } else if (payloadSize > threshold * 1024) {",
      "parent_sha": "f97b0cba833ddbe592cfb4c8f2f0c60975784eb7"
    }
  },
  {
    "oid": "fc5326b8f250d6b116e59e55b59cfd8ef5488079",
    "message": "1.7.0 (#129)\n\ndb=redis should use same configuration as dynomite for connection pooling.",
    "date": "2017-03-20T23:46:40Z",
    "url": "https://github.com/Netflix/conductor/commit/fc5326b8f250d6b116e59e55b59cfd8ef5488079",
    "details": {
      "sha": "d922c58fd7599299179c5cf7f7c4739767ac5f47",
      "filename": "server/src/main/java/com/netflix/conductor/server/ConductorServer.java",
      "status": "modified",
      "additions": 1,
      "deletions": 10,
      "changes": 11,
      "blob_url": "https://github.com/Netflix/conductor/blob/fc5326b8f250d6b116e59e55b59cfd8ef5488079/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorServer.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/fc5326b8f250d6b116e59e55b59cfd8ef5488079/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorServer.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorServer.java?ref=fc5326b8f250d6b116e59e55b59cfd8ef5488079",
      "patch": "@@ -51,7 +51,6 @@\n import com.netflix.dyno.jedis.DynoJedisClient;\n import com.sun.jersey.api.client.Client;\n \n-import redis.clients.jedis.Jedis;\n import redis.clients.jedis.JedisCommands;\n \n /**\n@@ -124,14 +123,7 @@ public Collection<Host> getHosts() {\n \t\t\n \t\tJedisCommands jedis = null;\n \t\tswitch(db) {\n-\t\tcase redis:\n-\t\t\t\n-\t\t\tString host = dynoHosts.get(0).getHostName();\n-\t\t\tint port = dynoHosts.get(0).getPort();\n-\t\t\tjedis = new Jedis(host, port);\n-\t\t\tlogger.info(\"Starting conductor server using standalone redis on \" + host + \":\" + port);\n-\t\t\tbreak;\n-\t\t\t\n+\t\tcase redis:\t\n \t\tcase dynomite:\n \t\t\t\n \t\t\tConnectionPoolConfigurationImpl cp = new ConnectionPoolConfigurationImpl(dynoClusterName).withTokenSupplier(new TokenMapSupplier() {\n@@ -161,7 +153,6 @@ public HostToken getTokenForHost(Host host, Set<Host> activeHosts) {\n \t\t\tbreak;\n \t\t\t\n \t\tcase memory:\n-\t\t\t\n \t\t\tjedis = new JedisMock();\n \t\t\ttry {\n \t\t\t\tEmbeddedElasticSearch.start();",
      "parent_sha": "2ae02585087f8808d2da52188d854b503339031a"
    }
  },
  {
    "oid": "fd9973b9ad30390dc32daa863bf12c398eb273f9",
    "message": "refactor(function): put the duplicate code into function",
    "date": "2018-08-07T01:13:04Z",
    "url": "https://github.com/Netflix/conductor/commit/fd9973b9ad30390dc32daa863bf12c398eb273f9",
    "details": {
      "sha": "c39b853b240ba0b44210860d9eee94dd4bad4954",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java",
      "status": "modified",
      "additions": 9,
      "deletions": 8,
      "changes": 17,
      "blob_url": "https://github.com/Netflix/conductor/blob/fd9973b9ad30390dc32daa863bf12c398eb273f9/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisMetadataDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/fd9973b9ad30390dc32daa863bf12c398eb273f9/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisMetadataDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisMetadataDAO.java?ref=fd9973b9ad30390dc32daa863bf12c398eb273f9",
      "patch": "@@ -173,6 +173,13 @@ public void update(WorkflowDef def) {\n         _createOrUpdate(def);\n     }\n \n+    private Optional<Integer> getWorkflowMaxVersion(String workflowName) {\n+        return dynoClient.hkeys(nsKey(WORKFLOW_DEF, workflowName)).stream()\n+                .filter(key -> !key.equals(LATEST))\n+                .map(Integer::valueOf)\n+                .max(Comparator.naturalOrder());\n+    }\n+\n     @Override\n     /*\n      * @param name Name of the workflow definition\n@@ -183,10 +190,7 @@ public WorkflowDef getLatest(String name) {\n         Preconditions.checkNotNull(name, \"WorkflowDef name cannot be null\");\n         WorkflowDef workflowDef = null;\n \n-        Optional<Integer> optionalMaxVersion = dynoClient.hkeys(nsKey(WORKFLOW_DEF, name)).stream()\n-                .filter(key -> !key.equals(LATEST))\n-                .map(Integer::valueOf)\n-                .max(Comparator.naturalOrder());\n+        Optional<Integer> optionalMaxVersion = getWorkflowMaxVersion(name);\n \n         if (optionalMaxVersion.isPresent()) {\n             String latestdata = dynoClient.hget(nsKey(WORKFLOW_DEF, name), optionalMaxVersion.get().toString());\n@@ -244,10 +248,7 @@ public void removeWorkflowDef(String name, Integer version) {\n \n         // check if there are any more versions remaining if not delete the\n         // workflow name\n-        Optional<Integer> optionMaxVersion = dynoClient.hkeys(nsKey(WORKFLOW_DEF, name)).stream()\n-                .filter(key -> !key.equals(LATEST))\n-                .map(Integer::valueOf)\n-                .max(Comparator.naturalOrder());\n+        Optional<Integer> optionMaxVersion = getWorkflowMaxVersion(name);\n \n         // delete workflow name\n         if (!optionMaxVersion.isPresent()) {",
      "parent_sha": "0afb1e35c76c5c2a65e40e45acb877334e98afe9"
    }
  },
  {
    "oid": "419ca79504362f8890fe9d4db7dc23ec965a9427",
    "message": "no changes made, but want start the build on the pull request",
    "date": "2018-09-23T04:24:45Z",
    "url": "https://github.com/Netflix/conductor/commit/419ca79504362f8890fe9d4db7dc23ec965a9427",
    "details": {
      "sha": "71f617499f6618940dbd53d8d144a754f6d1c577",
      "filename": "test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java",
      "status": "modified",
      "additions": 14,
      "deletions": 13,
      "changes": 27,
      "blob_url": "https://github.com/Netflix/conductor/blob/419ca79504362f8890fe9d4db7dc23ec965a9427/test-harness%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftests%2Fintegration%2FEnd2EndTests.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/419ca79504362f8890fe9d4db7dc23ec965a9427/test-harness%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftests%2Fintegration%2FEnd2EndTests.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/test-harness%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftests%2Fintegration%2FEnd2EndTests.java?ref=419ca79504362f8890fe9d4db7dc23ec965a9427",
      "patch": "@@ -18,6 +18,19 @@\n  */\n package com.netflix.conductor.tests.integration;\n \n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n import com.netflix.conductor.client.exceptions.ConductorClientException;\n import com.netflix.conductor.client.http.MetadataClient;\n import com.netflix.conductor.client.http.TaskClient;\n@@ -37,18 +50,6 @@\n import com.netflix.conductor.common.run.WorkflowSummary;\n import com.netflix.conductor.server.ConductorConfig;\n import com.netflix.conductor.server.ConductorServer;\n-import org.junit.BeforeClass;\n-import org.junit.Test;\n-\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertFalse;\n-import static org.junit.Assert.assertNotNull;\n-import static org.junit.Assert.assertTrue;\n \n \n /**\n@@ -57,7 +58,7 @@\n  */\n public class End2EndTests {\n \n-\tstatic {\n+   static {\n \t\tSystem.setProperty(\"EC2_REGION\", \"us-east-1\");\n \t\tSystem.setProperty(\"EC2_AVAILABILITY_ZONE\", \"us-east-1c\");\n \t\tSystem.setProperty(\"workflow.elasticsearch.url\", \"localhost:9300\");",
      "parent_sha": "bb52dee55cb915f71f3a3adb89e0b68cffebe1f4"
    }
  },
  {
    "oid": "1c8c0a680928901327903c717c2b60bcf6173b9f",
    "message": "Run all indexing except workflow indexing in a separate threadpool",
    "date": "2018-01-10T00:49:33Z",
    "url": "https://github.com/Netflix/conductor/commit/1c8c0a680928901327903c717c2b60bcf6173b9f",
    "details": {
      "sha": "e16282cd563f142ee57750eccc79078b044cef57",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java",
      "status": "modified",
      "additions": 125,
      "deletions": 99,
      "changes": 224,
      "blob_url": "https://github.com/Netflix/conductor/blob/1c8c0a680928901327903c717c2b60bcf6173b9f/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1c8c0a680928901327903c717c2b60bcf6173b9f/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java?ref=1c8c0a680928901327903c717c2b60bcf6173b9f",
      "patch": "@@ -27,7 +27,10 @@\n import java.util.List;\n import java.util.Map;\n import java.util.TimeZone;\n+import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n \n import javax.inject.Inject;\n@@ -118,9 +121,16 @@ public class ElasticSearchDAO implements IndexDAO {\n \tprivate static final TimeZone gmt = TimeZone.getTimeZone(\"GMT\");\n \t    \n     private static final SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMWW\");\n+\n+\tprivate static final ExecutorService executorService;\n \t\n     static {\n     \tsdf.setTimeZone(gmt);\n+\t    executorService = new ThreadPoolExecutor(6,\n+\t                                             12,\n+\t                                             60L,\n+\t                                             TimeUnit.SECONDS,\n+\t                                             new LinkedBlockingQueue<>());\n     }\n \t\n \t@Inject\n@@ -149,7 +159,7 @@ private void updateIndexName(Configuration config) {\n \t\t} catch (IndexNotFoundException infe) {\n \t\t\ttry {\n \t\t\t\tclient.admin().indices().prepareCreate(logIndexName).execute().actionGet();\n-\t\t\t} catch (IndexAlreadyExistsException ilee) {\n+\t\t\t} catch (IndexAlreadyExistsException ignored) {\n \n \t\t\t} catch (Exception e) {\n \t\t\t\tlog.error(e.getMessage(), e);\n@@ -182,7 +192,7 @@ private void initIndex() throws Exception {\n \t\t}catch(IndexNotFoundException infe) {\n \t\t\ttry {\n \t\t\t\tclient.admin().indices().prepareCreate(indexName).execute().actionGet();\n-\t\t\t}catch(IndexAlreadyExistsException done) {}\n+\t\t\t}catch(IndexAlreadyExistsException ignored) {}\n \t\t}\n \t\t\t\t\n \t\t//2. Mapping for the workflow document type\n@@ -221,20 +231,23 @@ public void index(Workflow workflow) {\n \t\n \t@Override\n \tpublic void index(Task task) {\n-\t\ttry {\n-\t\t\t\n-\t\t\tString id = task.getTaskId();\n-\t\t\tTaskSummary summary = new TaskSummary(task);\n-\t\t\tbyte[] doc = om.writeValueAsBytes(summary);\n-\t\t\t\n-\t\t\tUpdateRequest req = new UpdateRequest(indexName, TASK_DOC_TYPE, id);\n-\t\t\treq.doc(doc);\n-\t\t\treq.upsert(doc);\n-\t\t\tupdateWithRetry(req);\n- \t\t\t\n-\t\t} catch (Throwable e) {\n-\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n-\t\t}\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\ttry {\n+\n+\t\t\t\tString id = task.getTaskId();\n+\t\t\t\tTaskSummary summary = new TaskSummary(task);\n+\t\t\t\tbyte[] doc = om.writeValueAsBytes(summary);\n+\n+\t\t\t\tUpdateRequest req = new UpdateRequest(indexName, TASK_DOC_TYPE, id);\n+\t\t\t\treq.doc(doc);\n+\t\t\t\treq.upsert(doc);\n+\t\t\t\tupdateWithRetry(req);\n+\n+\t\t\t} catch (Throwable e) {\n+\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n+\t\t\t}\n+\t\t});\n \t}\n \t\n \t@Override\n@@ -243,31 +256,34 @@ public void add(List<TaskExecLog> taskExecLogs) {\n \t\tif (taskExecLogs.isEmpty()) {\n \t\t\treturn;\n \t\t}\n-\t\t\n-\t\tint retry = 3;\n-\t\twhile(retry > 0) {\n-\t\t\ttry {\n-\t\t\t\t\n-\t\t\t\tBulkRequestBuilder brb = client.prepareBulk();\n-\t\t\t\tfor(TaskExecLog taskExecLog : taskExecLogs) {\n-\t\t\t\t\tIndexRequest request = new IndexRequest(logIndexName, LOG_DOC_TYPE);\n-\t\t\t\t\trequest.source(om.writeValueAsBytes(taskExecLog));\n-\t\t\t\t\tbrb.add(request);\n-\t\t\t\t}\n-\t\t\t\tBulkResponse response = brb.execute().actionGet();\n-\t\t\t\tif(!response.hasFailures()) {\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t \t\t\tretry--;\n-\t \t\t\t\n-\t\t\t} catch (Throwable e) {\n-\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n-\t\t\t\tretry--;\n-\t\t\t\tif(retry > 0) {\n-\t\t\t\t\tUninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);\n+\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\tint retry = 3;\n+\t\t\twhile(retry > 0) {\n+\t\t\t\ttry {\n+\n+\t\t\t\t\tBulkRequestBuilder brb = client.prepareBulk();\n+\t\t\t\t\tfor(TaskExecLog taskExecLog : taskExecLogs) {\n+\t\t\t\t\t\tIndexRequest request = new IndexRequest(logIndexName, LOG_DOC_TYPE);\n+\t\t\t\t\t\trequest.source(om.writeValueAsBytes(taskExecLog));\n+\t\t\t\t\t\tbrb.add(request);\n+\t\t\t\t\t}\n+\t\t\t\t\tBulkResponse response = brb.execute().actionGet();\n+\t\t\t\t\tif(!response.hasFailures()) {\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\t}\n+\t\t            retry--;\n+\n+\t\t\t\t} catch (Throwable e) {\n+\t\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n+\t\t\t\t\tretry--;\n+\t\t\t\t\tif(retry > 0) {\n+\t\t\t\t\t\tUninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t});\n \t\t\n \t}\n \t\n@@ -276,7 +292,7 @@ public List<TaskExecLog> getTaskLogs(String taskId) {\n \t\t\n \t\ttry {\n \t\t\t\n-\t\t\tQueryBuilder qf = QueryBuilders.matchAllQuery();\n+\t\t\tQueryBuilder qf;\n \t\t\tExpression expression = Expression.fromString(\"taskId='\" + taskId + \"'\");\n \t\t\tqf = expression.getFilterBuilder();\n \t\t\t\n@@ -305,48 +321,54 @@ public List<TaskExecLog> getTaskLogs(String taskId) {\n \t\n \t@Override\n \tpublic void addMessage(String queue, Message msg) {\n-\t\t\n-\t\tint retry = 3;\n-\t\twhile(retry > 0) {\n-\t\t\ttry {\n-\t\t\t\t\n-\t\t\t\tMap<String, Object> doc = new HashMap<>();\n-\t\t\t\tdoc.put(\"messageId\", msg.getId());\n-\t\t\t\tdoc.put(\"payload\", msg.getPayload());\n-\t\t\t\tdoc.put(\"queue\", queue);\n-\t\t\t\tdoc.put(\"created\", System.currentTimeMillis());\n-\t\t\t\tIndexRequest request = new IndexRequest(logIndexName, MSG_DOC_TYPE);\n-\t\t\t\trequest.source(doc);\n-\t \t\t\tclient.index(request).actionGet();\n-\t \t\t\tbreak;\n-\t \t\t\t\n-\t\t\t} catch (Throwable e) {\n-\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n-\t\t\t\tretry--;\n-\t\t\t\tif(retry > 0) {\n-\t\t\t\t\tUninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);\n+\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\tint retry = 3;\n+\t\t\twhile(retry > 0) {\n+\t\t\t\ttry {\n+\n+\t\t\t\t\tMap<String, Object> doc = new HashMap<>();\n+\t\t\t\t\tdoc.put(\"messageId\", msg.getId());\n+\t\t\t\t\tdoc.put(\"payload\", msg.getPayload());\n+\t\t\t\t\tdoc.put(\"queue\", queue);\n+\t\t\t\t\tdoc.put(\"created\", System.currentTimeMillis());\n+\t\t\t\t\tIndexRequest request = new IndexRequest(logIndexName, MSG_DOC_TYPE);\n+\t\t\t\t\trequest.source(doc);\n+\t\t            client.index(request).actionGet();\n+\t\t            break;\n+\n+\t\t\t\t} catch (Throwable e) {\n+\t\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n+\t\t\t\t\tretry--;\n+\t\t\t\t\tif(retry > 0) {\n+\t\t\t\t\t\tUninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n-\t\t}\n+\t\t});\n \t\t\n \t}\n \t\n \t@Override\n \tpublic void add(EventExecution ee) {\n \n-\t\ttry {\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\ttry {\n \n-\t\t\tbyte[] doc = om.writeValueAsBytes(ee);\n-\t\t\tString id = ee.getName() + \".\" + ee.getEvent() + \".\" + ee.getMessageId() + \".\" + ee.getId();\n-\t\t\tUpdateRequest req = new UpdateRequest(logIndexName, EVENT_DOC_TYPE, id);\n-\t\t\treq.doc(doc);\n-\t\t\treq.upsert(doc);\n-\t\t\treq.retryOnConflict(5);\n-\t\t\tupdateWithRetry(req);\n- \t\t\t\n-\t\t} catch (Throwable e) {\n-\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n-\t\t}\n+\t\t\t\tbyte[] doc = om.writeValueAsBytes(ee);\n+\t\t\t\tString id = ee.getName() + \".\" + ee.getEvent() + \".\" + ee.getMessageId() + \".\" + ee.getId();\n+\t\t\t\tUpdateRequest req = new UpdateRequest(logIndexName, EVENT_DOC_TYPE, id);\n+\t\t\t\treq.doc(doc);\n+\t\t\t\treq.upsert(doc);\n+\t\t\t\treq.retryOnConflict(5);\n+\t\t\t\tupdateWithRetry(req);\n+\n+\t\t\t} catch (Throwable e) {\n+\t\t\t\tlog.error(\"Indexing failed {}\", e.getMessage(), e);\n+\t\t\t}\n+\t\t});\n \t\n \t\t\n \t}\n@@ -396,37 +418,43 @@ public SearchResult<String> searchTasks(String query, String freeText, int start\n \n \t@Override\n \tpublic void remove(String workflowId) {\n-\t\ttry {\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\ttry {\n \n-\t\t\tDeleteRequest req = new DeleteRequest(indexName, WORKFLOW_DOC_TYPE, workflowId);\n-\t\t\tDeleteResponse response = client.delete(req).actionGet();\n-\t\t\tif (!response.isFound()) {\n-\t\t\t\tlog.error(\"Index removal failed - document not found by id \" + workflowId);\n+\t\t\t\tDeleteRequest req = new DeleteRequest(indexName, WORKFLOW_DOC_TYPE, workflowId);\n+\t\t\t\tDeleteResponse response = client.delete(req).actionGet();\n+\t\t\t\tif (!response.isFound()) {\n+\t\t\t\t\tlog.error(\"Index removal failed - document not found by id \" + workflowId);\n+\t\t\t\t}\n+\t\t\t} catch (Throwable e) {\n+\t\t\t\tlog.error(\"Index removal failed failed {}\", e.getMessage(), e);\n+\t\t\t\tMonitors.error(className, \"remove\");\n \t\t\t}\n-\t\t} catch (Throwable e) {\n-\t\t\tlog.error(\"Index removal failed failed {}\", e.getMessage(), e);\n-\t\t\tMonitors.error(className, \"remove\");\n-\t\t}\n+\t\t});\n \t}\n \t\n \t@Override\n \tpublic void update(String workflowInstanceId, String[] keys, Object[] values) {\n \t\tif(keys.length != values.length) {\n \t\t\tthrow new IllegalArgumentException(\"Number of keys and values should be same.\");\n \t\t}\n-\t\t\n-\t\tUpdateRequest request = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, workflowInstanceId);\n-\t\tMap<String, Object> source = new HashMap<>();\n \n-\t\tfor (int i = 0; i < keys.length; i++) {\n-\t\t\tString key = keys[i];\n-\t\t\tObject value= values[i];\n-\t\t\tlog.debug(\"updating {} with {} and {}\", workflowInstanceId, key, value);\n-\t\t\tsource.put(key, value);\n-\t\t}\n-\t\trequest.doc(source);\t\t\n-\t\tActionFuture<UpdateResponse> response = client.update(request);\n-\t\tresponse.actionGet();\n+\t\t// Run all indexing other than workflow indexing in a separate threadpool\n+\t\texecutorService.submit(() -> {\n+\t\t\tUpdateRequest request = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, workflowInstanceId);\n+\t\t\tMap<String, Object> source = new HashMap<>();\n+\n+\t\t\tfor (int i = 0; i < keys.length; i++) {\n+\t\t\t\tString key = keys[i];\n+\t\t\t\tObject value= values[i];\n+\t\t\t\tlog.debug(\"updating {} with {} and {}\", workflowInstanceId, key, value);\n+\t\t\t\tsource.put(key, value);\n+\t\t\t}\n+\t\t\trequest.doc(source);\n+\t\t\tActionFuture<UpdateResponse> response = client.update(request);\n+\t\t\tresponse.actionGet();\n+\t\t});\n \t}\n \t\n \t@Override\n@@ -469,12 +497,10 @@ private SearchResult<String> search(String structuredQuery, int start, int size,\n \t\t\t\tsrb.addSort(field, order);\n \t\t\t});\n \t\t}\n-\t\tList<String> result = new LinkedList<String>();\n+\t\tList<String> result = new LinkedList<>();\n \t\tSearchResponse response = srb.execute().actionGet();\n-\t\tresponse.getHits().forEach(hit -> {\n-\t\t\tresult.add(hit.getId());\n-\t\t});\n+\t\tresponse.getHits().forEach(hit -> result.add(hit.getId()));\n \t\tlong count = response.getHits().getTotalHits();\n-\t\treturn new SearchResult<String>(count, result);\n+\t\treturn new SearchResult<>(count, result);\n \t}\n }",
      "parent_sha": "caffed1d4e7e7d8821ac2eb7dea36198883b08cc"
    }
  },
  {
    "oid": "1cc2a0d95caba40ccec98161644f2418bcdc42a5",
    "message": "reduce logging",
    "date": "2017-05-17T22:54:30Z",
    "url": "https://github.com/Netflix/conductor/commit/1cc2a0d95caba40ccec98161644f2418bcdc42a5",
    "details": {
      "sha": "477aff822bde16675830e248b3290b6809017902",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/1cc2a0d95caba40ccec98161644f2418bcdc42a5/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1cc2a0d95caba40ccec98161644f2418bcdc42a5/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java?ref=1cc2a0d95caba40ccec98161644f2418bcdc42a5",
      "patch": "@@ -365,7 +365,7 @@ public void update(String workflowInstanceId, String[] keys, Object[] values) {\n \t\tfor (int i = 0; i < keys.length; i++) {\n \t\t\tString key = keys[i];\n \t\t\tObject value= values[i];\n-\t\t\tlog.info(\"updating {} with {} and {}\", workflowInstanceId, key, value);\n+\t\t\tlog.debug(\"updating {} with {} and {}\", workflowInstanceId, key, value);\n \t\t\tsource.put(key, value);\n \t\t}\n \t\trequest.doc(source);\t\t",
      "parent_sha": "448657c1a24d89a3c01191178fa9f17c609373ab"
    }
  },
  {
    "oid": "4e993d354c16a8e375a3150af038b8b73b84cbd6",
    "message": "issue-3719: Added disk based approach to prevent oom",
    "date": "2023-09-02T08:14:08Z",
    "url": "https://github.com/Netflix/conductor/commit/4e993d354c16a8e375a3150af038b8b73b84cbd6",
    "details": {
      "sha": "a04a43710b1cb8de4c155d1cbf926205ad04a029",
      "filename": "core/src/main/java/com/netflix/conductor/core/storage/DummyPayloadStorage.java",
      "status": "modified",
      "additions": 51,
      "deletions": 21,
      "changes": 72,
      "blob_url": "https://github.com/Netflix/conductor/blob/4e993d354c16a8e375a3150af038b8b73b84cbd6/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fstorage%2FDummyPayloadStorage.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/4e993d354c16a8e375a3150af038b8b73b84cbd6/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fstorage%2FDummyPayloadStorage.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fstorage%2FDummyPayloadStorage.java?ref=4e993d354c16a8e375a3150af038b8b73b84cbd6",
      "patch": "@@ -12,17 +12,23 @@\n  */\n package com.netflix.conductor.core.storage;\n \n-import java.io.ByteArrayInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n import java.io.InputStream;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n+import java.nio.file.Files;\n+import java.util.UUID;\n \n+import org.apache.commons.io.IOUtils;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import com.netflix.conductor.common.run.ExternalStorageLocation;\n import com.netflix.conductor.common.utils.ExternalPayloadStorage;\n \n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n /**\n  * A dummy implementation of {@link ExternalPayloadStorage} used when no external payload is\n  * configured\n@@ -31,40 +37,64 @@ public class DummyPayloadStorage implements ExternalPayloadStorage {\n \n     private static final Logger LOGGER = LoggerFactory.getLogger(DummyPayloadStorage.class);\n \n-    private final Map<String, byte[]> dummyDataStore = new ConcurrentHashMap<>();\n+    private ObjectMapper objectMapper;\n+    private File payloadDir;\n \n-    private static final String DUMMY_DATA_STORE_KEY = \"DUMMY_PAYLOAD_STORE_KEY\";\n+    public DummyPayloadStorage() {\n+        try {\n+            this.objectMapper = new ObjectMapper();\n+            this.payloadDir = Files.createTempDirectory(\"payloads\").toFile();\n+            LOGGER.info(\n+                    \"{} initialized in directory: {}\",\n+                    this.getClass().getSimpleName(),\n+                    payloadDir.getAbsolutePath());\n+        } catch (IOException ioException) {\n+            LOGGER.error(\n+                    \"Exception encountered while creating payloads directory : {}\",\n+                    ioException.getMessage());\n+        }\n+    }\n \n     @Override\n     public ExternalStorageLocation getLocation(\n             Operation operation, PayloadType payloadType, String path) {\n-        ExternalStorageLocation externalStorageLocation = new ExternalStorageLocation();\n-        externalStorageLocation.setPath(path != null ? path : \"\");\n-        return externalStorageLocation;\n+        ExternalStorageLocation location = new ExternalStorageLocation();\n+        location.setPath(path + UUID.randomUUID() + \".json\");\n+        return location;\n     }\n \n     @Override\n     public void upload(String path, InputStream payload, long payloadSize) {\n+        File file = new File(payloadDir, path);\n+        String filePath = file.getAbsolutePath();\n         try {\n-            final byte[] payloadBytes = new byte[(int) payloadSize];\n-            final int bytesRead = payload.read(new byte[(int) payloadSize]);\n-\n-            if (bytesRead > 0) {\n-                dummyDataStore.put(\n-                        path == null || path.isEmpty() ? DUMMY_DATA_STORE_KEY : path, payloadBytes);\n+            if (!file.exists() && file.createNewFile()) {\n+                LOGGER.debug(\"Created file: {}\", filePath);\n+            }\n+            IOUtils.copy(payload, new FileOutputStream(file));\n+            LOGGER.debug(\"Written to {}\", filePath);\n+        } catch (IOException e) {\n+            // just handle this exception here and return empty map so that test will fail in case\n+            // this exception is thrown\n+            LOGGER.error(\"Error writing to {}\", filePath);\n+        } finally {\n+            try {\n+                if (payload != null) {\n+                    payload.close();\n+                }\n+            } catch (IOException e) {\n+                LOGGER.warn(\"Unable to close input stream when writing to file\");\n             }\n-        } catch (Exception e) {\n-            LOGGER.error(\"Error encountered while uploading payload {}\", e.getMessage());\n         }\n     }\n \n     @Override\n     public InputStream download(String path) {\n-        final byte[] data =\n-                dummyDataStore.get(path == null || path.isEmpty() ? DUMMY_DATA_STORE_KEY : path);\n-        if (data != null) {\n-            return new ByteArrayInputStream(data);\n-        } else {\n+        try {\n+            LOGGER.debug(\"Reading from {}\", path);\n+            return new FileInputStream(new File(payloadDir, path));\n+        } catch (IOException e) {\n+            LOGGER.error(\"Error reading {}\", path, e);\n             return null;\n         }\n     }",
      "parent_sha": "46dd3df90320912eddcae050738bc19a8ed9702e"
    }
  },
  {
    "oid": "41116f4a1bea0d6e781085362ede13bbc55f5d26",
    "message": "catch exceptions during polldata update",
    "date": "2020-04-02T21:07:14Z",
    "url": "https://github.com/Netflix/conductor/commit/41116f4a1bea0d6e781085362ede13bbc55f5d26",
    "details": {
      "sha": "9450f30292aaeb7da86fed4140f86a20725838b4",
      "filename": "core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java",
      "status": "modified",
      "additions": 8,
      "deletions": 2,
      "changes": 10,
      "blob_url": "https://github.com/Netflix/conductor/blob/41116f4a1bea0d6e781085362ede13bbc55f5d26/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/41116f4a1bea0d6e781085362ede13bbc55f5d26/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Forchestration%2FExecutionDAOFacade.java?ref=41116f4a1bea0d6e781085362ede13bbc55f5d26",
      "patch": "@@ -345,7 +345,7 @@ public void updateTask(Task task) {\n             /*\n              * Indexing a task for every update adds a lot of volume. That is ok but if async indexing\n              * is enabled and tasks are stored in memory until a block has completed, we would lose a lot\n-             * of tasks on a system failure. So only index for each update if async indexing is not enabled. \n+             * of tasks on a system failure. So only index for each update if async indexing is not enabled.\n              * If it *is* enabled, tasks will be indexed only when a workflow is in terminal state.\n              */\n             if (!config.enableAsyncIndexing()) {\n@@ -375,7 +375,13 @@ public PollData getTaskPollDataByDomain(String taskName, String domain) {\n     }\n \n     public void updateTaskLastPoll(String taskName, String domain, String workerId) {\n-        pollDataDAO.updateLastPollData(taskName, domain, workerId);\n+        try {\n+            pollDataDAO.updateLastPollData(taskName, domain, workerId);\n+        } catch (Exception e) {\n+            LOGGER.error(\"Error updating PollData for task: {} in domain: {} from worker: {}\", taskName, domain,\n+                workerId, e);\n+            Monitors.error(this.getClass().getCanonicalName(), \"updateTaskLastPoll\");\n+        }\n     }\n \n     /**",
      "parent_sha": "1007f23c9487745b89c24722366c0048393dc18a"
    }
  },
  {
    "oid": "7eaca1dced0b3537b083bd03616aa6db518107b8",
    "message": "removed NETFLIX_ENVIRONMENT variable",
    "date": "2019-01-07T18:23:01Z",
    "url": "https://github.com/Netflix/conductor/commit/7eaca1dced0b3537b083bd03616aa6db518107b8",
    "details": {
      "sha": "23f03dcf444bf27d0c70ac409e20130a58823bf6",
      "filename": "common/src/main/java/com/netflix/conductor/common/utils/EnvUtils.java",
      "status": "modified",
      "additions": 1,
      "deletions": 2,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/7eaca1dced0b3537b083bd03616aa6db518107b8/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Futils%2FEnvUtils.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/7eaca1dced0b3537b083bd03616aa6db518107b8/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Futils%2FEnvUtils.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Futils%2FEnvUtils.java?ref=7eaca1dced0b3537b083bd03616aa6db518107b8",
      "patch": "@@ -6,8 +6,7 @@ public class EnvUtils {\n     public enum SystemParameters {\n         CPEWF_TASK_ID,\n         NETFLIX_ENV,\n-        NETFLIX_STACK,\n-        NETFLIX_ENVIRONMENT\n+        NETFLIX_STACK\n     }\n \n     public static boolean isEnvironmentVariable(String test) {",
      "parent_sha": "0519e78da8a3165358ff7219528bdefa34723275"
    }
  },
  {
    "oid": "0d486f147c8aaf33332ed966d40a8d8202d4b193",
    "message": "override getTaskLogs",
    "date": "2017-06-12T12:46:33Z",
    "url": "https://github.com/Netflix/conductor/commit/0d486f147c8aaf33332ed966d40a8d8202d4b193",
    "details": {
      "sha": "84afcc905a0488dbce2a27dfdf09625974fbd5e3",
      "filename": "es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearch5DAO.java",
      "status": "modified",
      "additions": 37,
      "deletions": 7,
      "changes": 44,
      "blob_url": "https://github.com/Netflix/conductor/blob/0d486f147c8aaf33332ed966d40a8d8202d4b193/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearch5DAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/0d486f147c8aaf33332ed966d40a8d8202d4b193/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearch5DAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearch5DAO.java?ref=0d486f147c8aaf33332ed966d40a8d8202d4b193",
      "patch": "@@ -20,12 +20,7 @@\n \n import java.io.InputStream;\n import java.text.SimpleDateFormat;\n-import java.util.Date;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.TimeZone;\n+import java.util.*;\n import java.util.concurrent.Executors;\n import java.util.concurrent.TimeUnit;\n \n@@ -56,6 +51,7 @@\n import org.elasticsearch.index.query.QueryBuilder;\n import org.elasticsearch.index.query.QueryBuilders;\n import org.elasticsearch.index.query.QueryStringQueryBuilder;\n+import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.sort.SortOrder;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -260,7 +256,41 @@ public void add(TaskExecLog taskExecLog) {\n \t\t}\n \t\t\n \t}\n-\t\n+\n+\t@Override\n+\tpublic List<TaskExecLog> getTaskLogs(String taskId) {\n+\t\ttry {\n+\n+\t\t\tQueryBuilder qf = QueryBuilders.matchAllQuery();\n+\t\t\tExpression expression = Expression.fromString(\"taskId='\" + taskId + \"'\");\n+\t\t\tqf = expression.getFilterBuilder();\n+\n+\t\t\tBoolQueryBuilder filterQuery = QueryBuilders.boolQuery().must(qf);\n+\t\t\tQueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery(\"*\");\n+\t\t\tBoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);\n+\n+\t\t\tfinal SearchRequestBuilder srb = client.prepareSearch(indexName).setQuery(fq).setTypes(TASK_DOC_TYPE);\n+\t\t\tSearchResponse response = srb.execute().actionGet();\n+\t\t\tSearchHit[] hits = response.getHits().getHits();\n+\t\t\tList<TaskExecLog> logs = new ArrayList<>(hits.length);\n+\t\t\tfor(SearchHit hit : hits) {\n+\t\t\t\tMap<String, Object> source = hit.getSource();\n+\t\t\t\tTaskExecLog tel = new TaskExecLog();\n+\t\t\t\ttel.setCreatedTime((String)source.get(\"createdTime\"));\n+\t\t\t\ttel.setLog((String)source.get(\"log\"));\n+\t\t\t\ttel.setTaskId((String)source.get(\"taskId\"));\n+\t\t\t\tlogs.add(tel);\n+\t\t\t}\n+\n+\t\t\treturn logs;\n+\n+\t\t}catch(Exception e) {\n+\t\t\tlog.error(e.getMessage(), e);\n+\t\t}\n+\n+\t\treturn null;\n+\t}\n+\n \t@Override\n \tpublic void addMessage(String queue, Message msg) {\n \t\t",
      "parent_sha": "4fd6ff1a6cc4979b9fc7832c464615281f5734c9"
    }
  },
  {
    "oid": "f74601d92cade9d4c556241bd2b65f0da8d92b95",
    "message": "minor changes and code cleanup",
    "date": "2017-04-06T21:30:50Z",
    "url": "https://github.com/Netflix/conductor/commit/f74601d92cade9d4c556241bd2b65f0da8d92b95",
    "details": {
      "sha": "41bbb41d1114f651ad138223daef6e792edf3f86",
      "filename": "client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java",
      "status": "modified",
      "additions": 13,
      "deletions": 20,
      "changes": 33,
      "blob_url": "https://github.com/Netflix/conductor/blob/f74601d92cade9d4c556241bd2b65f0da8d92b95/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/f74601d92cade9d4c556241bd2b65f0da8d92b95/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java?ref=f74601d92cade9d4c556241bd2b65f0da8d92b95",
      "patch": "@@ -96,7 +96,7 @@ public WorkflowTaskCoordinator(EurekaClient ec, TaskClient client, int threadCou\n \t\tthis.updateRetryCount = updateRetryCount;\n \t\tthis.workerQueueSize = workerQueueSize;\n \t\tfor (Worker worker : taskWorkers) {\n-\t\t\tregisterWorker(worker);\n+\t\t\tworkers.add(worker);\n \t\t}\n \t}\n \t\n@@ -158,6 +158,9 @@ public Builder withWorkerQueueSize(int workerQueueSize) {\n \t\t * @return Builder instance\n \t\t */\n \t\tpublic Builder withThreadCount(int threadCount) {\n+\t\t\tif(threadCount < 1) {\n+\t\t\t\tthrow new IllegalArgumentException(\"No. of threads cannot be less than 1\");\n+\t\t\t}\n \t\t\tthis.threadCount = threadCount;\n \t\t\treturn this;\n \t\t}\n@@ -253,16 +256,6 @@ public Thread newThread(Runnable r) {\n \t\t\n \t}\n \n-\t/**\n-\t * \n-\t * @param worker Adds a new worker.\n-\t * If you register a worker after doing {@link #init()}, the no. of threads assigned to the poller will be less than the actual number of workers causing starvation.  \n-\t *  \n-\t */\n-\tpublic void registerWorker(Worker worker) {\n-\t\tworkers.add(worker);\n-\t}\n-\t\n \tprivate void pollForTask(Worker worker) {\n \t\t\n \t\tif(ec != null && !ec.getInstanceRemoteStatus().equals(InstanceStatus.UP)) {\n@@ -301,10 +294,6 @@ private void pollForTask(Worker worker) {\n \tprivate void execute(Worker worker, Task task) {\n \t\t\n \t\tString taskType = task.getTaskDefName();\n-\t\tif (!taskType.equals(task.getTaskType())) {\n-\t\t\tlogger.error(\"Queue name '{}' did not match type of task retrieved '{}' for task id '{}'.\", taskType, task.getTaskType(),task.getTaskId());\n-\t\t\treturn;\n-\t\t}\n \t\t\n \t\ttry {\n \t\t\t\n@@ -325,21 +314,24 @@ private void execute(Worker worker, Task task) {\n \t\t\treturn;\n \t\t}\n \t\t\n-\t\tTaskResult result = new TaskResult(task);\n-\t\tresult.getLog().getEnvironment().putAll(environmentData.get(worker));\n \t\tStopwatch sw = WorkflowTaskMetrics.executionTimer(worker.getTaskDefName());\n \t\t\n+\t\tTaskResult result = null;\n \t\ttry {\n \t\t\t\n \t\t\tlogger.debug(\"Executing task {} on worker {}\", task, worker.getClass().getSimpleName());\t\t\t\n \t\t\tresult = worker.execute(task);\n+\t\t\tresult.setWorkflowInstanceId(task.getWorkflowInstanceId());\n+\t\t\tresult.setTaskId(task.getTaskId());\n+\t\t\t\n \t\t\t\n \t\t} catch (Exception e) {\n \t\t\tlogger.error(\"Unable to execute task {}\", task, e);\n \t\t\t\n \t\t\tWorkflowTaskMetrics.executionException(worker.getTaskDefName(), e);\n+\t\t\tresult = new TaskResult(task);\n \t\t\tresult.setStatus(TaskResult.Status.FAILED);\n-\t\t\tresult.setReasonForIncompletion(\"Error while executing the task: \" + e);\n+\t\t\tresult.setReasonForIncompletion(\"Error while executing the task: \" + e.getMessage());\n \t\t\tTaskExecLog execLog = result.getLog();\n \t\t\texecLog.setError(e.getMessage());\n \t\t\tfor (StackTraceElement ste : e.getStackTrace()) {\n@@ -351,6 +343,7 @@ private void execute(Worker worker, Task task) {\n \t\t}\n \t\t\n \t\tlogger.debug(\"Task {} executed by worker {} with status {}\", task.getTaskId(), worker.getClass().getSimpleName(), task.getStatus());\n+\t\tresult.getLog().getEnvironment().putAll(environmentData.get(worker));\n \t\tupdateWithRetry(updateRetryCount, task, result, worker);\n \t\t\n \t}\n@@ -402,7 +395,7 @@ static Map<String, Object> getEnvData(Worker worker) {\n \t\t}\n \t\t\n \t\ttry {\n-\t\t\tdata.put(\"HOSTNAME\", InetAddress.getLocalHost().getHostName());\n+\t\t\tdata.put(\"HOSTNAME\", InetAddress.getLocalHost().getHostName());\t\t\t\n \t\t} catch (UnknownHostException e) {\n \t\t\t\n \t\t}\n@@ -419,7 +412,7 @@ private void updateWithRetry(int count, Task task, TaskResult result, Worker wor\n \t\ttry{\n \t\t\tclient.updateTask(result);\n \t\t\treturn;\n-\t\t}catch(Throwable t) {\n+\t\t}catch(Exception t) {\n \t\t\tWorkflowTaskMetrics.updateTaskError(worker.getTaskDefName(), t);\n \t\t\tlogger.error(\"Unable to update {} on count {}\", result, count, t);\n \t\t\ttry {",
      "parent_sha": "1d3330fb1407a0fd2c920e33b2aebade9dba728b"
    }
  },
  {
    "oid": "c698dc0388ab65b55e5691302d7daf4903506214",
    "message": "Issue-3611: Print actual value that is being validated\n\nPR for https://github.com/Netflix/conductor/issues/3611",
    "date": "2023-05-11T09:21:04Z",
    "url": "https://github.com/Netflix/conductor/commit/c698dc0388ab65b55e5691302d7daf4903506214",
    "details": {
      "sha": "10bc2f57b5446e87f55c347950adb8aaa76ad9b1",
      "filename": "common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/c698dc0388ab65b55e5691302d7daf4903506214/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskDef.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/c698dc0388ab65b55e5691302d7daf4903506214/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskDef.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskDef.java?ref=c698dc0388ab65b55e5691302d7daf4903506214",
      "patch": "@@ -63,7 +63,7 @@ public enum RetryLogic {\n \n     @ProtoField(id = 3)\n     @Min(value = 0, message = \"TaskDef retryCount: {value} must be >= 0\")\n-    @Max(value = 10, message = \"TaskDef retryCount: {value} must be <=10\")\n+    @Max(value = 10, message = \"TaskDef retryCount: ${validatedValue} must be <= {value}\")\n     private int retryCount = 3; // Default\n \n     @ProtoField(id = 4)",
      "parent_sha": "5bcd22abfc9b8c1fc055d00721490dd04492cb00"
    }
  },
  {
    "oid": "356631a195993983f03503ce7c7dd97f56b656b4",
    "message": "add separator",
    "date": "2018-12-27T07:25:21Z",
    "url": "https://github.com/Netflix/conductor/commit/356631a195993983f03503ce7c7dd97f56b656b4",
    "details": {
      "sha": "c9ccb9625d6f3a33be605efaf3275eb9b8f0ec1a",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/356631a195993983f03503ce7c7dd97f56b656b4/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/356631a195993983f03503ce7c7dd97f56b656b4/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=356631a195993983f03503ce7c7dd97f56b656b4",
      "patch": "@@ -862,11 +862,11 @@ public boolean decide(String workflowId) {\n     @VisibleForTesting\n     List<Task> dedupAndAddTasks(Workflow workflow, List<Task> tasks) {\n         List<String> tasksInWorkflow = workflow.getTasks().stream()\n-                .map(task -> task.getReferenceTaskName() + task.getRetryCount())\n+                .map(task -> task.getReferenceTaskName() + \"_\" + task.getRetryCount())\n                 .collect(Collectors.toList());\n \n         List<Task> dedupedTasks = tasks.stream()\n-                .filter(task -> !tasksInWorkflow.contains(task.getReferenceTaskName() + task.getRetryCount()))\n+                .filter(task -> !tasksInWorkflow.contains(task.getReferenceTaskName() + \"_\" + task.getRetryCount()))\n                 .collect(Collectors.toList());\n \n         workflow.getTasks().addAll(dedupedTasks);",
      "parent_sha": "d1a2188077209f2815cf28b76711b5fea4befaaa"
    }
  },
  {
    "oid": "0899863fa58bb7c111bb518b28c9d07b92ced38f",
    "message": "Adjust unit tests for the HTTP task fix",
    "date": "2017-02-14T20:18:27Z",
    "url": "https://github.com/Netflix/conductor/commit/0899863fa58bb7c111bb518b28c9d07b92ced38f",
    "details": {
      "sha": "356f72a06ed63209a4a5eb3eacb538f42e11bd4e",
      "filename": "contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java",
      "status": "modified",
      "additions": 13,
      "deletions": 12,
      "changes": 25,
      "blob_url": "https://github.com/Netflix/conductor/blob/0899863fa58bb7c111bb518b28c9d07b92ced38f/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/0899863fa58bb7c111bb518b28c9d07b92ced38f/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java?ref=0899863fa58bb7c111bb518b28c9d07b92ced38f",
      "patch": "@@ -58,6 +58,7 @@\n  * @author Viren\n  *\n  */\n+@SuppressWarnings(\"unchecked\")\n public class TestHttpTask {\n \n \tprivate static final String ERROR_RESPONSE = \"Something went wrong!\";\n@@ -126,8 +127,8 @@ public void testPost() throws Exception {\n \t\t\n \t\thttpTask.start(workflow, task, executor);\n \t\tassertEquals(task.getReasonForIncompletion(), Task.Status.COMPLETED, task.getStatus());\n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertTrue(\"response is: \" + response, response instanceof Map);\n \t\tMap<String, Object> map = (Map<String, Object>) response;\n@@ -153,8 +154,8 @@ public void testPostNoContent() throws Exception {\n \t\t\n \t\thttpTask.start(workflow, task, executor);\n \t\tassertEquals(task.getReasonForIncompletion(), Task.Status.COMPLETED, task.getStatus());\n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertNull(\"response is: \" + response, response);\n \t}\n@@ -189,8 +190,8 @@ public void testTextGET() throws Exception {\n \t\ttask.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);\n \t\t\n \t\thttpTask.start(workflow, task, executor);\n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertEquals(TEXT_RESPONSE, response);\t\n \t}\n@@ -205,8 +206,8 @@ public void testNumberGET() throws Exception {\n \t\ttask.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);\n \t\t\n \t\thttpTask.start(workflow, task, executor);\n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertEquals(NUM_RESPONSE, response);\n \t\tassertTrue(response instanceof Number);\n@@ -223,8 +224,8 @@ public void testJsonGET() throws Exception {\n \t\ttask.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);\n \t\t\n \t\thttpTask.start(workflow, task, executor);\n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertTrue(response instanceof Map);\n \t\tMap<String, Object> map = (Map<String, Object>) response;\n@@ -244,8 +245,8 @@ public void testExecute() throws Exception {\n \t\ttask.setScheduledTime(0);\n \t\thttpTask.execute(workflow, task, executor);\n \n-\t\tHttpResponse hr = (HttpResponse) task.getOutputData().get(\"response\");\n-\t\tObject response = hr.body;\n+\t\tMap<String, Object> hr = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tObject response = hr.get(\"body\");\n \t\tassertEquals(Task.Status.COMPLETED, task.getStatus());\n \t\tassertTrue(response instanceof Map);\n \t\tMap<String, Object> map = (Map<String, Object>) response;",
      "parent_sha": "f896c70fde514fd0292a01d74400ac817ef8ad11"
    }
  },
  {
    "oid": "e131870e55eff1b7add0e6afaa8a6af132433823",
    "message": "spotless",
    "date": "2023-05-02T03:18:57Z",
    "url": "https://github.com/Netflix/conductor/commit/e131870e55eff1b7add0e6afaa8a6af132433823",
    "details": {
      "sha": "ad47595232f7aa9fb7b366931e5bb037d7679fc6",
      "filename": "core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowRepairService.java",
      "status": "modified",
      "additions": 7,
      "deletions": 3,
      "changes": 10,
      "blob_url": "https://github.com/Netflix/conductor/blob/e131870e55eff1b7add0e6afaa8a6af132433823/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowRepairService.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/e131870e55eff1b7add0e6afaa8a6af132433823/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowRepairService.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Freconciliation%2FWorkflowRepairService.java?ref=e131870e55eff1b7add0e6afaa8a6af132433823",
      "patch": "@@ -16,7 +16,6 @@\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.function.Predicate;\n \n-import com.netflix.conductor.core.exception.NotFoundException;\n import org.apache.commons.lang3.StringUtils;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -26,6 +25,7 @@\n import com.netflix.conductor.annotations.VisibleForTesting;\n import com.netflix.conductor.common.metadata.tasks.TaskType;\n import com.netflix.conductor.core.config.ConductorProperties;\n+import com.netflix.conductor.core.exception.NotFoundException;\n import com.netflix.conductor.core.execution.tasks.SystemTaskRegistry;\n import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;\n import com.netflix.conductor.core.utils.QueueUtils;\n@@ -103,8 +103,12 @@ public boolean verifyAndRepairWorkflow(String workflowId, boolean includeTasks)\n \n     /** Verify and repair tasks in a workflow. */\n     public void verifyAndRepairWorkflowTasks(String workflowId) {\n-        WorkflowModel workflow = Optional.ofNullable(executionDAO.getWorkflow(workflowId, true))\n-                .orElseThrow(() -> new NotFoundException(\"Could not find workflow: \" + workflowId));\n+        WorkflowModel workflow =\n+                Optional.ofNullable(executionDAO.getWorkflow(workflowId, true))\n+                        .orElseThrow(\n+                                () ->\n+                                        new NotFoundException(\n+                                                \"Could not find workflow: \" + workflowId));\n         workflow.getTasks().forEach(this::verifyAndRepairTask);\n         // repair the parent workflow if needed\n         verifyAndRepairWorkflow(workflow.getParentWorkflowId());",
      "parent_sha": "34e37ef828b082e3c4df403c3f6c32dd15521482"
    }
  },
  {
    "oid": "69852d115d7b5dc2295ae33d1b2e09b6e803063d",
    "message": "Changing HttpTask test URI to fix failing test with conflicting IP Address.",
    "date": "2019-11-13T18:33:52Z",
    "url": "https://github.com/Netflix/conductor/commit/69852d115d7b5dc2295ae33d1b2e09b6e803063d",
    "details": {
      "sha": "18d7dda71ad813b0eb25467474ba8c652219712b",
      "filename": "contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/69852d115d7b5dc2295ae33d1b2e09b6e803063d/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/69852d115d7b5dc2295ae33d1b2e09b6e803063d/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java?ref=69852d115d7b5dc2295ae33d1b2e09b6e803063d",
      "patch": "@@ -292,7 +292,7 @@ public void testHTTPGetConnectionTimeOut() throws Exception{\n         Instant start  = Instant.now();\n         input.setConnectionTimeOut(110);\n         input.setMethod(\"GET\");\n-        input.setUri(\"http://10.255.255.255\");\n+        input.setUri(\"http://10.255.14.15\");\n         task.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);\n         task.setStatus(Status.SCHEDULED);\n         task.setScheduledTime(0);",
      "parent_sha": "77b719952499e520509a45cc3e5da603f190a422"
    }
  },
  {
    "oid": "e77a26fbb189f75031bc7cc546aa0c9f8d9dd599",
    "message": "set workflow input if not null or empty",
    "date": "2021-06-04T21:42:57Z",
    "url": "https://github.com/Netflix/conductor/commit/e77a26fbb189f75031bc7cc546aa0c9f8d9dd599",
    "details": {
      "sha": "2a5f931dfc50bb0a10e6712f5d96d3650718b334",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/e77a26fbb189f75031bc7cc546aa0c9f8d9dd599/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/e77a26fbb189f75031bc7cc546aa0c9f8d9dd599/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=e77a26fbb189f75031bc7cc546aa0c9f8d9dd599",
      "patch": "@@ -405,7 +405,7 @@ public String startWorkflow(\n         workflow.setTaskToDomain(taskToDomain);\n         workflow.setVariables(workflowDefinition.getVariables());\n \n-        if (workflowInput != null) {\n+        if (workflowInput != null && !workflowInput.isEmpty()) {\n             workflow.setInput(workflowInput);\n             deciderService.externalizeWorkflowData(workflow);\n         } else {",
      "parent_sha": "1ae474584b1a4572e9ecbd5e47473a42088f8f99"
    }
  },
  {
    "oid": "4a2002e5c3e68ff3cdc009d915163877e25a128a",
    "message": "checkin for perf.",
    "date": "2019-05-30T05:42:03Z",
    "url": "https://github.com/Netflix/conductor/commit/4a2002e5c3e68ff3cdc009d915163877e25a128a",
    "details": {
      "sha": "6c8f3a435047c2e7ebff61c256813bd90addf6a2",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java",
      "status": "modified",
      "additions": 4,
      "deletions": 2,
      "changes": 6,
      "blob_url": "https://github.com/Netflix/conductor/blob/4a2002e5c3e68ff3cdc009d915163877e25a128a/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/4a2002e5c3e68ff3cdc009d915163877e25a128a/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java?ref=4a2002e5c3e68ff3cdc009d915163877e25a128a",
      "patch": "@@ -18,6 +18,7 @@\n  */\n package com.netflix.conductor.core.execution.tasks;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.netflix.conductor.common.metadata.tasks.Task;\n import com.netflix.conductor.common.metadata.tasks.Task.Status;\n import com.netflix.conductor.common.metadata.workflow.WorkflowTask;\n@@ -128,6 +129,7 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider)\n \n \t}\n \n+\t@VisibleForTesting\n \tboolean getEvaluatedCondition(WorkflowTask taskToSchedule, Map<String, Object> taskInput) {\n \t\tString condition = taskToSchedule.getLoopCondition();\n \t\tboolean caseValue = false;\n@@ -141,8 +143,8 @@ boolean getEvaluatedCondition(WorkflowTask taskToSchedule, Map<String, Object> t\n \t\t\t\tthrow new RuntimeException(\"Error while evaluating the script \" + condition, e);\n \t\t\t}\n \t\t}\n-\n-\t\treturn caseValue;\n+\t\tint rand = (int)(Math.random() * 10);\n+\t\treturn rand %2 == 00 ;\n \t}\n \n }",
      "parent_sha": "5c7bb5ea498b411f494dac41cfd10b208d5fa835"
    }
  },
  {
    "oid": "c5de2c9b0701d8bbac2c77768fc7cca543c57a91",
    "message": "add createdTime property",
    "date": "2017-06-08T00:15:51Z",
    "url": "https://github.com/Netflix/conductor/commit/c5de2c9b0701d8bbac2c77768fc7cca543c57a91",
    "details": {
      "sha": "1647798a7c64ce6fbf5b54d31fe4aeb5defd8ecd",
      "filename": "common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java",
      "status": "modified",
      "additions": 18,
      "deletions": 3,
      "changes": 21,
      "blob_url": "https://github.com/Netflix/conductor/blob/c5de2c9b0701d8bbac2c77768fc7cca543c57a91/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskExecLog.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/c5de2c9b0701d8bbac2c77768fc7cca543c57a91/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskExecLog.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Ftasks%2FTaskExecLog.java?ref=c5de2c9b0701d8bbac2c77768fc7cca543c57a91",
      "patch": "@@ -32,9 +32,9 @@ public class TaskExecLog {\n \t\n \tprivate String taskId;\n \t\n-\tpublic TaskExecLog() {\n-\t\t\n-\t}\n+\tprivate String createdTime;\n+\t\n+\tpublic TaskExecLog() {}\n \n \t/**\n \t * \n@@ -74,6 +74,21 @@ public String getTaskId() {\n \tpublic void setTaskId(String taskId) {\n \t\tthis.taskId = taskId;\n \t}\n+\n+\t/**\n+\t * @return the createdTime\n+\t */\n+\tpublic String getCreatedTime() {\n+\t\treturn createdTime;\n+\t}\n+\n+\t/**\n+\t * @param createdTime the createdTime to set\n+\t * \n+\t */\n+\tpublic void setCreatedTime(String createdTime) {\n+\t\tthis.createdTime = createdTime;\n+\t}\n \t\n \t\n }",
      "parent_sha": "ad05cb135286b238144a9744fb38f27935a4b871"
    }
  },
  {
    "oid": "3710e09c3f6021684b5995cab549ce58e81d4bf4",
    "message": "Fixed searchArchivableWorkflows rangeQuery.",
    "date": "2018-07-14T02:10:36Z",
    "url": "https://github.com/Netflix/conductor/commit/3710e09c3f6021684b5995cab549ce58e81d4bf4",
    "details": {
      "sha": "0cb44fb1860704276bcc971c448762d422d03a29",
      "filename": "es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/3710e09c3f6021684b5995cab549ce58e81d4bf4/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearchDAOV5.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/3710e09c3f6021684b5995cab549ce58e81d4bf4/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearchDAOV5.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/es5-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes5%2Findex%2FElasticSearchDAOV5.java?ref=3710e09c3f6021684b5995cab549ce58e81d4bf4",
      "patch": "@@ -493,7 +493,7 @@ private SearchResult<String> search(String structuredQuery, int start, int size,\n \t@Override\n \tpublic List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {\n \t\tQueryBuilder q = QueryBuilders.boolQuery()\n-\t\t\t\t.must(QueryBuilders.rangeQuery(\"endTime\").lt(LocalDate.now().minusDays(archiveTtlDays)))\n+\t\t\t\t.must(QueryBuilders.rangeQuery(\"endTime\").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))\n \t\t\t\t.should(QueryBuilders.termQuery(\"status\", \"COMPLETED\"))\n \t\t\t\t.should(QueryBuilders.termQuery(\"status\", \"FAILED\"))\n \t\t\t\t.mustNot(QueryBuilders.existsQuery(\"archived\"))",
      "parent_sha": "4b0e18dc28c3ed97030644ae12e3f14f35fcfe02"
    }
  },
  {
    "oid": "1f2cdcef15889856003aca04db5fe8af6ed9469c",
    "message": "Apply Spotless",
    "date": "2023-04-19T21:13:49Z",
    "url": "https://github.com/Netflix/conductor/commit/1f2cdcef15889856003aca04db5fe8af6ed9469c",
    "details": {
      "sha": "c3270706b076ae14a2bcac60637a235a9f452b38",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/redis/dao/RedisEventHandlerDAO.java",
      "status": "modified",
      "additions": 3,
      "deletions": 5,
      "changes": 8,
      "blob_url": "https://github.com/Netflix/conductor/blob/1f2cdcef15889856003aca04db5fe8af6ed9469c/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fredis%2Fdao%2FRedisEventHandlerDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1f2cdcef15889856003aca04db5fe8af6ed9469c/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fredis%2Fdao%2FRedisEventHandlerDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fredis%2Fdao%2FRedisEventHandlerDAO.java?ref=1f2cdcef15889856003aca04db5fe8af6ed9469c",
      "patch": "@@ -17,7 +17,6 @@\n import java.util.Map;\n import java.util.Set;\n \n-import com.netflix.conductor.core.exception.TransientException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.springframework.context.annotation.Conditional;\n@@ -27,6 +26,7 @@\n import com.netflix.conductor.core.config.ConductorProperties;\n import com.netflix.conductor.core.exception.ConflictException;\n import com.netflix.conductor.core.exception.NotFoundException;\n+import com.netflix.conductor.core.exception.TransientException;\n import com.netflix.conductor.dao.EventHandlerDAO;\n import com.netflix.conductor.redis.config.AnyRedisCondition;\n import com.netflix.conductor.redis.config.RedisProperties;\n@@ -139,10 +139,8 @@ private EventHandler getEventHandler(String name) {\n         String json;\n         try {\n             json = jedisProxy.hget(nsKey(EVENT_HANDLERS), name);\n-        }\n-        catch (Exception e) {\n-            throw new TransientException(\n-                    \"Unable to get event handler named \" + name, e);\n+        } catch (Exception e) {\n+            throw new TransientException(\"Unable to get event handler named \" + name, e);\n         }\n         if (json != null) {\n             eventHandler = readValue(json, EventHandler.class);",
      "parent_sha": "f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15"
    }
  },
  {
    "oid": "129096f43cdc54f071318e3b375d6f7ff3284b84",
    "message": "Changed executorService from static variable to member variable",
    "date": "2017-12-21T18:22:49Z",
    "url": "https://github.com/Netflix/conductor/commit/129096f43cdc54f071318e3b375d6f7ff3284b84",
    "details": {
      "sha": "805c5b399e39f1166ea710aa83989cecfd07f3c1",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java",
      "status": "modified",
      "additions": 9,
      "deletions": 6,
      "changes": 15,
      "blob_url": "https://github.com/Netflix/conductor/blob/129096f43cdc54f071318e3b375d6f7ff3284b84/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/129096f43cdc54f071318e3b375d6f7ff3284b84/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java?ref=129096f43cdc54f071318e3b375d6f7ff3284b84",
      "patch": "@@ -122,15 +122,10 @@ public class ElasticSearchDAO implements IndexDAO {\n \t    \n     private static final SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMWW\");\n \n-\tprivate static final ExecutorService executorService;\n+\tprivate final ExecutorService executorService;\n \t\n     static {\n     \tsdf.setTimeZone(gmt);\n-\t    executorService = new ThreadPoolExecutor(6,\n-\t                                             12,\n-\t                                             60L,\n-\t                                             TimeUnit.SECONDS,\n-\t                                             new LinkedBlockingQueue<>());\n     }\n \t\n \t@Inject\n@@ -148,6 +143,14 @@ public ElasticSearchDAO(Client client, Configuration config, ObjectMapper om) {\n \t\t} catch (Exception e) {\n \t\t\tlog.error(e.getMessage(), e);\n \t\t}\n+\t\tint corePoolSize = 6;\n+\t\tint maximumPoolSize = 12;\n+\t\tlong keepAliveTime = 1L;\n+\t\tthis.executorService = new ThreadPoolExecutor(corePoolSize,\n+\t\t                                              maximumPoolSize,\n+\t\t                                              keepAliveTime,\n+\t\t                                              TimeUnit.MINUTES,\n+\t\t                                              new LinkedBlockingQueue<>());\n \t}\n \t\n \tprivate void updateIndexName(Configuration config) {",
      "parent_sha": "bf9ebb35338958e48a4177000d03c70777dbb550"
    }
  },
  {
    "oid": "358493862d79569061b4f788afd86229ea196bae",
    "message": "replaced '.' with '_' when using env vars",
    "date": "2017-11-17T14:17:01Z",
    "url": "https://github.com/Netflix/conductor/commit/358493862d79569061b4f788afd86229ea196bae",
    "details": {
      "sha": "c8956366f62d9cf5bfb88f12d0828969f0b4e463",
      "filename": "server/src/main/java/com/netflix/conductor/server/ConductorConfig.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/358493862d79569061b4f788afd86229ea196bae/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorConfig.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/358493862d79569061b4f788afd86229ea196bae/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorConfig.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FConductorConfig.java?ref=358493862d79569061b4f788afd86229ea196bae",
      "patch": "@@ -104,9 +104,10 @@ public int getIntProperty(String key, int defaultValue) {\n \n \t@Override\n \tpublic String getProperty(String key, String defaultValue) {\n+\n \t\tString val = null;\n \t\ttry{\n-\t\t\tval = System.getenv(key);\n+\t\t\tval = System.getenv(key.replace('.','_'));\n \t\t\tif (val == null || val.isEmpty()) {\n \t\t\t\tval = Optional.ofNullable(System.getProperty(key)).orElse(defaultValue);\n \t\t\t}",
      "parent_sha": "b2ac16bd4365bfc028222d9d2f661887b8222a37"
    }
  },
  {
    "oid": "5c91db2de32328aa9d474183bfc746ddf45080bc",
    "message": "Missed a file when checking in",
    "date": "2017-06-05T23:01:27Z",
    "url": "https://github.com/Netflix/conductor/commit/5c91db2de32328aa9d474183bfc746ddf45080bc",
    "details": {
      "sha": "e090f982266b3e4a48e00f1d46e51a80b004e503",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java",
      "status": "modified",
      "additions": 1,
      "deletions": 4,
      "changes": 5,
      "blob_url": "https://github.com/Netflix/conductor/blob/5c91db2de32328aa9d474183bfc746ddf45080bc/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/5c91db2de32328aa9d474183bfc746ddf45080bc/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java?ref=5c91db2de32328aa9d474183bfc746ddf45080bc",
      "patch": "@@ -87,10 +87,7 @@ public void setup(){\n \t\tMetadataDAO mdao = mock(MetadataDAO.class);\n \t\tTaskDef taskDef = new TaskDef();\n \t\twhen(mdao.getTaskDef(any())).thenReturn(taskDef);\n- \t\tExecutionDAO edao = mock(ExecutionDAO.class);\n- \t\twhen(edao.getPollData(any(), any())).thenReturn(null);\n- \t\tConfiguration config = mock(Configuration.class);\n-\t\tds = new DeciderService(mdao, new ObjectMapper(), edao, config);\n+\t\tds = new DeciderService(mdao, new ObjectMapper());\n \t\t\n \t\tworkflow = new Workflow();\n \t\tworkflow.getInput().put(\"requestId\", \"request id 001\");",
      "parent_sha": "2ba181a53cf3f9d8e89387b4a782ce2b62eed89e"
    }
  },
  {
    "oid": "0c0ef1af1c2ee4f557e0b6a427e7b4263491dfd3",
    "message": "logging correction.",
    "date": "2019-06-03T10:52:53Z",
    "url": "https://github.com/Netflix/conductor/commit/0c0ef1af1c2ee4f557e0b6a427e7b4263491dfd3",
    "details": {
      "sha": "2177fa4fb787f9707230c54fabd7093795b93a02",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java",
      "status": "modified",
      "additions": 8,
      "deletions": 6,
      "changes": 14,
      "blob_url": "https://github.com/Netflix/conductor/blob/0c0ef1af1c2ee4f557e0b6a427e7b4263491dfd3/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/0c0ef1af1c2ee4f557e0b6a427e7b4263491dfd3/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhile.java?ref=0c0ef1af1c2ee4f557e0b6a427e7b4263491dfd3",
      "patch": "@@ -85,11 +85,11 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider)\n \t\t\treturn false;\n \t\t}\n \t\tboolean shouldContinue = getEvaluatedCondition(task, workflow);\n-\t\tlogger.debug(\"workflowid {} shouldcontinue {}\",workflow.getWorkflowId(), shouldContinue);\n+\t\tlogger.debug(\"taskid {} condition evaluated to {}\",task.getTaskId(), shouldContinue);\n \t\tif (shouldContinue){\n \t\t\treturn scheduleLoopTasks(task, workflow, provider);\n \t\t} else {\n-\t\t\treturn markLoopTaskSuccess(task, workflow);\n+\t\t\treturn markLoopTaskSuccess(task);\n \t\t}\n \t}\n \n@@ -113,6 +113,8 @@ Map<String, Object> getConditionInput(Task task, Workflow workflow) {\n \t}\n \n \tboolean scheduleLoopTasks(Task task, Workflow workflow, WorkflowExecutor provider) {\n+\t\tlogger.debug(\"Scheduling loop tasks for taskid {} as condition {} evaluated to true\",\n+\t\t\t\ttask.getTaskId(), task.getWorkflowTask().getLoopCondition());\n \t\tList<WorkflowTask> loopOver = task.getWorkflowTask().getLoopOver();\n \t\tList<Task> taskToBeScheduled = new ArrayList<>();\n \t\tint iteration = task.getIteration() + 1;\n@@ -135,12 +137,12 @@ boolean scheduleLoopTasks(Task task, Workflow workflow, WorkflowExecutor provide\n \tboolean markLoopTaskFailed(Task task, String failureReason) {\n \t\ttask.setReasonForIncompletion(failureReason);\n \t\ttask.setStatus(Status.FAILED);\n-\t\tlogger.debug(\"taskid {} took {} iterations to failed\",task.getTaskId(), task.getIteration() + 1);\n+\t\tlogger.debug(\"taskid {} failed in {} iteration\",task.getTaskId(), task.getIteration() + 1);\n \t\treturn true;\n \t}\n \n-\tboolean markLoopTaskSuccess(Task task, Workflow workflow) {\n-\t\tlogger.debug(\"workflowid {} took {} iterations to complete\",workflow.getWorkflowId(), task.getIteration() + 1);\n+\tboolean markLoopTaskSuccess(Task task) {\n+\t\tlogger.debug(\"taskid {} took {} iterations to complete\",task.getTaskId(), task.getIteration() + 1);\n \t\ttask.setStatus(Status.COMPLETED);\n \t\treturn true;\n \t}\n@@ -151,7 +153,7 @@ boolean getEvaluatedCondition(Task task, Workflow workflow) {\n \t\tString condition = task.getWorkflowTask().getLoopCondition();\n \t\tboolean shouldContinue = false;\n \t\tif (condition != null) {\n-\t\t\tlogger.debug(\"Case being evaluated using loop expression: {}\", condition);\n+\t\t\tlogger.debug(\"Condition {} is being evaluated{}\", condition);\n \t\t\ttry {\n \t\t\t\t//Evaluate the expression by using the Nashhorn based script evaluator\n \t\t\t\tshouldContinue = ScriptEvaluator.evalBool(condition, taskInput);",
      "parent_sha": "ff83bb28d163270e01128c872086ca3663347198"
    }
  },
  {
    "oid": "8ea34fc16defd6a25cb5d4f3126bfd1fd800f981",
    "message": "Use I/O scheduler instead of computation scheduler",
    "date": "2020-07-08T00:18:19Z",
    "url": "https://github.com/Netflix/conductor/commit/8ea34fc16defd6a25cb5d4f3126bfd1fd800f981",
    "details": {
      "sha": "d1465610867e12058b035af3077e7597f7f6be39",
      "filename": "core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoObservableQueue.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/8ea34fc16defd6a25cb5d4f3126bfd1fd800f981/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/8ea34fc16defd6a25cb5d4f3126bfd1fd800f981/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java?ref=8ea34fc16defd6a25cb5d4f3126bfd1fd800f981",
      "patch": "@@ -28,6 +28,8 @@\n import org.slf4j.LoggerFactory;\n import rx.Observable;\n import rx.Observable.OnSubscribe;\n+import rx.Scheduler;\n+import rx.schedulers.Schedulers;\n \n import javax.inject.Inject;\n import javax.inject.Singleton;\n@@ -121,7 +123,7 @@ private List<Message> receiveMessages() {\n     @VisibleForTesting\n     private OnSubscribe<Message> getOnSubscribe() {\n         return subscriber -> {\n-            Observable<Long> interval = Observable.interval(pollTimeInMS, TimeUnit.MILLISECONDS);\n+            Observable<Long> interval = Observable.interval(pollTimeInMS, TimeUnit.MILLISECONDS, Schedulers.io());\n             interval.flatMap((Long x) -> {\n                 List<Message> msgs = receiveMessages();\n                 return Observable.from(msgs);",
      "parent_sha": "a14d7dbcd14f62a4264e9d22442bcdb458983121"
    }
  },
  {
    "oid": "ffc85cadb3998e28d6d2ec2eff3d46f758fd0cb1",
    "message": "fix typo error",
    "date": "2020-06-25T11:17:50Z",
    "url": "https://github.com/Netflix/conductor/commit/ffc85cadb3998e28d6d2ec2eff3d46f758fd0cb1",
    "details": {
      "sha": "fa452a636e5bc7a668a49899b8431ded7de805fc",
      "filename": "client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "changes": 6,
      "blob_url": "https://github.com/Netflix/conductor/blob/ffc85cadb3998e28d6d2ec2eff3d46f758fd0cb1/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftelemetry%2FMetricsContainer.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/ffc85cadb3998e28d6d2ec2eff3d46f758fd0cb1/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftelemetry%2FMetricsContainer.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftelemetry%2FMetricsContainer.java?ref=ffc85cadb3998e28d6d2ec2eff3d46f758fd0cb1",
      "patch": "@@ -34,7 +34,7 @@\n public class MetricsContainer {\n \n     private static final String TASK_TYPE = \"taskType\";\n-    private static final String WORFLOW_TYPE = \"workflowType\";\n+    private static final String WORKFLOW_TYPE = \"workflowType\";\n     private static final String WORKFLOW_VERSION = \"version\";\n     private static final String EXCEPTION = \"exception\";\n     private static final String ENTITY_NAME = \"entityName\";\n@@ -158,15 +158,15 @@ public static void incrementTaskPollCount(String taskType, int taskCount) {\n     }\n \n     public static void recordWorkflowInputPayloadSize(String workflowType, String version, long payloadSize) {\n-        getGauge(WORKFLOW_INPUT_SIZE, WORFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);\n+        getGauge(WORKFLOW_INPUT_SIZE, WORKFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);\n     }\n \n     public static void incrementExternalPayloadUsedCount(String name, String operation, String payloadType) {\n         incrementCount(EXTERNAL_PAYLOAD_USED, ENTITY_NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);\n     }\n \n     public static void incrementWorkflowStartErrorCount(String workflowType, Throwable t) {\n-        incrementCount(WORKFLOW_START_ERROR, WORFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());\n+        incrementCount(WORKFLOW_START_ERROR, WORKFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());\n     }\n \n     /**",
      "parent_sha": "5ebdd7f69ac71a9dbfc967bdce64746146f1535f"
    }
  },
  {
    "oid": "2ab7ff290267acfad506a2569546832e19c55afb",
    "message": "Issue 1148 : Reset start time when rerunning a workflow from that task (#1156)\n\n* Issue 1148 : Reset start time when rerunning a workflow from that task\r\n\r\n* Reset starttime only for type SUBWORKFLOW\r\n\r\n* Reset task externalOutputPayloadStoragePath",
    "date": "2019-05-23T00:48:18Z",
    "url": "https://github.com/Netflix/conductor/commit/2ab7ff290267acfad506a2569546832e19c55afb",
    "details": {
      "sha": "5ff7fe20a4c95ddf14aa4252db44b867b5fe5a94",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 9,
      "deletions": 1,
      "changes": 10,
      "blob_url": "https://github.com/Netflix/conductor/blob/2ab7ff290267acfad506a2569546832e19c55afb/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/2ab7ff290267acfad506a2569546832e19c55afb/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=2ab7ff290267acfad506a2569546832e19c55afb",
      "patch": "@@ -1300,9 +1300,17 @@ private boolean rerunWF(String workflowId, String taskId, Map<String, Object> ta\n                     executionDAOFacade.removeTask(task.getTaskId());\n                 }\n             }\n+            //reset fields before restarting the task\n+            rerunFromTask.setScheduledTime(System.currentTimeMillis());\n+            rerunFromTask.setStartTime(0);\n+            rerunFromTask.setUpdateTime(0);\n+            rerunFromTask.setEndTime(0);\n+            rerunFromTask.setOutputData(null);\n+            rerunFromTask.setExternalOutputPayloadStoragePath(null);\n             if (rerunFromTask.getTaskType().equalsIgnoreCase(SubWorkflow.NAME)) {\n-                // if task is sub workflow set task as IN_PROGRESS\n+                // if task is sub workflow set task as IN_PROGRESS and reset start time\n                 rerunFromTask.setStatus(IN_PROGRESS);\n+                rerunFromTask.setStartTime(System.currentTimeMillis());\n             } else {\n                 // Set the task to rerun as SCHEDULED\n                 rerunFromTask.setStatus(SCHEDULED);",
      "parent_sha": "874d56bde1a42103d8154999e99b2608b573fce9"
    }
  },
  {
    "oid": "19c3c70b4d9cdf7157df75d05a09d52aafa608c4",
    "message": "Fix: terminateReason in TERMINATE Task can use JSONPath expression to extract value",
    "date": "2023-09-14T07:51:17Z",
    "url": "https://github.com/Netflix/conductor/commit/19c3c70b4d9cdf7157df75d05a09d52aafa608c4",
    "details": {
      "sha": "e9c326410bef4c6067dc20470d73b90a714fa965",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 2,
      "deletions": 4,
      "changes": 6,
      "blob_url": "https://github.com/Netflix/conductor/blob/19c3c70b4d9cdf7157df75d05a09d52aafa608c4/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/19c3c70b4d9cdf7157df75d05a09d52aafa608c4/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=19c3c70b4d9cdf7157df75d05a09d52aafa608c4",
      "patch": "@@ -458,14 +458,12 @@ private void endExecution(WorkflowModel workflow, TaskModel terminateTask) {\n             String terminationStatus =\n                     (String)\n                             terminateTask\n-                                    .getWorkflowTask()\n-                                    .getInputParameters()\n+                                    .getInputData()\n                                     .get(Terminate.getTerminationStatusParameter());\n             String reason =\n                     (String)\n                             terminateTask\n-                                    .getWorkflowTask()\n-                                    .getInputParameters()\n+                                    .getInputData()\n                                     .get(Terminate.getTerminationReasonParameter());\n             if (StringUtils.isBlank(reason)) {\n                 reason =",
      "parent_sha": "6359617ff06607dda7f5e74a1e53d5207193ebf2"
    }
  },
  {
    "oid": "4eeaff71048191cdf48933129a131f7c2308be31",
    "message": "dont use string manipulation on parameter for processUnacks, processAllUnacks for Postgres - for 3.x (#2350)\n\n* dont use string manipulation on parameter for processUnacks, processAllUnacks - for 3.x\r\n\r\n* add Query.java, not sure what happened to that file in 3.x\r\n\r\n* change imports for new file locations\r\n\r\n* change imports for new file locations\r\n\r\n* change imports for new file locations\r\n\r\n* change imports for new file locations\r\n\r\n* use the Query class that was in the util package\r\n\r\nCo-authored-by: u447 <rick.fishman@bcbsfl.com>",
    "date": "2021-07-13T23:47:54Z",
    "url": "https://github.com/Netflix/conductor/commit/4eeaff71048191cdf48933129a131f7c2308be31",
    "details": {
      "sha": "c1e14a53de0624a450a0ad2eb10ee1f813189c3c",
      "filename": "postgres-persistence/src/main/java/com/netflix/conductor/postgres/dao/PostgresQueueDAO.java",
      "status": "modified",
      "additions": 46,
      "deletions": 36,
      "changes": 82,
      "blob_url": "https://github.com/Netflix/conductor/blob/4eeaff71048191cdf48933129a131f7c2308be31/postgres-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fpostgres%2Fdao%2FPostgresQueueDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/4eeaff71048191cdf48933129a131f7c2308be31/postgres-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fpostgres%2Fdao%2FPostgresQueueDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/postgres-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fpostgres%2Fdao%2FPostgresQueueDAO.java?ref=4eeaff71048191cdf48933129a131f7c2308be31",
      "patch": "@@ -21,12 +21,14 @@\n import java.sql.Connection;\n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.Executors;\n import java.util.concurrent.TimeUnit;\n import java.util.stream.Collectors;\n import javax.sql.DataSource;\n+import com.netflix.conductor.postgres.util.Query;\n \n public class PostgresQueueDAO extends PostgresBaseDAO implements QueueDAO {\n \n@@ -183,64 +185,67 @@ public Map<String, Map<String, Map<String, Long>>> queuesDetailVerbose() {\n \n     /**\n      * Un-pop all un-acknowledged messages for all queues.\n-     *\n+\n      * @since 1.11.6\n      */\n     public void processAllUnacks() {\n         logger.trace(\"processAllUnacks started\");\n \n         getWithRetriedTransactions(tx -> {\n-            String LOCK_TASKS = \"SELECT message_id FROM queue_message WHERE popped = true AND (deliver_on + (60 ||' seconds')::interval)  <  current_timestamp FOR UPDATE SKIP LOCKED\";\n+            String LOCK_TASKS = \"SELECT queue_name, message_id FROM queue_message WHERE popped = true AND (deliver_on + (60 ||' seconds')::interval)  <  current_timestamp limit 1000 FOR UPDATE SKIP LOCKED\";\n \n-            List<String> messages = query(tx, LOCK_TASKS, p -> p.executeAndFetch(rs -> {\n-                List<String> results = new ArrayList<>();\n+            List<QueueMessage> messages = query(tx, LOCK_TASKS, p -> p.executeAndFetch(rs -> {\n+            \tList<QueueMessage> results = new ArrayList<QueueMessage>();\n                 while (rs.next()) {\n-                    results.add(rs.getString(\"message_id\"));\n+                \tQueueMessage qm = new QueueMessage();\n+                \tqm.queueName = rs.getString(\"queue_name\");\n+                \tqm.messageId = rs.getString(\"message_id\");\n+                    results.add(qm);\n                 }\n                 return results;\n             }));\n \n             if (messages.size() == 0) {\n                 return 0;\n             }\n-            String msgIdsString = String.join(\",\", messages);\n \n-            final String PROCESS_UNACKS = \"UPDATE queue_message SET popped = false WHERE message_id IN (?)\";\n-            Integer unacked = query(tx, PROCESS_UNACKS, q -> q.addParameter(msgIdsString).executeUpdate());\n-            if (unacked > 0) {\n-                logger.debug(\"Unacked {} messages: {} from all queues\", unacked, messages);\n+            Map<String, List<String>> queueMessageMap = new HashMap<String, List<String>>();\n+            for(QueueMessage qm : messages) {\n+            \tif(!queueMessageMap.containsKey(qm.queueName)) {\n+            \t\tqueueMessageMap.put(qm.queueName, new ArrayList<String>());\n+            \t}\n+            \tqueueMessageMap.get(qm.queueName).add(qm.messageId);\n+            }\n+            \n+\t\t\tint totalUnacked = 0;\n+            for(String queueName : queueMessageMap.keySet()) {\n+    \t\t\tInteger unacked = 0;;\n+    \t\t\ttry {\n+                \tfinal List<String> msgIds = queueMessageMap.get(queueName);\n+    \t\t        final String UPDATE_POPPED = String.format(\n+    \t\t        \t\t\"UPDATE queue_message SET popped = false WHERE queue_name = ? and message_id IN (%s)\",\n+    \t\t                Query.generateInBindings(msgIds.size()));\n+\n+    \t\t\t\tunacked = query(tx, UPDATE_POPPED, q -> q.addParameter(queueName)\n+        \t\t\t\t\t.addParameters(msgIds).executeUpdate());\n+    \t\t\t} catch(Exception e) {\n+    \t\t\t\te.printStackTrace();\n+    \t\t\t}            \n+    \t\t\ttotalUnacked += unacked;\n+                logger.debug(\"Unacked {} messages from all queues\", unacked);\n+            }\n+\n+\t\t\tif (totalUnacked > 0) {\n+                logger.debug(\"Unacked {} messages from all queues\", totalUnacked);\n             }\n-            return unacked;\n+            return totalUnacked;\n         });\n     }\n \n     @Override\n     public void processUnacks(String queueName) {\n-        getWithRetriedTransactions(tx -> {\n-            String LOCK_TASKS = \"SELECT message_id FROM queue_message WHERE queue_name = ? AND popped = true AND (deliver_on + (60 ||' seconds')::interval)  <  current_timestamp FOR UPDATE SKIP LOCKED\";\n-\n-            List<String> messages = query(tx, LOCK_TASKS, p -> p.addParameter(queueName)\n-                .executeAndFetch(rs -> {\n-                    List<String> results = new ArrayList<>();\n-                    while (rs.next()) {\n-                        results.add(rs.getString(\"message_id\"));\n-                    }\n-                    return results;\n-                }));\n-\n-            if (messages.size() == 0) {\n-                return 0;\n-            }\n-            String msgIdsString = String.join(\",\", messages);\n-\n-            final String PROCESS_UNACKS = \"UPDATE queue_message SET popped = false WHERE queue_name = ? AND message_id IN (?)\";\n-            Integer unacked = query(tx, PROCESS_UNACKS,\n-                q -> q.addParameter(queueName).addParameter(msgIdsString).executeUpdate());\n-            if (unacked > 0) {\n-                logger.debug(\"Unacked {} messages: {} from queue: {}\", unacked, messages, queueName);\n-            }\n-            return unacked;\n-        });\n+        final String PROCESS_UNACKS = \"UPDATE queue_message SET popped = false WHERE queue_name = ? AND popped = true AND (current_timestamp - (60 ||' seconds')::interval)  > deliver_on\";\n+        executeWithTransaction(PROCESS_UNACKS, q -> q.addParameter(queueName).executeUpdate());\n     }\n \n     @Override\n@@ -339,4 +344,9 @@ private void createQueueIfNotExists(Connection connection, String queueName) {\n             execute(connection, CREATE_QUEUE, q -> q.addParameter(queueName).executeUpdate());\n         }\n     }\n+    \n+    private class QueueMessage {\n+    \tpublic String queueName;\n+    \tpublic String messageId;\n+    }\n }",
      "parent_sha": "9ba4793a1e693bfdaa2d7bae378fac6fbe990d2f"
    }
  },
  {
    "oid": "10a8ce5f7e66baeb9bdf146a504182343a2db85a",
    "message": "fixes formatting",
    "date": "2018-07-15T04:08:06Z",
    "url": "https://github.com/Netflix/conductor/commit/10a8ce5f7e66baeb9bdf146a504182343a2db85a",
    "details": {
      "sha": "3d8bdcacc67aa30e61daf639dd39aaed03d2e5ae",
      "filename": "client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java",
      "status": "modified",
      "additions": 7,
      "deletions": 7,
      "changes": 14,
      "blob_url": "https://github.com/Netflix/conductor/blob/10a8ce5f7e66baeb9bdf146a504182343a2db85a/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/10a8ce5f7e66baeb9bdf146a504182343a2db85a/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Ftask%2FWorkflowTaskCoordinator.java?ref=10a8ce5f7e66baeb9bdf146a504182343a2db85a",
      "patch": "@@ -273,15 +273,15 @@ public synchronized void init() {\n \t\t});\n \t}\n \n-    public void shutdown() {\n-        this.scheduledExecutorService.shutdown();\n-        this.executorService.shutdown();\n+    \tpublic void shutdown() {\n+        \tthis.scheduledExecutorService.shutdown();\n+        \tthis.executorService.shutdown();\n \n-        shutdownExecutorService(this.scheduledExecutorService, SHUTDOWN_WAIT_TIME_IN_SEC);\n-        shutdownExecutorService(this.executorService, SHUTDOWN_WAIT_TIME_IN_SEC);\n-    }\n+        \tshutdownExecutorService(this.scheduledExecutorService, SHUTDOWN_WAIT_TIME_IN_SEC);\n+        \tshutdownExecutorService(this.executorService, SHUTDOWN_WAIT_TIME_IN_SEC);\n+    \t}\n \n-    private void shutdownExecutorService(ExecutorService executorService, long timeout) {\n+    \tprivate void shutdownExecutorService(ExecutorService executorService, long timeout) {\n \t\ttry {\n \t\t\tif (executorService.awaitTermination(timeout, TimeUnit.SECONDS)) {\n \t\t\t\tlogger.debug(\"tasks completed, shutting down\");",
      "parent_sha": "4723993a227b7c3c05a188036579a6f7f058c26e"
    }
  },
  {
    "oid": "caaf639c69f7f90282a656e32ad9865784bfb474",
    "message": "fix workflow status in listener",
    "date": "2019-02-11T23:40:00Z",
    "url": "https://github.com/Netflix/conductor/commit/caaf639c69f7f90282a656e32ad9865784bfb474",
    "details": {
      "sha": "786a6888143ea6d18fbea7146b44caeeb4910e87",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/caaf639c69f7f90282a656e32ad9865784bfb474/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/caaf639c69f7f90282a656e32ad9865784bfb474/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=caaf639c69f7f90282a656e32ad9865784bfb474",
      "patch": "@@ -538,8 +538,8 @@ void completeWorkflow(Workflow wf) {\n         Monitors.recordWorkflowCompletion(workflow.getWorkflowName(), workflow.getEndTime() - workflow.getStartTime(), wf.getOwnerApp());\n         queueDAO.remove(DECIDER_QUEUE, workflow.getWorkflowId());    //remove from the sweep queue\n \n-        if (wf.getWorkflowDefinition().isWorkflowStatusListenerEnabled()) {\n-            workflowStatusListener.onWorkflowCompleted(wf);\n+        if (workflow.getWorkflowDefinition().isWorkflowStatusListenerEnabled()) {\n+            workflowStatusListener.onWorkflowCompleted(workflow);\n         }\n     }\n ",
      "parent_sha": "d7fbb3053bd2110a7f212f6ad3c30239a4c86f9a"
    }
  },
  {
    "oid": "16c634265086bff1dba5eabffa068c8352dc8654",
    "message": "reverted WorkflowExecutor.pushParentWorkflow changes from #2739, added log when subWorkflowChanged is reset.",
    "date": "2022-02-08T22:45:58Z",
    "url": "https://github.com/Netflix/conductor/commit/16c634265086bff1dba5eabffa068c8352dc8654",
    "details": {
      "sha": "48089faeba80610eebbb1883a63e9942ed784c4b",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 19,
      "deletions": 19,
      "changes": 38,
      "blob_url": "https://github.com/Netflix/conductor/blob/16c634265086bff1dba5eabffa068c8352dc8654/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/16c634265086bff1dba5eabffa068c8352dc8654/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=16c634265086bff1dba5eabffa068c8352dc8654",
      "patch": "@@ -44,7 +44,6 @@\n import com.netflix.conductor.core.utils.IDGenerator;\n import com.netflix.conductor.core.utils.ParametersUtils;\n import com.netflix.conductor.core.utils.QueueUtils;\n-import com.netflix.conductor.core.utils.Utils;\n import com.netflix.conductor.dao.MetadataDAO;\n import com.netflix.conductor.dao.QueueDAO;\n import com.netflix.conductor.metrics.Monitors;\n@@ -56,6 +55,7 @@\n import com.google.common.base.Preconditions;\n \n import static com.netflix.conductor.core.exception.ApplicationException.Code.*;\n+import static com.netflix.conductor.core.utils.Utils.DECIDER_QUEUE;\n import static com.netflix.conductor.model.TaskModel.Status.*;\n \n /** Workflow services provider interface */\n@@ -707,7 +707,7 @@ private void retry(WorkflowModel workflow) {\n         workflow.setReasonForIncompletion(null);\n         // Add to decider queue\n         queueDAO.push(\n-                Utils.DECIDER_QUEUE,\n+                DECIDER_QUEUE,\n                 workflow.getWorkflowId(),\n                 workflow.getPriority(),\n                 properties.getWorkflowOffsetTimeout().getSeconds());\n@@ -834,8 +834,7 @@ WorkflowModel completeWorkflow(WorkflowModel workflow) {\n         LOGGER.debug(\"Completing workflow execution for {}\", workflow.getWorkflowId());\n \n         if (workflow.getStatus().equals(WorkflowModel.Status.COMPLETED)) {\n-            queueDAO.remove(\n-                    Utils.DECIDER_QUEUE, workflow.getWorkflowId()); // remove from the sweep queue\n+            queueDAO.remove(DECIDER_QUEUE, workflow.getWorkflowId()); // remove from the sweep queue\n             executionDAOFacade.removeFromPendingWorkflow(\n                     workflow.getWorkflowName(), workflow.getWorkflowId());\n             LOGGER.debug(\"Workflow: {} has already been completed.\", workflow.getWorkflowId());\n@@ -1356,6 +1355,11 @@ private void adjustStateIfSubWorkflowChanged(WorkflowModel workflow) {\n             subWorkflowTask.setSubworkflowChanged(false);\n             executionDAOFacade.updateTask(subWorkflowTask);\n \n+            LOGGER.info(\n+                    \"{} reset subworkflowChanged flag for {}\",\n+                    workflow.toShortString(),\n+                    subWorkflowTask.getTaskId());\n+\n             // find all terminal and unsuccessful JOIN tasks and set them to IN_PROGRESS\n             if (workflow.getWorkflowDefinition().containsType(TaskType.TASK_TYPE_JOIN)\n                     || workflow.getWorkflowDefinition()\n@@ -1428,7 +1432,7 @@ List<String> cancelNonTerminalTasks(WorkflowModel workflow) {\n         if (erroredTasks.isEmpty()) {\n             try {\n                 workflowStatusListener.onWorkflowFinalizedIfEnabled(workflow);\n-                queueDAO.remove(Utils.DECIDER_QUEUE, workflow.getWorkflowId());\n+                queueDAO.remove(DECIDER_QUEUE, workflow.getWorkflowId());\n             } catch (Exception e) {\n                 LOGGER.error(\n                         \"Error removing workflow: {} from decider queue\",\n@@ -1483,7 +1487,7 @@ public void pauseWorkflow(String workflowId) {\n         // remove from the sweep queue\n         // any exceptions can be ignored, as this is not critical to the pause operation\n         try {\n-            queueDAO.remove(Utils.DECIDER_QUEUE, workflowId);\n+            queueDAO.remove(DECIDER_QUEUE, workflowId);\n         } catch (Exception e) {\n             LOGGER.info(\n                     \"[pauseWorkflow] Error removing workflow: {} from decider queue\",\n@@ -1510,7 +1514,7 @@ public void resumeWorkflow(String workflowId) {\n         workflow.setLastRetriedTime(System.currentTimeMillis());\n         // Add to decider queue\n         queueDAO.push(\n-                Utils.DECIDER_QUEUE,\n+                DECIDER_QUEUE,\n                 workflow.getWorkflowId(),\n                 workflow.getPriority(),\n                 properties.getWorkflowOffsetTimeout().getSeconds());\n@@ -1841,7 +1845,7 @@ private boolean rerunWF(\n             }\n \n             queueDAO.push(\n-                    Utils.DECIDER_QUEUE,\n+                    DECIDER_QUEUE,\n                     workflow.getWorkflowId(),\n                     workflow.getPriority(),\n                     properties.getWorkflowOffsetTimeout().getSeconds());\n@@ -1888,7 +1892,7 @@ private boolean rerunWF(\n             }\n             // Add to decider queue\n             queueDAO.push(\n-                    Utils.DECIDER_QUEUE,\n+                    DECIDER_QUEUE,\n                     workflow.getWorkflowId(),\n                     workflow.getPriority(),\n                     properties.getWorkflowOffsetTimeout().getSeconds());\n@@ -1990,20 +1994,16 @@ private void executeSubworkflowTaskAndSyncData(\n         WorkflowSystemTask subWorkflowSystemTask =\n                 systemTaskRegistry.get(TaskType.TASK_TYPE_SUB_WORKFLOW);\n         subWorkflowSystemTask.execute(subWorkflow, subWorkflowTask, this);\n-        // Keep Subworkflow task's data consistent with Subworkflow's.\n-        if (subWorkflowTask.getStatus().isTerminal()\n-                && subWorkflowTask.getExternalOutputPayloadStoragePath() != null\n-                && !subWorkflowTask.getOutputData().isEmpty()) {\n-            Map<String, Object> parentWorkflowTaskOutputData = subWorkflowTask.getOutputData();\n-            subWorkflowTask.getOutputData().putAll(parentWorkflowTaskOutputData);\n-        }\n     }\n \n     /** Pushes parent workflow id into the decider queue with a priority. */\n     private void pushParentWorkflow(String parentWorkflowId) {\n-        if (!queueDAO.containsMessage(Utils.DECIDER_QUEUE, parentWorkflowId)) {\n-            queueDAO.push(Utils.DECIDER_QUEUE, parentWorkflowId, PARENT_WF_PRIORITY, 0);\n-            LOGGER.info(\"Pushed parent workflow {} to {}\", parentWorkflowId, Utils.DECIDER_QUEUE);\n+        if (queueDAO.containsMessage(DECIDER_QUEUE, parentWorkflowId)) {\n+            queueDAO.postpone(DECIDER_QUEUE, parentWorkflowId, PARENT_WF_PRIORITY, 0);\n+        } else {\n+            queueDAO.push(DECIDER_QUEUE, parentWorkflowId, PARENT_WF_PRIORITY, 0);\n         }\n+\n+        LOGGER.info(\"Pushed parent workflow {} to {}\", parentWorkflowId, DECIDER_QUEUE);\n     }\n }",
      "parent_sha": "8c7742a83a8c906fffa745693a6c13843264de5c"
    }
  },
  {
    "oid": "e3fd284e95453dbebbbaaa5492780f73ac619f81",
    "message": "updated MySQLWorkflowModule.java to support connection pool",
    "date": "2018-07-09T17:53:28Z",
    "url": "https://github.com/Netflix/conductor/commit/e3fd284e95453dbebbbaaa5492780f73ac619f81",
    "details": {
      "sha": "d28cdafdd4cede3e6ac504385f1d2219802a5c9b",
      "filename": "mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLWorkflowModule.java",
      "status": "modified",
      "additions": 12,
      "deletions": 4,
      "changes": 16,
      "blob_url": "https://github.com/Netflix/conductor/blob/e3fd284e95453dbebbbaaa5492780f73ac619f81/mysql-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fmysql%2FMySQLWorkflowModule.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/e3fd284e95453dbebbbaaa5492780f73ac619f81/mysql-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fmysql%2FMySQLWorkflowModule.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/mysql-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fmysql%2FMySQLWorkflowModule.java?ref=e3fd284e95453dbebbbaaa5492780f73ac619f81",
      "patch": "@@ -1,5 +1,11 @@\n package com.netflix.conductor.dao.mysql;\n \n+import javax.sql.DataSource;\n+\n+import org.flywaydb.core.Flyway;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import com.google.inject.AbstractModule;\n import com.google.inject.Provides;\n import com.google.inject.Singleton;\n@@ -8,10 +14,6 @@\n import com.netflix.conductor.dao.MetadataDAO;\n import com.netflix.conductor.dao.QueueDAO;\n import com.zaxxer.hikari.HikariDataSource;\n-import javax.sql.DataSource;\n-import org.flywaydb.core.Flyway;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n \n /**\n  * @author mustafa\n@@ -27,6 +29,12 @@ public DataSource getDataSource(Configuration config) {\n         dataSource.setUsername(config.getProperty(\"jdbc.username\", \"conductor\"));\n         dataSource.setPassword(config.getProperty(\"jdbc.password\", \"password\"));\n         dataSource.setAutoCommit(false);\n+        \n+        dataSource.setMaximumPoolSize(config.getIntProperty(\"jdbc.maxPoolSize\", 20));\n+        dataSource.setMinimumIdle(config.getIntProperty(\"jdbc.minIdleSize\", 5));\n+        dataSource.setIdleTimeout(config.getIntProperty(\"jdbc.idleTimeout\", 1000*300));\n+        dataSource.setTransactionIsolation(config.getProperty(\"jdbc.isolationLevel\", \"TRANSACTION_REPEATABLE_READ\"));\n+        \n         flywayMigrate(config, dataSource);\n \n         return dataSource;",
      "parent_sha": "f888bb35fa8263f4f432df0daca09ae62bbf9c7e"
    }
  },
  {
    "oid": "b63c5744b0ff7536d43f76b1c0f624a6cddce641",
    "message": "unit test fix.",
    "date": "2019-07-12T15:11:57Z",
    "url": "https://github.com/Netflix/conductor/commit/b63c5744b0ff7536d43f76b1c0f624a6cddce641",
    "details": {
      "sha": "aa2147081593c973cfd81dcc82b4b9d0d4d29c0e",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java",
      "status": "modified",
      "additions": 16,
      "deletions": 1,
      "changes": 17,
      "blob_url": "https://github.com/Netflix/conductor/blob/b63c5744b0ff7536d43f76b1c0f624a6cddce641/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/b63c5744b0ff7536d43f76b1c0f624a6cddce641/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java?ref=b63c5744b0ff7536d43f76b1c0f624a6cddce641",
      "patch": "@@ -1,11 +1,13 @@\n package com.netflix.conductor.core.execution.tasks;\n \n import com.netflix.conductor.common.metadata.tasks.Task;\n+import com.netflix.conductor.common.metadata.tasks.TaskDef;\n import com.netflix.conductor.common.metadata.workflow.TaskType;\n import com.netflix.conductor.common.metadata.workflow.WorkflowTask;\n import com.netflix.conductor.common.run.Workflow;\n import com.netflix.conductor.core.config.Configuration;\n import com.netflix.conductor.core.execution.DeciderService;\n+import com.netflix.conductor.core.execution.ParametersUtils;\n import com.netflix.conductor.core.execution.WorkflowExecutor;\n import com.netflix.conductor.core.execution.WorkflowStatusListener;\n import com.netflix.conductor.core.metadata.MetadataMapperService;\n@@ -19,7 +21,11 @@\n import org.mockito.Mockito;\n \n import java.util.Arrays;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.isA;\n import static org.mockito.Mockito.spy;\n \n /**\n@@ -45,14 +51,16 @@ public class DoWhileTest {\n     ExecutionDAOFacade executionDAOFacade;\n     ExternalPayloadStorageUtils externalPayloadStorageUtils;\n     Configuration config;\n+    ParametersUtils parametersUtils;\n \n \n     @Before\n     public void setup() {\n-        workflow = new Workflow();\n+        workflow = Mockito.mock(Workflow.class);\n         deciderService = Mockito.mock(DeciderService.class);\n         metadataDAO = Mockito.mock(MetadataDAO.class);\n         queueDAO = Mockito.mock(QueueDAO.class);\n+        parametersUtils = Mockito.mock(ParametersUtils.class);\n         metadataMapperService = Mockito.mock(MetadataMapperService.class);\n         workflowStatusListener = Mockito.mock(WorkflowStatusListener.class);\n         executionDAOFacade = Mockito.mock(ExecutionDAOFacade.class);\n@@ -62,8 +70,10 @@ public void setup() {\n                 workflowStatusListener, executionDAOFacade, externalPayloadStorageUtils, config));\n         loopWorkflowTask1 = new WorkflowTask();\n         loopWorkflowTask1.setTaskReferenceName(\"task1\");\n+        loopWorkflowTask1.setName(\"task1\");\n         loopWorkflowTask2 = new WorkflowTask();\n         loopWorkflowTask2.setTaskReferenceName(\"task2\");\n+        loopWorkflowTask2.setName(\"task2\");\n         task1 = new Task();\n         task1.setWorkflowTask(loopWorkflowTask1);\n         task1.setReferenceTaskName(\"task1\");\n@@ -79,11 +89,16 @@ public void setup() {\n         loopTask.setTaskType(TaskType.DO_WHILE.name());\n         loopWorkflowTask = new WorkflowTask();\n         loopWorkflowTask.setTaskReferenceName(\"loopTask\");\n+        loopWorkflowTask.setName(\"loopTask\");\n         loopWorkflowTask.setLoopCondition(\"if ($.loopTask['iteration'] < 1) { false; } else { true; }\");\n         loopWorkflowTask.setLoopOver(Arrays.asList(task1.getWorkflowTask(), task2.getWorkflowTask()));\n         loopTask.setWorkflowTask(loopWorkflowTask);\n         doWhile = new DoWhile();\n         workflow.setTasks(Arrays.asList(task1, task2, loopTask));\n+        Mockito.doReturn(new TaskDef()).when(provider).getTaskDefinition(loopTask);\n+        Mockito.doReturn(task1).when(workflow).getTaskByRefName(task1.getReferenceTaskName());\n+        Mockito.doReturn(task2).when(workflow).getTaskByRefName(task2.getReferenceTaskName());\n+        Mockito.doReturn(new HashMap<>()).when(parametersUtils).getTaskInputV2(isA(Map.class), isA(Workflow.class), isA(String.class), isA(TaskDef.class));\n     }\n \n ",
      "parent_sha": "4e7a19bea37480a56e568a2f94f818d4400285be"
    }
  },
  {
    "oid": "e4b5e3c823becad83e8bed7e69d5e2879d3de604",
    "message": "Make fields and methods protected for override ability (#3255)",
    "date": "2022-10-03T21:25:43Z",
    "url": "https://github.com/Netflix/conductor/commit/e4b5e3c823becad83e8bed7e69d5e2879d3de604",
    "details": {
      "sha": "50bf1a3705da77a2e5837453ac2d4bc4aff4f527",
      "filename": "cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraExecutionDAO.java",
      "status": "modified",
      "additions": 28,
      "deletions": 28,
      "changes": 56,
      "blob_url": "https://github.com/Netflix/conductor/blob/e4b5e3c823becad83e8bed7e69d5e2879d3de604/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcassandra%2Fdao%2FCassandraExecutionDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/e4b5e3c823becad83e8bed7e69d5e2879d3de604/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcassandra%2Fdao%2FCassandraExecutionDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcassandra%2Fdao%2FCassandraExecutionDAO.java?ref=e4b5e3c823becad83e8bed7e69d5e2879d3de604",
      "patch": "@@ -47,32 +47,32 @@ public class CassandraExecutionDAO extends CassandraBaseDAO\n     private static final Logger LOGGER = LoggerFactory.getLogger(CassandraExecutionDAO.class);\n     private static final String CLASS_NAME = CassandraExecutionDAO.class.getSimpleName();\n \n-    private final PreparedStatement insertWorkflowStatement;\n-    private final PreparedStatement insertTaskStatement;\n-    private final PreparedStatement insertEventExecutionStatement;\n-\n-    private final PreparedStatement selectTotalStatement;\n-    private final PreparedStatement selectTaskStatement;\n-    private final PreparedStatement selectWorkflowStatement;\n-    private final PreparedStatement selectWorkflowWithTasksStatement;\n-    private final PreparedStatement selectTaskLookupStatement;\n-    private final PreparedStatement selectTasksFromTaskDefLimitStatement;\n-    private final PreparedStatement selectEventExecutionsStatement;\n-\n-    private final PreparedStatement updateWorkflowStatement;\n-    private final PreparedStatement updateTotalTasksStatement;\n-    private final PreparedStatement updateTotalPartitionsStatement;\n-    private final PreparedStatement updateTaskLookupStatement;\n-    private final PreparedStatement updateTaskDefLimitStatement;\n-    private final PreparedStatement updateEventExecutionStatement;\n-\n-    private final PreparedStatement deleteWorkflowStatement;\n-    private final PreparedStatement deleteTaskStatement;\n-    private final PreparedStatement deleteTaskLookupStatement;\n-    private final PreparedStatement deleteTaskDefLimitStatement;\n-    private final PreparedStatement deleteEventExecutionStatement;\n-\n-    private final int eventExecutionsTTL;\n+    protected final PreparedStatement insertWorkflowStatement;\n+    protected final PreparedStatement insertTaskStatement;\n+    protected final PreparedStatement insertEventExecutionStatement;\n+\n+    protected final PreparedStatement selectTotalStatement;\n+    protected final PreparedStatement selectTaskStatement;\n+    protected final PreparedStatement selectWorkflowStatement;\n+    protected final PreparedStatement selectWorkflowWithTasksStatement;\n+    protected final PreparedStatement selectTaskLookupStatement;\n+    protected final PreparedStatement selectTasksFromTaskDefLimitStatement;\n+    protected final PreparedStatement selectEventExecutionsStatement;\n+\n+    protected final PreparedStatement updateWorkflowStatement;\n+    protected final PreparedStatement updateTotalTasksStatement;\n+    protected final PreparedStatement updateTotalPartitionsStatement;\n+    protected final PreparedStatement updateTaskLookupStatement;\n+    protected final PreparedStatement updateTaskDefLimitStatement;\n+    protected final PreparedStatement updateEventExecutionStatement;\n+\n+    protected final PreparedStatement deleteWorkflowStatement;\n+    protected final PreparedStatement deleteTaskStatement;\n+    protected final PreparedStatement deleteTaskLookupStatement;\n+    protected final PreparedStatement deleteTaskDefLimitStatement;\n+    protected final PreparedStatement deleteEventExecutionStatement;\n+\n+    protected final int eventExecutionsTTL;\n \n     public CassandraExecutionDAO(\n             Session session,\n@@ -751,7 +751,7 @@ public void removeTaskFromLimit(TaskModel task) {\n         }\n     }\n \n-    private boolean removeTask(TaskModel task) {\n+    protected boolean removeTask(TaskModel task) {\n         // TODO: calculate shard number based on seq and maxTasksPerShard\n         try {\n             // get total tasks for this workflow\n@@ -788,7 +788,7 @@ private boolean removeTask(TaskModel task) {\n         }\n     }\n \n-    private void removeTaskLookup(TaskModel task) {\n+    protected void removeTaskLookup(TaskModel task) {\n         try {\n             recordCassandraDaoRequests(\n                     \"removeTaskLookup\", task.getTaskType(), task.getWorkflowType());",
      "parent_sha": "c306bf8d7c6e1c2261736e34c10003e6aba5df4b"
    }
  },
  {
    "oid": "307fade96f0c320211f251749995236c4834a75d",
    "message": "updated test to account for the change in TaskResource method signature",
    "date": "2021-02-25T18:35:15Z",
    "url": "https://github.com/Netflix/conductor/commit/307fade96f0c320211f251749995236c4834a75d",
    "details": {
      "sha": "11933dd62e783aa82f940e765de8fce8634f6c23",
      "filename": "rest/src/test/java/com/netflix/conductor/rest/controllers/TaskResourceTest.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/307fade96f0c320211f251749995236c4834a75d/rest%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Frest%2Fcontrollers%2FTaskResourceTest.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/307fade96f0c320211f251749995236c4834a75d/rest%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Frest%2Fcontrollers%2FTaskResourceTest.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/rest%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Frest%2Fcontrollers%2FTaskResourceTest.java?ref=307fade96f0c320211f251749995236c4834a75d",
      "patch": "@@ -59,7 +59,7 @@ public void testPoll() {\n         task.setDomain(\"test\");\n \n         when(mockTaskService.poll(anyString(), anyString(), anyString())).thenReturn(task);\n-        assertEquals(task, taskResource.poll(\"SIMPLE\", \"123\", \"test\"));\n+        assertEquals(ResponseEntity.ok(task), taskResource.poll(\"SIMPLE\", \"123\", \"test\"));\n     }\n \n     @Test\n@@ -73,7 +73,7 @@ public void testBatchPoll() {\n \n         when(mockTaskService.batchPoll(anyString(), anyString(), anyString(), anyInt(), anyInt()))\n             .thenReturn(listOfTasks);\n-        assertEquals(listOfTasks, taskResource.batchPoll(\"SIMPLE\", \"123\",\n+        assertEquals(ResponseEntity.ok(listOfTasks), taskResource.batchPoll(\"SIMPLE\", \"123\",\n             \"test\", 1, 100));\n     }\n ",
      "parent_sha": "facec91e85bfd3741ccc7066073836d6fd89f8a1"
    }
  },
  {
    "oid": "ec89a398f9a496557f75d0d1865fec003d098b20",
    "message": "Changed executorService from static variable to member variable",
    "date": "2018-01-10T00:49:33Z",
    "url": "https://github.com/Netflix/conductor/commit/ec89a398f9a496557f75d0d1865fec003d098b20",
    "details": {
      "sha": "805c5b399e39f1166ea710aa83989cecfd07f3c1",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java",
      "status": "modified",
      "additions": 9,
      "deletions": 6,
      "changes": 15,
      "blob_url": "https://github.com/Netflix/conductor/blob/ec89a398f9a496557f75d0d1865fec003d098b20/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/ec89a398f9a496557f75d0d1865fec003d098b20/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java?ref=ec89a398f9a496557f75d0d1865fec003d098b20",
      "patch": "@@ -122,15 +122,10 @@ public class ElasticSearchDAO implements IndexDAO {\n \t    \n     private static final SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMWW\");\n \n-\tprivate static final ExecutorService executorService;\n+\tprivate final ExecutorService executorService;\n \t\n     static {\n     \tsdf.setTimeZone(gmt);\n-\t    executorService = new ThreadPoolExecutor(6,\n-\t                                             12,\n-\t                                             60L,\n-\t                                             TimeUnit.SECONDS,\n-\t                                             new LinkedBlockingQueue<>());\n     }\n \t\n \t@Inject\n@@ -148,6 +143,14 @@ public ElasticSearchDAO(Client client, Configuration config, ObjectMapper om) {\n \t\t} catch (Exception e) {\n \t\t\tlog.error(e.getMessage(), e);\n \t\t}\n+\t\tint corePoolSize = 6;\n+\t\tint maximumPoolSize = 12;\n+\t\tlong keepAliveTime = 1L;\n+\t\tthis.executorService = new ThreadPoolExecutor(corePoolSize,\n+\t\t                                              maximumPoolSize,\n+\t\t                                              keepAliveTime,\n+\t\t                                              TimeUnit.MINUTES,\n+\t\t                                              new LinkedBlockingQueue<>());\n \t}\n \t\n \tprivate void updateIndexName(Configuration config) {",
      "parent_sha": "1c8c0a680928901327903c717c2b60bcf6173b9f"
    }
  },
  {
    "oid": "b53d6057f96721530d4fe62cddd3430ee9662f20",
    "message": "fix error message",
    "date": "2018-09-19T20:15:45Z",
    "url": "https://github.com/Netflix/conductor/commit/b53d6057f96721530d4fe62cddd3430ee9662f20",
    "details": {
      "sha": "23cff1e7dfafc4d4eb4af3598b8fe69ee322e74a",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/b53d6057f96721530d4fe62cddd3430ee9662f20/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/b53d6057f96721530d4fe62cddd3430ee9662f20/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=b53d6057f96721530d4fe62cddd3430ee9662f20",
      "patch": "@@ -652,7 +652,7 @@ public void pauseWorkflow(String workflowId) {\n     public void resumeWorkflow(String workflowId) {\n         Workflow workflow = executionDAO.getWorkflow(workflowId, false);\n         if (!workflow.getStatus().equals(WorkflowStatus.PAUSED)) {\n-            throw new IllegalStateException(\"The workflow \" + workflowId + \" is PAUSED so cannot resume\");\n+            throw new IllegalStateException(\"The workflow \" + workflowId + \" is not PAUSED so cannot resume\");\n         }\n         workflow.setStatus(WorkflowStatus.RUNNING);\n         executionDAO.updateWorkflow(workflow);",
      "parent_sha": "31ef58d0994c1e3dcb3eebc3726d1fedad09896b"
    }
  },
  {
    "oid": "319e2ba3a4a77b51f0e1ab93ad6182653dd932cd",
    "message": "fix the json formatting",
    "date": "2017-02-09T23:09:01Z",
    "url": "https://github.com/Netflix/conductor/commit/319e2ba3a4a77b51f0e1ab93ad6182653dd932cd",
    "details": {
      "sha": "be3374b16f7c2ddc5781229e9e8281825a3c38d8",
      "filename": "jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/319e2ba3a4a77b51f0e1ab93ad6182653dd932cd/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/319e2ba3a4a77b51f0e1ab93ad6182653dd932cd/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java?ref=319e2ba3a4a77b51f0e1ab93ad6182653dd932cd",
      "patch": "@@ -122,7 +122,7 @@ public String updateTask(TaskResult task) throws Exception {\n \t@ApiOperation(\"Ack Task is recieved\")\n \t@Consumes({ MediaType.WILDCARD })\n \tpublic String ack(@PathParam(\"taskId\") String taskId, @QueryParam(\"workerid\") String workerId) throws Exception {\n-\t\treturn \"\\\"\" + taskService.ackTaskRecieved(taskId, workerId) + \"\\\"\";\n+\t\treturn \"\" + taskService.ackTaskRecieved(taskId, workerId);\n \t}\n \n \t@GET",
      "parent_sha": "80f7b881e80eeef57f0a00fc8b4f5a9d03e4e552"
    }
  },
  {
    "oid": "b57eed8ec470091bce73ee21749f25a753efb092",
    "message": "rename task name",
    "date": "2019-02-14T06:51:05Z",
    "url": "https://github.com/Netflix/conductor/commit/b57eed8ec470091bce73ee21749f25a753efb092",
    "details": {
      "sha": "00c0d05777f31b9c17e44099236a2980af7c3c7e",
      "filename": "contribs/src/main/java/com/netflix/conductor/contribs/lambda/Lambda.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/b57eed8ec470091bce73ee21749f25a753efb092/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/b57eed8ec470091bce73ee21749f25a753efb092/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java?ref=b57eed8ec470091bce73ee21749f25a753efb092",
      "patch": "@@ -19,8 +19,8 @@ public class Lambda extends WorkflowSystemTask {\n     private static final String QUERY_EXPRESSION_PARAMETER = \"scriptExpression\";\n \n     public Lambda() {\n-        super(\"SCRIPT_TASK\");\n-        logger.info(\"SCRIPT_TASK initialized...\");\n+        super(\"LAMBDA\");\n+        logger.info(\"LAMBDA task initialized...\");\n     }\n \n ",
      "parent_sha": "9d6e045b623a37e58339dc88b05416b7d7531b9c"
    }
  },
  {
    "oid": "f6dbe6209b01deb3093ceb1b3e3afe19bc4b17e7",
    "message": "during skipTaskFromWorkflow, decide is performed inside a lock",
    "date": "2022-09-02T18:46:09Z",
    "url": "https://github.com/Netflix/conductor/commit/f6dbe6209b01deb3093ceb1b3e3afe19bc4b17e7",
    "details": {
      "sha": "ae2d71d517d53ff2b29523126304fe72894cc552",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/f6dbe6209b01deb3093ceb1b3e3afe19bc4b17e7/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/f6dbe6209b01deb3093ceb1b3e3afe19bc4b17e7/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FWorkflowExecutor.java?ref=f6dbe6209b01deb3093ceb1b3e3afe19bc4b17e7",
      "patch": "@@ -1619,7 +1619,7 @@ public void skipTaskFromWorkflow(\n             taskToBeSkipped.setOutputMessage(skipTaskRequest.getTaskOutputMessage());\n         }\n         executionDAOFacade.createTasks(Collections.singletonList(taskToBeSkipped));\n-        decide(workflow);\n+        decide(workflow.getWorkflowId());\n     }\n \n     public WorkflowModel getWorkflow(String workflowId, boolean includeTasks) {",
      "parent_sha": "b17ede74a095abc42e7c44bfef7406f00af560e8"
    }
  },
  {
    "oid": "b366e558aaae084ea8a3cd092da2f28ac26789bd",
    "message": "comment out the test - need to be re-written for updated code.",
    "date": "2017-10-12T17:52:54Z",
    "url": "https://github.com/Netflix/conductor/commit/b366e558aaae084ea8a3cd092da2f28ac26789bd",
    "details": {
      "sha": "ffa4a164ae110834ddcfa852940133dd6dc4f9ad",
      "filename": "redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAOTest.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/b366e558aaae084ea8a3cd092da2f28ac26789bd/redis-persistence%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisExecutionDAOTest.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/b366e558aaae084ea8a3cd092da2f28ac26789bd/redis-persistence%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisExecutionDAOTest.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fdynomite%2FRedisExecutionDAOTest.java?ref=b366e558aaae084ea8a3cd092da2f28ac26789bd",
      "patch": "@@ -518,10 +518,11 @@ public void test() throws Exception {\n \t\t\tdao.createWorkflow(workflow);\n \t\t}\n \n+\t\t/*\n \t\tList<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId(\"corr001\");\n \t\tassertNotNull(bycorrelationId);\n \t\tassertEquals(10, bycorrelationId.size());\n-\n+\t\t */\n \t\tlong count = dao.getPendingWorkflowCount(workflowName);\n \t\tassertEquals(10, count);\n ",
      "parent_sha": "bd124d40ba9f010254ca296cab9bb30ffb6ed04a"
    }
  },
  {
    "oid": "0031d2128d46769ccc90770c613774588ce81cb9",
    "message": "javadoc",
    "date": "2019-03-07T14:01:52Z",
    "url": "https://github.com/Netflix/conductor/commit/0031d2128d46769ccc90770c613774588ce81cb9",
    "details": {
      "sha": "598ffa04b170d2e94ddf0503d21ef4829b19b09b",
      "filename": "contribs/src/main/java/com/netflix/conductor/contribs/listener/DynoQueueStatusPublisher.java",
      "status": "modified",
      "additions": 3,
      "deletions": 4,
      "changes": 7,
      "blob_url": "https://github.com/Netflix/conductor/blob/0031d2128d46769ccc90770c613774588ce81cb9/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flistener%2FDynoQueueStatusPublisher.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/0031d2128d46769ccc90770c613774588ce81cb9/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flistener%2FDynoQueueStatusPublisher.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flistener%2FDynoQueueStatusPublisher.java?ref=0031d2128d46769ccc90770c613774588ce81cb9",
      "patch": "@@ -32,7 +32,9 @@\n import javax.inject.Inject;\n import java.util.Collections;\n \n-\n+/**\n+ * Publishes a @see Message containing a @see WorkflowSummary to a DynoQueue on a workflow completion or termination event.\n+ */\n public class DynoQueueStatusPublisher implements WorkflowStatusListener {\n \n     private static final Logger LOG = LoggerFactory.getLogger(DynoQueueStatusPublisher.class);\n@@ -42,9 +44,6 @@ public class DynoQueueStatusPublisher implements WorkflowStatusListener {\n     private final String successStatusQueue;\n     private final String failureStatusQueue;\n \n-    /**\n-     * Publishes a message containing a WorkflowSummary on a configured DynoQueue on workflow completion or termination.\n-     */\n     @Inject\n     public DynoQueueStatusPublisher(QueueDAO queueDAO, ObjectMapper objectMapper, Configuration config) {\n         this.queueDAO = queueDAO;",
      "parent_sha": "5da74e7eb8252fb61a721889ff258dba3efcadae"
    }
  },
  {
    "oid": "16a9e51291ae0df9693dcb4620957f4d5cc1756e",
    "message": "A recent change means this endpoint no longer returns a JSON string. This change allows plain text responses for clients that cannot parse the returned value as JSON. Leaving the `MediaType.APPLICATION_JSON` means clients that are still requesting JSON should not break with the change.",
    "date": "2018-09-19T07:13:50Z",
    "url": "https://github.com/Netflix/conductor/commit/16a9e51291ae0df9693dcb4620957f4d5cc1756e",
    "details": {
      "sha": "ca0fb165f2e87f1045ce0ba50f29228b7ad479cc",
      "filename": "jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java",
      "status": "modified",
      "additions": 6,
      "deletions": 5,
      "changes": 11,
      "blob_url": "https://github.com/Netflix/conductor/blob/16a9e51291ae0df9693dcb4620957f4d5cc1756e/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/16a9e51291ae0df9693dcb4620957f4d5cc1756e/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/jersey%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2Fresources%2FTaskResource.java?ref=16a9e51291ae0df9693dcb4620957f4d5cc1756e",
      "patch": "@@ -44,7 +44,7 @@\n import java.util.Map;\n \n /**\n- * \n+ *\n  * @author visingh\n  *\n  */\n@@ -107,6 +107,7 @@ public Task getPendingTaskForWorkflow(@PathParam(\"workflowId\") String workflowId\n \n \t@POST\n \t@ApiOperation(\"Update a task\")\n+    @Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})\n \tpublic String updateTask(TaskResult taskResult) {\n \t\treturn taskService.updateTask(taskResult);\n \t}\n@@ -119,14 +120,14 @@ public String ack(@PathParam(\"taskId\") String taskId,\n                       @QueryParam(\"workerid\") String workerId) {\n \t\treturn taskService.ackTaskReceived(taskId, workerId);\n \t}\n-\t\n+\n \t@POST\n \t@Path(\"/{taskId}/log\")\n \t@ApiOperation(\"Log Task Execution Details\")\n \tpublic void log(@PathParam(\"taskId\") String taskId, String log) {\n         taskService.log(taskId, log);\n \t}\n-\t\n+\n \t@GET\n \t@Path(\"/{taskId}/log\")\n \t@ApiOperation(\"Get Task Execution Logs\")\n@@ -197,7 +198,7 @@ public List<PollData> getAllPollData() {\n \tpublic String requeue() {\n \t\treturn taskService.requeue();\n \t}\n-\t\n+\n \t@POST\n \t@Path(\"/queue/requeue/{taskType}\")\n \t@ApiOperation(\"Requeue pending tasks\")\n@@ -206,7 +207,7 @@ public String requeue() {\n \tpublic String requeuePendingTask(@PathParam(\"taskType\") String taskType) {\n \t\treturn taskService.requeuePendingTask(taskType);\n \t}\n-\t\n+\n \t@ApiOperation(value=\"Search for tasks based in payload and other parameters\",\n             notes=\"use sort options as sort=<field>:ASC|DESC e.g. sort=name&sort=workflowId:DESC.\" +\n                     \" If order is not specified, defaults to ASC\")",
      "parent_sha": "31ef58d0994c1e3dcb3eebc3726d1fedad09896b"
    }
  },
  {
    "oid": "4f53c7d7a396443e3bce1cbc7e709aab11be5646",
    "message": "record metric only when workflow is found",
    "date": "2018-12-28T00:24:25Z",
    "url": "https://github.com/Netflix/conductor/commit/4f53c7d7a396443e3bce1cbc7e709aab11be5646",
    "details": {
      "sha": "c6ac1f7e8e8b567b7af912289280b3f05ce351da",
      "filename": "cassandra-persistence/src/main/java/com/netflix/conductor/dao/cassandra/CassandraExecutionDAO.java",
      "status": "modified",
      "additions": 9,
      "deletions": 3,
      "changes": 12,
      "blob_url": "https://github.com/Netflix/conductor/blob/4f53c7d7a396443e3bce1cbc7e709aab11be5646/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fcassandra%2FCassandraExecutionDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/4f53c7d7a396443e3bce1cbc7e709aab11be5646/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fcassandra%2FCassandraExecutionDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/cassandra-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fcassandra%2FCassandraExecutionDAO.java?ref=4f53c7d7a396443e3bce1cbc7e709aab11be5646",
      "patch": "@@ -371,14 +371,20 @@ public Workflow getWorkflow(String workflowId, boolean includeTasks) {\n                     }\n                 }\n \n-                workflow.setTasks(tasks);\n+                if (workflow != null) {\n+                    recordCassandraDaoRequests(\"getWorkflow\", \"n/a\", workflow.getWorkflowName());\n+                    workflow.setTasks(tasks);\n+                }\n             } else {\n                 resultSet = session.execute(selectWorkflowStatement.bind(UUID.fromString(workflowId)));\n                 workflow = Optional.ofNullable(resultSet.one())\n-                        .map(row -> readValue(row.getString(PAYLOAD_KEY), Workflow.class))\n+                        .map(row -> {\n+                            Workflow wf = readValue(row.getString(PAYLOAD_KEY), Workflow.class);\n+                            recordCassandraDaoRequests(\"getWorkflow\", \"n/a\", wf.getWorkflowName());\n+                            return wf;\n+                        })\n                         .orElse(null);\n             }\n-            recordCassandraDaoRequests(\"getWorkflow\", \"n/a\", workflow.getWorkflowName());\n             return workflow;\n         } catch (ApplicationException e) {\n             throw e;",
      "parent_sha": "3298882e03ce2013ccecd46dc38783f02fd506c7"
    }
  },
  {
    "oid": "576a6f3ee4a987c050ee2b04514a1fb9b2b0c0c5",
    "message": "Add an optional description in WorkflowTask model",
    "date": "2017-07-18T15:13:46Z",
    "url": "https://github.com/Netflix/conductor/commit/576a6f3ee4a987c050ee2b04514a1fb9b2b0c0c5",
    "details": {
      "sha": "029d6f745677ee28bc2f51cc57fc743af54a64ac",
      "filename": "common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java",
      "status": "modified",
      "additions": 17,
      "deletions": 1,
      "changes": 18,
      "blob_url": "https://github.com/Netflix/conductor/blob/576a6f3ee4a987c050ee2b04514a1fb9b2b0c0c5/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Fworkflow%2FWorkflowTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/576a6f3ee4a987c050ee2b04514a1fb9b2b0c0c5/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Fworkflow%2FWorkflowTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fmetadata%2Fworkflow%2FWorkflowTask.java?ref=576a6f3ee4a987c050ee2b04514a1fb9b2b0c0c5",
      "patch": "@@ -59,7 +59,9 @@ public static boolean is(String name) {\n \tprivate String name;\n \t\n \tprivate String taskReferenceName;\n-\t\n+\n+\tprivate String description;\n+\n \t//Key: Name of the input parameter.  MUST be one of the keys defined in TaskDef (e.g. fileName)\n \t//Value: mapping of the parameter from another task (e.g. task1.someOutputParameterAsFileName)\n \tprivate Map<String, Object> inputParameters = new HashMap<String, Object>();\n@@ -124,6 +126,20 @@ public void setTaskReferenceName(String taskReferenceName) {\n \t\tthis.taskReferenceName = taskReferenceName;\n \t}\n \n+\t/**\n+\t * @return the description\n+\t */\n+\tpublic String getDescription() {\n+\t\treturn description;\n+\t}\n+\n+\t/**\n+\t * @param description the description to set\n+\t */\n+\tpublic void setDescription(String description) {\n+\t\tthis.description = description;\n+\t}\n+\n \t/**\n \t * @return the inputParameters\n \t */",
      "parent_sha": "4ddae05a6fe671d29788cfb934687dd99e75195a"
    }
  },
  {
    "oid": "b46309bcdd29b4d4be2848121e56c7d993817556",
    "message": "fix unit tes.",
    "date": "2020-01-07T17:04:59Z",
    "url": "https://github.com/Netflix/conductor/commit/b46309bcdd29b4d4be2848121e56c7d993817556",
    "details": {
      "sha": "e717456c5fa93719a92f97705f289acbe716a1b1",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/b46309bcdd29b4d4be2848121e56c7d993817556/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/b46309bcdd29b4d4be2848121e56c7d993817556/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestDeciderService.java?ref=b46309bcdd29b4d4be2848121e56c7d993817556",
      "patch": "@@ -736,7 +736,7 @@ public void testDecideWithLoopTask() {\n         assertEquals(1, deciderOutcome.tasksToBeUpdated.size());\n         assertEquals(\"s1\", deciderOutcome.tasksToBeUpdated.get(0).getReferenceTaskName());\n         assertEquals(1, deciderOutcome.tasksToBeScheduled.size());\n-        assertEquals(\"s2__1\", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());\n+        assertEquals(\"s2\", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());\n         assertEquals(0, deciderOutcome.tasksToBeRequeued.size());\n         assertFalse(deciderOutcome.isComplete);\n     }",
      "parent_sha": "6965b85259282c232d52ddd71f17a23f0e2d7775"
    }
  },
  {
    "oid": "ca18e9436c17c10f110bc69c6d49d81135d7e0bf",
    "message": "update formatting",
    "date": "2023-03-03T20:41:35Z",
    "url": "https://github.com/Netflix/conductor/commit/ca18e9436c17c10f110bc69c6d49d81135d7e0bf",
    "details": {
      "sha": "0cbed1c5dd265d1d23de4946e758dae61bd01a7a",
      "filename": "json-jq-task/src/main/java/com/netflix/conductor/tasks/json/JsonJqTransform.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/ca18e9436c17c10f110bc69c6d49d81135d7e0bf/json-jq-task%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftasks%2Fjson%2FJsonJqTransform.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/ca18e9436c17c10f110bc69c6d49d81135d7e0bf/json-jq-task%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftasks%2Fjson%2FJsonJqTransform.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/json-jq-task%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Ftasks%2Fjson%2FJsonJqTransform.java?ref=ca18e9436c17c10f110bc69c6d49d81135d7e0bf",
      "patch": "@@ -113,7 +113,8 @@ private LoadingCache<String, JsonQuery> createQueryCache() {\n     }\n \n     @Override\n-    public boolean execute(WorkflowModel workflow, TaskModel task, WorkflowExecutor workflowExecutor) {\n+    public boolean execute(\n+            WorkflowModel workflow, TaskModel task, WorkflowExecutor workflowExecutor) {\n         this.start(workflow, task, workflowExecutor);\n         return true;\n     }",
      "parent_sha": "6cf9a7432e611a42e22c6a8a8105b6cd4090d8d7"
    }
  },
  {
    "oid": "125d532239ba49a94f30e304a6920380954cfda1",
    "message": "ParametersUtils error\n\nParametersUtils some code need catch exception #988",
    "date": "2019-06-05T14:50:34Z",
    "url": "https://github.com/Netflix/conductor/commit/125d532239ba49a94f30e304a6920380954cfda1",
    "details": {
      "sha": "a5f4a2df61ee0a356953c314dc25ce136cfc0b96",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java",
      "status": "modified",
      "additions": 10,
      "deletions": 3,
      "changes": 13,
      "blob_url": "https://github.com/Netflix/conductor/blob/125d532239ba49a94f30e304a6920380954cfda1/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/125d532239ba49a94f30e304a6920380954cfda1/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FParametersUtils.java?ref=125d532239ba49a94f30e304a6920380954cfda1",
      "patch": "@@ -35,11 +35,13 @@\n import java.util.Map;\n import java.util.Map.Entry;\n import java.util.Optional;\n-\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n /**\n  * Used to parse and resolve the JSONPath bindings in the workflow and task definitions.\n  */\n public class ParametersUtils {\n+    private static Logger logger = LoggerFactory.getLogger(ParametersUtils.class);\n \n     private ObjectMapper objectMapper = new ObjectMapper();\n \n@@ -196,7 +198,7 @@ private Object replaceVariables(String paramString, DocumentContext documentCont\n         Object[] convertedValues = new Object[values.length];\n         for (int i = 0; i < values.length; i++) {\n             convertedValues[i] = values[i];\n-            if (values[i].startsWith(\"${\") && values[i].endsWith(\"}\")) {\n+            if (values !=null && values[i].startsWith(\"${\") && values[i].endsWith(\"}\")) {\n                 String paramPath = values[i].substring(2, values[i].length() - 1);\n                 if (EnvUtils.isEnvironmentVariable(paramPath)) {\n                     String sysValue = EnvUtils.getSystemParametersValue(paramPath, taskId);\n@@ -205,7 +207,12 @@ private Object replaceVariables(String paramString, DocumentContext documentCont\n                     }\n \n                 } else {\n-                    convertedValues[i] = documentContext.read(paramPath);\n+                    try {\n+                        convertedValues[i] = documentContext.read(paramPath);\n+                    }catch (Exception e) {\n+                        logger.warn(\"Error reading documentContext for paramPath: {}. Exception: {}\", paramPath, e);\n+                        convertedValues[i] = null;\n+                    }\n                 }\n \n             }",
      "parent_sha": "a21a282bfba3bbc93573c08a79f2b3da99fa0749"
    }
  },
  {
    "oid": "bd2ee505bc4518f4fccf339457b4dd0801e460cc",
    "message": "Clean up",
    "date": "2018-03-29T22:50:11Z",
    "url": "https://github.com/Netflix/conductor/commit/bd2ee505bc4518f4fccf339457b4dd0801e460cc",
    "details": {
      "sha": "4f41046d0aeaae0faf9f28ade5e6c785d824f041",
      "filename": "core/src/main/java/com/netflix/conductor/dao/IndexDAO.java",
      "status": "modified",
      "additions": 34,
      "deletions": 16,
      "changes": 50,
      "blob_url": "https://github.com/Netflix/conductor/blob/bd2ee505bc4518f4fccf339457b4dd0801e460cc/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2FIndexDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/bd2ee505bc4518f4fccf339457b4dd0801e460cc/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2FIndexDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2FIndexDAO.java?ref=bd2ee505bc4518f4fccf339457b4dd0801e460cc",
      "patch": "@@ -33,25 +33,31 @@\n public interface IndexDAO {\n \n \t/**\n-\t * TODO sync/async - there are 2 different kinds of update responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the getResult in each of the update responses.\n \t * This method should return an unique identifier of the indexed doc\n \t * @param workflow Workflow to be indexed\n \t *\n \t */\n \tvoid indexWorkflow(Workflow workflow);\n \n-\t//TODO add java doc\n+\t/**\n+\t *\n+\t * /**\n+\t * This method should return an unique identifier of the indexed doc\n+\t * @param workflow Workflow to be indexed\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncIndexWorkflow(Workflow workflow);\n \t\n \t/**\n-\t * TODO sync/async - there are 2 different kinds of update responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the getResult in each of the update responses.\n \t * @param task Task to be indexed\n \t */\n \tvoid indexTask(Task task);\n \n-\t//TODO add java doc\n+\t/**\n+\t *\n+\t * @param task Task to be indexed asynchronously\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncIndexTask(Task task);\n \n \t/**\n@@ -78,27 +84,35 @@ public interface IndexDAO {\n \tSearchResult<String> searchTasks(String query, String freeText, int start, int count, List<String> sort);\n \n \t/**\n-\t * TODO sync/async there are 2 different kinds of delete responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the Builder available in each of the delete responses.\n \t * Remove the workflow index\n \t * @param workflowId workflow to be removed\n \t */\n \tvoid removeWorkflow(String workflowId);\n \n+\t/**\n+\t * Remove the workflow index\n+\t * @param workflowId workflow to be removed\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncRemoveWorkflow(String workflowId);\n \n \n \t/**\n \t *\n-\t * TODO sync/async - there are 2 different kinds of update responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the getResult in each of the update responses.\n \t * Updates the index\n \t * @param workflowInstanceId id of the workflow\n \t * @param keys keys to be updated\n \t * @param values values. Number of keys and values MUST match.\n \t */\n \tvoid updateWorkflow(String workflowInstanceId, String[] keys, Object[] values);\n \n+\t/**\n+\t * Updates the index\n+\t * @param workflowInstanceId id of the workflow\n+\t * @param keys keys to be updated\n+\t * @param values values. Number of keys and values MUST match.\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncUpdateWorkflow(String workflowInstanceId, String[] keys, Object[] values);\n \n \n@@ -111,12 +125,15 @@ public interface IndexDAO {\n \tString get(String workflowInstanceId, String key);\n \n \t/**\n-\t * TODO sync/async - there are 2 different kinds of bulk responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the BulkItemResponse in each of the update responses.\n \t * @param logs Task Execution logs to be indexed\n \t */\n \tvoid addTaskExecutionLogs(List<TaskExecLog> logs);\n \n+\t/**\n+\t *\n+\t * @param logs Task Execution logs to be indexed\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncAddTaskExecutionLogs(List<TaskExecLog> logs);\n \n \t/**\n@@ -128,18 +145,19 @@ public interface IndexDAO {\n \t\n \t\n \t/**\n-\t * TODO sync/async - there are 2 different kinds of update responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the getResult in each of the update responses.\n \t * @param eventExecution Event Execution to be indexed\n \t */\n \tvoid addEventExecution(EventExecution eventExecution);\n \n \n+\t/**\n+\t *\n+\t * @param eventExecution Event Execution to be indexed\n+\t * @return CompletableFuture of type void\n+\t */\n \tCompletableFuture<Void> asyncAddEventExecution(EventExecution eventExecution);\n \n \t/**\n-\t * TODO sync/async - there are 2 different kinds of index responses that are returned from ES2 and ES5.\n-\t * TODO Evaluate and see if there is a chance of converging them by looking at the getResult in each of the update responses.\n \t * Adds an incoming external message into the index\n \t * @param queue Name of the registered queue\n \t * @param msg Message",
      "parent_sha": "437a35dc1a0ddc6b4cf575793fccef90309341c3"
    }
  },
  {
    "oid": "be6cf505d50bb18e9ed487429ee7eb20a60b5b09",
    "message": "grpc-server: Make more functional",
    "date": "2018-06-08T14:37:41Z",
    "url": "https://github.com/Netflix/conductor/commit/be6cf505d50bb18e9ed487429ee7eb20a60b5b09",
    "details": {
      "sha": "0358d1199e26cd6cd17c9bd4bf3c66016c269643",
      "filename": "grpc-server/src/main/java/com/netflix/conductor/grpc/server/GRPCServer.java",
      "status": "modified",
      "additions": 2,
      "deletions": 6,
      "changes": 8,
      "blob_url": "https://github.com/Netflix/conductor/blob/be6cf505d50bb18e9ed487429ee7eb20a60b5b09/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCServer.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/be6cf505d50bb18e9ed487429ee7eb20a60b5b09/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCServer.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCServer.java?ref=be6cf505d50bb18e9ed487429ee7eb20a60b5b09",
      "patch": "@@ -2,8 +2,6 @@\n \n import com.google.inject.Inject;\n import com.netflix.conductor.core.config.Configuration;\n-import com.netflix.conductor.grpc.TaskServiceGrpc;\n-import com.netflix.conductor.grpc.WorkflowServiceGrpc;\n import io.grpc.BindableService;\n import io.grpc.Server;\n import io.grpc.ServerBuilder;\n@@ -12,6 +10,7 @@\n \n import javax.inject.Singleton;\n import java.io.IOException;\n+import java.util.Arrays;\n \n @Singleton\n public class GRPCServer {\n@@ -27,10 +26,7 @@ public GRPCServer(Configuration conf, BindableService... services) {\n         final int port = conf.getIntProperty(CONFIG_PORT, CONFIG_PORT_DEFAULT);\n \n         ServerBuilder<?> builder = ServerBuilder.forPort(port);\n-        for (BindableService s : services) {\n-            builder.addService(s);\n-        }\n-\n+        Arrays.stream(services).forEach(builder::addService);\n         server = builder.build();\n     }\n ",
      "parent_sha": "75bf49875a35278d73098468d979e50189f27416"
    }
  },
  {
    "oid": "d3cd3ba74b1ec1c68c283290d71f736314ae31f8",
    "message": "Fix issue in which a queue in an event-handler is defined as \"amqp:...\" and no events are consumed. (#1746)\n\nRename StringMapKey for amqp queue from \"amqp\" to amqp_queue\"\r\nIssue: https://github.com/Netflix/conductor/issues/1745#issue-642554258\r\n\r\nCo-authored-by: Heinrich Cohn <heinrichco@payoneer.com>",
    "date": "2020-06-22T23:42:06Z",
    "url": "https://github.com/Netflix/conductor/commit/d3cd3ba74b1ec1c68c283290d71f736314ae31f8",
    "details": {
      "sha": "9a9153938ff50538b2b8edb348a34494f171dcba",
      "filename": "contribs/src/main/java/com/netflix/conductor/contribs/AMQPModule.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/d3cd3ba74b1ec1c68c283290d71f736314ae31f8/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2FAMQPModule.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/d3cd3ba74b1ec1c68c283290d71f736314ae31f8/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2FAMQPModule.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2FAMQPModule.java?ref=d3cd3ba74b1ec1c68c283290d71f736314ae31f8",
      "patch": "@@ -55,7 +55,7 @@ protected void configure() {\n \t}\n \n \t@ProvidesIntoMap\n-\t@StringMapKey(\"amqp\")\n+\t@StringMapKey(\"amqp_queue\")\n \t@Singleton\n \t@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)\n \tpublic EventQueueProvider getAMQQueueEventQueueProvider(Configuration config) {",
      "parent_sha": "2cc716e8578b5da164278efc9a0b9ab874073ad3"
    }
  },
  {
    "oid": "381555f1d84b3d82e0d019643e2d2886dad22fe9",
    "message": "Log error message optimize",
    "date": "2019-02-16T14:09:44Z",
    "url": "https://github.com/Netflix/conductor/commit/381555f1d84b3d82e0d019643e2d2886dad22fe9",
    "details": {
      "sha": "9b31edaeb197c214d2d1b1a39c98161269e7be96",
      "filename": "contribs/src/main/java/com/netflix/conductor/contribs/lambda/Lambda.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/381555f1d84b3d82e0d019643e2d2886dad22fe9/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/381555f1d84b3d82e0d019643e2d2886dad22fe9/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Flambda%2FLambda.java?ref=381555f1d84b3d82e0d019643e2d2886dad22fe9",
      "patch": "@@ -49,7 +49,7 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) {\n             taskOutput.put(\"result\", returnValue);\n             task.setStatus(Task.Status.COMPLETED);\n         } catch (ScriptException e) {\n-            logger.error(e.getMessage(), e);\n+            logger.error(\"Failed to execute  Lambda: {}\", scriptExpression, e);\n             task.setStatus(Task.Status.FAILED);\n             task.setReasonForIncompletion(e.getMessage());\n             taskOutput.put(\"error\", e.getCause() != null ? e.getCause().getMessage() : e.getMessage());",
      "parent_sha": "ce2c9762e1d5df6d02cc3f6f204cab2792aabd95"
    }
  },
  {
    "oid": "57cbcdf8308906607665f1fd40a91074ba303b1d",
    "message": "protomapper: Sort all mappers alphabetically",
    "date": "2018-10-23T09:36:10Z",
    "url": "https://github.com/Netflix/conductor/commit/57cbcdf8308906607665f1fd40a91074ba303b1d",
    "details": {
      "sha": "59e3121789bed46e95a054085b926147db9c1dad",
      "filename": "grpc/src/main/java/com/netflix/conductor/grpc/AbstractProtoMapper.java",
      "status": "modified",
      "additions": 336,
      "deletions": 336,
      "changes": 672,
      "blob_url": "https://github.com/Netflix/conductor/blob/57cbcdf8308906607665f1fd40a91074ba303b1d/grpc%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2FAbstractProtoMapper.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/57cbcdf8308906607665f1fd40a91074ba303b1d/grpc%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2FAbstractProtoMapper.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/grpc%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2FAbstractProtoMapper.java?ref=57cbcdf8308906607665f1fd40a91074ba303b1d",
      "patch": "@@ -51,6 +51,55 @@\n \n @Generated(\"com.github.vmg.protogen.ProtoGen\")\n public abstract class AbstractProtoMapper {\n+    public DynamicForkJoinTaskPb.DynamicForkJoinTask toProto(DynamicForkJoinTask from) {\n+        DynamicForkJoinTaskPb.DynamicForkJoinTask.Builder to = DynamicForkJoinTaskPb.DynamicForkJoinTask.newBuilder();\n+        if (from.getTaskName() != null) {\n+            to.setTaskName( from.getTaskName() );\n+        }\n+        if (from.getWorkflowName() != null) {\n+            to.setWorkflowName( from.getWorkflowName() );\n+        }\n+        if (from.getReferenceName() != null) {\n+            to.setReferenceName( from.getReferenceName() );\n+        }\n+        for (Map.Entry<String, Object> pair : from.getInput().entrySet()) {\n+            to.putInput( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getType() != null) {\n+            to.setType( from.getType() );\n+        }\n+        return to.build();\n+    }\n+\n+    public DynamicForkJoinTask fromProto(DynamicForkJoinTaskPb.DynamicForkJoinTask from) {\n+        DynamicForkJoinTask to = new DynamicForkJoinTask();\n+        to.setTaskName( from.getTaskName() );\n+        to.setWorkflowName( from.getWorkflowName() );\n+        to.setReferenceName( from.getReferenceName() );\n+        Map<String, Object> inputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getInputMap().entrySet()) {\n+            inputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setInput(inputMap);\n+        to.setType( from.getType() );\n+        return to;\n+    }\n+\n+    public DynamicForkJoinTaskListPb.DynamicForkJoinTaskList toProto(DynamicForkJoinTaskList from) {\n+        DynamicForkJoinTaskListPb.DynamicForkJoinTaskList.Builder to = DynamicForkJoinTaskListPb.DynamicForkJoinTaskList.newBuilder();\n+        for (DynamicForkJoinTask elem : from.getDynamicTasks()) {\n+            to.addDynamicTasks( toProto(elem) );\n+        }\n+        return to.build();\n+    }\n+\n+    public DynamicForkJoinTaskList fromProto(\n+            DynamicForkJoinTaskListPb.DynamicForkJoinTaskList from) {\n+        DynamicForkJoinTaskList to = new DynamicForkJoinTaskList();\n+        to.setDynamicTasks( from.getDynamicTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n+        return to;\n+    }\n+\n     public EventExecutionPb.EventExecution toProto(EventExecution from) {\n         EventExecutionPb.EventExecution.Builder to = EventExecutionPb.EventExecution.newBuilder();\n         if (from.getId() != null) {\n@@ -295,6 +344,121 @@ public PollData fromProto(PollDataPb.PollData from) {\n         return to;\n     }\n \n+    public RerunWorkflowRequestPb.RerunWorkflowRequest toProto(RerunWorkflowRequest from) {\n+        RerunWorkflowRequestPb.RerunWorkflowRequest.Builder to = RerunWorkflowRequestPb.RerunWorkflowRequest.newBuilder();\n+        if (from.getReRunFromWorkflowId() != null) {\n+            to.setReRunFromWorkflowId( from.getReRunFromWorkflowId() );\n+        }\n+        for (Map.Entry<String, Object> pair : from.getWorkflowInput().entrySet()) {\n+            to.putWorkflowInput( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getReRunFromTaskId() != null) {\n+            to.setReRunFromTaskId( from.getReRunFromTaskId() );\n+        }\n+        for (Map.Entry<String, Object> pair : from.getTaskInput().entrySet()) {\n+            to.putTaskInput( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getCorrelationId() != null) {\n+            to.setCorrelationId( from.getCorrelationId() );\n+        }\n+        return to.build();\n+    }\n+\n+    public RerunWorkflowRequest fromProto(RerunWorkflowRequestPb.RerunWorkflowRequest from) {\n+        RerunWorkflowRequest to = new RerunWorkflowRequest();\n+        to.setReRunFromWorkflowId( from.getReRunFromWorkflowId() );\n+        Map<String, Object> workflowInputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getWorkflowInputMap().entrySet()) {\n+            workflowInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setWorkflowInput(workflowInputMap);\n+        to.setReRunFromTaskId( from.getReRunFromTaskId() );\n+        Map<String, Object> taskInputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getTaskInputMap().entrySet()) {\n+            taskInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setTaskInput(taskInputMap);\n+        to.setCorrelationId( from.getCorrelationId() );\n+        return to;\n+    }\n+\n+    public SkipTaskRequest fromProto(SkipTaskRequestPb.SkipTaskRequest from) {\n+        SkipTaskRequest to = new SkipTaskRequest();\n+        Map<String, Object> taskInputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getTaskInputMap().entrySet()) {\n+            taskInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setTaskInput(taskInputMap);\n+        Map<String, Object> taskOutputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getTaskOutputMap().entrySet()) {\n+            taskOutputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setTaskOutput(taskOutputMap);\n+        if (from.hasTaskInputMessage()) {\n+            to.setTaskInputMessage( fromProto( from.getTaskInputMessage() ) );\n+        }\n+        if (from.hasTaskOutputMessage()) {\n+            to.setTaskOutputMessage( fromProto( from.getTaskOutputMessage() ) );\n+        }\n+        return to;\n+    }\n+\n+    public StartWorkflowRequestPb.StartWorkflowRequest toProto(StartWorkflowRequest from) {\n+        StartWorkflowRequestPb.StartWorkflowRequest.Builder to = StartWorkflowRequestPb.StartWorkflowRequest.newBuilder();\n+        if (from.getName() != null) {\n+            to.setName( from.getName() );\n+        }\n+        if (from.getVersion() != null) {\n+            to.setVersion( from.getVersion() );\n+        }\n+        if (from.getCorrelationId() != null) {\n+            to.setCorrelationId( from.getCorrelationId() );\n+        }\n+        for (Map.Entry<String, Object> pair : from.getInput().entrySet()) {\n+            to.putInput( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        to.putAllTaskToDomain( from.getTaskToDomain() );\n+        if (from.getWorkflowDef() != null) {\n+            to.setWorkflowDef( toProto( from.getWorkflowDef() ) );\n+        }\n+        return to.build();\n+    }\n+\n+    public StartWorkflowRequest fromProto(StartWorkflowRequestPb.StartWorkflowRequest from) {\n+        StartWorkflowRequest to = new StartWorkflowRequest();\n+        to.setName( from.getName() );\n+        to.setVersion( from.getVersion() );\n+        to.setCorrelationId( from.getCorrelationId() );\n+        Map<String, Object> inputMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getInputMap().entrySet()) {\n+            inputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setInput(inputMap);\n+        to.setTaskToDomain( from.getTaskToDomainMap() );\n+        if (from.hasWorkflowDef()) {\n+            to.setWorkflowDef( fromProto( from.getWorkflowDef() ) );\n+        }\n+        return to;\n+    }\n+\n+    public SubWorkflowParamsPb.SubWorkflowParams toProto(SubWorkflowParams from) {\n+        SubWorkflowParamsPb.SubWorkflowParams.Builder to = SubWorkflowParamsPb.SubWorkflowParams.newBuilder();\n+        if (from.getName() != null) {\n+            to.setName( from.getName() );\n+        }\n+        if (from.getVersion() != null) {\n+            to.setVersion( from.getVersion() );\n+        }\n+        return to.build();\n+    }\n+\n+    public SubWorkflowParams fromProto(SubWorkflowParamsPb.SubWorkflowParams from) {\n+        SubWorkflowParams to = new SubWorkflowParams();\n+        to.setName( from.getName() );\n+        to.setVersion( from.getVersion() );\n+        return to;\n+    }\n+\n     public TaskPb.Task toProto(Task from) {\n         TaskPb.Task.Builder to = TaskPb.Task.newBuilder();\n         if (from.getTaskType() != null) {\n@@ -639,353 +803,51 @@ public TaskResult.Status fromProto(TaskResultPb.TaskResult.Status from) {\n         return to;\n     }\n \n-    public DynamicForkJoinTaskPb.DynamicForkJoinTask toProto(DynamicForkJoinTask from) {\n-        DynamicForkJoinTaskPb.DynamicForkJoinTask.Builder to = DynamicForkJoinTaskPb.DynamicForkJoinTask.newBuilder();\n-        if (from.getTaskName() != null) {\n-            to.setTaskName( from.getTaskName() );\n+    public TaskSummaryPb.TaskSummary toProto(TaskSummary from) {\n+        TaskSummaryPb.TaskSummary.Builder to = TaskSummaryPb.TaskSummary.newBuilder();\n+        if (from.getWorkflowId() != null) {\n+            to.setWorkflowId( from.getWorkflowId() );\n         }\n-        if (from.getWorkflowName() != null) {\n-            to.setWorkflowName( from.getWorkflowName() );\n+        if (from.getWorkflowType() != null) {\n+            to.setWorkflowType( from.getWorkflowType() );\n         }\n-        if (from.getReferenceName() != null) {\n-            to.setReferenceName( from.getReferenceName() );\n+        if (from.getCorrelationId() != null) {\n+            to.setCorrelationId( from.getCorrelationId() );\n         }\n-        for (Map.Entry<String, Object> pair : from.getInput().entrySet()) {\n-            to.putInput( pair.getKey(), toProto( pair.getValue() ) );\n+        if (from.getScheduledTime() != null) {\n+            to.setScheduledTime( from.getScheduledTime() );\n         }\n-        if (from.getType() != null) {\n-            to.setType( from.getType() );\n+        if (from.getStartTime() != null) {\n+            to.setStartTime( from.getStartTime() );\n         }\n-        return to.build();\n-    }\n-\n-    public DynamicForkJoinTask fromProto(DynamicForkJoinTaskPb.DynamicForkJoinTask from) {\n-        DynamicForkJoinTask to = new DynamicForkJoinTask();\n-        to.setTaskName( from.getTaskName() );\n-        to.setWorkflowName( from.getWorkflowName() );\n-        to.setReferenceName( from.getReferenceName() );\n-        Map<String, Object> inputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getInputMap().entrySet()) {\n-            inputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        if (from.getUpdateTime() != null) {\n+            to.setUpdateTime( from.getUpdateTime() );\n         }\n-        to.setInput(inputMap);\n-        to.setType( from.getType() );\n-        return to;\n-    }\n-\n-    public DynamicForkJoinTaskListPb.DynamicForkJoinTaskList toProto(DynamicForkJoinTaskList from) {\n-        DynamicForkJoinTaskListPb.DynamicForkJoinTaskList.Builder to = DynamicForkJoinTaskListPb.DynamicForkJoinTaskList.newBuilder();\n-        for (DynamicForkJoinTask elem : from.getDynamicTasks()) {\n-            to.addDynamicTasks( toProto(elem) );\n+        if (from.getEndTime() != null) {\n+            to.setEndTime( from.getEndTime() );\n         }\n-        return to.build();\n-    }\n-\n-    public DynamicForkJoinTaskList fromProto(\n-            DynamicForkJoinTaskListPb.DynamicForkJoinTaskList from) {\n-        DynamicForkJoinTaskList to = new DynamicForkJoinTaskList();\n-        to.setDynamicTasks( from.getDynamicTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n-        return to;\n-    }\n-\n-    public RerunWorkflowRequestPb.RerunWorkflowRequest toProto(RerunWorkflowRequest from) {\n-        RerunWorkflowRequestPb.RerunWorkflowRequest.Builder to = RerunWorkflowRequestPb.RerunWorkflowRequest.newBuilder();\n-        if (from.getReRunFromWorkflowId() != null) {\n-            to.setReRunFromWorkflowId( from.getReRunFromWorkflowId() );\n+        if (from.getStatus() != null) {\n+            to.setStatus( toProto( from.getStatus() ) );\n         }\n-        for (Map.Entry<String, Object> pair : from.getWorkflowInput().entrySet()) {\n-            to.putWorkflowInput( pair.getKey(), toProto( pair.getValue() ) );\n+        if (from.getReasonForIncompletion() != null) {\n+            to.setReasonForIncompletion( from.getReasonForIncompletion() );\n         }\n-        if (from.getReRunFromTaskId() != null) {\n-            to.setReRunFromTaskId( from.getReRunFromTaskId() );\n+        to.setExecutionTime( from.getExecutionTime() );\n+        to.setQueueWaitTime( from.getQueueWaitTime() );\n+        if (from.getTaskDefName() != null) {\n+            to.setTaskDefName( from.getTaskDefName() );\n         }\n-        for (Map.Entry<String, Object> pair : from.getTaskInput().entrySet()) {\n-            to.putTaskInput( pair.getKey(), toProto( pair.getValue() ) );\n+        if (from.getTaskType() != null) {\n+            to.setTaskType( from.getTaskType() );\n         }\n-        if (from.getCorrelationId() != null) {\n-            to.setCorrelationId( from.getCorrelationId() );\n-        }\n-        return to.build();\n-    }\n-\n-    public RerunWorkflowRequest fromProto(RerunWorkflowRequestPb.RerunWorkflowRequest from) {\n-        RerunWorkflowRequest to = new RerunWorkflowRequest();\n-        to.setReRunFromWorkflowId( from.getReRunFromWorkflowId() );\n-        Map<String, Object> workflowInputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getWorkflowInputMap().entrySet()) {\n-            workflowInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setWorkflowInput(workflowInputMap);\n-        to.setReRunFromTaskId( from.getReRunFromTaskId() );\n-        Map<String, Object> taskInputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getTaskInputMap().entrySet()) {\n-            taskInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setTaskInput(taskInputMap);\n-        to.setCorrelationId( from.getCorrelationId() );\n-        return to;\n-    }\n-\n-    public SkipTaskRequest fromProto(SkipTaskRequestPb.SkipTaskRequest from) {\n-        SkipTaskRequest to = new SkipTaskRequest();\n-        Map<String, Object> taskInputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getTaskInputMap().entrySet()) {\n-            taskInputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setTaskInput(taskInputMap);\n-        Map<String, Object> taskOutputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getTaskOutputMap().entrySet()) {\n-            taskOutputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setTaskOutput(taskOutputMap);\n-        if (from.hasTaskInputMessage()) {\n-            to.setTaskInputMessage( fromProto( from.getTaskInputMessage() ) );\n-        }\n-        if (from.hasTaskOutputMessage()) {\n-            to.setTaskOutputMessage( fromProto( from.getTaskOutputMessage() ) );\n-        }\n-        return to;\n-    }\n-\n-    public StartWorkflowRequestPb.StartWorkflowRequest toProto(StartWorkflowRequest from) {\n-        StartWorkflowRequestPb.StartWorkflowRequest.Builder to = StartWorkflowRequestPb.StartWorkflowRequest.newBuilder();\n-        if (from.getName() != null) {\n-            to.setName( from.getName() );\n-        }\n-        if (from.getVersion() != null) {\n-            to.setVersion( from.getVersion() );\n-        }\n-        if (from.getCorrelationId() != null) {\n-            to.setCorrelationId( from.getCorrelationId() );\n-        }\n-        for (Map.Entry<String, Object> pair : from.getInput().entrySet()) {\n-            to.putInput( pair.getKey(), toProto( pair.getValue() ) );\n-        }\n-        to.putAllTaskToDomain( from.getTaskToDomain() );\n-        if (from.getWorkflowDef() != null) {\n-            to.setWorkflowDef( toProto( from.getWorkflowDef() ) );\n-        }\n-        return to.build();\n-    }\n-\n-    public StartWorkflowRequest fromProto(StartWorkflowRequestPb.StartWorkflowRequest from) {\n-        StartWorkflowRequest to = new StartWorkflowRequest();\n-        to.setName( from.getName() );\n-        to.setVersion( from.getVersion() );\n-        to.setCorrelationId( from.getCorrelationId() );\n-        Map<String, Object> inputMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getInputMap().entrySet()) {\n-            inputMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setInput(inputMap);\n-        to.setTaskToDomain( from.getTaskToDomainMap() );\n-        if (from.hasWorkflowDef()) {\n-            to.setWorkflowDef( fromProto( from.getWorkflowDef() ) );\n-        }\n-        return to;\n-    }\n-\n-    public SubWorkflowParamsPb.SubWorkflowParams toProto(SubWorkflowParams from) {\n-        SubWorkflowParamsPb.SubWorkflowParams.Builder to = SubWorkflowParamsPb.SubWorkflowParams.newBuilder();\n-        if (from.getName() != null) {\n-            to.setName( from.getName() );\n-        }\n-        if (from.getVersion() != null) {\n-            to.setVersion( from.getVersion() );\n-        }\n-        return to.build();\n-    }\n-\n-    public SubWorkflowParams fromProto(SubWorkflowParamsPb.SubWorkflowParams from) {\n-        SubWorkflowParams to = new SubWorkflowParams();\n-        to.setName( from.getName() );\n-        to.setVersion( from.getVersion() );\n-        return to;\n-    }\n-\n-    public WorkflowDefPb.WorkflowDef toProto(WorkflowDef from) {\n-        WorkflowDefPb.WorkflowDef.Builder to = WorkflowDefPb.WorkflowDef.newBuilder();\n-        if (from.getName() != null) {\n-            to.setName( from.getName() );\n-        }\n-        if (from.getDescription() != null) {\n-            to.setDescription( from.getDescription() );\n-        }\n-        to.setVersion( from.getVersion() );\n-        for (WorkflowTask elem : from.getTasks()) {\n-            to.addTasks( toProto(elem) );\n-        }\n-        to.addAllInputParameters( from.getInputParameters() );\n-        for (Map.Entry<String, Object> pair : from.getOutputParameters().entrySet()) {\n-            to.putOutputParameters( pair.getKey(), toProto( pair.getValue() ) );\n-        }\n-        if (from.getFailureWorkflow() != null) {\n-            to.setFailureWorkflow( from.getFailureWorkflow() );\n-        }\n-        to.setSchemaVersion( from.getSchemaVersion() );\n-        to.setRestartable( from.isRestartable() );\n-        return to.build();\n-    }\n-\n-    public WorkflowDef fromProto(WorkflowDefPb.WorkflowDef from) {\n-        WorkflowDef to = new WorkflowDef();\n-        to.setName( from.getName() );\n-        to.setDescription( from.getDescription() );\n-        to.setVersion( from.getVersion() );\n-        to.setTasks( from.getTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n-        to.setInputParameters( from.getInputParametersList().stream().collect(Collectors.toCollection(ArrayList::new)) );\n-        Map<String, Object> outputParametersMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getOutputParametersMap().entrySet()) {\n-            outputParametersMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setOutputParameters(outputParametersMap);\n-        to.setFailureWorkflow( from.getFailureWorkflow() );\n-        to.setSchemaVersion( from.getSchemaVersion() );\n-        to.setRestartable( from.getRestartable() );\n-        return to;\n-    }\n-\n-    public WorkflowTaskPb.WorkflowTask toProto(WorkflowTask from) {\n-        WorkflowTaskPb.WorkflowTask.Builder to = WorkflowTaskPb.WorkflowTask.newBuilder();\n-        if (from.getName() != null) {\n-            to.setName( from.getName() );\n-        }\n-        if (from.getTaskReferenceName() != null) {\n-            to.setTaskReferenceName( from.getTaskReferenceName() );\n-        }\n-        if (from.getDescription() != null) {\n-            to.setDescription( from.getDescription() );\n-        }\n-        for (Map.Entry<String, Object> pair : from.getInputParameters().entrySet()) {\n-            to.putInputParameters( pair.getKey(), toProto( pair.getValue() ) );\n-        }\n-        if (from.getType() != null) {\n-            to.setType( from.getType() );\n-        }\n-        if (from.getDynamicTaskNameParam() != null) {\n-            to.setDynamicTaskNameParam( from.getDynamicTaskNameParam() );\n-        }\n-        if (from.getCaseValueParam() != null) {\n-            to.setCaseValueParam( from.getCaseValueParam() );\n-        }\n-        if (from.getCaseExpression() != null) {\n-            to.setCaseExpression( from.getCaseExpression() );\n-        }\n-        for (Map.Entry<String, List<WorkflowTask>> pair : from.getDecisionCases().entrySet()) {\n-            to.putDecisionCases( pair.getKey(), toProto( pair.getValue() ) );\n-        }\n-        if (from.getDynamicForkTasksParam() != null) {\n-            to.setDynamicForkTasksParam( from.getDynamicForkTasksParam() );\n-        }\n-        if (from.getDynamicForkTasksInputParamName() != null) {\n-            to.setDynamicForkTasksInputParamName( from.getDynamicForkTasksInputParamName() );\n-        }\n-        for (WorkflowTask elem : from.getDefaultCase()) {\n-            to.addDefaultCase( toProto(elem) );\n-        }\n-        for (List<WorkflowTask> elem : from.getForkTasks()) {\n-            to.addForkTasks( toProto(elem) );\n-        }\n-        to.setStartDelay( from.getStartDelay() );\n-        if (from.getSubWorkflowParam() != null) {\n-            to.setSubWorkflowParam( toProto( from.getSubWorkflowParam() ) );\n-        }\n-        to.addAllJoinOn( from.getJoinOn() );\n-        if (from.getSink() != null) {\n-            to.setSink( from.getSink() );\n-        }\n-        to.setOptional( from.isOptional() );\n-        if (from.getTaskDefinition() != null) {\n-            to.setTaskDefinition( toProto( from.getTaskDefinition() ) );\n-        }\n-        if (from.isRateLimited() != null) {\n-            to.setRateLimited( from.isRateLimited() );\n-        }\n-        return to.build();\n-    }\n-\n-    public WorkflowTask fromProto(WorkflowTaskPb.WorkflowTask from) {\n-        WorkflowTask to = new WorkflowTask();\n-        to.setName( from.getName() );\n-        to.setTaskReferenceName( from.getTaskReferenceName() );\n-        to.setDescription( from.getDescription() );\n-        Map<String, Object> inputParametersMap = new HashMap<String, Object>();\n-        for (Map.Entry<String, Value> pair : from.getInputParametersMap().entrySet()) {\n-            inputParametersMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setInputParameters(inputParametersMap);\n-        to.setType( from.getType() );\n-        to.setDynamicTaskNameParam( from.getDynamicTaskNameParam() );\n-        to.setCaseValueParam( from.getCaseValueParam() );\n-        to.setCaseExpression( from.getCaseExpression() );\n-        Map<String, List<WorkflowTask>> decisionCasesMap = new HashMap<String, List<WorkflowTask>>();\n-        for (Map.Entry<String, WorkflowTaskPb.WorkflowTask.WorkflowTaskList> pair : from.getDecisionCasesMap().entrySet()) {\n-            decisionCasesMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n-        }\n-        to.setDecisionCases(decisionCasesMap);\n-        to.setDynamicForkTasksParam( from.getDynamicForkTasksParam() );\n-        to.setDynamicForkTasksInputParamName( from.getDynamicForkTasksInputParamName() );\n-        to.setDefaultCase( from.getDefaultCaseList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n-        to.setForkTasks( from.getForkTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n-        to.setStartDelay( from.getStartDelay() );\n-        if (from.hasSubWorkflowParam()) {\n-            to.setSubWorkflowParam( fromProto( from.getSubWorkflowParam() ) );\n-        }\n-        to.setJoinOn( from.getJoinOnList().stream().collect(Collectors.toCollection(ArrayList::new)) );\n-        to.setSink( from.getSink() );\n-        to.setOptional( from.getOptional() );\n-        if (from.hasTaskDefinition()) {\n-            to.setTaskDefinition( fromProto( from.getTaskDefinition() ) );\n-        }\n-        to.setRateLimited( from.getRateLimited() );\n-        return to;\n-    }\n-\n-    public TaskSummaryPb.TaskSummary toProto(TaskSummary from) {\n-        TaskSummaryPb.TaskSummary.Builder to = TaskSummaryPb.TaskSummary.newBuilder();\n-        if (from.getWorkflowId() != null) {\n-            to.setWorkflowId( from.getWorkflowId() );\n-        }\n-        if (from.getWorkflowType() != null) {\n-            to.setWorkflowType( from.getWorkflowType() );\n-        }\n-        if (from.getCorrelationId() != null) {\n-            to.setCorrelationId( from.getCorrelationId() );\n-        }\n-        if (from.getScheduledTime() != null) {\n-            to.setScheduledTime( from.getScheduledTime() );\n-        }\n-        if (from.getStartTime() != null) {\n-            to.setStartTime( from.getStartTime() );\n-        }\n-        if (from.getUpdateTime() != null) {\n-            to.setUpdateTime( from.getUpdateTime() );\n-        }\n-        if (from.getEndTime() != null) {\n-            to.setEndTime( from.getEndTime() );\n-        }\n-        if (from.getStatus() != null) {\n-            to.setStatus( toProto( from.getStatus() ) );\n-        }\n-        if (from.getReasonForIncompletion() != null) {\n-            to.setReasonForIncompletion( from.getReasonForIncompletion() );\n-        }\n-        to.setExecutionTime( from.getExecutionTime() );\n-        to.setQueueWaitTime( from.getQueueWaitTime() );\n-        if (from.getTaskDefName() != null) {\n-            to.setTaskDefName( from.getTaskDefName() );\n-        }\n-        if (from.getTaskType() != null) {\n-            to.setTaskType( from.getTaskType() );\n-        }\n-        if (from.getInput() != null) {\n-            to.setInput( from.getInput() );\n-        }\n-        if (from.getOutput() != null) {\n-            to.setOutput( from.getOutput() );\n-        }\n-        if (from.getTaskId() != null) {\n-            to.setTaskId( from.getTaskId() );\n+        if (from.getInput() != null) {\n+            to.setInput( from.getInput() );\n+        }\n+        if (from.getOutput() != null) {\n+            to.setOutput( from.getOutput() );\n+        }\n+        if (from.getTaskId() != null) {\n+            to.setTaskId( from.getTaskId() );\n         }\n         return to.build();\n     }\n@@ -1100,6 +962,48 @@ public Workflow.WorkflowStatus fromProto(WorkflowPb.Workflow.WorkflowStatus from\n         return to;\n     }\n \n+    public WorkflowDefPb.WorkflowDef toProto(WorkflowDef from) {\n+        WorkflowDefPb.WorkflowDef.Builder to = WorkflowDefPb.WorkflowDef.newBuilder();\n+        if (from.getName() != null) {\n+            to.setName( from.getName() );\n+        }\n+        if (from.getDescription() != null) {\n+            to.setDescription( from.getDescription() );\n+        }\n+        to.setVersion( from.getVersion() );\n+        for (WorkflowTask elem : from.getTasks()) {\n+            to.addTasks( toProto(elem) );\n+        }\n+        to.addAllInputParameters( from.getInputParameters() );\n+        for (Map.Entry<String, Object> pair : from.getOutputParameters().entrySet()) {\n+            to.putOutputParameters( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getFailureWorkflow() != null) {\n+            to.setFailureWorkflow( from.getFailureWorkflow() );\n+        }\n+        to.setSchemaVersion( from.getSchemaVersion() );\n+        to.setRestartable( from.isRestartable() );\n+        return to.build();\n+    }\n+\n+    public WorkflowDef fromProto(WorkflowDefPb.WorkflowDef from) {\n+        WorkflowDef to = new WorkflowDef();\n+        to.setName( from.getName() );\n+        to.setDescription( from.getDescription() );\n+        to.setVersion( from.getVersion() );\n+        to.setTasks( from.getTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n+        to.setInputParameters( from.getInputParametersList().stream().collect(Collectors.toCollection(ArrayList::new)) );\n+        Map<String, Object> outputParametersMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getOutputParametersMap().entrySet()) {\n+            outputParametersMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setOutputParameters(outputParametersMap);\n+        to.setFailureWorkflow( from.getFailureWorkflow() );\n+        to.setSchemaVersion( from.getSchemaVersion() );\n+        to.setRestartable( from.getRestartable() );\n+        return to;\n+    }\n+\n     public WorkflowSummaryPb.WorkflowSummary toProto(WorkflowSummary from) {\n         WorkflowSummaryPb.WorkflowSummary.Builder to = WorkflowSummaryPb.WorkflowSummary.newBuilder();\n         if (from.getWorkflowType() != null) {\n@@ -1162,6 +1066,102 @@ public WorkflowSummary fromProto(WorkflowSummaryPb.WorkflowSummary from) {\n         return to;\n     }\n \n+    public WorkflowTaskPb.WorkflowTask toProto(WorkflowTask from) {\n+        WorkflowTaskPb.WorkflowTask.Builder to = WorkflowTaskPb.WorkflowTask.newBuilder();\n+        if (from.getName() != null) {\n+            to.setName( from.getName() );\n+        }\n+        if (from.getTaskReferenceName() != null) {\n+            to.setTaskReferenceName( from.getTaskReferenceName() );\n+        }\n+        if (from.getDescription() != null) {\n+            to.setDescription( from.getDescription() );\n+        }\n+        for (Map.Entry<String, Object> pair : from.getInputParameters().entrySet()) {\n+            to.putInputParameters( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getType() != null) {\n+            to.setType( from.getType() );\n+        }\n+        if (from.getDynamicTaskNameParam() != null) {\n+            to.setDynamicTaskNameParam( from.getDynamicTaskNameParam() );\n+        }\n+        if (from.getCaseValueParam() != null) {\n+            to.setCaseValueParam( from.getCaseValueParam() );\n+        }\n+        if (from.getCaseExpression() != null) {\n+            to.setCaseExpression( from.getCaseExpression() );\n+        }\n+        for (Map.Entry<String, List<WorkflowTask>> pair : from.getDecisionCases().entrySet()) {\n+            to.putDecisionCases( pair.getKey(), toProto( pair.getValue() ) );\n+        }\n+        if (from.getDynamicForkTasksParam() != null) {\n+            to.setDynamicForkTasksParam( from.getDynamicForkTasksParam() );\n+        }\n+        if (from.getDynamicForkTasksInputParamName() != null) {\n+            to.setDynamicForkTasksInputParamName( from.getDynamicForkTasksInputParamName() );\n+        }\n+        for (WorkflowTask elem : from.getDefaultCase()) {\n+            to.addDefaultCase( toProto(elem) );\n+        }\n+        for (List<WorkflowTask> elem : from.getForkTasks()) {\n+            to.addForkTasks( toProto(elem) );\n+        }\n+        to.setStartDelay( from.getStartDelay() );\n+        if (from.getSubWorkflowParam() != null) {\n+            to.setSubWorkflowParam( toProto( from.getSubWorkflowParam() ) );\n+        }\n+        to.addAllJoinOn( from.getJoinOn() );\n+        if (from.getSink() != null) {\n+            to.setSink( from.getSink() );\n+        }\n+        to.setOptional( from.isOptional() );\n+        if (from.getTaskDefinition() != null) {\n+            to.setTaskDefinition( toProto( from.getTaskDefinition() ) );\n+        }\n+        if (from.isRateLimited() != null) {\n+            to.setRateLimited( from.isRateLimited() );\n+        }\n+        return to.build();\n+    }\n+\n+    public WorkflowTask fromProto(WorkflowTaskPb.WorkflowTask from) {\n+        WorkflowTask to = new WorkflowTask();\n+        to.setName( from.getName() );\n+        to.setTaskReferenceName( from.getTaskReferenceName() );\n+        to.setDescription( from.getDescription() );\n+        Map<String, Object> inputParametersMap = new HashMap<String, Object>();\n+        for (Map.Entry<String, Value> pair : from.getInputParametersMap().entrySet()) {\n+            inputParametersMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setInputParameters(inputParametersMap);\n+        to.setType( from.getType() );\n+        to.setDynamicTaskNameParam( from.getDynamicTaskNameParam() );\n+        to.setCaseValueParam( from.getCaseValueParam() );\n+        to.setCaseExpression( from.getCaseExpression() );\n+        Map<String, List<WorkflowTask>> decisionCasesMap = new HashMap<String, List<WorkflowTask>>();\n+        for (Map.Entry<String, WorkflowTaskPb.WorkflowTask.WorkflowTaskList> pair : from.getDecisionCasesMap().entrySet()) {\n+            decisionCasesMap.put( pair.getKey(), fromProto( pair.getValue() ) );\n+        }\n+        to.setDecisionCases(decisionCasesMap);\n+        to.setDynamicForkTasksParam( from.getDynamicForkTasksParam() );\n+        to.setDynamicForkTasksInputParamName( from.getDynamicForkTasksInputParamName() );\n+        to.setDefaultCase( from.getDefaultCaseList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n+        to.setForkTasks( from.getForkTasksList().stream().map(this::fromProto).collect(Collectors.toCollection(ArrayList::new)) );\n+        to.setStartDelay( from.getStartDelay() );\n+        if (from.hasSubWorkflowParam()) {\n+            to.setSubWorkflowParam( fromProto( from.getSubWorkflowParam() ) );\n+        }\n+        to.setJoinOn( from.getJoinOnList().stream().collect(Collectors.toCollection(ArrayList::new)) );\n+        to.setSink( from.getSink() );\n+        to.setOptional( from.getOptional() );\n+        if (from.hasTaskDefinition()) {\n+            to.setTaskDefinition( fromProto( from.getTaskDefinition() ) );\n+        }\n+        to.setRateLimited( from.getRateLimited() );\n+        return to;\n+    }\n+\n     public abstract WorkflowTaskPb.WorkflowTask.WorkflowTaskList toProto(List<WorkflowTask> in);\n \n     public abstract List<WorkflowTask> fromProto(WorkflowTaskPb.WorkflowTask.WorkflowTaskList in);",
      "parent_sha": "3b9fc7dff56536e40223a1c08ea889874d930c18"
    }
  },
  {
    "oid": "d34b479519579134c2b222935d2a944cb64d21f5",
    "message": "read asyncComplete from definition if not overridden in task input",
    "date": "2019-09-03T19:01:15Z",
    "url": "https://github.com/Netflix/conductor/commit/d34b479519579134c2b222935d2a944cb64d21f5",
    "details": {
      "sha": "cfac220ea76090d1f9c140523c4e6f217eb3dd6e",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/WorkflowSystemTask.java",
      "status": "modified",
      "additions": 8,
      "deletions": 4,
      "changes": 12,
      "blob_url": "https://github.com/Netflix/conductor/blob/d34b479519579134c2b222935d2a944cb64d21f5/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FWorkflowSystemTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/d34b479519579134c2b222935d2a944cb64d21f5/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FWorkflowSystemTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FWorkflowSystemTask.java?ref=d34b479519579134c2b222935d2a944cb64d21f5",
      "patch": "@@ -19,12 +19,13 @@\n package com.netflix.conductor.core.execution.tasks;\n \n import com.netflix.conductor.common.metadata.tasks.Task;\n+import com.netflix.conductor.common.metadata.workflow.WorkflowTask;\n import com.netflix.conductor.common.run.Workflow;\n import com.netflix.conductor.core.execution.WorkflowExecutor;\n-\n import java.util.Collection;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.Optional;\n \n /**\n  * @author Viren\n@@ -86,10 +87,13 @@ public boolean isAsync() {\n \t */\n \tpublic boolean isAsyncComplete(Task task) {\n \t\tif (task.getInputData().containsKey(\"asyncComplete\")) {\n-\t\t\tObject result = task.getInputData().get(\"asyncComplete\");\n-\t\t\treturn (result == null)?false:(Boolean)result;\n+\t\t\treturn Optional.ofNullable(task.getInputData().get(\"asyncComplete\"))\n+\t\t\t\t.map(result -> (Boolean) result)\n+\t\t\t\t.orElse(false);\n \t\t} else {\n-\t\t\treturn false;\n+\t\t\treturn Optional.ofNullable(task.getWorkflowTask())\n+\t\t\t\t.map(WorkflowTask::isAsyncComplete)\n+\t\t\t\t.orElse(false);\n \t\t}\n \t}\n \t",
      "parent_sha": "b80cc8a05f994ca0176e84fadbf2b64b11d11a0b"
    }
  },
  {
    "oid": "75bf49875a35278d73098468d979e50189f27416",
    "message": "grpc-server: Simplify GRPCUtil",
    "date": "2018-06-08T14:37:41Z",
    "url": "https://github.com/Netflix/conductor/commit/75bf49875a35278d73098468d979e50189f27416",
    "details": {
      "sha": "34634f74ac6f9e993c08d452c40192f0401b9d9c",
      "filename": "grpc-server/src/main/java/com/netflix/conductor/grpc/server/GRPCUtil.java",
      "status": "modified",
      "additions": 4,
      "deletions": 15,
      "changes": 19,
      "blob_url": "https://github.com/Netflix/conductor/blob/75bf49875a35278d73098468d979e50189f27416/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCUtil.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/75bf49875a35278d73098468d979e50189f27416/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCUtil.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FGRPCUtil.java?ref=75bf49875a35278d73098468d979e50189f27416",
      "patch": "@@ -2,24 +2,13 @@\n \n import io.grpc.Status;\n import io.grpc.stub.StreamObserver;\n+import org.apache.commons.lang3.exception.ExceptionUtils;\n \n-import java.io.PrintWriter;\n-import java.io.StringWriter;\n-\n-public class GRPCUtil {\n-    private GRPCUtil() {}\n-\n-    private static String stacktraceToString(Throwable e) {\n-        StringWriter stringWriter = new StringWriter();\n-        PrintWriter printWriter = new PrintWriter(stringWriter);\n-        e.printStackTrace(printWriter);\n-        return stringWriter.toString();\n-    }\n-\n-    public static void onError(StreamObserver<?> response, Throwable t) {\n+public interface GRPCUtil {\n+    static void onError(StreamObserver<?> response, Throwable t) {\n         response.onError(Status.INTERNAL\n                 .withDescription(t.getMessage())\n-                .augmentDescription(stacktraceToString(t))\n+                .augmentDescription(ExceptionUtils.getStackTrace(t))\n                 .withCause(t)\n                 .asException());\n     }",
      "parent_sha": "84b0671287701377d2d98783f33bc53efd77eb63"
    }
  },
  {
    "oid": "0a180ac4cf8c7eb06766084956e959499f880195",
    "message": "test fix",
    "date": "2023-04-12T13:19:08Z",
    "url": "https://github.com/Netflix/conductor/commit/0a180ac4cf8c7eb06766084956e959499f880195",
    "details": {
      "sha": "9f60f49111b9124ebcc331f5b80c79ac1b29be05",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/0a180ac4cf8c7eb06766084956e959499f880195/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestWorkflowExecutor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/0a180ac4cf8c7eb06766084956e959499f880195/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestWorkflowExecutor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FTestWorkflowExecutor.java?ref=0a180ac4cf8c7eb06766084956e959499f880195",
      "patch": "@@ -2103,7 +2103,7 @@ public void testTerminateWorkflowWithFailureWorkflow() {\n                 failedTask.getTaskId(), startWorkflowInput.getWorkflowInput().get(\"failureTaskId\"));\n         assertNotNull(\n                 failedTask.getTaskId(),\n-                argumentCaptor.getAllValues().get(0).getInput().get(\"failedWorkflow\"));\n+                startWorkflowInput.getWorkflowInput().get(\"failedWorkflow\"));\n     }\n \n     @Test",
      "parent_sha": "19c1d7bd404388753c777a05adf6326b0435c3ed"
    }
  },
  {
    "oid": "a72599fbd673408d62701fa376373f5154c7d948",
    "message": "fixed formatting",
    "date": "2023-02-16T14:30:11Z",
    "url": "https://github.com/Netflix/conductor/commit/a72599fbd673408d62701fa376373f5154c7d948",
    "details": {
      "sha": "f1c508803e106778a1292abf87fba7413d278a7b",
      "filename": "core/src/main/java/com/netflix/conductor/core/events/queue/DefaultEventQueueProcessor.java",
      "status": "modified",
      "additions": 5,
      "deletions": 3,
      "changes": 8,
      "blob_url": "https://github.com/Netflix/conductor/blob/a72599fbd673408d62701fa376373f5154c7d948/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2FDefaultEventQueueProcessor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/a72599fbd673408d62701fa376373f5154c7d948/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2FDefaultEventQueueProcessor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2FDefaultEventQueueProcessor.java?ref=a72599fbd673408d62701fa376373f5154c7d948",
      "patch": "@@ -14,7 +14,6 @@\n \n import java.util.*;\n \n-import com.netflix.conductor.common.utils.TaskUtils;\n import org.apache.commons.lang3.StringUtils;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -23,6 +22,7 @@\n \n import com.netflix.conductor.common.metadata.tasks.Task;\n import com.netflix.conductor.common.metadata.tasks.TaskResult;\n+import com.netflix.conductor.common.utils.TaskUtils;\n import com.netflix.conductor.core.exception.NotFoundException;\n import com.netflix.conductor.core.execution.WorkflowExecutor;\n import com.netflix.conductor.model.TaskModel;\n@@ -125,8 +125,10 @@ private void startMonitor(Status status, ObservableQueue queue) {\n                                                     .filter(\n                                                             task ->\n                                                                     !task.getStatus().isTerminal()\n-                                                                            && TaskUtils.removeIterationFromTaskRefName(\n-                                                                                    task.getReferenceTaskName())\n+                                                                            && TaskUtils\n+                                                                                    .removeIterationFromTaskRefName(\n+                                                                                            task\n+                                                                                                    .getReferenceTaskName())\n                                                                                     .equals(\n                                                                                             taskRefName))\n                                                     .findFirst();",
      "parent_sha": "ef403ff953bdeb0d4a450e37588a898f7386da0c"
    }
  },
  {
    "oid": "34d1a5919afb19b6b731b52d4382e5a04831bb47",
    "message": "Updated MetadataMapperService with logging messages for checks",
    "date": "2018-08-28T22:32:41Z",
    "url": "https://github.com/Netflix/conductor/commit/34d1a5919afb19b6b731b52d4382e5a04831bb47",
    "details": {
      "sha": "1028628e5be7985cdc92b273c5249d7e8a89c557",
      "filename": "core/src/main/java/com/netflix/conductor/core/metadata/MetadataMapperService.java",
      "status": "modified",
      "additions": 10,
      "deletions": 11,
      "changes": 21,
      "blob_url": "https://github.com/Netflix/conductor/blob/34d1a5919afb19b6b731b52d4382e5a04831bb47/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fmetadata%2FMetadataMapperService.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/34d1a5919afb19b6b731b52d4382e5a04831bb47/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fmetadata%2FMetadataMapperService.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fmetadata%2FMetadataMapperService.java?ref=34d1a5919afb19b6b731b52d4382e5a04831bb47",
      "patch": "@@ -73,21 +73,20 @@ Optional<WorkflowDef> lookupWorkflowDefinition(String workflowName, int workflow\n \n     @VisibleForTesting\n     Optional<WorkflowDef> lookupLatestWorkflowDefinition(String workflowName) {\n-        // FIXME: Add messages.\n-        checkNotNull(workflowName);\n-        checkArgument(StringUtils.isNotBlank(workflowName));\n+        checkNotNull(workflowName, \"Workflow name cannot be null when searching for a definition\");\n+        checkArgument(StringUtils.isNotBlank(workflowName), \"Workflow name cannot be blank when searching for a definition\");\n \n         return metadataDAO.getLatest(workflowName);\n     }\n \n     public Workflow populateWorkflowWithDefinitions(Workflow workflow) {\n \n         WorkflowDef workflowDefinition = Optional.ofNullable(workflow.getWorkflowDefinition())\n-                .orElseGet(() -> lookupForWorkflowDefinition(workflow.getWorkflowName(), workflow.getWorkflowVersion()));\n-\n-        if (workflow.getWorkflowDefinition() == null) {\n-            workflow.setWorkflowDefinition(workflowDefinition);\n-        }\n+                .orElseGet(() -> {\n+                    WorkflowDef wd = lookupForWorkflowDefinition(workflow.getWorkflowName(), workflow.getWorkflowVersion());\n+                    workflow.setWorkflowDefinition(wd);\n+                    return wd;\n+                });\n \n         workflowDefinition.collectTasks().stream().forEach(\n                 workflowTask -> {\n@@ -99,7 +98,7 @@ public Workflow populateWorkflowWithDefinitions(Workflow workflow) {\n                 }\n         );\n \n-        checkForMissingDefinitions(workflowDefinition);\n+        checkNotEmptyDefinitions(workflowDefinition);\n \n         return workflow;\n     }\n@@ -108,7 +107,7 @@ public WorkflowDef populateTaskDefinitions(WorkflowDef workflowDefinition) {\n         workflowDefinition.collectTasks().stream().forEach(\n                 workflowTask -> populateWorkflowTaskWithDefinition(workflowTask)\n         );\n-        checkForMissingDefinitions(workflowDefinition);\n+        checkNotEmptyDefinitions(workflowDefinition);\n         return workflowDefinition;\n     }\n \n@@ -139,7 +138,7 @@ private void populateVersionForSubWorkflow(WorkflowTask workflowTask) {\n         }\n     }\n \n-    private void checkForMissingDefinitions(WorkflowDef workflowDefinition) {\n+    private void checkNotEmptyDefinitions(WorkflowDef workflowDefinition) {\n \n         // Obtain the names of the tasks with missing definitions\n         Set<String> missingTaskDefinitionNames = workflowDefinition.collectTasks().stream()",
      "parent_sha": "9f1100d6ee2295bca2779328b4fb3ea79fd604c5"
    }
  },
  {
    "oid": "1f6f23c98c6211e331cba3975a45238a1c00c6ab",
    "message": "sort results by date",
    "date": "2017-06-20T00:09:19Z",
    "url": "https://github.com/Netflix/conductor/commit/1f6f23c98c6211e331cba3975a45238a1c00c6ab",
    "details": {
      "sha": "a7c6e5baa05db0076d86528ae8238f87eeb8b809",
      "filename": "redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/1f6f23c98c6211e331cba3975a45238a1c00c6ab/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1f6f23c98c6211e331cba3975a45238a1c00c6ab/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/redis-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Findex%2FElasticSearchDAO.java?ref=1f6f23c98c6211e331cba3975a45238a1c00c6ab",
      "patch": "@@ -57,6 +57,7 @@\n import org.elasticsearch.index.query.QueryStringQueryBuilder;\n import org.elasticsearch.indices.IndexAlreadyExistsException;\n import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.sort.SortBuilders;\n import org.elasticsearch.search.sort.SortOrder;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -279,7 +280,7 @@ public List<TaskExecLog> getTaskLogs(String taskId) {\n \t\t\tQueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery(\"*\");\n \t\t\tBoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);\n \t\t\t\n-\t\t\tfinal SearchRequestBuilder srb = client.prepareSearch(logIndexPrefix + \"*\").setQuery(fq).setTypes(TASK_DOC_TYPE);\n+\t\t\tfinal SearchRequestBuilder srb = client.prepareSearch(logIndexPrefix + \"*\").setQuery(fq).setTypes(TASK_DOC_TYPE).addSort(SortBuilders.fieldSort(\"createdTime\").order(SortOrder.ASC));\n \t\t\tSearchResponse response = srb.execute().actionGet();\n \t\t\tSearchHit[] hits = response.getHits().getHits();\n \t\t\tList<TaskExecLog> logs = new ArrayList<>(hits.length);",
      "parent_sha": "e7a6acbc89445bed6c8b6145866ea115b31d5de8"
    }
  },
  {
    "oid": "f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15",
    "message": "Fix queue publish mock called - shouldn't be called when no errors occur.\nMoved to the test with transient exception, that required republish",
    "date": "2023-04-19T20:47:36Z",
    "url": "https://github.com/Netflix/conductor/commit/f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15",
    "details": {
      "sha": "e3a7351e89910c1c095641ae89947f142614035d",
      "filename": "core/src/test/java/com/netflix/conductor/core/events/TestDefaultEventProcessor.java",
      "status": "modified",
      "additions": 3,
      "deletions": 2,
      "changes": 5,
      "blob_url": "https://github.com/Netflix/conductor/blob/f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2FTestDefaultEventProcessor.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2FTestDefaultEventProcessor.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2FTestDefaultEventProcessor.java?ref=f6d6e95aa8b18bb6fcdb06742ae91355eb3f6c15",
      "patch": "@@ -222,7 +222,7 @@ public void testEventProcessor() {\n         assertTrue(completed.get());\n         verify(queue, atMost(1)).ack(any());\n         verify(queue, never()).nack(any());\n-        verify(queue, atLeastOnce()).publish(any());\n+        verify(queue, never()).publish(any());\n     }\n \n     @Test\n@@ -398,7 +398,8 @@ public void testEventProcessorWithRetriableError() {\n                         retryTemplate);\n         eventProcessor.handle(queue, message);\n         verify(queue, never()).ack(any());\n-        verify(queue, never()).publish(any());\n+        verify(queue, never()).nack(any());\n+        verify(queue, atLeastOnce()).publish(any());\n     }\n \n     @Test",
      "parent_sha": "42616b882e6bd97395106be90c20df83066ca144"
    }
  },
  {
    "oid": "caad53d6888de8cbbdc4e7d6974da1302bda2421",
    "message": "corrected JerseyRequestHandler initialization in ClientBase",
    "date": "2022-06-28T17:21:38Z",
    "url": "https://github.com/Netflix/conductor/commit/caad53d6888de8cbbdc4e7d6974da1302bda2421",
    "details": {
      "sha": "603697751b2aa240451afc9ad1da7fada782c2b3",
      "filename": "client/src/main/java/com/netflix/conductor/client/http/ClientBase.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/caad53d6888de8cbbdc4e7d6974da1302bda2421/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Fhttp%2FClientBase.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/caad53d6888de8cbbdc4e7d6974da1302bda2421/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Fhttp%2FClientBase.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/client%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fclient%2Fhttp%2FClientBase.java?ref=caad53d6888de8cbbdc4e7d6974da1302bda2421",
      "patch": "@@ -75,7 +75,9 @@ protected ClientBase(\n             objectMapper.registerModule(new JavaTimeModule());\n         }\n \n-        this.requestHandler = ObjectUtils.defaultIfNull(requestHandler, new JerseyRequestHandler());\n+        // we do not want to use defaultIfNull here since creation of JerseyRequestHandler requires\n+        // classes that may not be in the classpath\n+        this.requestHandler = requestHandler != null ? requestHandler : new JerseyRequestHandler();\n         this.conductorClientConfiguration =\n                 ObjectUtils.defaultIfNull(\n                         clientConfiguration, new DefaultConductorClientConfiguration());",
      "parent_sha": "83841ac065b98e845cf446a920b0c1c4a0c8d102"
    }
  },
  {
    "oid": "87671d7964417f3ccf7413d027dbb3ec9937ea43",
    "message": "Fixes compilation for ES6 configuration\n\nFixes #1147",
    "date": "2019-05-18T14:32:53Z",
    "url": "https://github.com/Netflix/conductor/commit/87671d7964417f3ccf7413d027dbb3ec9937ea43",
    "details": {
      "sha": "8fd5a06c10a628404b2ceeb0d38921ba7ce09dd7",
      "filename": "es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/87671d7964417f3ccf7413d027dbb3ec9937ea43/es6-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes6%2Findex%2FElasticSearchRestDAOV6.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/87671d7964417f3ccf7413d027dbb3ec9937ea43/es6-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes6%2Findex%2FElasticSearchRestDAOV6.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/es6-persistence%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fdao%2Fes6%2Findex%2FElasticSearchRestDAOV6.java?ref=87671d7964417f3ccf7413d027dbb3ec9937ea43",
      "patch": "@@ -141,7 +141,7 @@ public ElasticSearchRestDAOV6(RestClientBuilder restClientBuilder, ElasticSearch\n \n         this.objectMapper = objectMapper;\n         this.elasticSearchAdminClient = restClientBuilder.build();\n-        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder.build());\n+        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder);\n         this.clusterHealthColor = config.getClusterHealthColor();\n \n         this.indexPrefix = config.getIndexName();",
      "parent_sha": "a1443d013ee7cd90db813e6ba2ec342911fc2c01"
    }
  },
  {
    "oid": "9ff2f1911f6ff0fff16ae44b04abe6fc4b54d6e5",
    "message": "Fix bug in unique task reference name validation",
    "date": "2020-10-22T01:13:35Z",
    "url": "https://github.com/Netflix/conductor/commit/9ff2f1911f6ff0fff16ae44b04abe6fc4b54d6e5",
    "details": {
      "sha": "bb143d18c78c895d086d0f752ee4f711f12f137d",
      "filename": "common/src/main/java/com/netflix/conductor/common/constraints/TaskReferenceNameUniqueConstraint.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/9ff2f1911f6ff0fff16ae44b04abe6fc4b54d6e5/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fconstraints%2FTaskReferenceNameUniqueConstraint.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/9ff2f1911f6ff0fff16ae44b04abe6fc4b54d6e5/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fconstraints%2FTaskReferenceNameUniqueConstraint.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/common%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcommon%2Fconstraints%2FTaskReferenceNameUniqueConstraint.java?ref=9ff2f1911f6ff0fff16ae44b04abe6fc4b54d6e5",
      "patch": "@@ -64,7 +64,7 @@ public boolean isValid(WorkflowDef workflowDef, ConstraintValidatorContext conte\n \n             //check if taskReferenceNames are unique across tasks or not\n             HashMap<String, Integer> taskReferenceMap = new HashMap<>();\n-            for (WorkflowTask workflowTask : workflowDef.getTasks()) {\n+            for (WorkflowTask workflowTask : workflowDef.collectTasks()) {\n                 if (taskReferenceMap.containsKey(workflowTask.getTaskReferenceName())) {\n                     String message = String.format(\"taskReferenceName: %s should be unique across tasks for a given workflowDefinition: %s\",\n                             workflowTask.getTaskReferenceName(), workflowDef.getName());",
      "parent_sha": "ddafc5a85cee18428ec0b4c4e7c911b9cbff2975"
    }
  },
  {
    "oid": "4217fb043d81b62a2da71fb7a4186fad8e748c73",
    "message": "fix the check for argument length",
    "date": "2017-01-18T04:00:40Z",
    "url": "https://github.com/Netflix/conductor/commit/4217fb043d81b62a2da71fb7a4186fad8e748c73",
    "details": {
      "sha": "654876c7333494f53a48bfd8b8e78ed5d8f689e5",
      "filename": "server/src/main/java/com/netflix/conductor/server/Main.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/4217fb043d81b62a2da71fb7a4186fad8e748c73/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FMain.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/4217fb043d81b62a2da71fb7a4186fad8e748c73/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FMain.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fserver%2FMain.java?ref=4217fb043d81b62a2da71fb7a4186fad8e748c73",
      "patch": "@@ -32,7 +32,7 @@ public class Main {\n \t\n \tpublic static void main(String[] args) throws Exception {\n \t\t\n-\t\tif(args.length > 1) {\n+\t\tif(args.length > 0) {\n \t\t\tString propertyFile = args[0];\t\n \t\t\tSystem.out.println(\"Using \" + propertyFile);\n \t\t\tFileInputStream propFile = new FileInputStream(propertyFile);",
      "parent_sha": "cd57159e47b600600271de4de3927fd49bdfc808"
    }
  },
  {
    "oid": "5005a16eee51d4ed9d7d2ac47b3da93fe5b7c60a",
    "message": "Add unit test",
    "date": "2017-06-16T21:05:50Z",
    "url": "https://github.com/Netflix/conductor/commit/5005a16eee51d4ed9d7d2ac47b3da93fe5b7c60a",
    "details": {
      "sha": "a50d6228769212b8ffd274cc4126d58637647404",
      "filename": "contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java",
      "status": "modified",
      "additions": 43,
      "deletions": 4,
      "changes": 47,
      "blob_url": "https://github.com/Netflix/conductor/blob/5005a16eee51d4ed9d7d2ac47b3da93fe5b7c60a/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/5005a16eee51d4ed9d7d2ac47b3da93fe5b7c60a/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/contribs%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcontribs%2Fhttp%2FTestHttpTask.java?ref=5005a16eee51d4ed9d7d2ac47b3da93fe5b7c60a",
      "patch": "@@ -28,9 +28,11 @@\n import java.io.BufferedReader;\n import java.io.IOException;\n import java.io.PrintWriter;\n+import java.util.Arrays;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.Set;\n+import java.util.stream.Collectors;\n \n import javax.servlet.ServletException;\n import javax.servlet.http.HttpServletRequest;\n@@ -57,7 +59,6 @@\n import com.netflix.conductor.core.config.Configuration;\n import com.netflix.conductor.core.execution.DeciderService;\n import com.netflix.conductor.core.execution.WorkflowExecutor;\n-import com.netflix.conductor.dao.ExecutionDAO;\n import com.netflix.conductor.dao.MetadataDAO;\n \n /**\n@@ -289,6 +290,31 @@ public void testOptional() throws Exception {\n  \t\tSystem.out.println(workflow.getTasks());\n  \t\tSystem.out.println(workflow.getStatus());\n  \t}\n+\n+ \t@Test\n+\tpublic void testOAuth() throws Exception {\n+\t\tTask task = new Task();\n+\t\tInput input = new Input();\n+\t\tinput.setUri(\"http://localhost:7009/oauth\");\n+\t\tinput.setMethod(\"POST\");\n+\t\tinput.setOauthConsumerKey(\"someKey\");\n+\t\tinput.setOauthConsumerSecret(\"someSecret\");\n+\t\ttask.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);\n+\n+\t\thttpTask.start(workflow, task, executor);\n+\n+\t\tMap<String, Object> response = (Map<String, Object>) task.getOutputData().get(\"response\");\n+\t\tMap<String, String> body = (Map<String, String>) response.get(\"body\");\n+\n+\t\tassertEquals(\"someKey\", body.get(\"oauth_consumer_key\"));\n+\t\tassertTrue(\"Should have OAuth nonce\", body.containsKey(\"oauth_nonce\"));\n+\t\tassertTrue(\"Should have OAuth signature\", body.containsKey(\"oauth_signature\"));\n+\t\tassertTrue(\"Should have OAuth signature method\", body.containsKey(\"oauth_signature_method\"));\n+\t\tassertTrue(\"Should have OAuth oauth_timestamp\", body.containsKey(\"oauth_timestamp\"));\n+\t\tassertTrue(\"Should have OAuth oauth_version\", body.containsKey(\"oauth_version\"));\n+\t\t\n+\t\tassertEquals(\"Task output: \" + task.getOutputData(), Status.COMPLETED, task.getStatus());\n+\t}\n \t\n \tprivate static class EchoHandler extends AbstractHandler {\n \n@@ -317,7 +343,6 @@ public void handle(String target, Request baseRequest, HttpServletRequest reques\n \t\t\t\twriter.close();\n \t\t\t} else if(request.getMethod().equals(\"POST\") && request.getRequestURI().equals(\"/post\")) {\n \t\t\t\tresponse.addHeader(\"Content-Type\", \"application/json\");\n-\t\t\t\t\n \t\t\t\tBufferedReader reader = request.getReader();\n \t\t\t\tMap<String, Object> input = om.readValue(reader, mapOfObj);\n \t\t\t\tSet<String> keys = input.keySet();\n@@ -342,8 +367,22 @@ public void handle(String target, Request baseRequest, HttpServletRequest reques\n \t\t\t\twriter.print(NUM_RESPONSE);\n \t\t\t\twriter.flush();\n \t\t\t\twriter.close();\n-\t\t\t} \n+\t\t\t} else if(request.getMethod().equals(\"POST\") && request.getRequestURI().equals(\"/oauth\")) {\n+\t\t\t\t//echo back oauth parameters generated in the Authorization header in the response\n+\t\t\t\tMap<String, String> params = parseOauthParameters(request);\n+\t\t\t\tresponse.addHeader(\"Content-Type\", \"application/json\");\n+\t\t\t\tPrintWriter writer = response.getWriter();\n+\t\t\t\twriter.print(om.writeValueAsString(params));\n+\t\t\t\twriter.flush();\n+\t\t\t\twriter.close();\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate Map<String, String> parseOauthParameters(HttpServletRequest request) {\n+\t\t\tString paramString = request.getHeader(\"Authorization\").replaceAll(\"^OAuth (.*)\", \"$1\");\n+\t\t\treturn Arrays.stream(paramString.split(\"\\\\s*,\\\\s*\"))\n+\t\t\t\t.map(pair -> pair.split(\"=\"))\n+\t\t\t\t.collect(Collectors.toMap(o -> o[0], o -> o[1].replaceAll(\"\\\"\",\"\")));\n \t\t}\n-\t\t\n \t}\n }",
      "parent_sha": "10d3fed923f8bfe4b6e839e893ca495d0facc98f"
    }
  },
  {
    "oid": "14723e67f64fea32724f128373549a7b62b68a92",
    "message": "Fix tests for Workflow executor changes from locking service.",
    "date": "2019-11-13T18:33:52Z",
    "url": "https://github.com/Netflix/conductor/commit/14723e67f64fea32724f128373549a7b62b68a92",
    "details": {
      "sha": "ba4ae877fad68591dc37f378636268d97979f9be",
      "filename": "core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java",
      "status": "modified",
      "additions": 4,
      "deletions": 1,
      "changes": 5,
      "blob_url": "https://github.com/Netflix/conductor/blob/14723e67f64fea32724f128373549a7b62b68a92/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/14723e67f64fea32724f128373549a7b62b68a92/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Ftest%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FDoWhileTest.java?ref=14723e67f64fea32724f128373549a7b62b68a92",
      "patch": "@@ -33,6 +33,7 @@\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.Map;\n+import com.netflix.conductor.service.ExecutionLockService;\n import org.junit.Assert;\n import org.junit.Before;\n import org.junit.Test;\n@@ -60,6 +61,7 @@ public class DoWhileTest {\n     MetadataMapperService metadataMapperService;\n     WorkflowStatusListener workflowStatusListener ;\n     ExecutionDAOFacade executionDAOFacade;\n+    ExecutionLockService executionLockService;\n     Configuration config;\n     ParametersUtils parametersUtils;\n \n@@ -74,9 +76,10 @@ public void setup() {\n         metadataMapperService = Mockito.mock(MetadataMapperService.class);\n         workflowStatusListener = Mockito.mock(WorkflowStatusListener.class);\n         executionDAOFacade = Mockito.mock(ExecutionDAOFacade.class);\n+        executionLockService = Mockito.mock(ExecutionLockService.class);\n         config = Mockito.mock(Configuration.class);\n         provider = spy(new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService,\n-                workflowStatusListener, executionDAOFacade, config));\n+                workflowStatusListener, executionDAOFacade, externalPayloadStorageUtils, config, executionLockService));\n         loopWorkflowTask1 = new WorkflowTask();\n         loopWorkflowTask1.setTaskReferenceName(\"task1__1\");\n         loopWorkflowTask1.setName(\"task1__1\");",
      "parent_sha": "42c31584fc691f1c08f6e600d806892e16882101"
    }
  },
  {
    "oid": "7a19487a7a0f778e116f29fe5a93170d26ba9a0c",
    "message": "fix ordering of params in isolated task queue producer",
    "date": "2020-11-17T00:14:50Z",
    "url": "https://github.com/Netflix/conductor/commit/7a19487a7a0f778e116f29fe5a93170d26ba9a0c",
    "details": {
      "sha": "46dab7916a8091a8f1d456d324f8548a9505c9a1",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "blob_url": "https://github.com/Netflix/conductor/blob/7a19487a7a0f778e116f29fe5a93170d26ba9a0c/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FIsolatedTaskQueueProducer.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/7a19487a7a0f778e116f29fe5a93170d26ba9a0c/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FIsolatedTaskQueueProducer.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FIsolatedTaskQueueProducer.java?ref=7a19487a7a0f778e116f29fe5a93170d26ba9a0c",
      "patch": "@@ -79,7 +79,7 @@ void addTaskQueues() {\n \t\tfor (TaskDef isolatedTaskDef : isolationTaskDefs) {\n \t\t\tfor (String taskType : taskTypes) {\n \t\t\t\tString taskQueue = QueueUtils.getQueueName(taskType, null,\n-\t\t\t\t\tisolatedTaskDef.getExecutionNameSpace(), isolatedTaskDef.getIsolationGroupId());\n+\t\t\t\t\tisolatedTaskDef.getIsolationGroupId(), isolatedTaskDef.getExecutionNameSpace());\n \t\t\t\tlogger.debug(\"Adding taskQueue:'{}' to system task worker coordinator\", taskQueue);\n \t\t\t\tSystemTaskWorkerCoordinator.queue.add(taskQueue);\n \t\t\t}",
      "parent_sha": "6bce3912d3ce7a39ca4010b0537a7c37d0f27091"
    }
  },
  {
    "oid": "1841d07ddc9c75ed8adf17389157b3256396d107",
    "message": "Add more error handling and stack output on failure.",
    "date": "2018-09-03T15:18:20Z",
    "url": "https://github.com/Netflix/conductor/commit/1841d07ddc9c75ed8adf17389157b3256396d107",
    "details": {
      "sha": "ddd17f3089689d2024c4c756a80fa89defe54600",
      "filename": "server/src/main/java/com/netflix/conductor/bootstrap/Main.java",
      "status": "modified",
      "additions": 10,
      "deletions": 1,
      "changes": 11,
      "blob_url": "https://github.com/Netflix/conductor/blob/1841d07ddc9c75ed8adf17389157b3256396d107/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FMain.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/1841d07ddc9c75ed8adf17389157b3256396d107/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FMain.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FMain.java?ref=1841d07ddc9c75ed8adf17389157b3256396d107",
      "patch": "@@ -62,10 +62,17 @@ public static void main(String[] args) throws Exception {\n                  */\n                 Thread.sleep(EMBEDDED_ES_INIT_TIME);\n             } catch (Exception ioe) {\n+                ioe.printStackTrace(System.err);\n                 System.exit(3);\n             }\n         }\n-        serverInjector.getInstance(IndexDAO.class).setup();\n+\n+        try {\n+            serverInjector.getInstance(IndexDAO.class).setup();\n+        } catch (Exception e){\n+            e.printStackTrace(System.err);\n+            System.exit(3);\n+        }\n \n \n         System.out.println(\"\\n\\n\\n\");\n@@ -80,6 +87,7 @@ public static void main(String[] args) throws Exception {\n             try {\n                 server.start();\n             } catch (IOException ioe) {\n+                ioe.printStackTrace(System.err);\n                 System.exit(3);\n             }\n         });\n@@ -88,6 +96,7 @@ public static void main(String[] args) throws Exception {\n             try {\n                 server.start();\n             } catch (Exception ioe) {\n+                ioe.printStackTrace(System.err);\n                 System.exit(3);\n             }\n         });",
      "parent_sha": "cb5710e7b739951ef6bf78c0522b262f5ec09246"
    }
  },
  {
    "oid": "07ddb1a551dc5d3734bdd649df043bcbaef2ef68",
    "message": "updates to default thread count and poll count.  Make the polling interval configurable and default to 50ms",
    "date": "2017-06-23T18:30:31Z",
    "url": "https://github.com/Netflix/conductor/commit/07ddb1a551dc5d3734bdd649df043bcbaef2ef68",
    "details": {
      "sha": "a491a05f1c2020b22f10605797417f26a8a6bbe6",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java",
      "status": "modified",
      "additions": 8,
      "deletions": 3,
      "changes": 11,
      "blob_url": "https://github.com/Netflix/conductor/blob/07ddb1a551dc5d3734bdd649df043bcbaef2ef68/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/07ddb1a551dc5d3734bdd649df043bcbaef2ef68/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java?ref=07ddb1a551dc5d3734bdd649df043bcbaef2ef68",
      "patch": "@@ -59,8 +59,12 @@ public class SystemTaskWorkerCoordinator {\n \t\n \tprivate int workerQueueSize;\n \t\n+\t//Number of items to poll for\n \tprivate int pollCount;\n \t\n+\t//Interval in ms at which the polling is done\n+\tprivate int pollInterval;\n+\t\n \tprivate LinkedBlockingQueue<Runnable> workerQueue;\n \t\n \tprivate int unackTimeout;\n@@ -79,8 +83,9 @@ public SystemTaskWorkerCoordinator(QueueDAO taskQueues, WorkflowExecutor executo\n \t\tthis.executor = executor;\n \t\tthis.config = config;\n \t\tthis.unackTimeout = config.getIntProperty(\"workflow.system.task.worker.callback.seconds\", 30);\n-\t\tint threadCount = config.getIntProperty(\"workflow.system.task.worker.thread.count\", 5);\n-\t\tthis.pollCount = config.getIntProperty(\"workflow.system.task.worker.poll.count\", 5);\n+\t\tint threadCount = config.getIntProperty(\"workflow.system.task.worker.thread.count\", 10);\n+\t\tthis.pollCount = config.getIntProperty(\"workflow.system.task.worker.poll.count\", 10);\n+\t\tthis.pollInterval = config.getIntProperty(\"workflow.system.task.worker.poll.interval\", 50);\n \t\tthis.workerQueueSize = config.getIntProperty(\"workflow.system.task.worker.queue.size\", 100);\n \t\tthis.workerQueue = new LinkedBlockingQueue<Runnable>(workerQueueSize);\n \t\tif(threadCount > 0) {\n@@ -117,7 +122,7 @@ private void listen() {\n \t}\n \t\n \tprivate void listen(WorkflowSystemTask systemTask) {\n-\t\tExecutors.newScheduledThreadPool(1).scheduleWithFixedDelay(()->pollAndExecute(systemTask), 1000, 500, TimeUnit.MILLISECONDS);\n+\t\tExecutors.newScheduledThreadPool(1).scheduleWithFixedDelay(()->pollAndExecute(systemTask), 1000, pollInterval, TimeUnit.MILLISECONDS);\n \t\tlogger.info(\"Started listening {}\", systemTask.getName());\n \t}\n ",
      "parent_sha": "55a07706c0b3aeb6fd2748299c690f686fab3d36"
    }
  },
  {
    "oid": "ed886ff3c98cdfce553eda1715127e2c34c6fa92",
    "message": "grpc-server: Report search results",
    "date": "2018-06-08T14:34:59Z",
    "url": "https://github.com/Netflix/conductor/commit/ed886ff3c98cdfce553eda1715127e2c34c6fa92",
    "details": {
      "sha": "807d4ba7d8078dfd3adb8b999a8b19474e8e0a14",
      "filename": "grpc-server/src/main/java/com/netflix/conductor/grpc/server/WorkflowServiceImpl.java",
      "status": "modified",
      "additions": 10,
      "deletions": 5,
      "changes": 15,
      "blob_url": "https://github.com/Netflix/conductor/blob/ed886ff3c98cdfce553eda1715127e2c34c6fa92/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FWorkflowServiceImpl.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/ed886ff3c98cdfce553eda1715127e2c34c6fa92/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FWorkflowServiceImpl.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/grpc-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fgrpc%2Fserver%2FWorkflowServiceImpl.java?ref=ed886ff3c98cdfce553eda1715127e2c34c6fa92",
      "patch": "@@ -250,15 +250,20 @@ private void doSearch(boolean searchByTask, SearchPb.SearchRequest req, StreamOb\n             return;\n         }\n \n-        SearchResult<WorkflowSummary> searchResult;\n+        SearchResult<WorkflowSummary> search;\n         if (searchByTask) {\n-            searchResult = service.searchWorkflowByTasks(query, freeText, start, size, sort);\n+            search = service.searchWorkflowByTasks(query, freeText, start, size, sort);\n         } else {\n-            searchResult = service.search(query, freeText, start, size, sort);\n+            search = service.search(query, freeText, start, size, sort);\n         }\n \n-        // TODO\n-        // response.onNext(ProtoMapper.toProto(searchResult));\n+        response.onNext(\n+            SearchPb.WorkflowSummarySearchResult.newBuilder()\n+                .setTotalHits(search.getTotalHits())\n+                .addAllResults(\n+                    search.getResults().stream().map(ProtoMapper::toProto)::iterator\n+                ).build()\n+        );\n         response.onCompleted();\n     }\n ",
      "parent_sha": "6cd5a314b8f0efbe70abe7a11c641d81d6873133"
    }
  },
  {
    "oid": "5f24d794c19e8e346507e961a077032e124b8e38",
    "message": "Update ModulesProvider.java\n\nfix import",
    "date": "2019-02-14T06:55:49Z",
    "url": "https://github.com/Netflix/conductor/commit/5f24d794c19e8e346507e961a077032e124b8e38",
    "details": {
      "sha": "1c5ae6adbb9e832fa8bccc1382648801744ee259",
      "filename": "server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "blob_url": "https://github.com/Netflix/conductor/blob/5f24d794c19e8e346507e961a077032e124b8e38/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FModulesProvider.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/5f24d794c19e8e346507e961a077032e124b8e38/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FModulesProvider.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fbootstrap%2FModulesProvider.java?ref=5f24d794c19e8e346507e961a077032e124b8e38",
      "patch": "@@ -7,7 +7,7 @@\n import com.netflix.conductor.contribs.http.HttpTask;\n import com.netflix.conductor.contribs.http.RestClientManager;\n import com.netflix.conductor.contribs.json.JsonJqTransform;\n-import com.netflix.conductor.contribs.lambda.ScriptTask;\n+import com.netflix.conductor.contribs.lambda.Lambda;\n import com.netflix.conductor.core.config.Configuration;\n import com.netflix.conductor.core.execution.WorkflowExecutorModule;\n import com.netflix.conductor.core.utils.DummyPayloadStorage;\n@@ -136,7 +136,7 @@ protected void configure() {\n \n         new HttpTask(new RestClientManager(), configuration);\n         new JsonJqTransform();\n-        new ScriptTask();\n+        new Lambda();\n         modules.add(new ServerModule());\n \n         return modules;",
      "parent_sha": "b57eed8ec470091bce73ee21749f25a753efb092"
    }
  },
  {
    "oid": "2285531925bd8666685e1bd3a52db050bcc0497d",
    "message": "Fix disappearing outputs from long running tasks\n\nwith external storage enabled\n\nIn case of a:\n1. Long running task\n2. With big output (externalized)\n3. With output growing over time\n4. Causing multiple externalize / internalize executions\n5. ... such as a join task collecting outputs of all forked tasks\n6. Lost some of its outputs when finally completed\n\nThis issue was caused by / because:\n1. On an Nth execution of a task (such as described above)\n2. The task internalized its intermediate output from external storage\n3. The task was executed and it updated its output to current value in memory\n4. The task tried to externalize the new version of its output\n5. ... but while doing so, the outputPayload (last externalized value)\n   was combined with outputData (current, in-memory value) in a way\n   where output payload over-wrote the latest values\n6. Thus, newly calculated outputs have been lost\n\nSigned-off-by: Maros Marsalek <mmarsalek@frinx.io>",
    "date": "2023-04-11T08:56:11Z",
    "url": "https://github.com/Netflix/conductor/commit/2285531925bd8666685e1bd3a52db050bcc0497d",
    "details": {
      "sha": "617b013da9dc34e153f10e778809ad9442f00142",
      "filename": "core/src/main/java/com/netflix/conductor/model/TaskModel.java",
      "status": "modified",
      "additions": 6,
      "deletions": 1,
      "changes": 7,
      "blob_url": "https://github.com/Netflix/conductor/blob/2285531925bd8666685e1bd3a52db050bcc0497d/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmodel%2FTaskModel.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/2285531925bd8666685e1bd3a52db050bcc0497d/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmodel%2FTaskModel.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fmodel%2FTaskModel.java?ref=2285531925bd8666685e1bd3a52db050bcc0497d",
      "patch": "@@ -398,7 +398,12 @@ public void setWorkerId(String workerId) {\n     @JsonIgnore\n     public Map<String, Object> getOutputData() {\n         if (!outputPayload.isEmpty() && !outputData.isEmpty()) {\n-            outputData.putAll(outputPayload);\n+            // Combine payload + data\n+            // data has precedence over payload because:\n+            //  with external storage enabled, payload contains the old values\n+            //  while data contains the latest and if payload took precedence, it\n+            //  would remove latest outputs\n+            outputPayload.forEach(outputData::putIfAbsent);\n             outputPayload = new HashMap<>();\n             return outputData;\n         } else if (outputPayload.isEmpty()) {",
      "parent_sha": "92ad5303e8b7283b260f66d059589662c66e9d3e"
    }
  },
  {
    "oid": "797cb733d48f80c6ea86228d4a0433da233a98ca",
    "message": "review comments.",
    "date": "2019-06-03T07:33:51Z",
    "url": "https://github.com/Netflix/conductor/commit/797cb733d48f80c6ea86228d4a0433da233a98ca",
    "details": {
      "sha": "e1fc543b4890f32a252ae87c757584f23c220bf0",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/SystemTaskType.java",
      "status": "modified",
      "additions": 6,
      "deletions": 1,
      "changes": 7,
      "blob_url": "https://github.com/Netflix/conductor/blob/797cb733d48f80c6ea86228d4a0433da233a98ca/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FSystemTaskType.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/797cb733d48f80c6ea86228d4a0433da233a98ca/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FSystemTaskType.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2FSystemTaskType.java?ref=797cb733d48f80c6ea86228d4a0433da233a98ca",
      "patch": "@@ -21,7 +21,12 @@\n import java.util.HashSet;\n import java.util.Set;\n \n-import com.netflix.conductor.core.execution.tasks.*;\n+import com.netflix.conductor.core.execution.tasks.Decision;\n+import com.netflix.conductor.core.execution.tasks.Fork;\n+import com.netflix.conductor.core.execution.tasks.Join;\n+import com.netflix.conductor.core.execution.tasks.ExclusiveJoin;\n+import com.netflix.conductor.core.execution.tasks.DoWhile;\n+import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;\n \n /**\n  * Defines a system task type",
      "parent_sha": "2b03f8c2606e4807af8b0a8d8f31fdf667ad405e"
    }
  },
  {
    "oid": "81db5cf60f6c4770fc88aebec6f90e7fffe2b469",
    "message": "Remove magic numbers and add parameters in DynoObservableQueue.java",
    "date": "2018-01-10T01:14:28Z",
    "url": "https://github.com/Netflix/conductor/commit/81db5cf60f6c4770fc88aebec6f90e7fffe2b469",
    "details": {
      "sha": "80e25455f1e62b6a56aa64d447017a80feac5b5c",
      "filename": "core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoObservableQueue.java",
      "status": "modified",
      "additions": 27,
      "deletions": 37,
      "changes": 64,
      "blob_url": "https://github.com/Netflix/conductor/blob/81db5cf60f6c4770fc88aebec6f90e7fffe2b469/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/81db5cf60f6c4770fc88aebec6f90e7fffe2b469/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fevents%2Fqueue%2Fdyno%2FDynoObservableQueue.java?ref=81db5cf60f6c4770fc88aebec6f90e7fffe2b469",
      "patch": "@@ -14,26 +14,24 @@\n  * limitations under the License.\n  */\n /**\n- * \n+ *\n  */\n package com.netflix.conductor.core.events.queue.dyno;\n \n-import java.util.List;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import javax.inject.Inject;\n-import javax.inject.Singleton;\n-\n import com.google.common.annotations.VisibleForTesting;\n import com.netflix.conductor.core.config.Configuration;\n import com.netflix.conductor.core.events.queue.Message;\n import com.netflix.conductor.core.events.queue.ObservableQueue;\n import com.netflix.conductor.dao.QueueDAO;\n-\n import rx.Observable;\n import rx.Observable.OnSubscribe;\n-import rx.Subscriber;\n+\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n \n /**\n  * @author Viren\n@@ -42,19 +40,25 @@\n @Singleton\n public class DynoObservableQueue implements ObservableQueue {\n \n-\tpublic static final String TYPE = \"conductor\";\n+\tprivate static final String TYPE = \"conductor\";\n \t\n \tprivate String queueName;\n \t\n \tprivate QueueDAO queueDAO;\n \t\n \tprivate int pollTimeInMS;\n+\n+\tprivate int longPollTimeout;\n+\n+\tprivate int pollCount;\n \t\n \t@Inject\n-\tpublic DynoObservableQueue(String queueName, QueueDAO queueDAO, Configuration config) {\n+\tDynoObservableQueue(String queueName, QueueDAO queueDAO, Configuration config) {\n \t\tthis.queueName = queueName;\n \t\tthis.queueDAO = queueDAO;\n \t\tthis.pollTimeInMS = config.getIntProperty(\"workflow.dyno.queues.pollingInterval\", 100);\n+\t\tthis.pollCount = config.getIntProperty(\"workflow.dyno.queues.pollCount\", 10);\n+\t\tthis.longPollTimeout = config.getIntProperty(\"workflow.dyno.queues.longPollTimeout\", 1000);\n \t}\n \t\n \t@Override\n@@ -99,34 +103,20 @@ public String getName() {\n \tpublic String getURI() {\n \t\treturn queueName;\n \t}\n-\t\n-\t\n-\t\n+\n \t@VisibleForTesting\n-\tList<Message> receiveMessages() {\n-\t\tList<Message> messages = queueDAO.pollMessages(queueName, 10, 1000);\n-\t\treturn messages;\n+\tprivate List<Message> receiveMessages() {\n+\t\treturn queueDAO.pollMessages(queueName, pollCount, longPollTimeout);\n     }\n \t\n \t@VisibleForTesting\n-\tOnSubscribe<Message> getOnSubscribe() {\n-\t\tOnSubscribe<Message> subscriber = new Observable.OnSubscribe<Message>() {\n-\t\t\t@Override\n-\t\t\tpublic void call(Subscriber<? super Message> subscriber) {\n-\t\t\t\tObservable<Long> interval = Observable.interval(pollTimeInMS, TimeUnit.MILLISECONDS);\t\t\n-\t\t\t\tinterval.flatMap((Long x)->{\n-\t\t\t\t\tList<Message> msgs = receiveMessages();\n-\t\t            return Observable.from(msgs);\n-\t\t\t\t}).subscribe((Message msg)->{\n-\t\t\t\t\tsubscriber.onNext(msg);\n-\t\t\t\t}, (Throwable exception)->{\n-\t\t\t\t\tsubscriber.onError(exception);\n-\t\t\t\t});\n-\t\t\t}\n-\t\t};\n-\t\treturn subscriber;\n+\tprivate OnSubscribe<Message> getOnSubscribe() {\n+\t\treturn subscriber -> {\n+            Observable<Long> interval = Observable.interval(pollTimeInMS, TimeUnit.MILLISECONDS);\n+            interval.flatMap((Long x) -> {\n+                List<Message> msgs = receiveMessages();\n+                return Observable.from(msgs);\n+            }).subscribe(subscriber::onNext, subscriber::onError);\n+        };\n \t}\n-\t\n-\t\n-\t\n }",
      "parent_sha": "8bbded8d240e32d621e007364bba672d701c51f4"
    }
  },
  {
    "oid": "63197c9b188be498f62f3bb31aea04f1fd1e2b93",
    "message": "add a generic counter for the poller",
    "date": "2017-09-16T18:40:47Z",
    "url": "https://github.com/Netflix/conductor/commit/63197c9b188be498f62f3bb31aea04f1fd1e2b93",
    "details": {
      "sha": "827d7efa0b17ef97aa011b4afc8592c25bf3a2e1",
      "filename": "core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "blob_url": "https://github.com/Netflix/conductor/blob/63197c9b188be498f62f3bb31aea04f1fd1e2b93/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java",
      "raw_url": "https://github.com/Netflix/conductor/raw/63197c9b188be498f62f3bb31aea04f1fd1e2b93/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java",
      "contents_url": "https://api.github.com/repos/Netflix/conductor/contents/core%2Fsrc%2Fmain%2Fjava%2Fcom%2Fnetflix%2Fconductor%2Fcore%2Fexecution%2Ftasks%2FSystemTaskWorkerCoordinator.java?ref=63197c9b188be498f62f3bb31aea04f1fd1e2b93",
      "patch": "@@ -136,14 +136,15 @@ private void pollAndExecute(WorkflowSystemTask systemTask) {\n \n \t\t\t// get the remaining capacity of worker queue to prevent queue full exception\n \t\t\tint realPollCount = Math.min(workerQueue.remainingCapacity(), pollCount);\n-\t\t\tif (realPollCount <= 0) {\n+\t\t\tif (realPollCount <= 0) {\t\t\t\t\n                 logger.warn(\"All workers are busy, not polling.  queue size {}, max {}\", workerQueue.size(), workerQueueSize);\n                 return;\n \t\t\t}\n \n \t\t\tString name = systemTask.getName();\n \t\t\tList<String> polled = taskQueues.pop(name, realPollCount, 200);\n \t\t\tMonitors.recordTaskPoll(name);\n+\t\t\tMonitors.recordTaskPoll(className);\n \t\t\tlogger.debug(\"Polling for {}, got {}\", name, polled.size());\n \t\t\tfor(String task : polled) {\n \t\t\t\ttry {",
      "parent_sha": "01488d76e319bf76d5513550cd93baf2926944ac"
    }
  }
]